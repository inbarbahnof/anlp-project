[
  {
    "input": "Problem:\n\nI have a sparse matrix representing the features of a set of textual documents, where each row corresponds to a document and each column corresponds to a unique word. The entries of the matrix are counts of how many times each word appears in each document. Additionally, I have a list of word indices that I want to extract from the matrix into a new dense matrix. \n\nGiven the sparse matrix `X` (in the form of a COO format) and a list of word indices `word_indices`, how can I create a dense matrix `D` that retains only the columns indicated by `word_indices`? The shape of `D` should be `(num_documents, len(word_indices))`.\n\nFor instance, if `X` is defined as:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\n```\n\nAnd the `word_indices` is `[0, 2]`, the desired output for `D` should look like this:\n\n```\n[[0 3]\n [2 0]]\n```\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Given sparse matrix X\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\nword_indices = [0, 2]  # List of indices to extract\n\n# Convert X to a dense format and extract necessary columns\nD = ... # put solution in this variable\n### BEGIN SOLUTION\n```",
    "output": "\n<code>\nD = X[:, word_indices].toarray()\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user-item interactions in a recommendation system, where a user has interacted with a limited number of items. Given the following components:\n\n1. A sparse matrix `user_item` of shape (1000, 5000) representing interactions, where rows correspond to users and columns to items.\n2. A list `user_ids` containing the indices of users whose interactions you want to extract.\n\nYou need to create a new sparse matrix `selected_users` that contains only the interactions of the specified users.\n\nThe `user_item` matrix is defined as follows:\n\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]  # example user indices\n```\n\nHow can you fill the variable `selected_users` to contain only the rows of `user_item` corresponding to the users in `user_ids`?\n\nA:\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]\n```\nselected_users = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_users = user_item[user_ids, :]\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data with the following structure:\n\n| order_id | customer_id | amount | date       |\n|----------|-------------|--------|------------|\n| 1        | A           | 100    | 2023-01-01 |\n| 2        | B           | 150    | 2023-01-02 |\n| 3        | A           | 50     | 2023-01-03 |\n| 4        | C           | 200    | 2023-01-01 |\n| 5        | B           | 80     | 2023-01-03 |\n\nI want to calculate the total amount spent by each customer and return a new DataFrame with `customer_id` and `total_spent`. \n\nBased on the given example, the expected output would be:\n\n| customer_id | total_spent |\n|-------------|-------------|\n| A           | 150         |\n| B           | 230         |\n| C           | 200         |\n\nWhat I tried:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'order_id': [1, 2, 3, 4, 5],\n    'customer_id': ['A', 'B', 'A', 'C', 'B'],\n    'amount': [100, 150, 50, 200, 80],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03'])\n})\n\nresult = ...  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('customer_id', as_index=False)['amount'].sum().rename(columns={'amount': 'total_spent'})\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of email addresses, and I need to extract the usernames (the part before the '@') and create a new column for them. Here's the DataFrame I have:\n\n```\n      Email\n0  john.doe@example.com\n1  jane.smith@website.org\n2  test.user123@gmail.com\n3  sample@domain.com\n```\n\nI want to create a new column called 'Username' that contains just the usernames extracted from the 'Email' column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Email': ['john.doe@example.com', 'jane.smith@website.org', 'test.user123@gmail.com', 'sample@domain.com']})\n</code>\ndf['Username'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Username'] = df['Email'].str.split('@').str[0]"
  },
  {
    "input": "## Problem:\nYou have a time series data containing daily stock prices for multiple companies in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': pd.date_range(start='2020-01-01', periods=10),\n        'CompanyA': [100, 102, 101, 103, 105, 107, 106, 108, 110, 111],\n        'CompanyB': [200, 198, 202, 201, 203, 205, 206, 204, 207, 203],\n        'CompanyC': [300, 303, 301, 299, 298, 300, 302, 303, 305, 306]}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nYour task is to calculate the daily percentage change of each company's stock prices relative to their previous day's closing prices. You want to save this as a new DataFrame. \n\nProvide the code to achieve this, filling in the blank below:\n\n```python\nresult = df.______\n```\n",
    "output": "\n```python\nresult = df.pct_change() * 100\n```"
  },
  {
    "input": "Problem:\n\nYou have a sparse tensor representing a 3D object, where each slice along the first dimension is a sparse matrix containing the properties of that object. Given the sparse tensor, you want to retrieve a specific property from a particular slice efficiently without converting the entire tensor to a dense format. Each slice is stored in COO format, and you need to access the value at a specified coordinate (slice_index, row, column).\n\nHow can you do this in a concise way while leveraging the sparse tensor's structure?\n\nA: \n<code>\nimport torch\n\n# Example Sparse Tensor in COO format\nvalues = torch.tensor([1, 2, 3])\nindices = torch.tensor([[0, 1, 2], [0, 1, 2]])  # (slice_index, row_index)\nshape = (3, 3, 3)  # 3 slices of 3x3\n\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size=shape)\nslice_index = 1\nrow_index = 1\ncolumn_index = 2\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = sparse_tensor.indices()[0][(sparse_tensor.indices()[0] == slice_index) & (sparse_tensor.indices()[1] == row_index) & (sparse_tensor.indices()[2] == column_index)].tolist()"
  },
  {
    "input": "Problem:\n\nI am working on a machine learning project that involves handling a sparse tensor. The input tensor has a shape of (5, 4, 0) due to the third dimension being sparse. I want to efficiently store the non-zero entries of this tensor using coordinate format (COO) and perform a simple operation on its non-zero elements.\n\nGiven the non-zero elements and their respective indices in the input tensor:\n- Non-zero values: [10, 20, 30, 40]\n- Row indices: [0, 1, 1, 2]\n- Column indices: [0, 1, 3, 2]\n\nHow can I create a sparse tensor and then increment all non-zero elements by 5 and convert it back to a dense form?\n\nTo illustrate, the sparse tensor filled with the above values should look like this in dense form after the increment:\n\n[[15, 0, 0, 0],\n [0, 25, 0, 45],\n [0, 0, 0, 0],\n [0, 0, 0, 0],\n [0, 0, 0, 0]]\n\nHere is the initialization for the non-zero elements:\n\n```python\nimport numpy as np\nimport scipy.sparse as sp\n\nnon_zero_values = np.array([10, 20, 30, 40])\nrow_indices = np.array([0, 1, 1, 2])\ncolumn_indices = np.array([0, 1, 3, 2])\n```\n\nYou need to fill in the code segment to create the sparse tensor and perform the operation.\n\nA:\n<code>\n# Fill in the solution here\nsparse_tensor = sp.coo_matrix((non_zero_values, (row_indices, column_indices)), shape=(5, 4))\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = sparse_tensor.toarray() + 5\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains sentences with various punctuation marks. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n```\n\nYour goal is to create a new column in the DataFrame that contains the number of punctuation marks found in each sentence. The final DataFrame should look like this:\n\n```\n                     sentences      punctuation_count\n0                  Hello, world!                     1\n1         Python is great; isn't it?                  3\n2          Let's code: Python is fun!                  3\n3      Data science; is changing the world.          4\n```\n\nTo accomplish this, I've started with the following approach using a lambda function to count the punctuation:\n\n```python\nimport string\ndf['punctuation_count'] = df['sentences'].apply(lambda x: ...)\n```\n\nPlease fill in the blank where the lambda function processes the `x` variable to return the count of punctuation marks. \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n</code>\ndf['punctuation_count'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndf['punctuation_count'] = df['sentences'].apply(lambda x: sum(1 for char in x if char in string.punctuation))\n```"
  },
  {
    "input": "Problem:\nI'm working with a sparse matrix representing user-item interactions in a recommendation system. The sparse matrix is defined using coordinate format (COO), and I need to construct a dense tensor that can be used for further calculations. Given three lists: `row_indices`, `col_indices`, and `data` which represent the non-zero entries of the sparse tensor, how can I create a 2D tensor of shape `(num_users, num_items)`? Here\u2019s how the inputs look:\n\n```python\nrow_indices = [0, 1, 2, 0, 1]\ncol_indices = [0, 1, 2, 2, 0]\ndata = [1, 2, 3, 4, 5]\n```\n\nThe expected output tensor should have zeros in the places without direct user-item interactions. Assuming `num_users` is 3 and `num_items` is 3, the resulting tensor should look like this:\n\n```\n[[1 0 4]\n [5 2 0]\n [0 0 3]]\n```\n\nA:\n<code>\nimport tensorflow as tf\n\nrow_indices = [0, 1, 2, 0, 1]\ncol_indices = [0, 1, 2, 2, 0]\ndata = [1, 2, 3, 4, 5]\nnum_users = 3\nnum_items = 3\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = tf.zeros((num_users, num_items), dtype=tf.int32)\nresult = tf.tensor_scatter_nd_update(result, tf.stack((row_indices, col_indices), axis=1), data)\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({'text': ['Value: 100 units', 'Count is 250 items', 'Total is 50', 'Not a number', 'Amount: 85']})\n\n# There are mixed strings in the 'text' column, and I want to extract only the numeric values (if they exist) in a new column called 'amount'.\n# If no numeric value is found, 'amount' should be NaN.\n\ndf['amount'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['amount'] = df['text'].str.extract('(\\d+)').astype(float)\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing hourly temperature readings from multiple sensors over several days. The DataFrame is structured as follows:\n\n```\nSensor_ID   Timestamp                Temperature\nA           2023-10-01 00:00:00     20.1\nA           2023-10-01 01:00:00     19.8\nA           2023-10-01 02:00:00     20.2\nB           2023-10-01 00:00:00     21.5\nB           2023-10-01 01:00:00     21.6\nB           2023-10-01 02:00:00     21.2\nA           2023-10-02 00:00:00     18.7\nA           2023-10-02 01:00:00     19.0\nB           2023-10-02 00:00:00     20.0\n```\n\nYou want to resample the data to a daily frequency, calculating the mean temperature for each sensor per day. However, you also need to ensure that the date-time index is properly converted. You started with the following imports and DataFrame creation:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Sensor_ID': ['A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'B'],\n    'Timestamp': ['2023-10-01 00:00:00', '2023-10-01 01:00:00', '2023-10-01 02:00:00',\n                  '2023-10-01 00:00:00', '2023-10-01 01:00:00', '2023-10-01 02:00:00',\n                  '2023-10-02 00:00:00', '2023-10-02 01:00:00', '2023-10-02 00:00:00'],\n    'Temperature': [20.1, 19.8, 20.2, 21.5, 21.6, 21.2, 18.7, 19.0, 20.0]\n}\ndf = pd.DataFrame(data)\n```\n\nFollowing this, you want to fill in the missing section of code to achieve your goal. Your current attempt is:\n```python\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\ndf.set_index('Timestamp', inplace=True)\nresult = df.groupby('Sensor_ID').resample('D').mean()\n```\n\nFill in the blank to produce the result variable correctly:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('Sensor_ID').resample('D').mean().reset_index()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing features in a tensor format and I want to normalize these features using TensorFlow. The tensor `data` has a shape of (100, 10) representing 100 samples and 10 features. I want to scale these features to a range of [0, 1]. How can I efficiently perform this normalization operation?\n\nA:\n\n<code>\nimport tensorflow as tf\n\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = (data - tf.reduce_min(data, axis=0)) / (tf.reduce_max(data, axis=0) - tf.reduce_min(data, axis=0))</code>"
  },
  {
    "input": "```python\nimport pandas as pd\n\n# Create a DataFrame with a date range of stock prices\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2020-01-01', periods=100, freq='D'),\n    'Price': (100 + pd.Series(range(100)).cumsum() + (np.random.randn(100) * 5))\n})\n\n# I want to resample this DataFrame to get the monthly average price. \n# Fill in the blank to get the resampled DataFrame as `monthly_avg`.\n\nmonthly_avg = df.set_index('Date').resample('M').mean()\n\n# The idea is to be able to see the average stock price at the end of each month.\n```",
    "output": "\n```python\nimport numpy as np\n\nmonthly_avg = df.set_index('Date').resample('M').mean()\n```"
  },
  {
    "input": "Problem:\n\nI'm working on a sentiment analysis project using TensorFlow and I have a tensor containing the embeddings of sentences. The shape of my tensor is (50, 300), representing 50 sentences each with 300 features. I want to create a simple feedforward model with TensorFlow that predicts sentiment scores between 0 and 1. I am looking for the appropriate layer to use in TensorFlow to achieve this output shape of (50, 1) after applying a dense layer to my input tensor. \n\nWhat should I use to create this single output layer?\n\nA:\n<code>\nimport tensorflow as tf\n\ninput_tensor = tf.random.uniform((50, 300))\nmodel = tf.keras.Sequential()\n# Add an appropriate layer below to predict sentiment scores\n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains email addresses in a column named 'emails', but some of those emails are malformed. I want to clean up this column by ensuring all emails have a standard format: they should be lowercase, and any leading or trailing spaces should be removed. Additionally, any emails with invalid formats should be replaced with NaN. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({\n    'emails': ['Example@Domain.com', 'hello@world.com ', ' user@domain ', 'invalid-email', 'GOOD@EXAMPLE.COM ']\n})\n```\n\nOnce the transformation is complete, I need to output the cleaned DataFrame.\n\nPlease provide the code that will achieve this cleanup and fill in the blank:\n\n```python\nemail_df['emails'] = _____\n```",
    "output": "\n```python\nemail_df['emails'] = email_df['emails'].str.strip().str.lower().where(email_df['emails'].str.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'), pd.NA)\n```"
  },
  {
    "input": "## Problem\nI have a DataFrame containing sales data over several months for a product with daily sales figures. The DataFrame looks like this:\n\n```\n        Date         Sales\n0 2019-01-01           100\n1 2019-01-02           150\n2 2019-01-03           120\n3 2019-01-04           130\n4 2019-01-05           200\n5 2019-02-01           170\n6 2019-02-02           160\n7 2019-02-03           180\n8 2019-02-04           190\n9 2019-02-05           220\n```\n\nI want to resample this DataFrame to get the total sales for each month, but I need to maintain the original date format. I have started by converting the `Date` column to datetime format:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Date': ['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', \n             '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05'],\n    'Sales': [100, 150, 120, 130, 200, 170, 160, 180, 190, 220]\n})\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, what is the code I should use to resample the DataFrame to monthly sales totals while keeping the date format as the first date of the month?\n\n```python\nmonthly_sales = ... # put solution in this variable\n```",
    "output": "\n```python\nmonthly_sales = df.resample('M', on='Date').sum().reset_index()\nmonthly_sales['Date'] = monthly_sales['Date'].dt.to_period('M').dt.to_timestamp()\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for various products over several months:\n\n| product_id | month      | sales |\n|------------|------------|-------|\n| 1          | 2023-01   | 100   |\n| 1          | 2023-02   | 150   |\n| 1          | 2023-03   | 120   |\n| 2          | 2023-01   | 200   |\n| 2          | 2023-03   | 250   |\n| 3          | 2023-02   | 300   |\n| 3          | 2023-03   | 200   |\n\nI want to create a custom function that takes this DataFrame and generates a new DataFrame that shows the average monthly sales for each product. The resulting DataFrame should look like this:\n\n| product_id | average_sales |\n|------------|---------------|\n| 1          | 123.33        |\n| 2          | 225.00        |\n| 3          | 250.00        |\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 1, 2, 2, 3, 3],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-03', '2023-02', '2023-03'],\n    'sales': [100, 150, 120, 200, 250, 300, 200]\n}\ndf = pd.DataFrame(data)\n\ndef calculate_average_sales(df):\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    average_sales = df.groupby('product_id')['sales'].mean().reset_index()\n    average_sales.columns = ['product_id', 'average_sales']\n    return average_sales\n\nresult = calculate_average_sales(df)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe containing email addresses and I want to extract the username (the part before the '@') and the domain (the part after the '@') from the email addresses. The email addresses are in a column called 'email'. I also want to create a separate column that contains the length of the username. Here\u2019s a sample of my data:\n\n```\n   email\n0  john.doe@example.com\n1  jane_smith@company.org\n2  user123@domain.net\n3  test.user@web-service.com\n```\n\nI want to achieve the following structure:\n\n```\n   email                     username     domain           username_length\n0  john.doe@example.com     john.doe     example.com     8\n1  jane_smith@company.org   jane_smith   company.org     10\n2  user123@domain.net       user123      domain.net      7\n3  test.user@web-service.com test.user    web-service.com 9\n```\n\nHere\u2019s what I have tried so far:\n\n```python\ndf['username'] = df.email.replace(r'(.+)@.+', r'\\1', regex=True)\ndf['domain'] = df.email.replace(r'.+@(.+)', r'\\1', regex=True)\ndf['username_length'] = df.username.map(len)\n```\n\nBut it seems this approach does not work as expected. Can you provide the correct solution for the variables? \n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'email': ['john.doe@example.com', 'jane_smith@company.org', 'user123@domain.net', 'test.user@web-service.com']\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['username'] = df['email'].str.split('@').str[0]\ndf['domain'] = df['email'].str.split('@').str[1]\ndf['username_length'] = df['username'].str.len()\nresult = df\n```"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains daily stock prices for a company over a year. It looks something like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2022-01-01', end='2022-12-31'),\n    'Close': [100 + i * 0.5 for i in range(365)]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to calculate the 30-day rolling mean of the 'Close' prices, and you want to add this as a new column called '30_day_avg' in the same DataFrame. However, you want this new column to have NaN values for the first 29 days where the rolling mean cannot be calculated.\n\nWhat is the code to create the '30_day_avg' column in the DataFrame?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['30_day_avg'] = df['Close'].rolling(window=30).mean()\n```"
  },
  {
    "input": "Problem:\nYou are working with TensorFlow 2.10.0 and PyTorch 1.10.0. You have a dataset of images represented as a tensor in PyTorch, and you want to compute and display statistics about pixel intensity values across the dataset. The pixels are represented in a 4D tensor of shape (batch_size, height, width, channels), where you want to calculate the mean pixel intensity for each channel separately.\n\nGiven a PyTorch tensor named 'image_tensor' with shape (8, 64, 64, 3) representing 8 images of size 64x64 with 3 color channels, you need to calculate the means and convert the result into a TensorFlow tensor.\n\nHow can you compute the mean pixel intensity for each channel and convert it into a TensorFlow tensor? \n\nA:\n<code>\nimport torch\nimport tensorflow as tf\n\nimage_tensor = torch.rand((8, 64, 64, 3))\n</code>\nmean_intensity_tf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmean_intensity = image_tensor.mean(dim=(0, 1, 2))\nmean_intensity_tf = tf.convert_to_tensor(mean_intensity.numpy())</code>"
  },
  {
    "input": "Problem:\nI have the following dataframe containing product descriptions and prices:\n  description           price\n0 \"apple pie\"         4.50\n1 \"banana bread\"      5.00\n2 \"cherry tart\"       6.25\n3 \"date square\"       3.75\n\nI need to extract the dessert type (the part before the space) from each description and create a new column that lists all unique dessert types in a single string, separated by commas. The desired output should look like this:\n\n  description           price       dessert_types\n0 \"apple pie\"         4.50         apple, banana, cherry, date\n1 \"banana bread\"      5.00         apple, banana, cherry, date\n2 \"cherry tart\"       6.25         apple, banana, cherry, date\n3 \"date square\"       3.75         apple, banana, cherry, date\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'description': [\"apple pie\", \"banana bread\", \"cherry tart\", \"date square\"],\n    'price': [4.50, 5.00, 6.25, 3.75]\n})\n</code>\ndf['dessert_types'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['dessert_types'] = ', '.join(df['description'].str.split().str[0].unique())\n</code>"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame that contains information about sales transactions, structured like this:\n\n```\n   transaction_id    product_id    quantity\n0               1            101          2\n1               2            102          4\n2               3            103          1\n3               4            101          3\n4               5            102          2\n```\n\nI want to create a function that computes the total quantity sold for each product and returns a new DataFrame that lists each unique `product_id` along with its corresponding total quantity sold. \n\nHere\u2019s how the DataFrame should look after the operation:\n\n```\n   product_id    total_quantity\n0          101               5\n1          102               6\n2          103               1\n```\n\nWhat code can I use to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4, 5],\n    'product_id': [101, 102, 103, 101, 102],\n    'quantity': [2, 4, 1, 3, 2]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('product_id', as_index=False)['quantity'].sum().rename(columns={'quantity': 'total_quantity'})\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data with columns 'Product', 'Region', and 'Sales'. I want to create a custom function that calculates the total sales for each product across different regions, and then returns a DataFrame with the products and their respective total sales.\n\nFor example, given the following DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n    'Region': ['North', 'South', 'East', 'West', 'East', 'South', 'West'],\n    'Sales': [100, 200, 150, 300, 250, 200, 100]\n})\n```\n\nI want to use a function `calculate_total_sales(df)` that returns a DataFrame like this:\n\n```\n  Product  Total_Sales\n0       A          450\n1       B          450\n2       C          400\n```\n\nFill in the blank to complete the creation of the function:\n\n```python\ndef calculate_total_sales(df):\n    result = ...  # put solution in this variable\n    return result\n```",
    "output": "\n```python\ndef calculate_total_sales(df):\n    result = df.groupby('Product', as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\n    return result\n```"
  },
  {
    "input": "Problem:\n\nI have a DataFrame with a column of email addresses and I want to extract the domain from each email into a new column called 'domain'. My DataFrame looks like this:\n\n```\n       email\n0  alice@example.com\n1  bob@sample.org\n2  charlie@example.net\n3  dave@website.com\n4  eve@domain.io\n```\n\nI know I can create a new column and populate it with some transformation, but I'm not sure how to extract just the domain from the email addresses using pandas string methods.\n\nCurrent attempts to split the email are returning the full string or parts I'm not interested in. I want the 'domain' column to look like this:\n\n```\n       domain\n0  example.com\n1  sample.org\n2  example.net\n3  website.com\n4  domain.io\n```\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'email': ['alice@example.com', 'bob@sample.org', \n                  'charlie@example.net', 'dave@website.com', \n                  'eve@domain.io']}\ndf = pd.DataFrame(data)\n</code>\ndf['domain'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['domain'] = df['email'].str.split('@').str[1]"
  },
  {
    "input": "Problem:\nSuppose you have a sparse tensor representing a 3D data structure for image features, stored in a PyTorch SparseTensor. The tensor is of size (5, 5, 5), with a few non-zero entries. You want to create a dense representation of this sparse tensor, but only for a specific slice along the first dimension (batch). You need the slice for the first two batches (i.e., `tensor[0:2, :, :]`).\n\nA:\n<code>\nimport torch\nindices = torch.tensor([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\nvalues = torch.tensor([10.0, 20.0, 30.0])\nsize = (5, 5, 5)\nsparse_tensor = torch.sparse_coo_tensor(indices.t(), values, size)\n</code>\ndense_slice = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_slice = sparse_tensor.to_dense()[0:2, :, :]"
  },
  {
    "input": "Problem:\nYou have collected daily temperature data for a city over the past two weeks, represented in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-10-01', '2023-10-02', '2023-10-03', '2023-10-04', '2023-10-05', \n             '2023-10-06', '2023-10-07', '2023-10-08', '2023-10-09', '2023-10-10', \n             '2023-10-11', '2023-10-12', '2023-10-13', '2023-10-14'],\n    'Temperature': [22, 21, 19, 24, 25, 23, 22, 20, 21, 19, 18, 22, 23, 26]\n}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])  # Converting 'Date' to datetime\n```\n\nYour goal is to compute the rolling average temperature over a 3-day window and add it as a new column called 'Rolling_Avg_Temp' in the DataFrame. Fill any missing values in the 'Rolling_Avg_Temp' column with the overall mean temperature from the 'Temperature' column.\n\nWrite the following line of code to fill in the blank, ensuring it addresses the requirements:\n\n```python\ndf['Rolling_Avg_Temp'] = df['Temperature'].rolling(window=3).mean().fillna(____)\n```\n",
    "output": "\n```python\ndf['Rolling_Avg_Temp'] = df['Temperature'].rolling(window=3).mean().fillna(df['Temperature'].mean())\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing sales transactions for various products, structured as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'Product': ['A', 'B', 'A', 'C', 'B'],\n    'Quantity': [2, 1, 3, 4, 2],\n    'Price': [10, 20, 10, 30, 20]\n})\n```\n\nYou want to create a function that calculates the total sales for each product based on the Quantity and Price columns. The desired output should be a dictionary with product names as keys and total sales as values.\n\n```python\ntotal_sales = ... # Write your function and assign the output here\n```\n\nMake sure the function is reusable and can handle different DataFrames structured like the provided one.",
    "output": "\n```python\ndef calculate_total_sales(dataframe):\n    sales = {}\n    for index, row in dataframe.iterrows():\n        product = row['Product']\n        total = row['Quantity'] * row['Price']\n        if product in sales:\n            sales[product] += total\n        else:\n            sales[product] = total\n    return sales\n\ntotal_sales = calculate_total_sales(df)\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame with a column of addresses that look like this:\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n\nI want to extract the city and state from each address and create separate columns for them. If the address does not contain a state, I want the state column to be None.\n\nThe final DataFrame should look like this:\n\naddress                     city          state\n0 123 Main St, Springfield, IL  Springfield            IL\n1 456 Elm St, Gotham City, NY  Gotham City            NY\n2 789 Oak St, Metropolis, CA  Metropolis            CA\n3 101 Maple Ave, Star City, TX  Star City            TX\n\nI've attempted to use string manipulation to achieve this, but I'm unsure how to split and extract the components correctly. Can you help me get this working?\n\nA:\n<code>\nimport pandas as pd\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n</code>\naddress_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\naddress_df[['city', 'state']] = address_df['address'].str.extract(r',\\s*([^,]+),\\s*([A-Z]{2})$')\n</code>"
  },
  {
    "input": "Problem:\nI have a sparse tensor that represents a multi-dimensional dataset. The tensor is initialized as follows:\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\nshape = (10, 10, 10)  # 3D tensor\nsparse_tensor = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 3], [4, 5, 6]], values=[1, 2, 3], dense_shape=shape)\n```\n\nI want to convert this sparse tensor to a dense numpy array where all unspecified elements are filled with zeros, and then reshape it into a 5x20 array.\n\nHow can I achieve this with a single line of code? \n\nA:\n<code>\nresult = ...  # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = tf.sparse.to_dense(sparse_tensor).numpy().reshape(5, 20)  \n</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing user data in a single column called 'info'. The 'info' column consists of strings formatted as \"Name: Age: Email\". For example:\n\n```\ninfo\n0  John Doe: 28: john@example.com\n1  Jane Smith: 35: jane@example.com\n2  Sam Johnson: 22: sam@example.com\n3  Lisa Lee: 30: lisa@example.com\n```\n\nI need to split this 'info' column into three new columns: 'Name', 'Age', and 'Email'. The resulting DataFrame should look like this:\n\n```\n   Name          Age               Email\n0  John Doe      28            john@example.com\n1  Jane Smith    35            jane@example.com\n2  Sam Johnson    22           sam@example.com\n3  Lisa Lee      30            lisa@example.com\n```\n\nHow can I achieve this using pandas string manipulation methods? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'info': ['John Doe: 28: john@example.com', \n                             'Jane Smith: 35: jane@example.com',\n                             'Sam Johnson: 22: sam@example.com',\n                             'Lisa Lee: 30: lisa@example.com']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['Name', 'Age', 'Email']] = df['info'].str.split(': ', expand=True)"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a 2D tensor where each row corresponds to a training example and each column corresponds to a feature. I want to build a simple feedforward neural network using TensorFlow and then train it on this dataset. The model should consist of one hidden layer with ReLU activation and an output layer with softmax activation. After defining the model, I need to compile it with categorical crossentropy loss and an Adam optimizer. \n\nHere is a simplified version of the code that establishes the tensor and defines the model up to the compilation step:\n\n```python\nimport tensorflow as tf\n\n# Example data: shape (num_examples, num_features)\nX_train = tf.constant([[0.1, 0.2], [0.2, 0.4], [0.3, 0.6]], dtype=tf.float32)\ny_train = tf.constant([[1, 0], [0, 1], [1, 0]], dtype=tf.float32) # One-hot encoded labels\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(2,))) \nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=...)\n```\n\nWhat should I place in the loss parameter to correctly set up the model for categorical classification?\n\nA:\n\n<code>\nmodel.compile(optimizer='adam', loss='...') \n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.compile(optimizer='adam', loss='categorical_crossentropy') \n</code>"
  },
  {
    "input": "Problem:\nI have a daily sales record in a DataFrame as follows:\n\n```\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'Sales': [200, 220, 250, 270, 300, 320, 340, 360, 380, 400]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the 3-day moving average of the sales. The result should be a Series with the same index but showing `NaN` for the first two days as there are not enough data points to compute the average.\n\nHow can I obtain this moving average?\n\nA:\n```python\nmoving_average = df['Sales'].rolling(window=3).mean()\n```",
    "output": "\n<code>\nmoving_average = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI am working with a pandas DataFrame that contains sales data for a retail store. The DataFrame looks like this:\n\n```\nstore_id    sale_date      sale_amount\n1           2023-01-01     200.00\n1           2023-01-02     150.00\n1           2023-01-03     300.00\n2           2023-01-01     250.00\n2           2023-01-03     350.00\n2           2023-01-05     300.00\n```\n\nI want to calculate the rolling average of the `sale_amount` for each store over a window of 2 days but want to ensure that the rolling average includes only values from same store and looks like this:\n\n```\nstore_id    sale_date      sale_amount  rolling_avg\n1           2023-01-01     200.00       200.00\n1           2023-01-02     150.00       175.00\n1           2023-01-03     300.00       225.00\n2           2023-01-01     250.00       250.00\n2           2023-01-03     350.00       300.00\n2           2023-01-05     300.00       325.00\n```\n\nHow can I achieve this using pandas? \n\nHere is the code to create the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'store_id': [1, 1, 1, 2, 2, 2],\n    'sale_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03', '2023-01-05']),\n    'sale_amount': [200.00, 150.00, 300.00, 250.00, 350.00, 300.00]\n}\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['rolling_avg'] = df.groupby('store_id')['sale_amount'].apply(lambda x: x.rolling(window=2, min_periods=1).mean())\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix that represents user-item interactions, where most of the entries are zero. I want to perform a transformation on this sparse matrix to obtain a new sparse matrix that represents the interactions squared. However, directly squaring the entries will generate many zeros, and I want to ensure that the result remains in sparse format for memory efficiency. \n\nAssuming I have a sparse matrix `interaction_matrix` defined as a COO (Coordinate) format with given user-item data, how do I apply the squaring operation efficiently?\n\nA:\n<code>\nfrom scipy import sparse\n\ndata = [1, 2, 3, 4, 5]\nrows = [0, 0, 1, 2, 2]\ncols = [0, 2, 2, 0, 1]\ninteraction_matrix = sparse.coo_matrix((data, (rows, cols)), shape=(3, 3))\n</code>\nsquared_interaction_matrix = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsquared_interaction_matrix = sparse.coo_matrix((interaction_matrix.data**2, interaction_matrix.nonzero()), shape=interaction_matrix.shape)\n</code>"
  },
  {
    "input": "Problem:\nI have a time series dataset containing timestamps and sales transactions in a DataFrame:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   100\n1 2023-01-01 10:05:00   150\n2 2023-01-01 10:10:00   200\n3 2023-01-01 10:15:00   50\n4 2023-01-01 10:20:00   300\n5 2023-01-01 10:40:00   120\n6 2023-01-01 10:50:00   180\n7 2023-01-01 11:00:00   250\n```\n\nWhat I want to achieve is resampling this data to 15-minute intervals and calculating the sum of sales for each interval. If there are any intervals with no sales data, they should still appear in the final output with a sales value of 0.\n\nThe desired output format should look like this:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   450\n1 2023-01-01 10:15:00   0\n2 2023-01-01 10:30:00   0\n3 2023-01-01 10:45:00   180\n4 2023-01-01 11:00:00   250\n```\n\nHere's the starting point of the code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': ['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:10:00', \n                  '2023-01-01 10:15:00', '2023-01-01 10:20:00', '2023-01-01 10:40:00', \n                  '2023-01-01 10:50:00', '2023-01-01 11:00:00'],\n    'Sales': [100, 150, 200, 50, 300, 120, 180, 250]\n})\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYour task is to fill in the blank to complete the code for the resampling and summing of sales:\n\n```python\ndf.set_index('Timestamp', inplace=True)\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = df.resample('15T').sum().fillna(0).reset_index()\ndf['Sales'] = df['Sales'].astype(int)\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe containing customer data:\n\n```\ncustomer_info\n1   John Doe, 29, New York\n2   Jane Smith, 34, San Francisco\n3   Alice Johnson, 22, Boston\n4   Bob Brown, 45, Chicago\n```\n\nI need to split this `customer_info` column into three separate columns: `name`, `age`, and `city`. The final dataframe should look like this:\n\n```\n      name   age           city\n1  John Doe   29       New York\n2  Jane Smith 34  San Francisco\n3  Alice Johnson 22         Boston\n4  Bob Brown   45        Chicago\n```\n\nI tried to achieve this using the `str.split` method but I'm not getting the expected output. Here is the initial code I have:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'customer_info': ['John Doe, 29, New York', 'Jane Smith, 34, San Francisco', \n                                      'Alice Johnson, 22, Boston', 'Bob Brown, 45, Chicago']})\n```\n\nHow can I correctly extract and separate the name, age, and city into different columns? \n\nA:\n<code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['name', 'age', 'city']] = df['customer_info'].str.split(', ', expand=True)\ndf['age'] = df['age'].astype(int)\ndf = df.drop(columns=['customer_info'])\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing customer orders, and you want to calculate the total quantity of items ordered per customer. Your dataset looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['C001', 'C002', 'C001', 'C003', 'C002', 'C001', 'C003'],\n    'OrderID': [101, 102, 103, 104, 105, 106, 107],\n    'Quantity': [5, 3, 2, 4, 1, 7, 8]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a function that sums the quantities for each customer and returns the results in a new DataFrame with columns: `CustomerID` and `TotalQuantity`. \n\nA:\n```python\n# Define your function here\ndef calculate_total_quantity(df):\n    ...\n```\n\nUse this function to get the total quantities for each customer. For the provided data, the expected result should look like:\n\n```\n  CustomerID  TotalQuantity\n0       C001             14\n1       C002              4\n2       C003             12\n```\n\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef calculate_total_quantity(df):\n    return df.groupby('CustomerID', as_index=False)['Quantity'].sum().rename(columns={'Quantity': 'TotalQuantity'})\n\nresult = calculate_total_quantity(df)\n```"
  },
  {
    "input": "Problem:\nI have a time series data set containing daily temperature readings for a month. The data is represented as a pandas DataFrame with a `Date` column and a `Temperature` column. I want to compute a new column `7_day_avg` that contains the average temperature of the past 7 days for each entry, while handling the first 6 days where there aren't enough previous entries for a full 7-day average (you can set those values to NaN). \n\nHere is an example of my DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'Temperature': np.random.randint(low=-10, high=35, size=30)\n}\ndf = pd.DataFrame(data)\n```\n\nWhat is the code to calculate the `7_day_avg` column in this DataFrame? Fill in the blank below:\n\nA:\n<code>\ndf['7_day_avg'] = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset represented as a list of dictionaries where each dictionary corresponds to an individual's records. Each record includes 'age', 'income', and 'expenses'. I want to create a function that calculates the savings for each record by subtracting expenses from income. The function should return a list of savings. Here\u2019s a sample of my dataset:\n\n```python\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n```\n\nI need a way to efficiently calculate the savings and return them as a list.\n\nA:\n<code>\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n\ndef calculate_savings(records):\n    # return the savings list here\n    savings = ...\n</code>\nsavings = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    savings = [record['income'] - record['expenses'] for record in records]\n    return savings\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains product sales data with the following columns: 'product_id', 'sales', and 'returns'. The aim is to create a new DataFrame that summarizes this data by calculating the net sales for each product (which is defined as sales minus returns). Additionally, if the net sales are negative, we want to store 'Low' in a new column; if they are zero, store 'None'; and if they are positive, store 'High'.\n\nHere is what the DataFrame looks like:\n\nproduct_id  sales  returns\n1           150    10\n2           200    50\n3           100    200\n4           300    0\n5           50     100\n\nI need a function that computes the net sales and labels them accordingly, producing a new DataFrame with 'product_id', 'net_sales', and 'sales_label'.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 3, 4, 5],\n    'sales': [150, 200, 100, 300, 50],\n    'returns': [10, 50, 200, 0, 100]\n})\n\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.copy()\nresult['net_sales'] = result['sales'] - result['returns']\nresult['sales_label'] = result['net_sales'].apply(lambda x: 'Low' if x < 0 else ('None' if x == 0 else 'High'))\nresult = result[['product_id', 'net_sales', 'sales_label']]\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a sparse tensor to perform a multi-label classification task, where each row of your data can belong to multiple classes represented as a sparse tensor. Given a sparse tensor `sparse_tensor` with shape (3, 5, 4) that has non-zero elements indicating the presence of classes, how can you efficiently convert the sparse tensor to a dense version that reflects the presence or absence of each class per sample? \n\nHere's a sample of how the sparse tensor is defined in TensorFlow:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.sparse.SparseTensor(\n    indices=[[0, 0, 1], [1, 2, 3], [2, 4, 0]],\n    values=[1, 1, 1],\n    dense_shape=[3, 5, 4]\n)\n```\n\nYou need to fill in the following statement to convert it to a dense tensor:\n\n```python\ndense_tensor = ...  # put solution in this variable\n```\nEnsure that the resulting dense tensor should correctly reflect which classes are present for each data point.",
    "output": "\n```python\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data with the following structure:\n\n    Date       | Product  | Sales\n    -----------|----------|------\n    2023-01-01 | Widget A | 150\n    2023-01-02 | Widget A | 120\n    2023-01-01 | Widget B | 100\n    2023-01-02 | Widget B | 130\n    2023-01-03 | Widget A | 170\n    2023-01-03 | Widget B | 90\n\nI want to create a custom function that computes the total sales for each product over the entire period. I will be using the following DataFrame to perform that task:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-03'],\n    'Product': ['Widget A', 'Widget A', 'Widget B', 'Widget B', 'Widget A', 'Widget B'],\n    'Sales': [150, 120, 100, 130, 170, 90]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, please fill in the blank below to define a function called `total_sales` that takes this DataFrame as input and returns a new DataFrame that has the total sales for each product. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef total_sales(df):\n    return df.groupby('Product')['Sales'].sum().reset_index()\n    \nresult = total_sales(df)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a deep learning application using TensorFlow where I'm handling a sparse tensor representing user-item interactions in a recommender system. The original sparse tensor is of shape (1000, 5000) and is represented using `tf.SparseTensor`. I want to create a function that takes this sparse tensor as input and increments all non-zero values by 1 and converts it back to a dense tensor for further processing.\n\nHere's the definition of the sparse tensor:\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\nindices = np.array([[0, 0], [1, 2], [2, 3], [3, 4]])\nvalues = np.array([1, 2, 3, 4])\ndense_shape = np.array([1000, 5000])\n\nsparse_tensor = tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n```\n\nWhat I want is to create a dense tensor where each non-zero entry of the sparse tensor is incremented by 1, while preserving the shape.\n\nA:\n\n```python\nsparse_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\ndef increment_sparse_tensor(sparse_tensor):\n    dense_tensor = tf.sparse.to_dense(sparse_tensor)\n    incremented_tensor = dense_tensor + 1\n    return incremented_tensor\n\nsparse_tensor = increment_sparse_tensor(sparse_tensor)\n```"
  },
  {
    "input": "## Problem:\nI have a dataframe with a column containing dates in various formats mixed with their respective timestamps. The goal is to extract only the date part without the time and convert it to the format \"dd-mm-yyyy\". Here's an example of what the dataframe looks like:\n\n| datetime                |\n|-------------------------|\n| 2023-10-12 14:23:44     |\n| 2023/11/01 10:05:22     |\n| October 15, 2023 03:12  |\n\nI wish to create a new column `formatted_date` that contains the dates extracted and formatted as specified. I started with the following code but I'm not sure how to parse the varying formats.\n\n```python\ndf['formatted_date'] = df['datetime'].str[...] \n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'datetime': ['2023-10-12 14:23:44', '2023/11/01 10:05:22', 'October 15, 2023 03:12']}\ndf = pd.DataFrame(data)\n</code>\ndf['formatted_date'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['formatted_date'] = pd.to_datetime(df['datetime'], errors='coerce').dt.strftime('%d-%m-%Y') \n</code>"
  },
  {
    "input": "## Problem\n\nYou are building a neural network model using TensorFlow for image classification. The output layer of your model is a dense layer with 10 units (one for each class), activated by the softmax function. After obtaining the class probabilities, you need to create a tensor that will contain the predicted class indices based on the highest probabilities for a batch of images. \n\nGiven the output tensor of your model:\n\n```python\ntf.Tensor(\n    [[0.1, 0.3, 0.1, 0.4, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n     [0.2, 0.2, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1],\n     [0.3, 0.1, 0.1, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]]\n)\n```\n\nYou want to convert this tensor to a one-dimensional tensor that only contains the index of the highest value in each row. For the provided example, the desired output should be:\n\n```\ntf.Tensor([3, 2, 0])\n```\n\nHow can you achieve this?\n\nA:\n```python\nimport tensorflow as tf\n\npredictions = tf.constant(\n    [[0.1, 0.3, 0.1, 0.4, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n     [0.2, 0.2, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1],\n     [0.3, 0.1, 0.1, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]]\n)\n```\npredicted_classes = ... # put solution in this variable",
    "output": "\n```python\npredicted_classes = tf.argmax(predictions, axis=1)\n```"
  },
  {
    "input": "### Problem\nI have a dataset represented as a Pandas DataFrame containing a column with email addresses, and I want to extract the domain part from each email to create a new column called 'domain'. For example, if the email is 'user@example.com', the domain should be 'example.com'. \n\nHere is what my DataFrame looks like:\n\n```\n           email\n0  user1@gmail.com\n1  user2@yahoo.com\n2  user3@hotmail.com\n3  user4@outlook.com\n4  user5@company.org\n```\n\nHow can I achieve this? Here is my current attempt to create the new column:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'email': ['user1@gmail.com', 'user2@yahoo.com', \n                             'user3@hotmail.com', 'user4@outlook.com', \n                             'user5@company.org']})\n```\n\nI want to fill in the blank for this line in my code to extract the domain:\n```python\ndf['domain'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['domain'] = df['email'].str.split('@').str[1]\n```"
  },
  {
    "input": "Problem:\nYou have a dataframe representing sales data, shown below:\n\n```python\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\n\nYou want to create a new column called `total_sales`, which is calculated as `quantity * price`. However, if the total sales for any row is less than 50, you want to set it to 0. Your goal is to implement a custom function to achieve this. \n\nWhat should you write to obtain the modified dataframe with the new column?\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n```python\ndef calculate_total_sales(row):\n    total = row['quantity'] * row['price']\n    return total if total >= 50 else 0\n\ndf['total_sales'] = df.apply(calculate_total_sales, axis=1)\n```",
    "output": "\n```python\ndf['total_sales'] = df.apply(lambda row: max(row['quantity'] * row['price'], 0) if row['quantity'] * row['price'] >= 50 else 0, axis=1)\n```"
  },
  {
    "input": "### Problem\n\nYou are given a dataset representing images, where each image is stored as a 3D tensor in a batch format (batch_size, height, width, channels). You want to preprocess these images using TensorFlow by subtracting the mean pixel value from each channel of the images in the batch. \n\nGiven a batch of images with shape (batch_size, height, width, channels), the goal is to compute a tensor `normalized_images` which contains the images with the mean normalized.\n\nFor example:\n\n```python\nimages = tf.random.normal((10, 64, 64, 3))  # A batch of 10 images of size 64x64 with 3 channels\n```\n\nWrite the code to perform the mean normalization for the images so that `normalized_images` contains the result of subtracting the mean of each channel.\n\n```python\nimport tensorflow as tf\n\nimages = load_data()  # shapes as indicated above\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean_values = tf.reduce_mean(images, axis=[0, 1, 2], keepdims=True)\nnormalized_images = images - mean_values\n</code>"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.10.0.\nI have two tensors, one for features and another for labels, and I want to perform a linear regression using these tensors. The feature tensor has the shape (100, 1), and the label tensor has the shape (100,). \nHow can I define a simple linear regression model and compute the predictions for the features tensor?\n\nA:\n<code>\nimport torch\n\n# Define feature and label tensors\nfeatures = torch.randn(100, 1)\nlabels = torch.randn(100)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch.nn as nn\n\n# Define a simple linear regression model\nmodel = nn.Linear(1, 1)\n\n# Compute predictions\nresult = model(features)\n</code>"
  },
  {
    "input": "Problem:\n\nYou are training a neural network model using TensorFlow and PyTorch interchangeably. After training a simple model in TensorFlow, you extract the weights and want to load them into a PyTorch model. Suppose the TensorFlow model weights are given as a NumPy array of the shape (128, 64) for a fully connected layer.\n\nHow can you convert this NumPy array into a PyTorch tensor and assign it directly to the weights of a PyTorch model's layer called `fc_layer`?\n\nA:\n```python\nimport torch\nimport numpy as np\ntf_weights = np.random.rand(128, 64)  # Example weights from TensorFlow model\nfc_layer = torch.nn.Linear(128, 64)\n```\nfc_layer.weight.data = ... # put solution in this variable\nBEGIN SOLUTION\n```python",
    "output": "\n```python\nfc_layer.weight.data = torch.from_numpy(tf_weights).float()\n```"
  },
  {
    "input": "## Problem:\nI am training a multi-class classification model using PyTorch, and after obtaining the model's output probabilities through a softmax layer, I need to identify the indices of the two highest probabilities for each input sample. The softmax layer output looks like this:\n\n```\n[[0.1, 0.3, 0.6],\n [0.8, 0.1, 0.1],\n [0.2, 0.5, 0.3]]\n```\n\nI would like to extract the indices of the two highest probabilities for each input to create a tensor. For the example above, the expected output would be:\n\n```\n[[2, 1],\n [0, 1],\n [1, 2]]\n```\n\nHow can I achieve this using PyTorch? \n\nA:\n<code>\nimport torch\n\noutput_probs = torch.tensor([[0.1, 0.3, 0.6],\n                              [0.8, 0.1, 0.1],\n                              [0.2, 0.5, 0.3]])\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = torch.topk(output_probs, 2, dim=1).indices\n</code>"
  },
  {
    "input": "### Problem:\nGiven a sparse tensor representing a 3D RGB image batch of shape (batch_size, height, width, channels), where the tensor has a significant number of zero entries, you want to perform a normalization operation only on the non-zero entries in the channels. The tensor `image_tensor` is a `scipy.sparse.csr_matrix` representation of the images, and you want to apply the normalization as follows:\n\nFor each channel, divide the non-zero pixel values by the maximum pixel value found in that channel across the entire batch, while retaining the original shape of the tensor, including the zeros.\n\nHere's how you can conceptualize it:\n\n```python\nfrom scipy import sparse\nimport numpy as np\n\n# Create a sparse tensor of random values and some zeros\nimage_tensor = sparse.rand(5, 100, 100, 3, density=0.3, format='csr').tocoo()  # shape (5, 100, 100, 3)\n\n# Fill in the blank to normalize non-zero entries in the tensor along the channel dimension.\n```\n\nYou need to fill in the blank to perform this normalization correctly while maintaining the shape of the input sparse tensor. \n\nA:\n<code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n# Convert the sparse tensor to a dense format for processing\ndense_tensor = image_tensor.toarray()\n\n# Normalize non-zero entries in each channel\nmax_values = np.max(dense_tensor, axis=(0, 1), keepdims=True)\nnormalized_tensor = np.where(dense_tensor != 0, dense_tensor / max_values, 0)\n\n# Convert back to sparse format\nnormalized_tensor = sparse.csr_matrix(normalized_tensor)\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing sales data from different stores over several months. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Store_ID': ['S001', 'S002', 'S001', 'S003', 'S002'],\n    'Month': ['January', 'January', 'February', 'February', 'March'],\n    'Sales': [200, np.nan, 150, 300, 250]\n})\n```\n\nYour task is to write a custom function that calculates the total sales for each store, ensuring that NaN values are ignored in the sum calculation. You should modify the DataFrame to include a new column called 'Total_Sales' that holds the calculated total for each unique Store_ID.\n\nExpected DataFrame after operation:\n```\n  Store_ID     Month  Sales  Total_Sales\n0     S001   January  200.0         350.0\n1     S002   January    NaN         250.0\n2     S001  February  150.0         350.0\n3     S003  February  300.0         300.0\n4     S002     March  250.0         250.0\n```\n\nA:\n```python\ndf['Total_Sales'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Total_Sales'] = df.groupby('Store_ID')['Sales'].transform(lambda x: x.sum(skipna=True))\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer transactions in a DataFrame, where each transaction has a 'price' and a 'quantity' column. You want to create a new column that calculates the total amount spent for each transaction, which is the product of 'price' and 'quantity'. To ensure your code is reusable, you plan to implement a custom function for this calculation.\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'price': [10.5, 20.0, 7.5, 15.0],\n    'quantity': [2, 1, 3, 4]\n})\n```\n\nYou should define a function named `calculate_total` that takes two arguments, `price` and `quantity`, and returns the total spent for that transaction. Then, use this function to apply it to the DataFrame and create a new column called 'total_spent'.\n\n```python\ndf['total_spent'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_total(price, quantity):\n    return price * quantity\n\ndf['total_spent'] = df.apply(lambda row: calculate_total(row['price'], row['quantity']), axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe that contains user details with names and emails in a single column. The format of the column is \"Name (email@example.com)\". I want to separate the names and emails into two separate columns called 'name' and 'email'. \n\nThe dataframe looks like this:\n\n```\ndetails\n0  John Doe (john.doe@example.com)\n1  Jane Smith (jane.smith@example.com)\n2  Alice Johnson (alice.j@gmail.com)\n3  Bob Brown (bob.brown@mail.com)\n```\n\nHow can I achieve this separation using column operations in pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'details': ['John Doe (john.doe@example.com)', \n                               'Jane Smith (jane.smith@example.com)', \n                               'Alice Johnson (alice.j@gmail.com)', \n                               'Bob Brown (bob.brown@mail.com)']})\n</code>\ndf[['name', 'email']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['details'].str.extract(r'(.+?) \\((.+?)\\)')"
  },
  {
    "input": "Problem:\nI have a time series data in a pandas DataFrame containing timestamps and corresponding temperatures taken every hour. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'timestamp': ['2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00', \n                  '2023-01-01 03:00:00', '2023-01-01 04:00:00', '2023-01-01 05:00:00'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n})\n```\n\nWhat I want to achieve is to create a new DataFrame that includes the average temperature computed over a 2-hour rolling window, but only for the timestamps that fall exactly on the hour (e.g., '2023-01-01 00:00:00', '2023-01-01 01:00:00', etc.). \n\nThe resulting DataFrame should have the following structure:\n\n```python\n          timestamp  avg_temperature\n0  2023-01-01 00:00:00              ?\n1  2023-01-01 01:00:00              ?\n2  2023-01-01 02:00:00              ?\n3  2023-01-01 03:00:00              ?\n4  2023-01-01 04:00:00              ?\n5  2023-01-01 05:00:00              ?\n```\n\nPlease fill in the blank with the proper code to derive the column `avg_temperature`. \n\n```python\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.set_index('timestamp').rolling('2H').mean().reset_index().rename(columns={'temperature': 'avg_temperature'})\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse tensor representation of a 3D grid where many of the elements are zero. This tensor is represented in the COO format using the `scipy.sparse` module. My goal is to efficiently compute the sum of all non-zero elements in this tensor without converting it into a dense format, as it would consume too much memory.\n\nThe tensor has been initialized and populated as follows:\n\n```python\nimport numpy as np\nfrom scipy import sparse\n\n# Randomly generating sparse tensor coordinates and values\ncoords = np.array([[0, 1, 2], [0, 2, 1], [1, 0, 2], [1, 1, 1], [2, 0, 0]])\nvalues = np.array([1, 2, 3, 4, 5])\nsparse_tensor = sparse.coo_matrix((values, (coords[:, 0], coords[:, 1], coords[:, 2])), shape=(3, 3, 3))\n```\n\nHow can I compute the sum of all non-zero values in this sparse tensor using the appropriate method from `scipy`?\n\nA:\n```python\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\nsum_non_zero = sparse_tensor.sum()\n</code>\n```"
  },
  {
    "input": "## Problem\nYou are analyzing customer purchase data stored in a pandas DataFrame, and you want to compute the total amount spent by each customer across all their purchases. The DataFrame contains columns 'customer_id' and 'amount'. To streamline your calculations, you decide to implement a custom function that takes the DataFrame as input and returns a new DataFrame with 'customer_id' and 'total_spent' columns.\n\nHere's a sample DataFrame you'll be working with:\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 2, 1, 3, 2, 1],\n    'amount': [150, 200, 50, 300, 30, 70]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat code should you use to define the function `calculate_total_spent(df)` that generates the desired output and fill in the blank below?\n\nA:\n```python\ndef calculate_total_spent(df):\n    # Your code here that groups by 'customer_id' and sums 'amount'\n    return result\n\nresult = ...\n```",
    "output": "\n```python\ndef calculate_total_spent(df):\n    result = df.groupby('customer_id', as_index=False)['amount'].sum()\n    result.rename(columns={'amount': 'total_spent'}, inplace=True)\n    return result\n\nresult = calculate_total_spent(df)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame with a column that contains mixed content, including product IDs and quantities in a semi-structured format. The DataFrame looks like this:\n\n```\n   products\n0  ID123: 45\n1  ID456: 29\n2  ID123: 60\n3  ID789: 15\n4  ID456: 22\n```\n\nI want to extract the product IDs and their corresponding quantities into two new columns, 'ProductID' and 'Quantity'. The expected output should look like this:\n\n```\n   products   ProductID  Quantity\n0  ID123: 45     ID123        45\n1  ID456: 29     ID456        29\n2  ID123: 60     ID123        60\n3  ID789: 15     ID789        15\n4  ID456: 22     ID456        22\n```\n\nThe code I have written has not been effective. Here is what I attempted:\n\n```\ndf['ProductID'] = df.products.replace(r'([A-Z]+\\d+): \\d+', r'\\1', regex=True)\ndf['Quantity'] = df.products.replace(r'[A-Z]+\\d+: (\\d+)', r'\\1', regex=True)\n```\n\nBut it doesn't work as expected. Can you provide a suggestion? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'products': ['ID123: 45', 'ID456: 29', 'ID123: 60', 'ID789: 15', 'ID456: 22']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['ProductID'] = df['products'].str.split(': ').str[0]\ndf['Quantity'] = df['products'].str.split(': ').str[1].astype(int)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe that contains a column with product descriptions that include both the product name and its price in a mixed format like so:\n\n```python\ndata = {'description': ['Laptop - $1200', 'Mouse - $25', 'Keyboard - $75', 'Monitor - $300']}\ndf = pd.DataFrame(data)\n```\n\nI want to extract the product name into a new column called `product_name` and the price (as a numeric value) into another new column called `price`. The final dataframe should look like this:\n\n```\n       description     product_name  price\n0   Laptop - $1200           Laptop  1200.0\n1     Mouse - $25            Mouse    25.0\n2  Keyboard - $75         Keyboard    75.0\n3  Monitor - $300         Monitor     300.0\n```\n\nHowever, my current attempt to extract these values is failing. I want the correct pandas code to achieve this transformation. \n\nPlease provide the solution in the following blank:\n```python\ndf[['product_name', 'price']] = df['description'].str.extract(r'(?P<product_name>.*?) - \\$(?P<price>\\d+)')\n```",
    "output": "\n```python\ndf[['product_name', 'price']] = df['description'].str.extract(r'(?P<product_name>.*?) - \\$(?P<price>\\d+)')\ndf['price'] = df['price'].astype(float)\n```"
  },
  {
    "input": "Problem:\nI am working with a dictionary representing sales data for different products over several months:\n\nsales_data = {\n    'Product A': [100, 150, 200],\n    'Product B': [200, 250, 300],\n    'Product C': [50, 75, 100]\n}\n\nI want to create a function that calculates the average sales for each product and returns a new dictionary with the product names and their respective average sales. The function should handle any number of products and sales records.\n\nWhat I have tried is below, but it's incomplete. I need help completing the function to get the desired output.\n\ndef calculate_average_sales(data):\n    averages = {}\n    # Your logic to calculate averages goes here\n    return averages\n\nA:\n<code>\nsales_data = {\n    'Product A': [100, 150, 200],\n    'Product B': [200, 250, 300],\n    'Product C': [50, 75, 100]\n}\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_average_sales(data):\n    averages = {}\n    for product, sales in data.items():\n        averages[product] = sum(sales) / len(sales)\n    return averages\n\nresult = calculate_average_sales(sales_data)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales of a product over several months, stored in a DataFrame with two columns: 'Date' and 'Sales'. The 'Date' column contains dates in the format 'YYYY-MM-DD', and the 'Sales' column contains the number of products sold on that date. \n\nI need to calculate a moving average of the sales over a 7-day window, ensuring that if there are any gaps in the dates (missing days), those entries are filled with NaN. The result should include the original date and the corresponding moving average in a new DataFrame.\n\nHere's how the DataFrame looks:\n\n```\n          Date    Sales\n0   2023-01-01      10\n1   2023-01-02      15\n2   2023-01-05      25\n3   2023-01-06      20\n4   2023-01-08      30\n5   2023-01-09      40\n```\n\nWhat I'm struggling with is how to properly apply the moving average while handling the missing dates. \nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-06', '2023-01-08', '2023-01-09'],\n                   'Sales': [10, 15, 25, 20, 30, 40]})\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.set_index('Date').asfreq('D')  # Fill missing dates with NaN\nresult = df.assign(Moving_Average=df['Sales'].rolling(window=7).mean()).reset_index()\n</code>"
  },
  {
    "input": "## Problem\nI have a dataset that records the daily temperatures of a city over several years. The data is in a pandas DataFrame with two columns: `Date` and `Temperature`. I want to resample this DataFrame to get the average temperature for each month, and then calculate the rolling average of these monthly averages over a window of 3 months.\n\nThe format of the DataFrame is as follows:\n```\n        Date       Temperature\n0  2018-01-01         5.0\n1  2018-01-02         4.5\n2  2018-01-03         5.5\n3  2018-02-01         6.5\n4  2018-02-02         7.0\n...\n```\nAfter performing the resampling and rolling average calculation, I would like to see the output that only shows the `Date` (as the first day of the month) and the rolling average `Temperature`.\n\nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\n# Sample DataFrame\ndf = pd.DataFrame({\n        'Date': pd.date_range(start='2018-01-01', periods=90, freq='D'),\n        'Temperature': [5.0, 4.5, 5.5, 6.5, 7.0] * 18\n})\n\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmonthly_avg = df.resample('M').mean()\nrolling_avg = monthly_avg.rolling(window=3).mean()\nresult = rolling_avg.reset_index().rename(columns={'Date': 'Date', 'Temperature': 'Rolling_Avg_Temperature'})\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of strings where each string includes a person's full name in the format \"Last, First\". I want to split this column into two new columns: one for the first name and one for the last name. However, I noticed that some names also have a middle name or initial included, and I only want the first name to be extracted, regardless of its presence. \n\nHere\u2019s how my DataFrame looks:\n```\n    Names\n0  Smith, John A.\n1  Doe, Jane\n2  Johnson, Emily R.\n```\nI want to achieve a DataFrame that looks like this:\n```\n    First Name    Last Name\n0      John         Smith\n1      Jane         Doe\n2      Emily        Johnson\n```\nI have the following code, but I am struggling to properly extract the first and last names:\n```\ndf[['Last Name', 'First Name']] = df['Names'].str.split(',', expand=True)\n```\nThis splits the Last and First names but includes the middle name with the first name. How can I just get the first name?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Names': ['Smith, John A.', 'Doe, Jane', 'Johnson, Emily R.']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['Names'].str.split(',', expand=True)\nresult.columns = ['Last Name', 'First Name']\nresult['First Name'] = result['First Name'].str.split().str[0]\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor in PyTorch and need to efficiently manipulate it. Specifically, I want to sum a scalar value to all non-zero elements in a 3D sparse tensor. The tensor is initialized as follows:\n\n```python\nimport torch\nsparse_tensor = torch.sparse_coo_tensor(indices=torch.tensor([[0, 1, 1, 2], [0, 2, 3, 1]]), \n                                        values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n                                        size=(3, 4))\n```\n\nNow, I want to add a scalar value of 5 to all non-zero elements in `sparse_tensor`. \n\nWhat should I use to accomplish this?\n\nA:\n<code>\nscalar = 5\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = sparse_tensor + scalar * sparse_tensor.to_dense().clamp(min=0)"
  },
  {
    "input": "Problem:\nI have a dataset that contains employee performance metrics across multiple departments, formatted as follows:\n\n| EmployeeID | Department | PerformanceScores          |\n|------------|------------|----------------------------|\n| 1          | HR         | [3, 5, 4]                  |\n| 2          | IT         | [4, 4, 5]                  |\n| 3          | HR         | [2, 3, 4]                  |\n| 4          | Sales      | [5, 3, 2]                  |\n| 5          | IT         | [4, 5, 4]                  |\n| 6          | Sales      | [3, 5, 3]                  |\n\nI want to create a function that computes the average performance score for each employee, but I also want to store the maximum score achieved. Given the current dataframe, this is what I have tried:\n\n```python\ndf['AverageScore'] = df['PerformanceScores'].apply(lambda x: sum(x) / len(x))\n```\n\nHowever, I also want to keep track of the maximum score. Can you help create a function `calculate_performance_metrics` that takes a dataframe as input and returns a new dataframe including two new columns: 'AverageScore' and 'MaxScore'?\n\nYour function should look something like:\n\n```python\ndef calculate_performance_metrics(df):\n    df['AverageScore'] = ...\n    df['MaxScore'] = ...\n    return df\n```\n\nUsing the above dataframe, `df` should be transformed to include the 'AverageScore' and 'MaxScore'. \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4, 5, 6],\n    'Department': ['HR', 'IT', 'HR', 'Sales', 'IT', 'Sales'],\n    'PerformanceScores': [[3, 5, 4], [4, 4, 5], [2, 3, 4], [5, 3, 2], [4, 5, 4], [3, 5, 3]]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef calculate_performance_metrics(df):\n    df['AverageScore'] = df['PerformanceScores'].apply(lambda x: sum(x) / len(x))\n    df['MaxScore'] = df['PerformanceScores'].apply(lambda x: max(x))\n    return df\n```"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains email addresses in a single column. The DataFrame is structured like this:\n\nemail_df = pd.DataFrame({'email': ['alice@example.com', 'bob@domain.com', 'charlie123@service.org', 'david@company.org', 'eve@xyz.com']})\n\nYour goal is to extract the username and domain from each email address and create two new columns: 'username' and 'domain'. The final DataFrame should look like this:\n\n|      username      |         domain        |\n|---------------------|-----------------------|\n|       alice         |      example.com      |\n|         bob         |       domain.com      |\n|     charlie123      |      service.org      |\n|        david        |      company.org      |\n|         eve         |        xyz.com        |\n\nYou'd like to accomplish this using string manipulation methods in pandas. Start by applying code to extract the username and domain appropriately. \n\nHere is your input DataFrame structure:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email': ['alice@example.com', 'bob@domain.com', 'charlie123@service.org', 'david@company.org', 'eve@xyz.com']})\n```\n\nYour task is to fill in the blank below to create the columns 'username' and 'domain':\n```python\nemail_df[['username', 'domain']] = ...\n```",
    "output": "\n```python\nemail_df[['username', 'domain']] = email_df['email'].str.split('@', expand=True)\n```"
  },
  {
    "input": "### Problem:\nI have a time series dataset represented in a Pandas DataFrame where the index is a datetime object. The DataFrame contains daily sales data for a store. I want to calculate a moving average of the sales over a 7-day window, and I also want to retain the original index format.\n\nHere is an example of the DataFrame structure:\n\n```\n             sales\ndate               \n2023-01-01    200\n2023-01-02    210\n2023-01-03    180\n2023-01-04    240\n2023-01-05    220\n2023-01-06    190\n2023-01-07    210\n2023-01-08    250\n2023-01-09    260\n2023-01-10    240\n```\n\nHow can I compute the moving average and save it in a new column named `moving_average` in the same DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'sales': [200, 210, 180, 240, 220, 190, 210, 250, 260, 240]}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\ndf['moving_average'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "## Problem:\nYou have a 2D tensor representing image data in PyTorch, where each element represents a pixel value. The tensor shape is `(batch_size, height, width)`. You want to normalize the pixel values in the tensor to a range between 0 and 1 using Min-Max normalization. Specifically, the normalization formula you want to apply is:\n\n\\[ \\text{normalized\\_value} = \\frac{\\text{value} - \\text{min}}{\\text{max} - \\text{min}} \\]\n\nHow can you perform this operation on a given tensor `image_tensor` using PyTorch? \n\nA:\n```python\nimport torch\n\nimage_tensor = load_data()  # Assume this gives a tensor of shape (batch_size, height, width)\nmin_val = image_tensor.min()\nmax_val = image_tensor.max()\n# Fill in the blank below to get the normalized image tensor\nnormalized_image = ...  # put solution in this variable\n```",
    "output": "\n```python\nnormalized_image = (image_tensor - min_val) / (max_val - min_val)\n```"
  },
  {
    "input": "Problem:\n\nI am building a neural network to classify images using both TensorFlow and PyTorch. I need to apply a common preprocessing step to my image tensor that consists of normalizing it by subtracting the mean and dividing by the standard deviation per channel. The images are represented as a tensor in the shape of (batch_size, height, width, channels). \n\nGiven a tensor `images` and the mean and standard deviation tensors `mean` and `std`, how can I perform this normalization for both frameworks?\n\nMCVE\nDesired Output\n\nimport torch\nimport tensorflow as tf\n\n# PyTorch normalization\nimages_pytorch = torch.rand((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean = torch.tensor([0.5, 0.5, 0.5])  # mean for each channel\nstd = torch.tensor([0.2, 0.2, 0.2])   # std for each channel\n\n# TensorFlow normalization\nimages_tensorflow = tf.random.uniform((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean_tf = tf.constant([0.5, 0.5, 0.5])  # mean for each channel\nstd_tf = tf.constant([0.2, 0.2, 0.2])    # std for each channel\n\n# PyTorch normalization\nnormalized_images_pt = ...  # put solution in this variable\n\n# TensorFlow normalization\nnormalized_images_tf = ...  # put solution in this variable\n\nA:\n<code>\nimages_pt, mean, std = load_data()\n</code>\nnormalized_images_pt = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nnormalized_images_pt = (images_pytorch - mean[None, None, None, :]) / std[None, None, None, :]\nnormalized_images_tf = (images_tensorflow - mean_tf) / std_tf\n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset that records daily sales of a product over several months. The data is organized in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=60, freq='D'),\n        'sales': np.random.poisson(lam=200, size=60)}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\n\nYou want to calculate a moving average of the sales data over a 7-day window. However, you also want to exclude the moving average for days where the sales count is below 150. Fill in the blank with the correct code to create a new column in the DataFrame that contains the desired moving average, ensuring that it doesn't include values below 150:\n\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean() # fill in this code to apply the condition\n```\n\nWhat code would replace the `# fill in this code to apply the condition` comment? \n\nA:\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean().where(df['sales'] >= 150)\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].where(df['sales'] >= 150).rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset represented as a list of dictionaries containing information about various products in an e-commerce store. Each dictionary has the following structure: `{'product_name': str, 'price': float, 'category': str, 'quantity': int}`. You want to create a function that, given this dataset, will return a new list of dictionaries that contains only the products in a specified category and includes an additional field `total_value` which is calculated as `price * quantity`.\n\nYour list of products looks like this:\n\n```python\nproducts = [\n    {'product_name': 'Laptop', 'price': 999.99, 'category': 'Electronics', 'quantity': 10},\n    {'product_name': 'Headphones', 'price': 199.99, 'category': 'Electronics', 'quantity': 5},\n    {'product_name': 'Desk', 'price': 149.99, 'category': 'Furniture', 'quantity': 2},\n    {'product_name': 'Chair', 'price': 89.99, 'category': 'Furniture', 'quantity': 4}\n]\n```\n\nWrite a function `filter_products_by_category(products, category)` that filters the products by the given category and calculates the `total_value` for each product. Use the function to call `filter_products_by_category(products, 'Electronics')`.\n\nA:\n```python\ndef filter_products_by_category(products, category):\n    # Your code here\n    return filtered_products\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef filter_products_by_category(products, category):\n    filtered_products = []\n    for product in products:\n        if product['category'] == category:\n            product['total_value'] = product['price'] * product['quantity']\n            filtered_products.append(product)\n    return filtered_products\n\nresult = filter_products_by_category(products, 'Electronics')\n```"
  },
  {
    "input": "## Problem\nI have a set of images in a tensor `images` of shape `(batch_size, height, width, channels)` and a corresponding tensor of labels `labels` of shape `(batch_size,)`. I want to build a simple neural network model using PyTorch that will classify these images into one of the `num_classes` categories. I am using the `nn.CrossEntropyLoss` as my loss function. \n\nAfter defining my model and putting it in training mode, I have the following code to calculate the predictions from the model and the loss. How can I get the predicted class indices from the raw model outputs `outputs`?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\n# Assuming the model and data is already defined\noutputs = model(images)  # outputs has shape (batch_size, num_classes)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(outputs, labels)\n\n# I need to fill in this part to get the predicted class indices\npredicted_classes = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = torch.argmax(outputs, dim=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a time series DataFrame containing daily temperature readings for a city over a year, indexed by date. I want to calculate a rolling average temperature over the last 7 days for each date. After calculating the rolling average, I want to create a new DataFrame that contains only the dates where the rolling average was above a specified threshold. The DataFrame is defined as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(start='2023-01-01', periods=365)\ntemperatures = np.random.normal(loc=20, scale=5, size=len(dates))  # Average temperature around 20\u00b0C\ntemp_df = pd.DataFrame(data=temperatures, index=dates, columns=['Temperature'])\n```\n\nNow, I want to extract the dates where the rolling average is greater than a threshold of 22\u00b0C. To achieve this, I'm looking to complete the following code:\n\n```python\nrolling_avg = temp_df['Temperature'].rolling(window=7).mean()\nfiltered_dates = ... # put solution in this variable\n```\n",
    "output": "\n```python\nfiltered_dates = temp_df[rolling_avg > 22].index\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales for different products, structured as follows:\n\n```python\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI want to analyze the sales data by filling in the missing dates for each product and ensuring that the `sales` value for those missing dates is set to zero. The desired output should retain the product column and include continuous dates, even for those with no sales recorded.\n\nHow can I achieve this? \n\nThe expected output should look like this:\n\n```\n        date product  sales\n0 2023-01-01       A    100\n1 2023-01-02       A    150\n2 2023-01-03       A      0\n3 2023-01-04       A      0\n4 2023-01-05       A    130\n5 2023-01-06       A      0\n6 2023-01-01       B      0\n7 2023-01-02       B      0\n8 2023-01-03       B    200\n9 2023-01-04       B      0\n10 2023-01-05       B      0\n11 2023-01-06       B    180\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndate_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\nproducts = df['product'].unique()\ndf_full = pd.MultiIndex.from_product([date_range, products], names=['date', 'product']).to_frame(index=False)\ndf_full = df_full.merge(df, on=['date', 'product'], how='left').fillna(0)\ndf_full['sales'] = df_full['sales'].astype(int)\ndf = df_full.sort_values(by=['date', 'product']).reset_index(drop=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a tensor representing image data, specifically for a batch of images in the format (batch_size, channels, height, width). I want to apply a basic thresholding operation to each image in the batch. The thresholding will set all pixel values below a certain threshold to zero and leave the others unchanged. I want to achieve this efficiently without converting to a numpy array. \n\nGiven a 4D tensor for the images and a specified threshold, how can I perform this operation directly on the tensor?\n\nFor example, if I have:\n\n```python\nimport torch \nimages = torch.rand((5, 3, 256, 256))  # 5 images, 3 channels, 256x256 pixels\nthreshold = 0.5\n```\n\nI want to apply the thresholding operation with:\n\n```python\nresult_tensor = ...\n```\n\nFill in the blank with the appropriate PyTorch operation to achieve this.",
    "output": "\n```python\nresult_tensor = images * (images >= threshold).float()\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix represented in coordinate format (COO) and I'm trying to convert it into a dense NumPy array while rearranging the non-zero values in a specific order. The sparse matrix is as follows:\n\n```\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\n```\n\nThis creates a sparse matrix where only the specified (row, col) pairs have non-zero values. I want to convert this sparse matrix into a dense 3x3 NumPy array in a way that the values appear in descending order of their row indices first, and if there are duplicates in the row indices, they should be sorted by their column indices. \n\nHow can I achieve this? \n\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\n# Create the sparse matrix\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\nsparse_matrix = coo_matrix((data, (row, col)), shape=(3, 3))\n</code>\ndense_array = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_array = np.zeros((3, 3))\nsorted_indices = sorted(zip(row, col, data), key=lambda x: (-x[0], x[1]))\nfor r, c, v in sorted_indices:\n    dense_array[r, c] = v\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains details about book sales, including the title, author, and number of copies sold. I want to create a function that calculates the total sales for each author and returns the results as a new DataFrame. Here's a glimpse of my DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Title': ['Book A', 'Book B', 'Book C', 'Book D', 'Book E'],\n    'Author': ['Author 1', 'Author 2', 'Author 1', 'Author 2', 'Author 3'],\n    'Copies Sold': [150, 200, 100, 300, 50]\n})\n```\n\nThe desired output should group the sales by author and sum the total copies sold, resulting in a DataFrame that looks like this:\n\n```\n       Author  Total Sales\n0    Author 1          250\n1    Author 2          500\n2    Author 3           50\n```\n\nHere is my attempt at calculating the total sales:\n\n```python\ndef calculate_total_sales(df):\n    # this function should return a new DataFrame with total sales per author\n    pass\n\nresult = calculate_total_sales(df) # put the solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df):\n    total_sales = df.groupby('Author')['Copies Sold'].sum().reset_index()\n    total_sales.columns = ['Author', 'Total Sales']\n    return total_sales\n\nresult = calculate_total_sales(df) # put the solution in this variable\n```"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains a column with mixed strings, and I need to extract only the email addresses from this column into a separate list. The dataframe looks like this:\n\ndata\n0  John Doe john.doe@example.com\n1  Jane Smith janesmith@web.net\n2  No Email Here\n3  Contact us at support@mywebsite.org\n4  Another Guy with email: anotherguy@domain.com\n\nI am currently struggling to filter the valid email addresses using regex and pandas string operations. Can you help me extract these email addresses into a list?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'data': ['John Doe john.doe@example.com',\n                            'Jane Smith janesmith@web.net',\n                            'No Email Here',\n                            'Contact us at support@mywebsite.org',\n                            'Another Guy with email: anotherguy@domain.com']})\n</code>\nemails = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nemails = df['data'].str.extractall(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})')[0].tolist()  \n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing product descriptions, and I want to extract the brand name and product type from a \"description\" column. The descriptions follow the format \"Brand: [brand name], Type: [product type]\". I would like to create two new columns: \"brand\" and \"type\" filled with the corresponding values.\n\nHere's the DataFrame I have:\n```python\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\n\nWhat is the correct code to parse the \"description\" column and create the new \"brand\" and \"type\" columns?\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\nproduct_df[['brand', 'type']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nproduct_df[['brand', 'type']] = product_df['description'].str.extract(r'Brand: (.*?), Type: (.*)')\n```"
  },
  {
    "input": "Problem:\n\nYou are developing a neural network in TensorFlow to classify images into one of four categories. After training the model, you need to convert the model predictions, which come as a tensor of shape (n, 4), into integer class labels indicating the most likely category for each prediction.\n\nThe tensor output from your model looks something like this:\n\n[[0.1, 0.2, 0.6, 0.1],\n [0.4, 0.3, 0.2, 0.1],\n [0.25, 0.25, 0.25, 0.25],\n [0.7, 0.1, 0.1, 0.1]]\n\nYour goal is to extract the index of the maximum value from each row of this tensor, which corresponds to the predicted class label (0, 1, 2, or 3) for each input sample.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.1, 0.2, 0.6, 0.1],\n                            [0.4, 0.3, 0.2, 0.1],\n                            [0.25, 0.25, 0.25, 0.25],\n                            [0.7, 0.1, 0.1, 0.1]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI'm building a neural network model in TensorFlow and PyTorch to classify images from the CIFAR-10 dataset. After training the model, I want to visualize the predictions made on a batch of images. The model outputs a tensor `predictions` of shape `[batch_size, 10]` where each row contains the predicted probabilities for each class. To determine the final predicted class for each image, I need to extract the indices of the maximum values along the class dimension. \n\nAssuming I have the following tensor:\n```python\npredictions = tf.constant([[0.1, 0.2, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n                           [0.0, 0.1, 0.1, 0.0, 0.0, 0.3, 0.5, 0.0, 0.0, 0.0],\n                           [0.2, 0.0, 0.0, 0.1, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0]])\n```\n\nI need to create a tensor indicating the index of the class with the highest predicted probability for each image. How can I achieve this using TensorFlow?\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.1, 0.2, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n                           [0.0, 0.1, 0.1, 0.0, 0.0, 0.3, 0.5, 0.0, 0.0, 0.0],\n                           [0.2, 0.0, 0.0, 0.1, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "Problem:\n\nI need to analyze a list of customer purchase records that includes various attributes. Each record is a dictionary with keys: 'customer_id', 'item', 'quantity', and 'price'. I want to create a function that takes this list of records and returns the total revenue generated, which is calculated as the sum of `quantity * price` for each record. \n\nFor example, given the following records:\n\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n\nI would expect your function to return a total revenue of 4.0.\n\nA:\n<code>\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n</code>\ntotal_revenue = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ntotal_revenue = sum(record['quantity'] * record['price'] for record in records)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame with the following structure:\n\n```\n|   product_id | rating | review_count |\n|--------------|--------|--------------|\n|            1 |      5 |           10 |\n|            2 |      4 |            5 |\n|            3 |      3 |          100 |\n|            4 |      2 |             0 |\n|            5 |      1 |           30 |\n```\n\nI would like to create a new column `quality` that categorizes products based on their `rating` and `review_count`. The criteria are as follows:\n- If the `rating` is 4 or higher and `review_count` is greater than 10, label it as \"High Quality\".\n- If the `rating` is between 3 and 4 (inclusive) and `review_count` is greater than 0, label it as \"Moderate Quality\".\n- Otherwise, label it as \"Low Quality\".\n\nMy current function approach is not very efficient. Here is my code so far:\n\n```python\ndef categorize_quality(row):\n    if row['rating'] >= 4 and row['review_count'] > 10:\n        return 'High Quality'\n    elif 3 <= row['rating'] < 4 and row['review_count'] > 0:\n        return 'Moderate Quality'\n    else:\n        return 'Low Quality'\n\ndf['quality'] = df.apply(categorize_quality, axis=1)\n```\n\nI want to optimize this code to avoid using `apply`. How can I implement a custom function that achieves this more efficiently?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4, 5],\n    'rating': [5, 4, 3, 2, 1],\n    'review_count': [10, 5, 100, 0, 30]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['quality'] = pd.cut(\n    df['rating'].where(df['review_count'] > 10, 0),\n    bins=[-1, 2, 3, 4, 5],\n    labels=['Low Quality', 'Low Quality', 'Moderate Quality', 'High Quality'],\n    right=True\n).fillna('Low Quality')\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains a column with comments where users sometimes mention specific products using hashtags. I want to extract these product mentions into a new column. For example, if a comment contains \"#ProductA\" or \"#ProductB\", I want to create a new column that lists all mentioned products in a single string, separated by commas. \n\nHere is what my DataFrame looks like:\n\n```\n   User        Comment\n0   Alice     Great #ProductA!\n1   Bob       I love #ProductB and #ProductA.\n2   Charlie   No products mentioned.\n3   Dave      Just purchased #ProductC.\n```\n\nI need to extract the hashtags (product mentions) from the Comment column and save them in a new column called 'Mentioned_Products'. The rows without any product mentions should have an empty string in the new column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'User': ['Alice', 'Bob', 'Charlie', 'Dave'],\n    'Comment': ['Great #ProductA!', 'I love #ProductB and #ProductA.', 'No products mentioned.', 'Just purchased #ProductC.']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['Mentioned_Products'] = df['Comment'].str.extractall(r'(#\\w+)')[0].groupby(level=0).agg(', '.join).reindex(df.index, fill_value='').astype(str)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix representing customer purchase data, where each row corresponds to a customer and each column corresponds to a product. The matrix contains purchase counts, but many entries are zero (indicating no purchase). I want to normalize this matrix so that each row sums to 1 (i.e., each customer's purchases are represented as a proportion of their total purchases). If a row sums to zero, it should remain unchanged.\n\nHere is my sparse matrix:\n\n```python\nfrom scipy import sparse\npurchase_data = sparse.csr_matrix([[0, 0, 3], [0, 0, 0], [2, 0, 0], [0, 5, 0]])\n```\n\nI would like to achieve the normalization with the following code structure. \n\nnormalized_matrix = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nrow_sums = purchase_data.sum(axis=1).A1\nnormalized_matrix = purchase_data.copy()\nfor i in range(normalized_matrix.shape[0]):\n    if row_sums[i] > 0:\n        normalized_matrix[i] = normalized_matrix[i] / row_sums[i]\n</code>\n```"
  },
  {
    "input": "Problem:\nYou have a list of dictionaries representing sales data from a store. Each dictionary contains information about the product sold, quantity sold, and price per unit. You want to implement a function that calculates the total revenue generated for each product and returns a list of dictionaries with the product name and the calculated total revenue.\n\nFor example:\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nYour desired output should be:\n[\n    {'product': 'apple', 'total_revenue': 19.5},\n    {'product': 'banana', 'total_revenue': 3.75},\n    {'product': 'orange', 'total_revenue': 8.0}\n]\n\nDefine your function below:\n<code>\ndef calculate_revenue(sales_data):\n    revenue_dict = {}\n    for sale in sales_data:\n        product = sale['product']\n        total = sale['quantity'] * sale['price_per_unit']\n        # Your code here\n    return [{'product': product, 'total_revenue': revenue} for product, revenue in revenue_dict.items()]\n\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n        if product in revenue_dict:\n            revenue_dict[product] += total\n        else:\n            revenue_dict[product] = total\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a sparse tensor representing a collection of images in a batch of size `10`, each with a height of `32` pixels, width of `32` pixels, and `3` color channels. The tensor uses a coordinate format and has only a few values set. You want to replace all values in this tensor that are below a certain threshold (e.g., `0.5`) with a set value, `1.0`.\n\nGiven your sparse tensor and threshold, how can you fill in the gaps with `1.0` for all elements below this threshold without modifying the existing values above the threshold?\n\nYour starting code looks like this:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse.FloatTensor(\n    torch.tensor([[0, 0, 1], [1, 2, 3]]), \n    torch.tensor([0.1, 0.8, 0.4, 0.7])\n)\nthreshold = 0.5\n```\n\nYou need to fill the sparse tensor. \n\nPlease complete the following line of code to achieve this:\n\n```python\nfilled_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\nfilled_tensor = sparse_tensor.to_dense().clamp(min=threshold).masked_fill(sparse_tensor.to_dense() < threshold, 1.0)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of product sales that includes information on product IDs, quantities sold, and prices. You want to calculate the total revenue for each product. Write a custom function `calculate_revenue` that takes three lists: `product_ids`, `quantities`, and `prices`. The function should return a dictionary where the keys are the product IDs and the values are the corresponding total revenue (calculated as quantity sold multiplied by price). \n\nHere's an example of the data you will be working with:\n\n```python\nproduct_ids = ['A101', 'B202', 'C303', 'A101', 'B202']\nquantities = [10, 5, 3, 2, 7]\nprices = [20, 50, 100, 20, 50]\n```\n\nFill in the blank for the line where the output of your function is assigned.\n\n```python\nproduct_ids = ['A101', 'B202', 'C303', 'A101', 'B202']\nquantities = [10, 5, 3, 2, 7]\nprices = [20, 50, 100, 20, 50]\n\ndef calculate_revenue(product_ids, quantities, prices):\n    revenue_dict = {}\n    # Implement your code here\n    \n    return revenue_dict\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = calculate_revenue(product_ids, quantities, prices)\n```"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains user activity logs for an online platform, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'UserId': [101, 102, 103, 101, 102, 104, 105, 101, 103, 102],\n    'Activity': ['login', 'signup', 'login', 'logout', 'login', 'signup', 'logout', 'login', 'logout', 'login'],\n    'Timestamp': pd.to_datetime(['2023-01-01 10:00', '2023-01-02 11:00', '2023-01-02 12:00', \n                                  '2023-01-01 14:00', '2023-01-02 14:00', '2023-01-03 09:00', \n                                  '2023-01-03 10:00', '2023-01-04 15:00', '2023-01-04 16:00', \n                                  '2023-01-04 17:00'])\n})\n\n```\n\nI would like to create a custom function that processes this dataframe to add a new column called `'SessionDuration'`. This column will calculate the duration of sessions (in minutes) for each user based on their login and logout activities. A session is defined as the time between the first login and the corresponding logout for each user.\n\nThe expected output, after applying this custom function, will include the original dataframe with an additional column for `'SessionDuration'` that reflects the session duration in minutes for users who logged out.\n\nThanks!\n\n```python\n# Define the function here\ndef calculate_session_duration(df):\n    # Your code goes here to compute session durations\n    ...\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndef calculate_session_duration(df):\n    df['SessionDuration'] = None\n    for user in df['UserId'].unique():\n        user_logs = df[df['UserId'] == user]\n        logins = user_logs[user_logs['Activity'] == 'login']\n        logouts = user_logs[user_logs['Activity'] == 'logout']\n        \n        for index, login in logins.iterrows():\n            corresponding_logout = logouts[logouts['Timestamp'] > login['Timestamp']]\n            if not corresponding_logout.empty:\n                duration = (corresponding_logout.iloc[0]['Timestamp'] - login['Timestamp']).total_seconds() / 60\n                df.loc[index, 'SessionDuration'] = duration\n    return df\n\nresult = calculate_session_duration(data)\n```"
  },
  {
    "input": "Problem:\nYou have a time series dataset stored in a DataFrame with the following structure:\n\n| date       | value |\n|------------|-------|\n| 2021-01-01 | 10    |\n| 2021-01-02 | 15    |\n| 2021-01-03 | 13    |\n| 2021-01-04 | 20    |\n| 2021-01-05 | 22    |\n| 2021-01-06 | 25    |\n\nYour goal is to calculate the rolling average of the 'value' column over a window size of 3 days. You also want the result to be in a new column named 'rolling_avg' in the original DataFrame. \n\nHere is the initial setup of your code:\n\n```python\nimport pandas as pd\ndata = {\n    'date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06'],\n    'value': [10, 15, 13, 20, 22, 25]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nThe final code you need to complete is:\n\n```python\ndf['rolling_avg'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['value'].rolling(window=3).mean()\n```"
  },
  {
    "input": "### Problem:\nI have a DataFrame that contains stock price data like this:\n\ndate          | ticker      | closing_price\n--------------|-------------|---------------\n2023-01-01    | AAPL        | 150.00\n2023-01-01    | MSFT        | 300.00\n2023-01-02    | AAPL        | 155.00\n2023-01-02    | MSFT        | 305.00\n2023-01-03    | AAPL        | 157.00\n2023-01-03    | MSFT        | 310.00\n2023-01-04    | AAPL        | 156.00\n2023-01-04    | MSFT        | 308.00\n\nI need to calculate the daily percentage change in the closing price for each stock ticker and add this as a new column to the DataFrame. The desired output format should look like this:\n\ndate          | ticker      | closing_price | pct_change\n--------------|-------------|---------------|-------------\n2023-01-01    | AAPL        | 150.00        | NaN\n2023-01-01    | MSFT        | 300.00        | NaN\n2023-01-02    | AAPL        | 155.00        | 3.33\n2023-01-02    | MSFT        | 305.00        | 1.67\n2023-01-03    | AAPL        | 157.00        | 1.29\n2023-01-03    | MSFT        | 310.00        | 1.61\n2023-01-04    | AAPL        | 156.00        | -0.64\n2023-01-04    | MSFT        | 308.00        | -0.65\n\nWhat code should I use to achieve this? Here is the initial setup:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', \n             '2023-01-03', '2023-01-03', '2023-01-04', '2023-01-04'],\n    'ticker': ['AAPL', 'MSFT', 'AAPL', 'MSFT', \n                'AAPL', 'MSFT', 'AAPL', 'MSFT'],\n    'closing_price': [150.00, 300.00, 155.00, 305.00, \n                      157.00, 310.00, 156.00, 308.00]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, please provide the code to compute the 'pct_change' column. The calculation of percentage change can be done using the following syntax:\n```python\ndf['pct_change'] = ...\n```",
    "output": "\n```python\ndf['pct_change'] = df.groupby('ticker')['closing_price'].pct_change() * 100\n```"
  },
  {
    "input": "Problem:\nI have a dataset that contains product reviews in a DataFrame. Each review is a string of text in a column named \"review\". I want to extract the product names mentioned at the beginning of each review, which are always followed by the keyword \"reviewed\". However, the reviews may also contain punctuation or multiple spaces. For example:\n\n| review                       |\n|------------------------------|\n| \"ProductA reviewed this item ...\" |\n| \"ProductB     reviewed it ...\"  |\n| \"An excellent experience with ProductC reviewed\" |\n\nI need to create a new column called \"product_name\" that contains just the product names extracted from the reviews.\n\nHere is how my DataFrame looks:\n\n```python\ndf = pd.DataFrame({\n    'review': [\n        \"ProductA reviewed this item ...\",\n        \"ProductB     reviewed it ...\",\n        \"An excellent experience with ProductC reviewed\"\n    ]\n})\n```\n\nI am struggling to implement this extraction correctly. Can you help me fill in the missing piece of code here?\n\n---\n\ndf['product_name'] = df['review'].str.extract(r'^\\s*(.*?)\\s+reviewed')\n\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df['product_name']\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix of shape (5, 5) represented in COO format, filled with random integers. I want to convert this sparse matrix to a dense NumPy array and then extract the diagonal elements as a 1D array. Here's the sparse matrix I created:\n\n```\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\n\nGiven the `sparse_matrix`, please provide the code to obtain the diagonal elements in a 1D NumPy array.\n\nA:\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\ndiagonal_elements = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndiagonal_elements = sparse_matrix.toarray().diagonal()\n```"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains a column of addresses in the following format:\n```plaintext\naddress\n123 Main St, Springfield, IL 62704\n456 Elm St, Smalltown, TX 75000\n789 Oak Ave, Metropolis, NY\n101 Pine Ln, Gotham City, NJ 07001\n```\nI want to extract the street name and city into two separate columns. The final DataFrame should look like this:\n```plaintext\n     street_name        city\n0   123 Main St  Springfield\n1    456 Elm St    Smalltown\n2     789 Oak Ave   Metropolis\n3   101 Pine Ln   Gotham City\n```\nI've tried using regular expressions, but I'm struggling to properly extract these parts. Here's what I have so far:\n```python\nimport pandas as pd\n\ndata = {'address': ['123 Main St, Springfield, IL 62704',\n                    '456 Elm St, Smalltown, TX 75000',\n                    '789 Oak Ave, Metropolis, NY',\n                    '101 Pine Ln, Gotham City, NJ 07001']}\ndf = pd.DataFrame(data)\n```\nWhat should I fill in for the code to achieve this output?\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['street_name', 'city']] = df['address'].str.extract(r'([^,]+),\\s*([^,]+),?\\s*[A-Z]{2}\\s*\\d{0,5}')\nresult = df[['street_name', 'city']]\n</code>"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing product information as follows:\n```python\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nI want to extract the product name and price into two separate columns: `product_name` and `product_price`. The final DataFrame should look like this:\n```\n  product_name  product_price\n0        Apple          1.50\n1       Banana          0.75\n2       Cherry          3.00\n3         Date          2.50\n```\nI've attempted to use string splitting but it hasn't worked as intended. The column entries always include unwanted spaces. Please help me extract these values properly.\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nproduct_df[['product_name', 'product_price']] = product_df['product_info'].str.split(' - \\$', expand=True)\nproduct_df['product_price'] = product_df['product_price'].astype(float)\nproduct_df['product_name'] = product_df['product_name'].str.strip()\nproduct_df = product_df[['product_name', 'product_price']]\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a dataset consisting of images that you want to preprocess before feeding them into a neural network for classification. The images are stored in a 4D tensor of shape (batch_size, height, width, channels). You would like to normalize the pixel values to be between 0 and 1 using PyTorch. \n\nGiven a 4D tensor `images`, how can you normalize it?\n\nA:\n\n<code>\nimport torch\n\nbatch_size, height, width, channels = 10, 32, 32, 3\nimages = torch.randn(batch_size, height, width, channels) * 255  # Simulated image data with pixel values from 0 to 255\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nnormalized_images = images / 255.0\n</code>",
    "output": "\n<code>\nnormalized_images = images / 255.0\n</code>"
  },
  {
    "input": "Problem:\n\nI have a large sparse matrix represented as a `csr_matrix` in SciPy that contains customer purchase data across different product categories. Each customer is a row, and each product category is a column. Some product categories may have missing data (zeros), which I want to identify. \n\nTo optimize for memory, I would like to find the indices of all non-zero elements in the sparse matrix and store them in a list of tuples, each representing the (row_index, column_index) pairs. For example, if I have a sparse matrix that looks like this:\n\n```\n[[0, 1, 0],\n [0, 0, 3],\n [4, 0, 0]]\n```\n\nThe output should be:\n```\n[(0, 1), (1, 2), (2, 0)]\n```\n\nHow can I achieve this using the `tocoo()` method of the sparse matrix to get the necessary indices?\n\nA:\n<code>\nfrom scipy import sparse\n\n# Assuming `sparse_matrix` is your csr_matrix\nsparse_matrix = sparse.csr_matrix([[0, 1, 0], [0, 0, 3], [4, 0, 0]])\n</code>\nnon_zero_indices = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnon_zero_indices = list(zip(*sparse_matrix.nonzero()))\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product information with a column of product codes that includes both letters and numbers, and I want to extract only the numeric part from these codes into a new column. Here\u2019s how my DataFrame looks:\n\n      Product_Code\n0     AB12345\n1     CD67890\n2     EF23456\n3     GH89012\n4     IJ34567\n\nI would like to achieve the following output:\n\n      Product_Code  Numeric_Code\n0     AB12345        12345\n1     CD67890        67890\n2     EF23456        23456\n3     GH89012        89012\n4     IJ34567        34567\n\nHow can I do this using the `str.extract` method in pandas to create the new column?\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Product_Code': ['AB12345', 'CD67890', 'EF23456', 'GH89012', 'IJ34567']})\n</code>\ndf['Numeric_Code'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Numeric_Code'] = df['Product_Code'].str.extract('(\\d+)')"
  },
  {
    "input": "### Problem:\nI have a dataset containing product reviews, and I need to extract the numerical ratings from a comments column that contains both text and the ratings. The reviews are mixed with non-numeric characters, such as \"Rating: 4/5\", \"This is great, I give it 5!\", or \"Not worth it - scored 2 out of 5\". I want to create a new column that contains just the numerical ratings extracted from these strings, ideally as floats.\n\nHere is my dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review': [\n        'Rating: 4/5 Awesome product!',\n        'This is great, I give it 5!',\n        'Not worth it - scored 2 out of 5',\n        'Excellent experience with 4.5/5',\n        'Completely satisfied with a score of 5'\n    ]\n})\n```\n\nI\u2019ve attempted to use regex to find the ratings, but I am struggling to get it to work correctly. I want to extract the ratings as floats. \n\nYour task is to write the missing code for extracting the ratings into a new column called \"rating\" in the dataframe below:\n\n```python\ndf['rating'] = ...\n```\n\nEnsure that your final ratings are in the range of 0 to 5.",
    "output": "\n```python\ndf['rating'] = df['review'].str.extract(r'(\\d+\\.?\\d*)/?\\s*5?')[0].astype(float)\ndf['rating'] = df['rating'].clip(0, 5)\n```"
  },
  {
    "input": "Problem:\nYou are working on a neural network model for image classification using TensorFlow. You have a batch of images represented as a 4D tensor and want to apply a dropout layer to prevent overfitting. The dropout rate is specified and you need to ensure that the dropout is applied correctly. Assuming `images` is your input tensor with shape (batch_size, height, width, channels), fill in the blank to apply the dropout layer with the specified rate.\n\nA:\n<code>\nimport tensorflow as tf\n\nimages = tf.random.normal((32, 64, 64, 3))  # Example shape for a batch of images\ndropout_rate = 0.5\n</code>\noutput = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\noutput = tf.keras.layers.Dropout(rate=dropout_rate)(images)\n</code>",
    "output": "\n<code>\noutput = tf.keras.layers.Dropout(rate=dropout_rate)(images, training=True)\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing hourly temperature measurements recorded over several days. The DataFrame looks as follows:\n\n```python\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYou need to calculate the daily average temperature and include it in the original DataFrame with a new column named `Daily_Avg`. The output should have the same rows as the original DataFrame, but with the daily average values appropriate for each timestamp's date. \n\nWhat code would you use to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n</code>\ndf['Daily_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Daily_Avg'] = df.groupby(df['Timestamp'].dt.date)['Temperature'].transform('mean')  \n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing daily temperature readings as follows:\n\n```\n   Date         Temperature\n0  2022-01-01    30\n1  2022-01-02    28\n2  2022-01-03    32\n3  2022-01-04    35\n4  2022-01-05    29\n5  2022-01-06    31\n```\n\nYou need to calculate the 3-day rolling average temperature. The resulting DataFrame should include a new column for the rolling average, with the first two rows of the new column containing NaN values because there are not enough prior days to compute the average. Furthermore, you want to convert the Date column from a string format to a datetime format before performing the rolling average computation.\n\nThe expected resulting DataFrame should look like this:\n\n```\n   Date         Temperature  Rolling_Avg\n0  2022-01-01    30          NaN\n1  2022-01-02    28          NaN\n2  2022-01-03    32          30.0\n3  2022-01-04    35          31.0\n4  2022-01-05    29          32.0\n5  2022-01-06    31          31.0\n```\n\nHere is the current code snippet that you have, but it is incomplete:\n\n```\nimport pandas as pd\nimport numpy as np\n\ndata = {'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06'],\n        'Temperature': [30, 28, 32, 35, 29, 31]}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date']) \ndf['Rolling_Avg'] = df['Temperature']... # put solution in this variable\n```\n\nFill in the blank to calculate the 3-day rolling average for the temperature readings.",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of employees in a company represented as a Pandas dataframe with their details as shown below:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [101, 102, 103, 104, 105],\n    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'salary': [70000, 80000, 60000, 75000, 85000],\n    'department': ['HR', 'Engineering', 'HR', 'Marketing', 'Engineering']\n})\n```\n\nYou need to create a function called `average_salary_by_department` that takes this dataframe as an input and returns a new dataframe showing the average salary for each department. The resulting dataframe should have two columns: `department` and `average_salary`.\n\nFor example, the output should look like this:\n\n```\n    department  average_salary\n0  Engineering         82500.0\n1             HR         65000.0\n2      Marketing         75000.0\n```\n\nPlease fill in the code below to complete your solution.\n\n```python\nresult = ...\ndef average_salary_by_department(df):\n    ...\n```",
    "output": "\n```python\nresult = df.groupby('department')['salary'].mean().reset_index(name='average_salary')\ndef average_salary_by_department(df):\n    return result\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that represents a time series dataset of stock prices:\n```\n                  Date      Price\n0  2023-01-01 00:00:00   150.50\n1  2023-01-01 01:00:00   152.30\n2  2023-01-01 02:00:00   153.45\n3  2023-01-01 03:00:00   156.01\n4  2023-01-01 04:00:00   155.75\n5  2023-01-01 05:00:00   157.90\n6  2023-01-01 06:00:00   158.20\n7  2023-01-01 07:00:00   157.80\n8  2023-01-01 08:00:00   159.00\n9  2023-01-01 09:00:00   160.50\n```\n\nI would like to calculate the rolling average of the stock prices over a window of 3 hours. \n\nHow can I achieve this using the `rolling` method in pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', \n        '2023-01-01 02:00:00', '2023-01-01 03:00:00',\n        '2023-01-01 04:00:00', '2023-01-01 05:00:00',\n        '2023-01-01 06:00:00', '2023-01-01 07:00:00',\n        '2023-01-01 08:00:00', '2023-01-01 09:00:00'\n    ],\n    'Price': [150.50, 152.30, 153.45, 156.01, 155.75, \n              157.90, 158.20, 157.80, 159.00, 160.50]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nrolling_average = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nrolling_average = df['Price'].rolling(window='3H').mean()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix in a Scipy environment, and you would like to efficiently find the non-zero elements and their indices. Let's say you have a sparse matrix `sparse_matrix` created using `scipy.sparse.csr_matrix`. You want to extract the indices of the non-zero elements in a way that they can be represented as a coordinate tensor. How can you achieve this?\n\nHere\u2019s a small snippet for context:\n\n```python\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\n# Sample sparse matrix\ndata = np.array([1, 2, 3, 4])\nrow_indices = np.array([0, 0, 1, 2])\ncol_indices = np.array([0, 2, 2, 1])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n```\n\nYou need to fill in the blank to extract the indices of the non-zero elements in `sparse_matrix`:\n\nnon_zero_indices = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>non_zero_indices = sparse_matrix.nonzero()</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing various product reviews, and one of the columns is a string containing product details in the format \"Product_Name (Category) - Review_Score\". The DataFrame looks like this:\n\n```\n       Reviews\n0  Laptop (Electronics) - 5\n1  Coffee Maker (Home) - 4\n2  Phone (Electronics) - 3\n3  Blender (Home) - 5\n4  Camera (Electronics) - 4\n```\n\nI would like to separate the product name, category, and review score into three distinct columns named 'Product', 'Category', and 'Score'. How can I achieve this to transform my DataFrame into the following format?\n\n```\n      Product       Category  Score\n0      Laptop      Electronics     5\n1  Coffee Maker        Home         4\n2      Phone       Electronics     3\n3     Blender         Home         5\n4     Camera       Electronics     4\n```\n\nHere's my initial code, which only creates the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'Reviews': ['Laptop (Electronics) - 5', \n                    'Coffee Maker (Home) - 4', \n                    'Phone (Electronics) - 3', \n                    'Blender (Home) - 5', \n                    'Camera (Electronics) - 4']}\ndf = pd.DataFrame(data)\n```\n\nI need to fill in the blank for the transformation:\n\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>df[['Product', 'Category', 'Score']] = df['Reviews'].str.extract(r'(.+?) \\((.+?)\\) - (\\d+)')</code>"
  },
  {
    "input": "Problem:\nI have a sparse tensor represented in a list format where the first element is the shape of the tensor, and the second element is a list of tuples (row_index, column_index, value) representing the non-zero entries. I need to convert this into a format that allows easy access to elements and supports efficient computations. Specifically, I want to convert this list representation into a sparse tensor and then access a specific element based on its indices.\n\nHere's the data I have:\n```\ntensor_data = [\n    (3, 4, 2),  # shape of the tensor: 3 rows, 4 columns, 2 non-zero entries\n    [(0, 1, 5), (2, 3, 8)]  # non-zero entries: (row_index, column_index, value)\n]\n```\n\nTo achieve this, I want to use the `scipy.sparse` module to create a sparse matrix from this representation. Additionally, I want to retrieve the value at the entry located at row 2 and column 3 of the sparse tensor.\n\nHow can I fill in the blank below to accomplish this task?\n\nA:\n<code>\nfrom scipy import sparse\n\ntensor_data = [\n    (3, 4, 2),\n    [(0, 1, 5), (2, 3, 8)]\n]\n\nentries = tensor_data[1]\nrows, cols, values = zip(*entries)\n\n# Create the sparse matrix\nsparse_tensor = ...  # put solution in this variable\n\n# Accessing the value at row 2, column 3\nvalue_at_2_3 = sparse_tensor[2, 3]\n</code>\n",
    "output": "\n<code>\nsparse_tensor = sparse.coo_matrix((values, (rows, cols)), shape=tensor_data[0][:2]).toarray()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset that I want to prepare for training a model using TensorFlow. The dataset consists of a 2D tensor where each row represents a sample and each column corresponds to a feature. I need to standardize this tensor (subtract the mean and divide by the standard deviation) feature-wise. Given a TensorFlow tensor `data` with shape (100, 20), how can I perform this operation?\n\nA:\n<code>\nimport tensorflow as tf\nimport numpy as np\n\n# Create a sample data tensor\ndata = tf.constant(np.random.rand(100, 20), dtype=tf.float32)\n</code>\nstandardized_data = ... # put solution in this variable",
    "output": "\n<code>\nmean = tf.reduce_mean(data, axis=0)\nstddev = tf.math.reduce_std(data, axis=0)\nstandardized_data = (data - mean) / stddev\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe with a column containing text containing URLs, and I want to extract just the domain names from those URLs. Here is the initial dataframe:\n\n  urls\n0 https://www.example.com/path/to/page\n1 http://subdomain.example.org\n2 https://www.test.com\n3 ftp://files.test.com/resource\n\nI want to transform this dataframe to only contain the domain names like this:\n\n  domain\n0 example.com\n1 example.org\n2 test.com\n3 files.test.com\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'urls': ['https://www.example.com/path/to/page', 'http://subdomain.example.org', 'https://www.test.com', 'ftp://files.test.com/resource']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['domain'] = df['urls'].str.extract(r'://(?:www\\.)?([^/]+)')[0]\ndf['domain'] = df['domain'].str.replace(r'^[^.]+\\.', '', regex=True)\ndf = df[['domain']]\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset represented as a sparse tensor that has a significant number of zero entries, and I need to perform a specific operation to extract meaningful information from this sparse representation without converting it to a dense format. Specifically, I have a 3D sparse tensor that represents the presence of certain features across multiple samples.\n\nThe sparse tensor is defined as follows:\n\n```python\nimport torch\n\nindices = torch.tensor([[0, 0, 0],\n                        [1, 0, 2],\n                        [1, 1, 0]])\nvalues = torch.tensor([3.0, 4.0, 5.0])\nsize = (2, 2, 3)\n\nsparse_tensor = torch.sparse_coo_tensor(indices.t(), values, size)\n```\n\nI want to obtain a tensor that holds the maximum value for each 2D slice (i.e., across the last dimension) of this sparse tensor. The output should be a 2D tensor where each row corresponds to a slice of the sparse tensor, and each column represents the maximum value of that slice. \n\nFor example, the desired output for the above sparse tensor should be:\n\n```\ntensor([[3., 4.],\n        [5., 0.]])\n```\n\nWhat is the code that will generate this result? \n\nA:\n```python\nimport torch\n\n# Assume sparse_tensor is defined as above\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nimport torch\n\n# Assume sparse_tensor is defined as above\nresult = torch.sparse.max(sparse_tensor, dim=2)[0].to_dense()\n```"
  },
  {
    "input": "Problem:\nYou have two 3D tensors, `A` and `B`, both with shape (5, 4, 3) in PyTorch. You want to perform an element-wise multiplication of these tensors and then compute the sum along the first dimension (the batch dimension). Write the line of code that performs this operation and stores the result in the variable `result`.\n\nA:\n<code>\nimport torch\n\nA = torch.randn(5, 4, 3)\nB = torch.randn(5, 4, 3)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = (A * B).sum(dim=0)"
  },
  {
    "input": "Problem:\nI am training a neural network using TensorFlow and I want to combine multiple batches of tensor data for further processing. I have a list of tensors where each tensor is of shape (batch_size, features). However, I want to concatenate these tensors along the first dimension (batch dimension) while ensuring that their feature dimensions match. How can I achieve this effectively with TensorFlow?\n\nExample input:\nbatch1 = tf.constant([[1, 2], [3, 4]])\nbatch2 = tf.constant([[5, 6], [7, 8]])\nbatch3 = tf.constant([[9, 10]])\nbatches = [batch1, batch2, batch3]\n\n# Desired output shape would be (6, 2)\n\nA:\n<code>\nimport tensorflow as tf\n\nbatches = [tf.constant([[1, 2], [3, 4]]), tf.constant([[5, 6], [7, 8]]), tf.constant([[9, 10]])]\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = tf.concat(batches, axis=0)\n</code>"
  },
  {
    "input": "## Problem:\nYou have a DataFrame containing daily sales data for a retail store over a year. The DataFrame has two columns: 'Date' in the format 'YYYY-MM-DD' and 'Sales' indicating the total sales for that day. You need to compute the rolling 7-day average of sales to understand weekly performance.\n\nHere is a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2022-01-01', periods=12, freq='D'),\n    'Sales': [200, 220, 250, 270, 290, 300, 330, 360, 400, 420, 450, 480]\n}\ndf = pd.DataFrame(data)\n```\n\nYour task is to fill in the blank to create a new column in the DataFrame called '7-day Average' that computes the rolling mean of the 'Sales' column over a 7-day window.\n\nA:\n```python\ndf['7-day Average'] = ...\n```",
    "output": "\n```python\ndf['7-day Average'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing a column of email addresses, and you want to extract the usernames (the part before the '@') and the domain names (the part after the '@'). The DataFrame looks like this:\n\n```python\nemail_df = pd.DataFrame({'email': ['user@example.com', 'john.doe@test.org', 'alice@company.net']})\n```\n\nYou want to create two new columns: \"username\" for the part before the '@' and \"domain\" for the part after it. \n\nI've attempted to split the email addresses using the `str.split()` method, but I'm unsure how to apply this to create new columns effectively.\n\nA:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email': ['user@example.com', 'john.doe@test.org', 'alice@company.net']})\n```\nemail_df[['username', 'domain']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nemail_df[['username', 'domain']] = email_df['email'].str.split('@', expand=True)\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix representing user interactions in a recommendation system. The matrix is stored as a list of tuples, with each tuple containing the row index, column index, and the value (indicating the interaction score). Your task is to convert this sparse representation into a dense matrix using NumPy. Specifically, given a sparse matrix in the form of `sparse_data = [(0, 1, 5), (1, 0, 3), (2, 2, 2)]`, which indicates that user 0 interacted with item 1 with a score of 5, user 1 with item 0 with a score of 3, and user 2 with item 2 with a score of 2, how can you represent this as a dense matrix of shape (3, 3)?\n\nA:\n\n<code>\nimport numpy as np\nsparse_data = load_data()\ndef solve(sparse_data):\n    # return the solution in this function\n    # dense_matrix = solve(sparse_data)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    dense_matrix = np.zeros((3, 3))\n    for row, col, value in sparse_data:\n        dense_matrix[row, col] = value\n    return dense_matrix\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou are working with sparse matrices using SciPy and need to create a function that generates a compressed sparse row (CSR) matrix from a dense 2D list representation. The dense list may contain both zeros and non-zero elements, and the function should efficiently handle and return the CSR matrix. Given the following dense list:\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n\nHow can you create a CSR matrix from this dense representation?\n\nA:\n<code>\nfrom scipy import sparse\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n</code>\ncsr_matrix_result = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncsr_matrix_result = sparse.csr_matrix(dense_matrix)\n</code>"
  },
  {
    "input": "### Problem:\nYou are tasked with implementing a simple neural network using TensorFlow 2.10.0 and PyTorch to classify grayscale images. Each model will output a probability distribution across three classes (0, 1, or 2).\n\nAfter training both models, you need to create a tensor that captures the predicted class with the highest probability for the TensorFlow model's output. Given the tensor output from the TensorFlow model as follows:\n\n```\npredictions_tf = [[0.1, 0.6, 0.3],\n                  [0.8, 0.1, 0.1],\n                  [0.4, 0.4, 0.2]]\n```\n\nYour goal is to extract the indices of the maximum probabilities across each row and convert it to a tensor with shape (n, 1) using TensorFlow.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions_tf = tf.constant([[0.1, 0.6, 0.3],\n                               [0.8, 0.1, 0.1],\n                               [0.4, 0.4, 0.2]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\npredicted_classes = tf.argmax(predictions_tf, axis=1, output_type=tf.int32)[:, tf.newaxis]</code>"
  },
  {
    "input": "Problem:\nI have a list of employee records where each record contains an employee's name and their respective department. I want to create a function that organizes these records into a dictionary, where each key is a department name and the corresponding value is a list of employee names belonging to that department. \n\nThe input is a list structured like this:\n\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\nHow can I implement such a function that populates a dictionary with this information? \n\nPlease define the function to achieve this task and output the result into the variable 'department_dict'. \n\n<code>\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\n### Define the function and populate the department_dict variable\n</code>\ndepartment_dict = ... # put solution in this variable",
    "output": "\n<code>\ndef organize_records(records):\n    department_dict = {}\n    for name, department in records:\n        if department not in department_dict:\n            department_dict[department] = []\n        department_dict[department].append(name)\n    return department_dict\n\ndepartment_dict = organize_records(records)\n</code>"
  },
  {
    "input": "## Problem\n\nYou are tasked with training a simple neural network using both TensorFlow and PyTorch to classify images of handwritten digits (from the MNIST dataset). You need to preprocess the images by normalizing the pixel values to the range [0, 1] and then create a model that consists of one hidden layer with 128 neurons and a ReLU activation function. Finally, you will compile and train the model using the Adam optimizer and categorical crossentropy loss.\n\nGiven a TensorFlow and PyTorch setup, you have the following variable declarations:\n\n```python\nimport tensorflow as tf\nimport torch\nfrom torchvision import datasets, transforms\n\n# TensorFlow part\ntrain_images = tf.keras.datasets.mnist.load_data()[0][0]\nnormalized_images_tf = train_images.astype('float32') / 255.0\n\n# PyTorch part\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_images_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\nYou need to define the model architecture and the training process in TensorFlow:\n\n```python\nmodel_tf = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```\n\nYour task is to fill in the training code for the TensorFlow model to fit the normalized_images_tf. Please provide the code snippet that goes in the blank below:\n\n```python\nmodel_tf.fit(_____, epochs=5)\n```",
    "output": "\n```python\nnormalized_labels_tf = tf.keras.datasets.mnist.load_data()[0][1]\nmodel_tf.fit(normalized_images_tf, normalized_labels_tf, epochs=5)\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\n\n# Simulated time series data representing daily sales over two weeks\ndate_rng = pd.date_range(start='2023-10-01', end='2023-10-14', freq='D')\nsales_data = np.random.randint(100, 500, size=(len(date_rng),))\ndf = pd.DataFrame(sales_data, index=date_rng, columns=['Sales'])\n\n# Assume we have an external holiday data frame indicating holidays\nholidays = pd.DataFrame({'Date': pd.to_datetime(['2023-10-03', '2023-10-10'])})\nholidays.set_index('Date', inplace=True)\n\n# Now, I want to identify the sales for all weekdays, and I am interested in calculating the average sales excluding holidays.\n# Can you provide the code to fill in the blank below that does this?\n\naverage_sales_excluding_holidays = ... # put solution in this variable\n```",
    "output": "\n```python\naverage_sales_excluding_holidays = df[~df.index.isin(holidays.index) & (df.index.weekday < 5)].mean()\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset of product sales. The DataFrame consists of columns for product names, sales numbers, and the dates of sales. I need to create a function that calculates the total sales for each product and returns a new DataFrame with the product names and their corresponding total sales.\n\nHere is a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n    'Sales': [100, 150, 200, 300, 100, 150, 400],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-05', \n                             '2023-01-03', '2023-01-06', '2023-01-07', \n                             '2023-01-08'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nCreate a function `calculate_total_sales(df)` that processes this DataFrame to compute the total sales for each product. The expected output should be a DataFrame that looks like this:\n\n```\n  Product  Total Sales\n0       A          450\n1       B          250\n2       C          700\n```\n\nA:\n<code>\ndef calculate_total_sales(df):\n    # return the solution in this function\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    total_sales = df.groupby('Product')['Sales'].sum().reset_index()\n    total_sales.columns = ['Product', 'Total Sales']\n    return total_sales\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily sales data of a product as follows:\n\n```\n   date        sales\n0  2023-01-01   100\n1  2023-01-02   150\n2  2023-01-03   200\n3  2023-01-04   250\n4  2023-01-05   300\n```\n\nI want to calculate the rolling average of sales over a 3-day window. The resulting DataFrame should have the same index as the original DataFrame, and the rolling average values should be aligned with the last date of each window.\n\nHow can I achieve this in Python? \n\nHere's the initial DataFrame setup:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=5, freq='D'),\n    'sales': [100, 150, 200, 250, 300]\n}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\n\nI would like the output to look like this:\n\n```\n             sales  rolling_avg\ndate                         \n2023-01-01   100          NaN\n2023-01-02   150          NaN\n2023-01-03   200        150.0\n2023-01-04   250        200.0\n2023-01-05   300        250.0\n```\n\nYour task is to fill in the blank below with the code to calculate the rolling average.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.assign(rolling_avg=df['sales'].rolling(window=3).mean())\n```"
  },
  {
    "input": "Problem:\n\nI'm working with a sparse tensor representation of a dataset, where each entry corresponds to a count of some event in a 3D space (e.g., time, user ID, and item ID). The tensor is initialized to zero, and I receive updates in the form of a list of tuples that indicate which indices to increment.\n\nSuppose I have a 3D sparse tensor initialized with size (5, 5, 5) and I receive an update list as follows:\n\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n\nI want to update the tensor so that each specified index in the updates list has its count incremented by 1.\n\nHow can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\nsparse_tensor = torch.zeros((5, 5, 5))\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n</code>\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfor update in updates:\n    sparse_tensor[update] += 1\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a pandas DataFrame that contains daily sales data for a store over a period of time, structured as follows:\n\n```plaintext\nID   date       sales\n1    2022-01-01 100\n2    2022-01-02 150\n3    2022-01-01 200\n4    2022-01-03 250\n5    2022-01-03 100\n6    2022-01-04 300\n```\n\nYou want to analyze the total sales by day, where if multiple entries exist for the same date, they should be summed together. Your goal is to compute this total and output a new DataFrame containing the unique dates and their corresponding total sales.\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ID': [1, 2, 3, 4, 5, 6],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-01', '2022-01-03', '2022-01-03', '2022-01-04'],\n    'sales': [100, 150, 200, 250, 100, 300]\n})\n\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nThe result should be a DataFrame `result` that contains the total sales for each unique date:\n\n```plaintext\n        date  total_sales\n0 2022-01-01          300\n1 2022-01-02          150\n2 2022-01-03          350\n3 2022-01-04          300\n```\n\nFill in the missing part of the code to achieve this.\n\n```python\nresult = df.groupby('date').agg(total_sales=('sales', 'sum')).reset_index()\n```",
    "output": "\n```python\nresult = df.groupby('date').agg(total_sales=('sales', 'sum')).reset_index()\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0 and PyTorch 1.10.0. I am implementing a neural network to classify handwritten digits from the MNIST dataset. After training, I would like to calculate the confusion matrix to understand the model's performance across different classes. To do this, I have a tensor `preds` containing the predicted class indices and another tensor `true_labels` with the actual class indices. Both tensors have the same length, representing the number of samples.\n\nHere\u2019s how to create the confusion matrix from these predictions:\n\n```python\nimport torch\nimport tensorflow as tf\n\n# Simulating some data\npreds = torch.tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1])\ntrue_labels = torch.tensor([0, 0, 2, 3, 0, 1, 1, 3, 0, 2])\n\n# Assuming you have 4 classes (0 to 3)\nnum_classes = 4\nconfusion_matrix = tf.zeros((num_classes, num_classes), dtype=tf.int32)\n```\n\nHow can I fill the confusion matrix, where `confusion_matrix[i][j]` will contain the number of times class `i` was predicted as class `j`? Here is the line that needs completing:\n\n```python\nfor i in range(preds.shape[0]):\n    confusion_matrix[...]\n```\nA:\n<code>\n# put solution in this variable\n</code>",
    "output": "\n<code>\n    confusion_matrix[true_labels[i], preds[i]] += 1\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor representation for a multi-dimensional dataset, where our data consists of customer purchases across different categories over several months. The shape of my sparse tensor is [30, 12, 5], which represents 30 customers, 12 months, and 5 product categories. I have a tensor containing the actual number of purchases for each customer in each category with the shape [30, 5]. The challenge is to populate the sparse tensor with the corresponding purchase values for each customer and category from the purchase tensor in a way that only the relevant entries are updated.\n\nThe sparse tensor is initialized as follows:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.Variable(tf.zeros((30, 12, 5), dtype=tf.float32))\npurchase_tensor = tf.constant([[2, 0, 5, 3, 1],\n                                [0, 3, 0, 1, 0],\n                                [1, 1, 1, 1, 1], \n                                # ... (and so on for 30 customers)\n                               ])\n```\n\nHow do I fill `sparse_tensor` so that each customer's purchases only fill in their respective category across the months? For instance, for the first customer with purchase values `[2, 0, 5, 3, 1]`, we should populate the sparse tensor accordingly for the available months.\n\nThe specific code line to fill in is:\n\n```python\nsparse_tensor[...] = ...\n```",
    "output": "\n```python\nsparse_tensor[...] = tf.reshape(purchase_tensor, (30, 1, 5)) * tf.ones((1, 12, 1), dtype=tf.float32)\n```"
  },
  {
    "input": "Problem:\nI have a list of temperatures recorded over a week in Celsius, and I want to convert these temperatures to Fahrenheit using a custom function. The conversion is done using the formula: Fahrenheit = (Celsius * 9/5) + 32. I need to apply this function to the entire list and return the converted list of temperatures. Here is what I have so far:\n\ntemperatures_celsius = [15, 22, 30, 10, 25, 28, 0]\n\ndef convert_to_fahrenheit(celsius):\n    # Conversion logic\n    \nfahrenheit_temperatures = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef convert_to_fahrenheit(celsius):\n    return (celsius * 9/5) + 32\n\nfahrenheit_temperatures = [convert_to_fahrenheit(temp) for temp in temperatures_celsius]\n</code>"
  }
]