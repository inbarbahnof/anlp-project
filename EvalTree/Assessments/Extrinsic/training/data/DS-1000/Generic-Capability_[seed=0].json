[
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Generate a random dataset with 100 samples and 10 features\nnp.random.seed(42)\ndata = np.random.rand(100, 10)\n\n# Create a DataFrame from the generated data\ndf = pd.DataFrame(data, columns=[f\"feature_{i}\" for i in range(10)])\n\n# Scale the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Apply PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(scaled_data)\n\n# Create a DataFrame with the principal components\npca_df = pd.DataFrame(data=principal_components, columns=[\"PC1\", \"PC2\"])\n\n# Plot the PCA results\nplt.figure(figsize=(8, 6))\nplt.scatter(pca_df[\"PC1\"], pca_df[\"PC2\"])\nplt.title(\"PCA of Random Dataset\")\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\nplt.grid()\n\n# Show the plot\nplt.show()\n\n# Which variable below should you use to store the explained variance ratio of the PCA model?\nratio = ...  # put solution in this variable\n```",
    "output": "\n```python\nratio = pca.explained_variance_ratio_\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various houses including their prices and features. This dataset is structured as a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'price': [300000, 450000, 500000, 600000, 700000],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'bathrooms': [2, 3, 2, 4, 3],\n    'area': [1500, 2000, 1800, 2500, 2200]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to apply a preprocessing step to normalize the 'price', 'bedrooms', and 'bathrooms' features in the DataFrame before feeding it into a machine learning model in Scikit-learn. Specifically, I want to scale these features such that they have a mean of 0 and a standard deviation of 1. \n\nGiven that I will use `StandardScaler` from Scikit-learn, how can I implement this normalization and add the scaled values back into the DataFrame under new column names prefixed with 'scaled_'?\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n```\ndf[['scaled_price', 'scaled_bedrooms', 'scaled_bathrooms']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf[['scaled_price', 'scaled_bedrooms', 'scaled_bathrooms']] = scaler.fit_transform(df[['price', 'bedrooms', 'bathrooms']])\n```"
  },
  {
    "input": "## Problem:\nI have a dataset containing daily temperature readings and I want to analyze it using various data science libraries. \n\nThe dataset is structured as follows:\n```python\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n    'temperature': [23.5, 19.0, 20.1, 22.3],\n}\n```\nI want to convert this into a Pandas DataFrame, calculate the moving average of the temperature for a window of 2 days, and then plot the original temperature along with the moving average using Matplotlib.\n\nGiven this context, I have started the implementation but I'm missing the code that calculates the moving average. Here is what I have done so far:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n    'temperature': [23.5, 19.0, 20.1, 22.3],\n}\n\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n\n# Calculate the moving average with a window size of 2\ndf['moving_average'] = ...\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\ndf['moving_average'] = df['temperature'].rolling(window=2).mean()\n\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset containing sales information with missing values and you want to prepare the data for analysis. Your dataset consists of daily sales, and you want to compute the total sales per month, while also filling any missing values with the mean sales of that month. \n\nGiven the following code snippet, your goal is to fill in the blank to calculate the monthly sales from the provided daily sales while handling the missing values:\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Sample daily sales data\ndates = pd.date_range(start=\"2023-01-01\", periods=100)\nsales = np.random.randint(100, 200, size=100)\nsales[::10] = np.nan  # Introducing NaN values for missing days\ndf = pd.DataFrame({'date': dates, 'sales': sales})\n\n# Convert 'date' to datetime format and set as index\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n\n# Calculate the monthly total sales, filling NaN values with the mean of that month\nmonthly_sales = df.resample('M').sum()  # put solution in this variable\n```\nresult = ...  # put solution in this variable",
    "output": "\n```python\nmonthly_sales = df.resample('M').apply(lambda x: x.fillna(x.mean()).sum())\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing the height (in centimeters) and weight (in kilograms) of several individuals stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'height': [170, 180, 165, 175, 160],\n        'weight': [70, 80, 65, 75, 60]}\ndf = pd.DataFrame(data)\n```\n\nYou want to normalize the height and weight attributes using Min-Max scaling, which transforms the values to a range between 0 and 1. The formula for Min-Max normalization is:\n\n\\[ \\text{normalized\\_value} = \\frac{\\text{value} - \\text{min}}{\\text{max} - \\text{min}} \\]\n\nPlease write the code to perform the normalization for both height and weight, and store the results back into the DataFrame in new columns named `normalized_height` and `normalized_weight`. \n\nYour code should look like this:\n\n```python\ndf['normalized_height'] = ...  # put solution in this variable\ndf['normalized_weight'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['normalized_height'] = (df['height'] - df['height'].min()) / (df['height'].max() - df['height'].min())\ndf['normalized_weight'] = (df['weight'] - df['weight'].min()) / (df['weight'].max() - df['weight'].min())\n```"
  },
  {
    "input": "Problem:\nYou are working on a sentiment analysis project. You need to preprocess your text data stored in a pandas DataFrame. The DataFrame contains two columns: 'id' and 'text'. Your goal is to convert the text to lowercase, remove punctuation, and tokenize the sentences. \n\nHere is the initial DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'id': [1, 2, 3],\n    'text': ['I love Python! It is great.', \n             'Data science with Python is awesome!!!', \n             'Let\\'s build amazing models...']\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter preprocessing, you want to create a new column 'tokens' that contains the list of tokens for each text entry.\n\nTo achieve this, you are using the following setup:\n\n```python\nimport string\n\ndef preprocess_text(text):\n    # Your preprocessing steps will go here\n    pass\n\ndf['tokens'] = df['text'].apply(preprocess_text)\n```\n\nWhat completes the `preprocess_text` function so that it correctly processes the text?\n\nA:\n```python\ntext = ... # put solution in this variable\n```",
    "output": "\n```python\ntext = text.lower()  # Convert to lowercase\ntext = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\ntokens = text.split()  # Tokenize the text\nreturn tokens  # Return the list of tokens\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that records daily temperatures over a month and you want to visualize the trend of temperature using a moving average. You have a Pandas DataFrame named `temperature_data` with a column `temperature` that contains daily recordings. You want to calculate a 7-day moving average and plot it using Matplotlib. How would you go about computing this moving average and storing it in a new column named `moving_avg` in the same DataFrame? \n\nBelow is the starting point of your code:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Sample data\ntemperature_data = pd.DataFrame({\n    'date': pd.date_range(start='2023-01-01', periods=30),\n    'temperature': [23, 21, 22, 24, 25, 24, 23, 20, 19, 22, 24, 27, 26, 29, 30, 28, 25, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n})\n\n# Solution starts here\ntemperature_data['moving_avg'] = ...\n```\n\nYou need to complete the line marked `...` with appropriate Python code to compute the moving average.",
    "output": "\n```python\ntemperature_data['moving_avg'] = temperature_data['temperature'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nI am analyzing some sales data using Pandas and I want to calculate the moving average of the sales over the last 3 days. Here\u2019s the current setup of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'Sales': [100, 150, 200, 220, 300, 250, 230, 300, 400, 350]}\ndf = pd.DataFrame(data)\n```\n\nI would like to create a new column 'Moving_Average' that contains the moving average of 'Sales' over the last 3 days. However, I want the first three entries of 'Moving_Average' to be NaN instead of being filled with the moving average value. How can I do that? \n\nCan you provide the code to calculate this and store the result in `result` variable? \nBEGIN SOLUTION\n```python\nresult = df['Sales'].rolling(window=3).mean()\nresult.iloc[:3] = np.nan\n```",
    "output": "\n```python\nimport numpy as np\n\nresult = df['Sales'].rolling(window=3).mean()\nresult.iloc[:3] = np.nan\n```"
  },
  {
    "input": "Problem:\nI have a dataset of employee salaries and performance scores stored in a pandas DataFrame. I want to standardize the salary column using the StandardScaler from Scikit-learn. Additionally, after standardizing, I would like to visualize the distribution of the standardized salaries using a histogram in Matplotlib. \n\nHere\u2019s a sample of the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n    'salary': [50000, 60000, 55000, 70000, 80000, 85000],\n    'performance_score': [3, 4, 4, 5, 2, 3]\n}\ndf = pd.DataFrame(data)\n```\n\nHow can I standardize the salary column and plot a histogram of the standardized salaries? \n\nPlease fill in the solution in the variable `standardized_salaries` and create the histogram with the appropriate labels.\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\nscaler = StandardScaler()\nstandardized_salaries = ... # put solution in this variable\n\nplt.hist(standardized_salaries, bins=5, edgecolor='black')\nplt.title('Histogram of Standardized Salaries')\nplt.xlabel('Standardized Salary')\nplt.ylabel('Frequency')\nplt.show()\n```",
    "output": "\n```python\nstandardized_salaries = scaler.fit_transform(df[['salary']]).flatten()\n```"
  },
  {
    "input": "## Problem\nYou are working on a machine learning project where you need to preprocess a dataset before feeding it into a model. The dataset consists of two features: 'age' and 'salary'. \n\nYou want to replace any missing values in the 'salary' column with the median salary of the entire dataset. After handling the missing values, you also want to normalize the 'age' feature to a range between 0 and 1. The dataset is in a Pandas DataFrame format.\n\nHere is a portion of the code you have written:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Sample DataFrame\ndata = pd.DataFrame({\n    'age': [23, 45, None, 35, 50, None, 60],\n    'salary': [50000, 60000, 55000, None, 80000, 72000, None]\n})\n\n# Replace missing values in 'salary' with the median salary\ndata['salary'] = data['salary'].fillna(data['salary'].median())\n\n# Normalize the 'age' feature\nscaler = MinMaxScaler()\ndata['age'] = scaler.fit_transform(data[['age']])\n```\n\nCurrently, the code for replacing missing values in the 'salary' column is missing. Please fill in the blank to complete the code.\n\nA:\n\n```python\ndata['salary'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndata['salary'] = data['salary'].fillna(data['salary'].median())\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset of customer orders from an e-commerce website stored in a Pandas DataFrame, which has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'order_id': [1, 2, 3, 4, 5, 6],\n    'customer_id': [101, 102, 103, 101, 104, 102],\n    'amount': [250, 300, 150, 400, 200, 100],\n    'order_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to find the total amount spent by each customer but only for those customers who have made at least 2 orders. Use the following approach:\n\n1. Group the DataFrame by 'customer_id'.\n2. Filter out customers with fewer than 2 orders.\n3. Calculate the total amount spent for the remaining customers.\n\nStore the resulting DataFrame in a variable called `result`.\n\nBEGIN SOLUTION\n<code>\nresult = ...  # Your solution here\n</code>",
    "output": "\n<code>\nresult = df.groupby('customer_id').filter(lambda x: len(x) >= 2).groupby('customer_id')['amount'].sum().reset_index()\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset that contains information about sales across different stores. The dataset looks like this:\n\n| Store | Date       | Sales |\n|-------|------------|-------|\n| A     | 2023-01-01 | 100   |\n| A     | 2023-01-02 | 150   |\n| B     | 2023-01-01 | 200   |\n| B     | 2023-01-02 | 250   |\n| C     | 2023-01-01 | 300   |\n| C     | 2023-01-02 | 350   |\n\nI want to visualize the sales trend for each store over the provided dates using a line chart with Matplotlib. To achieve this, I'm attempting to plot a line for each store. Here\u2019s the initial setup code:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Store': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02']),\n    'Sales': [100, 150, 200, 250, 300, 350]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, I want to fill in the missing code to create the line plot where the x-axis is the `Date` and the y-axis is `Sales`, with each line representing a different store. The line plotting code should be:\n\n```python\nfor store in df['Store'].unique():\n    plt.plot(____, ____, label=store)\n\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.title('Sales Trend by Store')\nplt.legend()\nplt.show()\n```\n\nFill in the blanks with the appropriate Pandas DataFrame operations to create the desired plot. \nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nfor store in df['Store'].unique():\n    plt.plot(df[df['Store'] == store]['Date'], df[df['Store'] == store]['Sales'], label=store)\n\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.title('Sales Trend by Store')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nYou have a CSV file containing stock prices of a particular company over a set of dates, which looks like this:\n\n```\ndate,open,high,low,close,volume\n2022-01-01,100,110,90,105,10000\n2022-01-02,105,115,95,110,15000\n2022-01-03,110,120,100,115,12000\n...\n```\n\nYou want to analyze the closing prices and visualize the trend over time. To do that, you decide to calculate the rolling average of the closing prices over a window of 3 days and plot it.\n\nHere's the starting code:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"stock_prices.csv\", parse_dates=[\"date\"])\ndf['rolling_avg'] = df['close'].... # insert your solution here\n\nplt.plot(df['date'], df['close'], label='Closing Prices')\nplt.plot(df['date'], df['rolling_avg'], label='3-Day Rolling Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.title('Stock Prices with 3-Day Rolling Average')\nplt.legend()\nplt.show()\n```\n\nWhat should you put in the blank to calculate the rolling average?\n\nA:\n```python\ndf['rolling_avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['close'].rolling(window=3).mean()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n# Standardize the data\nstandardized_data = (df - df.mean()) / df.std()\n\n# Apply PCA and capture the principal components\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(standardized_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'], alpha=0.5)\n\n# I want to add labels to the scatter plot for the three different species in the dataset.\n# I know that the target is stored in the iris dataset as well but I want to create a legend for it in the plot.\n\n# Replace with the actual solution to extract the target labels\ntarget_labels = ...  # put solution in this variable\n```",
    "output": "\n```python\ntarget_labels = data.target\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing the sales data of a retail store, which includes columns for 'Product', 'Units Sold', and 'Sales Amount'. You want to normalize the 'Sales Amount' column values so that they have a mean of 0 and a standard deviation of 1 while handling any missing values appropriately.\n\nHere's a snippet of your DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Units Sold': [250, 150, np.nan, 400, 300],\n    'Sales Amount': [5000, 3000, 4000, np.nan, 6000]\n}\ndf = pd.DataFrame(data)\n```\n\nTo accomplish this normalization, you plan to use the `StandardScaler` from scikit-learn. However, you need to fill in the blank to apply the normalization to the 'Sales Amount' column.\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf['Sales Amount Normalized'] = ... # put solution in this variable\n```\nBEGIN SOLUTION\n```python\n",
    "output": "\n```python\ndf['Sales Amount Normalized'] = scaler.fit_transform(df[['Sales Amount']].fillna(df['Sales Amount'].mean()))\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset that contains multiple features, and I want to perform K-means clustering on this dataset. After fitting the model, I need to append the cluster labels as a new column to my original DataFrame. I already have the data loaded into a Pandas DataFrame named `df`, and I have specified the number of clusters as `n_clusters`. I have imported the necessary libraries. How can I accomplish this using Scikit-learn?\n\nHere's my setup:\n```python\nimport pandas as pd\nfrom sklearn.cluster import KMeans\n\n# Assuming df is my DataFrame and n_clusters is defined\n```\nYou need to put the solution in the following variable:\n```\ndf['Cluster'] = ... # put solution in this variable\n``` \nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nkmeans = KMeans(n_clusters=n_clusters)\ndf['Cluster'] = kmeans.fit_predict(df)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing time-series temperature readings from multiple cities. I want to standardize the temperatures for each city using the `StandardScaler` from scikit-learn, and then create a line plot for the standardized values of the first city using Matplotlib.\n\nAssuming you have already loaded the dataset into a Pandas DataFrame called `df`, where the first column is \"City\" and the remaining columns contain temperature readings, how can I standardize the temperature readings while keeping the city information intact and plot the standardized temperature values for the first city?\n\nHere is how the DataFrame `df` looks like:\n\n```\n      City    Jan    Feb    Mar ...   Dec\n0   CityA  30.1  32.0  45.2 ...  50.5\n1   CityB  25.0  27.0  35.0 ...  29.0\n2   CityC  20.5  22.4  30.2 ...  34.0\n...\n```\n\nWhat would be the best way to perform the above operations in Python? \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Assuming df is already loaded\ndf = pd.DataFrame({\n    'City': ['CityA', 'CityB', 'CityC'],\n    'Jan': [30.1, 25.0, 20.5],\n    'Feb': [32.0, 27.0, 22.4],\n    'Mar': [45.2, 35.0, 30.2],\n    'Dec': [50.5, 29.0, 34.0]\n})\n\n# Define the scaler\nscaler = StandardScaler()\n\n# Fit and transform the temperature data excluding the 'City' column\nstandardized_temperatures = scaler.fit_transform(df.iloc[:, 1:])\n\n# Create a new DataFrame with standardized values\nstandardized_df = pd.DataFrame(standardized_temperatures, columns=df.columns[1:])\nstandardized_df['City'] = df['City']\n\n# Filter the standardized values for the first city\ncity1_temperatures = standardized_df[standardized_df['City'] == standardized_df['City'].iloc[0]].iloc[:, :-1]\n\n# Plot the standardized temperatures for the first city\nplt.plot(city1_temperatures.columns, city1_temperatures.values.flatten())\nplt.title('Standardized Temperatures for ' + standardized_df['City'].iloc[0])\nplt.xlabel('Month')\nplt.ylabel('Standardized Temperature')\nplt.xticks(rotation=45)\nplt.show()\n</code>\nstandardized_temperatures = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>standardized_temperatures = scaler.fit_transform(df.iloc[:, 1:])</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about house prices with features such as square footage, number of bedrooms, and year built. I would like to preprocess this data by normalizing the numeric features to have a mean of 0 and a standard deviation of 1. However, I want to make sure that I only normalize the columns that are of numeric type, and I would like to use Scikit-learn's `StandardScaler` for this task.\n\nHere is my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'square_footage': [1500, 2500, 3000, 2000],\n    'num_bedrooms': [3, 4, 5, 3],\n    'year_built': [2000, 1995, 2010, 2005],\n    'house_type': ['Detached', 'Semi-Detached', 'Detached', 'Townhouse']\n}\ndf = pd.DataFrame(data)\n```\n\nNow, I want to normalize only the numeric columns and store the result in a new DataFrame called `normalized_df`.\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n```\n\nnormalized_df = ... # put solution in this variable",
    "output": "\n```python\nnumeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\nnormalized_df = df.copy()\nnormalized_df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n```"
  },
  {
    "input": "### Problem:\nYou have a DataFrame containing the sales data for a store, structured as follows:\n\n```\n  Product   Date        Sales\n0 A        2023-01-01  100\n1 B        2023-01-01  150\n2 A        2023-01-02  200\n3 C        2023-01-02  250\n4 B        2023-01-03  300\n5 C        2023-01-03  350\n```\n\nYou need to pivot this DataFrame to create a summary table that shows the total sales per product over the entire period. The resulting DataFrame should look like this:\n\n```\n  Product   Total_Sales\n0 A        300\n1 B        450\n2 C        600\n```\n\nYou can achieve this using the `groupby` method from Pandas. You have already created the DataFrame and your task is to fill in the code to calculate the `Total_Sales` for each product.\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-03'],\n    'Sales': [100, 150, 200, 250, 300, 350]\n}\n\ndf = pd.DataFrame(data)\nresult = ...  # Put your solution here\n```\n\nHow would you fill in the blank to get the summarized sales per product?",
    "output": "\n```python\nresult = df.groupby('Product', as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\n```"
  },
  {
    "input": "Problem:  \nI am working with a dataset of adult income information. The dataset is stored in a CSV file called `adult_income.csv` which has two columns: `age` and `income`. I want to standardize the `age` variable to have a mean of 0 and a standard deviation of 1, and create a new column called `age_standardized` to store the results.\n\nHere\u2019s how you can read the data and prepare for the standardization:\n\n```python\nimport pandas as pd\n\n# Read the CSV file\ndf = pd.read_csv('adult_income.csv')\n```\n\nNow, I need to fill in the code to standardize the `age` column. Can you provide the line of code to compute `age_standardized` such that it follows the standardization formula: (value - mean) / standard deviation?\n\nA:  \n```python\ndf['age_standardized'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['age_standardized'] = (df['age'] - df['age'].mean()) / df['age'].std()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset that contains information about housing prices, including features like square footage, number of bedrooms, and the year built. I'm performing some exploratory data analysis and want to visualize the distribution of housing prices. I'm using Matplotlib for visualization and I need to create a histogram of the 'price' column from my DataFrame. I want to customize the histogram so that it has 30 bins, a title 'Distribution of Housing Prices', and labels for the x-axis ('Price') and y-axis ('Frequency').\n\nHere\u2019s the setup:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the housing dataset\ndf = pd.DataFrame({\n    'square_footage': np.random.randint(500, 5000, size=1000),\n    'bedrooms': np.random.randint(1, 6, size=1000),\n    'year_built': np.random.randint(1900, 2022, size=1000),\n    'price': np.random.randint(75000, 500000, size=1000)\n})\n```\n\nWhat code should I fill in to create the histogram?\n\n```python\nplt.hist(df['price'], bins=..., alpha=0.7)\nplt.title('Distribution of Housing Prices')\nplt.xlabel('Price')\nplt.ylabel('Frequency')\nplt.show()\n```\n\nA:\n\n<code>\nplt.hist(df['price'], bins=30, alpha=0.7)\n</code>",
    "output": "\n<code>\nplt.hist(df['price'], bins=30, alpha=0.7)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset with the following structure representing various features of car models:\n\n```python\nimport pandas as pd\n\ndata = {\n    'model': ['A', 'B', 'C', 'A', 'B', 'C', 'A'],\n    'year': [2018, 2019, 2020, 2020, 2021, 2021, 2019],\n    'price': [20000, 22000, 25000, 21000, 23000, 24000, 19000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to compute the average price of each model per year, and then visualize this average price in a bar chart using Matplotlib. How should I fill in the code to achieve the average price calculation and plotting?\n\n```python\naverage_price = df.groupby(['model', 'year']).mean().reset_index()  # This line is provided.\n```\n\nNow I am looking for the code to create the bar chart and show it:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Create a bar chart to visualize the average price\nplt.bar(x=..., height=...)  # Fill in the x and height parameters\nplt.xlabel('Model-Year')\nplt.ylabel('Average Price')\nplt.title('Average Price of Car Models per Year')\nplt.xticks(rotation=45)\nplt.show()\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\naverage_price['model_year'] = average_price['model'] + '-' + average_price['year'].astype(str)\nplt.bar(x=average_price['model_year'], height=average_price['price'])\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about customers and their orders. The dataset consists of the following two columns:\n\n- `CustomerID`: Unique identifier for each customer.\n- `OrderAmount`: The amount of each order made by the customer.\n\nExample data:\n```python\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'OrderAmount': [100, 150, 200, 120, 300, 400]\n}\n```\n\nYou want to calculate the total order amount for each customer and visualize this data using a bar chart. \n\n1. Create a DataFrame from the provided data.\n2. Group the data by `CustomerID` and sum the `OrderAmount` for each customer.\n3. Plot a bar chart where the x-axis represents `CustomerID` and the y-axis represents the total order amount.\n\nTo achieve the bar chart visualization, the following code can be used:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'OrderAmount': [100, 150, 200, 120, 300, 400]\n}\ndf = pd.DataFrame(data)\n```\n\nNow fill in the blanks to obtain the grouped data and create the plot:\n\n```python\ngrouped_df = df.groupby('CustomerID')['OrderAmount'].sum().reset_index()\nplt.bar(grouped_df['CustomerID'], grouped_df['OrderAmount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Order Amount')\nplt.title('Total Order Amount by Customer')\nplt.show()\n```\nFill in the variable `grouped_df` to complete the solution. \nA:\n<code>\ngrouped_df = ... # put solution in this variable\n```",
    "output": "\n<code>\ngrouped_df = df.groupby('CustomerID')['OrderAmount'].sum().reset_index()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset with housing prices that I've loaded into a pandas DataFrame as follows:\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Price': [850000, 720000, 450000, 360000, 330000],\n    'Size_sqft': [900, 1200, 1500, 1300, 1100],\n    'Year_Built': [2001, 1998, 2010, 2005, 2012]\n}\ndf = pd.DataFrame(data)\n```\nI want to normalize the `Price` column and create a new column called `Normalized_Price` that contains the normalized value. The normalization formula I want to apply is:\n\\[ \\text{Normalized\\_Price} = \\frac{\\text{Price} - \\text{min(Price)}}{\\text{max(Price)} - \\text{min(Price)}} \\]\nPlease complete the following code to achieve this:\n```python\ndf['Normalized_Price'] = ...\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Normalized_Price'] = (df['Price'] - df['Price'].min()) / (df['Price'].max() - df['Price'].min())</code>"
  },
  {
    "input": "Problem:\nYou are given a dataset of house prices in a Pandas DataFrame that includes the following columns: 'SquareFootage', 'Bedrooms', 'Bathrooms', and 'Price'. You want to create a new column 'PricePerSquareFoot' based on the ratio of 'Price' to 'SquareFootage', but only for rows where 'SquareFootage' is greater than 0. The DataFrame looks like this:\n\n```\n   SquareFootage  Bedrooms  Bathrooms   Price\n0            1200         3          2  300000\n1            1500         4          3  400000\n2            0             2          1  150000\n3            2000         5          4  500000\n4            1800         4          2  420000\n```\n\nYou want to fill in the 'PricePerSquareFoot' column such that it only contains valid calculated values, leaving NaN for any rows where 'SquareFootage' is 0 or less.\n\nWhat code will you use to achieve this?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'SquareFootage': [1200, 1500, 0, 2000, 1800],\n    'Bedrooms': [3, 4, 2, 5, 4],\n    'Bathrooms': [2, 3, 1, 4, 2],\n    'Price': [300000, 400000, 150000, 500000, 420000]\n}\n\ndf = pd.DataFrame(data)\n\n# Here is the placeholder for your solution\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['PricePerSquareFoot'] = np.where(df['SquareFootage'] > 0, df['Price'] / df['SquareFootage'], np.nan)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a time series dataset containing daily temperature readings from different cities. The dataset is organized in a Pandas DataFrame with columns \"Date\", \"City\", and \"Temperature\". Your aim is to convert the temperature readings from Celsius to Fahrenheit. The formula for conversion is F = (C * 9/5) + 32. Please write the code to perform this conversion and return the updated DataFrame.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\n    'Temperature': [1.0, 15.0, 0.0, 16.5]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.copy()\nresult['Temperature'] = (result['Temperature'] * 9/5) + 32\n</code>"
  },
  {
    "input": "Problem:\nI want to perform a multiclass classification using a neural network built with TensorFlow and Keras. I have a dataset with features and target classes as follows:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Sample dataset\ndata = {\n    'feature1': [1.2, 2.3, 3.1, 4.5, 5.6, 2.9, 3.5],\n    'feature2': [7.1, 6.2, 8.3, 5.4, 7.5, 6.6, 5.7],\n    'class': ['A', 'B', 'A', 'C', 'B', 'C', 'A']\n}\n\ndf = pd.DataFrame(data)\n\n# Prepare the features and labels\nX = df[['feature1', 'feature2']]\ny = df[['class']]\n```\n\nI want to split the dataset into training and testing sets, one-hot encode the target variable, and then build and compile a simple neural network with one hidden layer having 10 neurons. What should I put in the blank to create the model?\n\n```python\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# One-hot encoding the target\nencoder = OneHotEncoder(sparse=False)\ny_encoded = encoder.fit_transform(y_train)\n\n# Defining the model architecture\nmodel = keras.Sequential()\nmodel.add(layers.Dense(10, activation='relu', input_shape=(2,)))\nmodel.add(layers.Dense(len(encoder.categories_[0]), activation='softmax'))  # Output layer for multiclass\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Training the model\nmodel.fit(X_train, ... )\n```\n\nresult = ... # put solution in this variable",
    "output": "\n```python\ny_encoded, epochs=50, batch_size=5)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing various features of houses, including their size (in square feet), number of bedrooms, and the price. I want to preprocess this dataset by normalizing the 'size' and 'price' columns and encoding the 'bedrooms' column into one-hot encoding format. Here's a simplified representation of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 1800, 2400, 3000],\n    'bedrooms': [3, 4, 4, 5],\n    'price': [300000, 400000, 500000, 600000]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a new DataFrame that normalizes the 'size' and 'price' columns to a range of [0, 1], and creates one-hot encoding for the 'bedrooms' column. The resulting DataFrame should keep the normalized values along with the new one-hot encoded columns. How can I achieve that?\n\nA:\n```python\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\ndf = pd.DataFrame(data)\nscaler = MinMaxScaler()\n# Normalize 'size' and 'price'\ndf[['size', 'price']] = scaler.fit_transform(df[['size', 'price']])\nencoder = OneHotEncoder(sparse=False)\n# Encode 'bedrooms'\nencoded_bedrooms = ...  # Fill in this part\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nencoded_bedrooms = encoder.fit_transform(df[['bedrooms']])\nresult = pd.concat([df[['size', 'price']], pd.DataFrame(encoded_bedrooms, columns=encoder.get_feature_names_out(['bedrooms']))], axis=1)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load iris dataset\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a random forest classifier\nclf = RandomForestClassifier(n_estimators=100)\n\n# Fit the classifier to the training data\nclf.fit(X_train, y_train)\n\n# Calculate the accuracy on the test data\naccuracy = clf.score(X_test, y_test)\n\n# Plotting the feature importances\nfeature_importances = clf.feature_importances_\n# Create a bar plot of feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(X.columns, feature_importances)\nplt.title(\"Feature Importances\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Importance\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Specify a variable to hold the accuracy result\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = accuracy\n```"
  },
  {
    "input": "Problem:\nI have a dataset represented as a Pandas DataFrame containing information about house prices, and I need to preprocess it for a machine learning model. The DataFrame contains several features, including 'Size' (in square feet), 'Bedrooms', and 'Price'. I want to normalize the 'Size' and 'Bedrooms' columns using Min-Max scaling so that their values fall in the range [0, 1]. How can I achieve this normalization?\n\nExample:\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 1600, 1700, 1800, 1900],\n    'Bedrooms': [3, 4, 3, 5, 4],\n    'Price': [300000, 320000, 330000, 350000, 360000]\n}\ndf = pd.DataFrame(data)\n\nA:\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_features = scaler.fit_transform(df[['Size', 'Bedrooms']])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.DataFrame(normalized_features, columns=['Size', 'Bedrooms'])</code>"
  },
  {
    "input": "Problem:\n\nI am analyzing a time series dataset of daily stock prices. I have loaded the data using Pandas and computed the moving average for a given window size. Now, I want to visualize the original stock prices alongside the moving average using Matplotlib. \n\nHere is my current code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Assuming 'stock_prices.csv' contains a 'Date' and 'Close' column\ndf = pd.read_csv('stock_prices.csv')\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n\nwindow_size = 10\ndf['Moving_Average'] = df['Close'].rolling(window=window_size).mean()\n\n# Now I want to plot the original stock prices and the moving average\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['Close'], label='Original Stock Prices')\nplt.plot(df.index, df['Moving_Average'], label='Moving Average', color='orange')\n# Fill in the blank to display the legend\nplt....   # fill this line\nplt.title('Stock Prices and Moving Average')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n```\n\nWhat should I put in the blank space to display the legend on the plot?",
    "output": "\n```python\nplt.legend()\n```"
  },
  {
    "input": "Problem:\nI have a dataset that contains sales data over several months for multiple products. I want to calculate the month-over-month percent change in sales for each product. To do this, I need to compute the ratio of the difference in sales between consecutive months to the sales of the previous month, multiplied by 100. After calculating this, I want to visualize the percent changes for each product using a bar plot.\n\nHere is a sample structure of the dataset:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': ['2023-01', '2023-02', '2023-03', '2023-04'],\n    'Product_A': [100, 150, 120, 180],\n    'Product_B': [200, 220, 210, 215],\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou can fill in the blank below to achieve the month-over-month percent change for each product:\n\n```python\npercent_change = df.set_index('Month').pct_change() * 100\n```\n\nFor visualization using Matplotlib, you can create a bar plot to show the percent changes. Fill in the blank to accomplish this:\n\n```python\nimport matplotlib.pyplot as plt\n\npercent_change.plot(kind='bar', title='Month-over-Month Percent Change in Sales')\nplt.ylabel('Percent Change')\nplt.xlabel('Month')\nplt.show()\n```\n\nThe correct way to store the results after calculating the percent change is:\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = percent_change\n```"
  },
  {
    "input": "Problem:\nI have a dataset of product sales represented as a Pandas DataFrame. I want to analyze the sales performance based on different regions and visualize the trends over time. However, I need to calculate the cumulative sales for each region and store them in a new DataFrame. The original DataFrame, `sales_data`, has columns 'Date', 'Region', and 'Sales'. I also want to plot the cumulative sales for each region using Matplotlib.\n\nHere is a sample DataFrame you can use:\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=6),\n    'Region': ['North', 'South', 'North', 'South', 'East', 'West'],\n    'Sales': [100, 150, 200, 175, 130, 90]\n}\nsales_data = pd.DataFrame(data)\n```\n\nWhat I need is to create a new DataFrame, `cumulative_sales`, that contains the cumulative sales for each region over time. Additionally, provide the code to plot this data.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=6),\n    'Region': ['North', 'South', 'North', 'South', 'East', 'West'],\n    'Sales': [100, 150, 200, 175, 130, 90]\n}\nsales_data = pd.DataFrame(data)\n</code>\ncumulative_sales = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncumulative_sales = sales_data.groupby(['Region', 'Date'])['Sales'].sum().groupby(level=0).cumsum().reset_index()\ncumulative_sales = cumulative_sales.pivot(index='Date', columns='Region', values='Sales')\ncumulative_sales.plot(title='Cumulative Sales by Region')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Sales')\nplt.legend(title='Region')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some sample data\nnp.random.seed(42)\nx = np.random.rand(100, 1) * 10  # 100 random numbers from 0 to 10\ny = 2.5 * x + np.random.randn(100, 1)  # Linear relationship with noise\n\n# Create a DataFrame\ndf = pd.DataFrame(data=np.hstack((x, y)), columns=['X', 'Y'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['X']], df['Y'])\n\n# Predict the Y values\ndf['Predicted_Y'] = model.predict(df[['X']])\n\n# Plot the original data and the regression line\nplt.scatter(df['X'], df['Y'], color='blue', label='Original data')\nplt.plot(df['X'], df['Predicted_Y'], color='red', label='Regression line')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\nplt.show()\n\n# Calculate the Mean Squared Error of the model\nmse = np.mean((df['Y'] - df['Predicted_Y']) ** 2)\n\n# What\u2019s the solution to calculate R\u00b2 of the regression model?\nr_squared = ... # fill this spot\n```",
    "output": "\n```python\nr_squared = model.score(df[['X']], df['Y'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about house prices, including location, size (in square feet), and the number of bedrooms. I want to preprocess this dataset to prepare it for training a machine learning model. \n\nHere is the dataset:\n\n```python\nimport pandas as pd\n\ndata = {\n    'location': ['Urban', 'Suburban', 'Urban', 'Rural', 'Suburban'],\n    'size': [1500, 2000, 1300, 1600, 2200],\n    'bedrooms': [3, 4, 2, 3, 5],\n    'price': [300000, 400000, 280000, 250000, 450000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to one-hot encode the 'location' column and get a NumPy array containing the resulting features excluding the 'price' column. The expected format for the output array should not include any columns related to 'price'.\n\nCould you please provide the line of code that achieves this?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'location': ['Urban', 'Suburban', 'Urban', 'Rural', 'Suburban'],\n    'size': [1500, 2000, 1300, 1600, 2200],\n    'bedrooms': [3, 4, 2, 3, 5],\n    'price': [300000, 400000, 280000, 250000, 450000]\n}\n\ndf = pd.DataFrame(data)\n### Output your answer into variable 'features'\n</code>\nfeatures = ... # put solution in this variable",
    "output": "\n<code>\nfeatures = pd.get_dummies(df.drop('price', axis=1), drop_first=True).values\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing the daily temperature readings for a city over the last month, structured in a Pandas DataFrame. The DataFrame looks like this:\n\n```\n   Date       Temperature\n0  2023-01-01  30.5\n1  2023-01-02  29.0\n2  2023-01-03  31.2\n...\n30 2023-01-31  28.5\n```\nI want to calculate the moving average temperature over a 7-day window for the entire month and plot this moving average with respect to the dates. How can I achieve this in a single line of code after importing the necessary libraries?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=31),\n    'Temperature': [30.5, 29.0, 31.2, 30.1, 29.5, 28.9, 32.0, 31.8, 30.9, 29.7, 31.0, 30.3, 32.1, 29.6, 30.2, 31.5, 30.7, 29.8, 28.4, 30.8, 31.1, 29.5, 30.0, 30.4, 29.6, 31.3, 30.2, 28.9, 29.8, 30.1, 28.5]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \nresult = df.set_index('Date')['Temperature'].rolling(window=7).mean().plot(title='7-Day Moving Average Temperature', ylabel='Temperature', xlabel='Date')\nplt.show()\n</code>",
    "output": "\n<code> \nresult = df.set_index('Date')['Temperature'].rolling(window=7).mean().plot(title='7-Day Moving Average Temperature', ylabel='Temperature', xlabel='Date')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of housing prices in a Pandas DataFrame and want to predict the house prices using a machine learning model from Scikit-learn. I want to preprocess the features by scaling them using StandardScaler, but I would also like to visualize the distribution of the house prices using Matplotlib. Specifically, I need to extract features and labels, scale the features, fit a Linear Regression model, and plot the original prices against predicted prices. Here is my current code where I'm stuck:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Sample data\ndata = {\n    'bedrooms': [1, 2, 3, 4, 2],\n    'bathrooms': [1, 1, 2, 3, 2],\n    'price': [150000, 200000, 250000, 300000, 220000]\n}\n\ndf = pd.DataFrame(data)\n\n# Extract features and labels\nX = df[['bedrooms', 'bathrooms']]\ny = df['price']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_train)\n\n# Fit the model\nmodel = LinearRegression()\nmodel.fit(X_scaled, y_train)\n\n# Predict prices\nX_test_scaled = scaler.transform(X_test)\npredicted_prices = model.predict(X_test_scaled)\n\n# Plotting original prices against predicted prices\nplt.scatter(y_test, predicted_prices)\nplt.xlabel(\"Original Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.title(\"Original vs Predicted House Prices\")\nplt.show()\n\n# I want to get the coefficients of the features after fitting the model\ncoefficients = model.coef_\n```\n\nI need to fill in the missing part for the coefficients to be stored in a variable. What should the final line look like?\n\nA:\n<code>\ncoefficients = ...  # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\ncoefficients = model.coef_\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a time series dataset containing daily stock prices. You want to normalize the 'closing_price' column using Min-Max Scaling, which transforms the values to a range between 0 and 1. Given the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n    'closing_price': [100, 150, 200]\n}\ndf = pd.DataFrame(data)\n```\n\nFill in the code to perform Min-Max Scaling on the 'closing_price' column and store the normalized values in a new column called 'normalized_price'.\n\nA:\n\n```python\n# Assuming df is already defined\ndf['normalized_price'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['normalized_price'] = (df['closing_price'] - df['closing_price'].min()) / (df['closing_price'].max() - df['closing_price'].min())\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset representing some sales data in a Pandas DataFrame. The DataFrame looks like this:\n\n```\n   Product   Year  Sales\n0  A        2020  150\n1  A        2021  200\n2  B        2020  250\n3  B        2021  300\n4  C        2020  100\n5  C        2021  50\n```\n\nI want to normalize the sales data for each product across the years, such that each sale is represented as a fraction of the product's total sales over the years. For example, for Product A, the normalized sales for 2020 would be 150 / (150 + 200). \n\nI have already imported the necessary libraries and created the DataFrame. Now, I need to perform this normalization. Here is my code:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Year': [2020, 2021, 2020, 2021, 2020, 2021],\n    'Sales': [150, 200, 250, 300, 100, 50]\n}\ndf = pd.DataFrame(data)\n```\n\nNow I am looking for the appropriate line of code to normalize the `Sales` column. \n\n```python\ndf['Normalized_Sales'] = ...  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Normalized_Sales'] = df['Sales'] / df.groupby('Product')['Sales'].transform('sum')\n```"
  },
  {
    "input": "Problem:\nI am analyzing a set of customer data for a retail business and I want to visualize the distribution of customer ages in a histogram. My data is stored in a Pandas DataFrame, where 'age' is one of the columns. The DataFrame has 1000 entries, and I would like to plot this histogram with specific parameters. Here's the code snippet I'm currently using to prepare my data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generating sample data\nnp.random.seed(42)\ndata = {\n    'age': np.random.randint(18, 70, size=1000),\n}\ndf = pd.DataFrame(data)\n\n# Creating a histogram\nplt.figure(figsize=(10, 5))\nplt.hist(df['age'], bins=20, color='blue', alpha=0.7)\nplt.title('Age Distribution of Customers')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n```\n\nI would like to know how to properly display the grid that enhances the readability of the histogram. \nA:\n<code>\nplt.grid(...) # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a dataset of house prices where I have features like square footage, number of bedrooms, and location. I want to predict house prices using a machine learning model. The dataset is in a Pandas DataFrame called `house_data`, and I need to preprocess this data by scaling the numeric features before feeding it to a model in Scikit-learn. The features to scale are 'square_footage' and 'num_bedrooms'. I'll be using `StandardScaler` for this task.\n\nHere\u2019s an example of how to define the DataFrame:\n```python\nimport pandas as pd\n\nhouse_data = pd.DataFrame({\n    'square_footage': [1500, 2500, 1800, 2200],\n    'num_bedrooms': [3, 4, 2, 3],\n    'location': ['A', 'B', 'A', 'B'],\n    'price': [300000, 500000, 350000, 400000]\n})\n```\n\nI want to create a function that will return the scaled version of the features. The scaled features should replace the original ones in the DataFrame. What is the line of code I need to complete this?\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeatures_to_scale = ['square_footage', 'num_bedrooms']\nscaled_features = ... # put solution in this variable\n```",
    "output": "\n```python\nscaled_features = scaler.fit_transform(house_data[features_to_scale])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses, including their sizes, number of rooms, and prices, stored in a Pandas dataframe. I want to create a synthetic dataset using TensorFlow to predict house prices. The original dataframe looks like this:\n\n| size (sq ft) | rooms | price   |\n|--------------|-------|---------|\n| 1500         | 3     | 400000  |\n| 1800         | 4     | 550000  |\n| 2400         | 5     | 650000  |\n| 3000         | 5     | 750000  |\n| 1200         | 2     | 300000  |\n\nI need to define a simple neural network model in TensorFlow that has two layers: the first layer should have 10 neurons and the second layer should output the predicted price. \n\nHere is the starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\ndata = {\n    'size': [1500, 1800, 2400, 3000, 1200],\n    'rooms': [3, 4, 5, 5, 2],\n    'price': [400000, 550000, 650000, 750000, 300000]\n}\n\ndf = pd.DataFrame(data)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation='relu'), \n    ...\n])\n```\n\nWhere should I fill in the blank to complete the model and return the predicted price of the house?\n\nA:\n<code>\nmodel.add(tf.keras.layers.Dense(1))\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = model.predict(df[['size', 'rooms']])\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset of customer transactions that includes various details such as customer ID, purchase amount, and product category. I want to visualize the total sales per product category using a bar chart. Here is how I'm currently organizing my data using Pandas:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 2, 3, 1, 2, 3, 4, 5],\n    'purchase_amount': [250, 150, 300, 200, 220, 100, 90, 400],\n    'product_category': ['A', 'B', 'A', 'A', 'C', 'B', 'C', 'A']\n}\ndf = pd.DataFrame(data)\n```\n\nAfter aggregating the total purchase amounts for each product category, I want to create a bar chart to visualize this data. What code should I add to produce the bar chart?\n\nA:\n```python\n# Code to visualize the total sales per product category\nplt.bar(..., ...)\nplt.xlabel('Product Category')\nplt.ylabel('Total Sales')\nplt.title('Total Sales per Product Category')\nplt.show()\n```",
    "output": "\n```python\ntotal_sales = df.groupby('product_category')['purchase_amount'].sum()\nplt.bar(total_sales.index, total_sales.values)\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset represented as a Pandas DataFrame, where I want to calculate the rolling average of a specific column. I would like to perform the calculation over a window size of 3 for the 'value' column. The dataset may also have missing values, and I need to make sure that the rolling average handles them appropriately. After calculating the rolling average, I want to visualize the results using Matplotlib.\n\nHere is the starting code:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {'time': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'value': [1, 2, np.nan, 4, 5, np.nan, 7, 8, 9, 10]}\ndf = pd.DataFrame(data).set_index('time')\n</code>\nrolling_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nrolling_avg = df['value'].rolling(window=3, min_periods=1).mean()\n\nplt.figure(figsize=(10, 5))\nplt.plot(df.index, df['value'], label='Original Values', marker='o')\nplt.plot(df.index, rolling_avg, label='Rolling Average', marker='x', color='orange')\nplt.title('Rolling Average of Value Column')\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.legend()\nplt.show()"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Simulate a dataset\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10  # 100 random values for feature\ny = 2.5 * X + np.random.randn(100, 1)  # Linear relation with noise\n\n# Create a dataframe\ndf = pd.DataFrame(data=np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Now I want to train a linear regression model to fit this dataset.\n# I'm using the following line to fit the model, but I'm unsure if it's correct:\nmodel = LinearRegression()\nmodel.fit(df['Feature'].values.reshape(-1, 1), df['Target'].values)\n\n# I need to predict on the same feature but want to also generate a scatter plot\n# alongside the regression line. \n# To plot the line, I'll create predictions for a range of values:\nx_range = np.linspace(0, 10, 100).reshape(-1, 1)\npredictions = ...  # Fill this blank with the correct method to get predictions from the model\n\n# Now to visualize the results:\nplt.scatter(df['Feature'], df['Target'], color='blue', label='Data points')\nplt.plot(x_range, predictions, color='red', label='Regression line')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.legend()\nplt.show()\n\n# What should go in the blank for predictions?\n```",
    "output": "\n```python\npredictions = model.predict(x_range)\n```"
  },
  {
    "input": "### Problem:\nYou have a dataset comprised of features and a target variable stored in a Pandas DataFrame. The features include several numerical columns that you want to standardize using Scikit-learn's `StandardScaler`. After scaling, you want to create a scatter plot using Matplotlib to visualize the first two principal components obtained from the scaled features via PCA (Principal Component Analysis). Your DataFrame is named `df`, and your target variable is a column labeled `target`.\n\nHere is the current code you have for scaling:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n```\n\nIn the code above, fill in the blank for `X_scaled`. \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...  # Fill in this part\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n</code>",
    "output": "\n<code>\nX_scaled = scaler.fit_transform(X)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Create a random dataset with 100 samples and 5 features\ndata = np.random.rand(100, 5)\ndf = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(5)])\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Reduce dimensionality to 2D using PCA\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Create a scatter plot of the PCA result\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA Result')\n\n# How to display the plot\n# SOLUTION START\n\n```",
    "output": "\n```python\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about products sold in a store. The dataset consists of the following three attributes represented as lists:\n\nproduct_ids = [\"P001\", \"P002\", \"P003\", \"P001\", \"P002\", \"P003\"]\nsales_dates = [\"2023-01-01\", \"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-02\"]\nsales_amounts = [100, 150, 200, 120, 180, 160]\n\nI want to analyze the total sales for each product across the two days using pandas. After aggregating the total sales, I also want to visualize the results with a bar chart using Matplotlib.\n\nThe expected output should look like this after grouping and summing:\nproduct_id    total_sales\nP001                220\nP002                330\nP003                360\n\nHow can I achieve this using pandas for data manipulation and Matplotlib for visualization?\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nproduct_ids = [\"P001\", \"P002\", \"P003\", \"P001\", \"P002\", \"P003\"]\nsales_dates = [\"2023-01-01\", \"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-02\"]\nsales_amounts = [100, 150, 200, 120, 180, 160]\n\ndf = pd.DataFrame({'product_id': product_ids, 'sales_date': sales_dates, 'sales_amount': sales_amounts})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('product_id')['sales_amount'].sum().reset_index(name='total_sales')\nplt.bar(result['product_id'], result['total_sales'])\nplt.xlabel('Product ID')\nplt.ylabel('Total Sales')\nplt.title('Total Sales per Product')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a time series dataset containing daily stock prices for multiple companies and I want to perform some analysis to understand correlations between their returns. Specifically, I want to:\n1. Calculate daily returns for each stock based on the prices.\n2. Compute the correlation matrix of the returns.\n\nHere\u2019s the code I have so far that loads the dataset into a Pandas DataFrame:\n\n```python\nimport pandas as pd\ndf = pd.read_csv('stock_prices.csv')  # Assume the CSV has columns 'Date', 'Stock_A', 'Stock_B', ..., 'Stock_N'\n```\n\nNow, what I want is to calculate the daily returns and store them in a new DataFrame called `returns`. The daily return is computed as: \n\\[ \\text{return} = \\frac{\\text{current\\_price} - \\text{previous\\_price}}{\\text{previous\\_price}} \\]\n\nYou can assume that the necessary libraries have been imported and the dataframe setup is correctly in place.\n\nA:\n```python\nreturns = df.pct_change()  # put solution in this variable\n```",
    "output": "\n```python\nreturns = df.set_index('Date').pct_change().dropna()  # put solution in this variable\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# You have a dataset of house prices with their respective square footage:\ndata = {\n    'square_footage': [1500, 2500, 3500, 4500, 5500],\n    'price': [300000, 500000, 700000, 800000, 1000000]\n}\n\n# You want to fit a linear regression model to predict price based on square footage.\n# After fitting the model, you will evaluate it using mean squared error on the training data.\n# First, create a DataFrame from the data and then fill in the blank for the predicted prices.\n\ndf = pd.DataFrame(data)\nX = df[['square_footage']]\ny = df['price']\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Now we want to predict the prices based on the square footage in the DataFrame\npredicted_prices = ... # fill in this variable with the predicted prices from the model\n\n# Finally, calculate the mean squared error\nmse = mean_squared_error(y, predicted_prices)\nprint(\"Mean Squared Error:\", mse)\n```",
    "output": "\n```python\npredicted_prices = model.predict(X)\n```"
  },
  {
    "input": "Problem:\nConsider a dataset of housing prices stored in a Pandas DataFrame. The DataFrame contains features such as 'size', 'bedrooms', 'price', 'location', and 'year_built'. I want to create a Pandas DataFrame `df` with some sample data.\n\nYou need to implement a function that normalizes the column 'price' using Min-Max scaling to ensure all values are between 0 and 1. The scaling formula is given by:\n\n\\[ \\text{normalized\\_value} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}} \\]\n\nHere is an example of how the DataFrame should initially look:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 2500, 3000, 4000, 2300],\n    'bedrooms': [3, 4, 5, 5, 4],\n    'price': [400000, 600000, 650000, 750000, 580000],\n    'location': ['A', 'B', 'A', 'C', 'B'],\n    'year_built': [2005, 2010, 2015, 2000, 2015]\n}\n```\n\nNow complete the following function that normalizes the 'price' column:\n\n```python\ndef normalize_price(df):\n    price_min = df['price'].min()\n    price_max = df['price'].max()\n    df['price'] = (df['price'] - price_min) / (price_max - price_min)\n    return df\n\ndf = ... # fill in with your DataFrame creation code to match the example above\n```\n\nAfter running the `normalize_price` function on `df`, the 'price' column should contain values scaled between 0 and 1. The task is to correctly create the DataFrame.",
    "output": "\n```python\ndf = pd.DataFrame(data)\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing the sales data for a grocery store, recorded in a pandas DataFrame. The DataFrame contains the following columns: 'date' (the date of the sales), 'item' (the item being sold), and 'quantity' (the quantity sold). I want to analyze the monthly sales trends for each item.\n\nHere is a snippet of the dataset:\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-05', '2023-01-12', '2023-02-05', '2023-02-20', \n             '2023-03-15', '2023-01-25', '2023-03-05', '2023-02-15'],\n    'item': ['apple', 'banana', 'apple', 'banana', \n             'apple', 'orange', 'orange', 'banana'],\n    'quantity': [10, 5, 15, 10, \n                 20, 10, 5, 12]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to get the total quantity sold for each item, aggregated by month. The desired output should look like this in a new DataFrame:\n```\n       item    month     total\n0     apple  2023-01      10\n1     apple  2023-02      15\n2     apple  2023-03      20\n3    banana  2023-01       5\n4    banana  2023-02      10\n5    banana  2023-03      12\n6    orange  2023-01      10\n7    orange  2023-02       0\n8    orange  2023-03       5\n```\n\nI am struggling with how to group by both item and month, while also ensuring that I capture months with zero sales for certain items. My attempt at the solution doesn't seem to work. \n\nI would like you to provide the code for consolidating this information into a new DataFrame called `result`. \n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': ['2023-01-05', '2023-01-12', '2023-02-05', '2023-02-20', \n             '2023-03-15', '2023-01-25', '2023-03-05', '2023-02-15'],\n    'item': ['apple', 'banana', 'apple', 'banana', \n             'apple', 'orange', 'orange', 'banana'],\n    'quantity': [10, 5, 15, 10, \n                 20, 10, 5, 12]\n}\n\ndf = pd.DataFrame(data)\n\n# Your answer here should assign result\nresult = ... # put solution in this variable\n</code>\n",
    "output": "\n<code>\ndf['date'] = pd.to_datetime(df['date'])\ndf['month'] = df['date'].dt.to_period('M')\n\nmonthly_sales = df.groupby(['item', 'month'])['quantity'].sum().reset_index()\nmonthly_sales['total'] = monthly_sales['quantity']\n\nall_items = df['item'].unique()\nall_months = df['month'].unique()\n\nresult = (pd.MultiIndex.from_product([all_items, all_months], names=['item', 'month'])\n          .to_frame(index=False)\n          .merge(monthly_sales, on=['item', 'month'], how='left')\n          .fillna(0)\n          .astype({'total': 'int'}))\n</code>"
  },
  {
    "input": "## Problem:\n\nYou are working with a dataset that contains information about a series of machine learning models, their hyperparameters, and their corresponding accuracy metrics. The dataframe is structured as follows:\n\n```\n   Model      Hyperparameter1   Hyperparameter2   Accuracy\n0   ModelA            0.01             0.1             0.85\n1   ModelB            0.02             0.3             0.90\n2   ModelA            0.01             0.2             0.88\n3   ModelC            0.02             0.1             0.92\n4   ModelB            0.03             0.3             0.94\n5   ModelC            0.02             0.4             0.91\n```\n\nYou want to summarize the average accuracy of each model based on different combinations of hyperparameters. To achieve this, you'll group the dataset by 'Model' and calculate the mean 'Accuracy'.\n\nGiven the dataframe `df` is defined as:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Model': ['ModelA', 'ModelB', 'ModelA', 'ModelC', 'ModelB', 'ModelC'],\n    'Hyperparameter1': [0.01, 0.02, 0.01, 0.02, 0.03, 0.02],\n    'Hyperparameter2': [0.1, 0.3, 0.2, 0.1, 0.3, 0.4],\n    'Accuracy': [0.85, 0.90, 0.88, 0.92, 0.94, 0.91]\n}\n\ndf = pd.DataFrame(data)\n```\n\nFill in the blank for an operation that computes the mean accuracy for each model:\n\n```python\nmean_accuracy = df.groupby('Model')['Accuracy'].mean()\n```\nThe resulting variable `mean_accuracy` should contain the average accuracies of 'ModelA', 'ModelB', and 'ModelC'. \n\nA:\n\n```python\nmean_accuracy = ... # put solution in this variable\n```",
    "output": "\n```python\nmean_accuracy = df.groupby('Model')['Accuracy'].mean()\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset containing user ratings for various movies, and I'd like to compute the cosine similarity between each pair of movie ratings using a sparse matrix representation. The dataset is structured as follows (a simplified version):\n\n```\nUser    Movie1  Movie2  Movie3  Movie4\n1      4      0      3      5\n2      0      2      0      1\n3      5      0      4      0\n4      0      3      5      4\n```\n\nTo achieve this, I have already created a sparse matrix representation using `scipy.sparse`. Next, I want to calculate the cosine similarity for the movie ratings. However, I need a method that allows me to calculate and return a sparse similarity matrix without converting it to a dense format, as the matrix is large. Below is a code snippet where I've created a sparse matrix from the dataset.\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndata = {\n    'User': [1, 2, 3, 4],\n    'Movie1': [4, 0, 5, 0],\n    'Movie2': [0, 2, 0, 3],\n    'Movie3': [3, 0, 4, 5],\n    'Movie4': [5, 1, 0, 4]\n}\n\ndf = pd.DataFrame(data)\nsparse_matrix = csr_matrix(df.iloc[:, 1:].values)\n```\n\nI want to compute the cosine similarity matrix of the sparse matrix and store it in a variable called `similarity_matrix`. \n\nA:\n```python\nsimilarity_matrix = ... # put solution in this variable\n```",
    "output": "\n```python\nsimilarity_matrix = cosine_similarity(sparse_matrix, dense_output=False)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing temperature readings from multiple sensors over several days. The data is in a Pandas DataFrame format with columns: `date`, `sensor_id`, and `temperature`. I need to compute the daily average temperature for each sensor and then visualize the results using Matplotlib. The DataFrame is structured as follows:\n\n```\n      date      sensor_id  temperature\n0 2023-01-01        1           22.5\n1 2023-01-01        2           23.0\n2 2023-01-01        1           20.0\n3 2023-01-02        2           24.5\n4 2023-01-02        1           21.5\n```\n\nWhat is the Python code to compute the daily average temperature for each sensor and visualize it?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'sensor_id': [1, 2, 1, 2, 1],\n    'temperature': [22.5, 23.0, 20.0, 24.5, 21.5]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n\n# Compute the daily average temperature for each sensor\navg_temp = ... # put solution in this variable\n\n# Visualize the results\nplt.figure(figsize=(10, 5))\nplt.plot(avg_temp['date'], avg_temp['temperature'], label='Avg Temperature')\nplt.title('Daily Average Temperature per Sensor')\nplt.xlabel('Date')\nplt.ylabel('Average Temperature')\nplt.legend()\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\navg_temp = df.groupby(['date', 'sensor_id'])['temperature'].mean().reset_index()\navg_temp = avg_temp.groupby('date')['temperature'].mean().reset_index()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing temperatures over several days for multiple cities. The dataset is in a CSV file, \"temperature_data.csv\", which has the following structure:\n\n```\ndate,city,temperature\n2023-01-01,CityA,15.2\n2023-01-01,CityB,18.5\n2023-01-02,CityA,16.3\n2023-01-02,CityB,20.1\n...\n```\n\nI want to calculate the daily average temperature for each city and visualize the results in a line plot. I have already imported the necessary libraries and read the data into a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('temperature_data.csv')\n```\n\nWhat code should I use to calculate the daily average temperatures and plot them, so that the x-axis represents the dates and each city has a separate line for its average temperature?\n\nresult = ... # put solution in this variable",
    "output": "\n<code>\nresult = df.groupby(['date', 'city'])['temperature'].mean().unstack()\nresult.plot(kind='line', marker='o')\nplt.title('Daily Average Temperature by City')\nplt.xlabel('Date')\nplt.ylabel('Average Temperature (\u00b0C)')\nplt.xticks(rotation=45)\nplt.legend(title='City')\nplt.tight_layout()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing historic temperatures from multiple cities, structured as follows:\n\n```\n   Date       City       Temperature\n0 2021-01-01  New York   30\n1 2021-01-01  Los Angeles 70\n2 2021-01-01  Chicago     25\n3 2021-01-02  New York   32\n4 2021-01-02  Los Angeles 68\n5 2021-01-02  Chicago     28\n6 2021-01-03  New York   31\n7 2021-01-03  Los Angeles 72\n8 2021-01-03  Chicago     26\n```\n\nI would like to compute the moving average temperature for each city over the last two days. The resultant DataFrame should add a new column 'Moving_Avg_Temp' indicating this average. The first two rows for each city should contain `NaN` for the moving average due to insufficient data.\n\nHere's the initial DataFrame setup:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02', '2021-01-02', \n             '2021-01-03', '2021-01-03', '2021-01-03'],\n    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago', \n             'New York', 'Los Angeles', 'Chicago'],\n    'Temperature': [30, 70, 25, 32, 68, 28, 31, 72, 26]\n}\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the blank for the line of code that computes the moving average:\n\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().reset_index(drop=True)\n```\n\nWhat would the complete line look like to create the `Moving_Avg_Temp` column? \n\nA:\n```python\ndf['Moving_Avg_Temp'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().shift(1).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nYou are working with a historical dataset of temperature readings collected daily from multiple weather stations. The data is organized in a Pandas DataFrame with the following structure:\n\n| station_id | date       | temperature |\n|------------|------------|-------------|\n| 1          | 2021-01-01 | 5.0         |\n| 1          | 2021-01-02 | 7.0         |\n| 2          | 2021-01-01 | 3.0         |\n| 2          | 2021-01-02 | 2.0         |\n| 1          | 2021-01-03 | 8.0         |\n| 2          | 2021-01-03 | 1.0         |\n\nYou need to calculate the rolling average temperature for each station over a window of 2 days, but for each entry, you want to replace missing (NaN) values with 0. The desired DataFrame should look like this:\n\n| station_id | date       | rolling_avg |\n|------------|------------|-------------|\n| 1          | 2021-01-01 | 5.0         |\n| 1          | 2021-01-02 | 6.0         |\n| 2          | 2021-01-01 | 3.0         |\n| 2          | 2021-01-02 | 2.5         |\n| 1          | 2021-01-03 | 7.5         |\n| 2          | 2021-01-03 | 1.5         |\n\nGiven the DataFrame in the variable `df`, how would you compute the rolling average and store the result in the column `rolling_avg`?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'station_id': [1, 1, 2, 2, 1, 2],\n    'date': ['2021-01-01', '2021-01-02', '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-03'],\n    'temperature': [5.0, 7.0, 3.0, 2.0, 8.0, 1.0]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['rolling_avg'] = df.groupby('station_id')['temperature'].apply(lambda x: x.rolling(window=2, min_periods=1).mean().fillna(0))\nresult = df[['station_id', 'date', 'rolling_avg']]\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load iris dataset\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train a RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Generate a classification report and store the result\n# SOLUTION START\n```",
    "output": "\n```python\nreport = classification_report(y_test, y_pred, target_names=data.target_names)\nprint(report)\n# SOLUTION END\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing various features of houses (e.g., size, number of rooms, year built) in a pandas DataFrame, and you'd like to perform data normalization to prepare it for training a machine learning model. The DataFrame contains both numerical and categorical columns. To simplify, let's assume the DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 2000, 2500, 3000],\n    'num_rooms': [3, 4, 3, 5],\n    'year_built': [2000, 1995, 2010, 2005],\n    'location': ['A', 'B', 'A', 'C']\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to normalize the numerical features ('size', 'num_rooms', 'year_built') using Min-Max scaling, and leave the categorical feature ('location') unchanged. What is the code to normalize the numerical columns in your DataFrame to a range from 0 to 1 and return the updated DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 2000, 2500, 3000],\n    'num_rooms': [3, 4, 3, 5],\n    'year_built': [2000, 1995, 2010, 2005],\n    'location': ['A', 'B', 'A', 'C']\n}\ndf = pd.DataFrame(data)\n```\ndf_normalized = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\ndf_normalized = df.copy()\ndf_normalized[['size', 'num_rooms', 'year_built']] = (df[['size', 'num_rooms', 'year_built']] - df[['size', 'num_rooms', 'year_built']].min()) / (df[['size', 'num_rooms', 'year_built']].max() - df[['size', 'num_rooms', 'year_built']].min())</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\n\n# Load the Iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Calculate the mean of each feature grouped by the target class\n# I want to visualize this in a bar plot with the class labels on the x-axis.\n# Let's start plotting the mean of each feature for each class. \n# The first step is to obtain the mean values.\n\nmean_values = df.groupby('target').mean()\n\n# Now, create a bar plot of these mean values.\n# SOLUTION START\n```",
    "output": "\n```python\nmean_values.plot(kind='bar')\nplt.title('Mean Feature Values by Iris Class')\nplt.xlabel('Iris Class')\nplt.ylabel('Mean Feature Value')\nplt.xticks(rotation=0)\nplt.legend(title='Features')\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nI am working on a dataset that contains sales data for a retail store, structured in a pandas DataFrame like this:\n\n| product_id | sale_date  | quantity | price_per_unit |\n|------------|------------|----------|-----------------|\n| 1          | 2023-01-01 | 10       | 5.0             |\n| 1          | 2023-01-02 | 4        | 5.0             |\n| 2          | 2023-01-01 | 3        | 10.0            |\n| 2          | 2023-01-01 | 7        | 10.0            |\n| 1          | 2023-01-03 | 5        | 5.0             |\n| 2          | 2023-01-03 | 6        | 10.0            |\n\nI want to compute the total revenue generated for each product on each sale date. The total revenue for each entry can be calculated by multiplying the quantity sold by the price per unit.\n\nAfter computing the total revenue, I want to reshape the resulting DataFrame to have a summary that displays the total revenue for each product by date in a wider format.\n\nHow can I achieve this using Pandas?\n\nHere is the DataFrame that you start with:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 2, 2, 1, 2],\n    'sale_date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-01', '2023-01-03', '2023-01-03'],\n    'quantity': [10, 4, 3, 7, 5, 6],\n    'price_per_unit': [5.0, 5.0, 10.0, 10.0, 5.0, 10.0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter computing and reshaping, I want to obtain a DataFrame that looks like this:\n\n| product_id | 2023-01-01 | 2023-01-02 | 2023-01-03 |\n|------------|-------------|-------------|-------------|\n| 1          | total_revenue_for_1_on_2023-01-01 | total_revenue_for_1_on_2023-01-02 | total_revenue_for_1_on_2023-01-03 |\n| 2          | total_revenue_for_2_on_2023-01-01 | 0           | total_revenue_for_2_on_2023-01-03 |\n\nWhat code can be placed in this variable to get the desired output?\n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf['total_revenue'] = df['quantity'] * df['price_per_unit']\nresult = df.pivot_table(index='product_id', columns='sale_date', values='total_revenue', aggfunc='sum', fill_value=0)\n</code>"
  },
  {
    "input": "Problem:\n\nYou are analyzing a dataset of stock prices using Pandas and want to compute the daily returns. After calculating the returns, you decide to visualize the distribution of these returns using Matplotlib. Additionally, you wish to standardize the returns using the Z-score method and then apply a simple linear regression using Scikit-learn to check if returns can predict the next day's price change.\n\nUsing NumPy, Pandas, Matplotlib, and Scikit-learn, how would you structure the following code to achieve the Z-score standardization of the returns and return the trained linear regression model?\n\nYour input variable `returns` is a Pandas Series containing daily returns.\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Assuming 'returns' is a Pandas Series of daily returns\nreturns = load_data()\nreturns_z = (returns - returns.mean()) / returns.std()\n\n# Now create a feature set and target using the standardized returns\nX = returns_z[:-1].values.reshape(-1, 1)  # all but last\ny = returns_z[1:].values  # all but first (next day's return)\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Code to visualize the distribution of the standardized returns\nplt.hist(returns_z, bins=30)\nplt.title('Distribution of Standardized Returns')\nplt.xlabel('Z-score')\nplt.ylabel('Frequency')\nplt.show()\n\ntrained_model = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntrained_model = model\n</code>"
  },
  {
    "input": "Problem:\nI have two datasets representing customer transactions and product information. The `transactions` dataframe has columns for 'customer_id', 'product_id', and 'amount_spent', while the `products` dataframe contains 'product_id' and 'product_category'. I want to analyze the total spending of each customer per product category. Therefore, I need to merge these dataframes on 'product_id' and then group the result by 'customer_id' and 'product_category' to calculate the total spending in each category. \n\nHere are the transactions and products dataframes:\n\n```python\nimport pandas as pd\n\ntransactions = pd.DataFrame({\n    'customer_id': [1, 2, 1, 3, 2, 1],\n    'product_id': [101, 102, 103, 101, 103, 102],\n    'amount_spent': [10.5, 20.0, 30.5, 15.0, 25.0, 5.0]\n})\n\nproducts = pd.DataFrame({\n    'product_id': [101, 102, 103],\n    'product_category': ['A', 'B', 'A']\n})\n```\n\nI want to end up with a dataframe that shows 'customer_id', 'product_category', and 'total_spending' for each product category. \n\nThe desired output would look like this:\n\n```\n   customer_id product_category  total_spending\n0            1                A            41.0\n1            1                B            5.0\n2            2                A            0.0\n3            2                B            20.0\n4            3                A            15.0\n```\n\nI have attempted to use pd.merge and groupby, but I can't seem to get the total spending by category accurately. Below is my current code:\n\n```python\nmerged_df = pd.merge(transactions, products, on='product_id')\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = merged_df.groupby(['customer_id', 'product_category'], as_index=False).agg(total_spending=('amount_spent', 'sum')).fillna(0)\nresult = result.pivot_table(index='customer_id', columns='product_category', values='total_spending', fill_value=0).reset_index()\nresult = result.melt(id_vars='customer_id', value_vars=result.columns[1:], var_name='product_category', value_name='total_spending')\n```"
  },
  {
    "input": "### Problem\nYou have a dataset representing daily average temperatures for a city over a year in a pandas DataFrame, with some missing values. Your goal is to fill these missing temperature values with the mean temperature for that day of the week. \n\nHere's how your DataFrame looks:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2021-01-01', periods=365, freq='D'),\n    'Temperature': [np.nan if i % 30 == 0 else np.random.randint(15, 35) for i in range(365)]\n}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nNow, using the `fillna` method, fill the NaN values with the mean of the temperatures for the respective day of the week. The desired DataFrame should have no NaN entries.\n\nYour code should replace the ellipsis with the appropriate solution to complete this task.\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby(df.index.dayofweek)['Temperature'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "## Problem\nYou have a dataset of student scores in a pandas DataFrame, which includes the following columns: 'Student', 'Subject', and 'Score'. You want to normalize the scores to a range between 0 and 1 for each subject. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science'],\n    'Score': [90, 80, 85, 70, 95]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to compute the normalized score for each student in each subject. The normalized score is calculated using this formula:\n\n\\[\n\\text{Normalized Score} = \\frac{\\text{Score} - \\text{min(Score)}}{\\text{max(Score)} - \\text{min(Score)}}\n\\]\n\nPlease fill in the blank to add the normalized score column to your DataFrame like this:\n\n```python\ndf['Normalized_Score'] = ...\n```\nWhere `...` is the solution to compute the normalized scores using `Scikit-learn`'s `MinMaxScaler`.",
    "output": "\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf['Normalized_Score'] = df.groupby('Subject')['Score'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)))\n```"
  },
  {
    "input": "Problem:\nI want to implement a machine learning model to predict housing prices based on various features such as square footage, number of bedrooms, and location. After training the model, I would like to visualize the predicted prices against the actual prices in a scatter plot. \n\nGiven the dataset:\n```python\nimport pandas as pd\ndata = pd.DataFrame({\n    'square_footage': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'location': ['Urban', 'Suburban', 'Urban', 'Suburban', 'Urban'],\n    'price': [300000, 320000, 340000, 360000, 400000]\n})\n```\nand a simple linear regression model using Scikit-learn:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nX = data[['square_footage', 'bedrooms', 'location']]\ny = data['price']\n```\n\nCreate and fit a pipeline that includes both preprocessing and training steps, and then store the predicted prices in the variable `predicted_prices` after fitting the model. \nYour code should look like:\n```python\npipeline = ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\npipeline = Pipeline(steps=[\n    ('preprocessor', ColumnTransformer(\n        transformers=[\n            ('num', 'passthrough', ['square_footage', 'bedrooms']),\n            ('cat', OneHotEncoder(), ['location'])\n        ])),\n    ('model', LinearRegression())\n])\npipeline.fit(X, y)\npredicted_prices = pipeline.predict(X)\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses, including their size in square feet and their corresponding prices. I want to predict the prices of houses using a linear regression model. The features are stored in a Pandas DataFrame called `houses` with columns 'Size' and 'Price'. After fitting the model using Scikit-learn, I would like to visualize the regression line over the scatter plot of the data points using Matplotlib.\n\nThe DataFrame looks like this:\n```\n   Size  Price\n0   1500  300000\n1   2000  400000\n2   2500  500000\n3   3000  600000\n4   3500  700000\n```\n\nYou need to import the required libraries, fit the linear regression model, and plot the regression line. To prepare for plotting, please make sure to create the `size` variable for the feature data, and the `price` variable for the target data.\n\nHere's the initial code:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nhouses = pd.DataFrame({\n    'Size': [1500, 2000, 2500, 3000, 3500],\n    'Price': [300000, 400000, 500000, 600000, 700000]\n})\n\nsize = houses['Size'].values.reshape(-1, 1)\nprice = houses['Price'].values\n\nmodel = LinearRegression()\nmodel.fit(...)  # Complete this line to fit the model \n\n# Generate predictions for the sizes\npredicted_price = ...  # Complete this line to get predicted prices for the given sizes\n\n# Now plot the results\nplt.scatter(..., ...)  # Replace with the proper data to create a scatter plot\nplt.plot(..., ...)  # Replace with the code to plot the regression line\nplt.xlabel('Size')\nplt.ylabel('Price')\nplt.title('House Price Prediction')\nplt.show()\n``` \n\nWhat should complete the fitting of the model, prediction generation, and plotting?",
    "output": "\n```python\nmodel.fit(size, price)\n\npredicted_price = model.predict(size)\n\nplt.scatter(size, price)\nplt.plot(size, predicted_price, color='red')\n```"
  },
  {
    "input": "Problem:\nI have a dataset consisting of several years of daily temperature recordings in a Pandas DataFrame. The DataFrame has two columns: 'date' (datetime objects) and 'temperature' (float values representing degrees Celsius). I need to compute the weekly average temperatures and return them as a new DataFrame with two columns: 'week' (the week number of the year) and 'average_temperature' (the average temperature for that week).\n\nHere's how the data looks:\n\n```\n        date    temperature\n0 2020-01-01           5.0\n1 2020-01-02           6.5\n2 2020-01-07           4.0\n3 2020-01-08           7.0\n4 2020-01-14           8.0\n...\n```\n\nWhat would be the most efficient way to achieve this using Pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2020-01-01', periods=15, freq='D'),\n    'temperature': [5.0, 6.5, 4.0, 7.0, 8.0, 10.0, 9.5, 11.0, 12.0, 10.5, 9.0, 8.5, 7.5, 6.5, 5.5]\n}\ndf = pd.DataFrame(data)\n</code>\nweekly_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['week'] = df['date'].dt.isocalendar().week\nweekly_avg = df.groupby('week')['temperature'].mean().reset_index(name='average_temperature')\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing several features, and I would like to preprocess the data by normalizing it. My dataset, `data`, is a Pandas DataFrame with columns 'feature1', 'feature2', and 'feature3'. The normalization of each feature can be performed using the formula:\n\nnormalized_value = (value - mean) / std_dev\n\nTo achieve this, I want to use Scikit-learn's `StandardScaler`. However, I want to apply the transformation and also convert the result back into a DataFrame with the same column names. Given the code snippet, how can I fill in the blank to perform this normalization?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = pd.DataFrame({\n    'feature1': [10, 20, 30, 40, 50],\n    'feature2': [5, 10, 15, 20, 25],\n    'feature3': [1, 2, 3, 4, 5]\n})\n\nscaler = StandardScaler()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
  },
  {
    "input": "Problem:\nI have a DataFrame containing student scores in different subjects, and I want to standardize these scores across all subjects. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Student': ['Alice', 'Bob', 'Charlie', 'David'],\n    'Math': [90, 80, 70, 60],\n    'Science': [85, 75, 65, 55],\n    'English': [95, 85, 75, 65]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to normalize each subject's score (Math, Science, and English) to have a mean of 0 and a standard deviation of 1 by applying z-score normalization. What is the correct way to compute the standardized scores for the subjects?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df[['Math', 'Science', 'English']].apply(lambda x: (x - x.mean()) / x.std())\n</code>"
  },
  {
    "input": "```python\nProblem:\nI have a dataset of sales data in a Pandas DataFrame, and I want to normalize the sales figures to have a mean of 0 and a standard deviation of 1 using Scikit-learn's StandardScaler. Given the following DataFrame:\n\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Sales': [150, 200, 250, 300, 350]\n}\ndf = pd.DataFrame(data)\n\nHow can I normalize the 'Sales' column, and store the result in a new column called 'Normalized_Sales'?\nA:\n<code>\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n                   'Sales': [150, 200, 250, 300, 350]})\n</code>\ndf['Normalized_Sales'] = ... # put solution in this variable\n```",
    "output": "\n<code>\nscaler = StandardScaler()\ndf['Normalized_Sales'] = scaler.fit_transform(df[['Sales']])\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # 100 random points in range 0-10\ny = 3 * X.squeeze() + np.random.randn(100) * 5  # Linear relation with noise\n\n# Create a DataFrame\ndf = pd.DataFrame({'X': X.squeeze(), 'y': y})\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['X']], df['y'])\n\n# Predict values\ndf['y_pred'] = model.predict(df[['X']])\n\n# Plot the original data and the regression line\nplt.scatter(df['X'], df['y'], color='blue', label='Data Points')\nplt.plot(df['X'], df['y_pred'], color='red', label='Regression Line')\nplt.title('Linear Regression Fit')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.legend()\nplt.grid()\n\n# Now, set the x-axis limits to (0, 10) and the y-axis limits to (min y - 5, max y + 5)\n# SOLUTION START\n```",
    "output": "\n```python\nplt.xlim(0, 10)\nplt.ylim(df['y'].min() - 5, df['y'].max() + 5)\n# SOLUTION END\n\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nI am working on a project that involves analyzing customer purchase data to identify associations between different products. I would like to apply the Apriori algorithm to generate association rules from the data. \n\nI have loaded the data into a DataFrame called `df`, which contains a column named 'transactions'. I know that I need to use the `apriori` function from the `mlxtend` library, and I want to set a minimum support threshold to 0.01 to filter the frequent item sets.\n\nNow, I need to generate the frequent item sets based on that support. I have the necessary imports done already; here is the loading part:\n\n<code>\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori\n\ndf = load_transaction_data()  # This will return a DataFrame with a 'transactions' column\n</code>\nfrequent_itemsets = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nfrequent_itemsets = apriori(df['transactions'], min_support=0.01, use_colnames=True)  \n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset that contains information about different products. The dataset is represented as a Pandas DataFrame and contains columns for 'ProductID', 'Category', and 'Sales'. You want to aggregate the total sales for each category and visualize the results as a bar chart. Your DataFrame is defined as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': [1, 2, 3, 4, 5],\n    'Category': ['A', 'B', 'A', 'C', 'B'],\n    'Sales': [100, 150, 200, 300, 250]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new DataFrame called `category_sales` that aggregates the total sales per category. Following that, you would like to visualize the total sales by category using Matplotlib. You know how to create the plots, but you're looking for a concise way to fill in the blank below to achieve the category aggregation before plotting.\n\nA:\n```python\ncategory_sales = df.groupby('Category')['Sales'].sum().reset_index()\n```\n\nNow, for the plotting part, execute the following code:\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.bar(category_sales['Category'], category_sales['Sales'])\nplt.xlabel('Category')\nplt.ylabel('Total Sales')\nplt.title('Total Sales by Category')\nplt.show()\n```\n\nFill in the blank below to complete the DataFrame creation step.\n\n```python\ncategory_sales = ... # put solution in this variable\n```",
    "output": "\n```python\ncategory_sales = df.groupby('Category')['Sales'].sum().reset_index()\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Perform PCA to reduce the data to two dimensions\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(df)\n\n# Create a DataFrame with the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the PCA results\nplt.scatter(pc_df['PC1'], pc_df['PC2'])\nplt.title('PCA of Iris Dataset')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\n# How can I annotate the points with the class labels from the iris dataset?\n# The labels are in iris.target; add labels to the scatter plot accordingly.\n# SOLUTION START\n```",
    "output": "\n```python\nfor i in range(len(pc_df)):\n    plt.annotate(iris.target[i], (pc_df['PC1'][i], pc_df['PC2'][i]))\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of houses with their features stored in a Pandas DataFrame, and I want to predict the sale price using a machine learning model. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndata = {\n    'SquareFeet': [1500, 2500, 1800, 2300, 1200],\n    'Bedrooms': [3, 4, 3, 4, 2],\n    'Age': [10, 5, 15, 7, 20],\n    'SalePrice': [300000, 500000, 350000, 480000, 200000]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a TensorFlow model to predict the sale price based on 'SquareFeet', 'Bedrooms', and 'Age'. The features should be normalized before training the model. How can I fill in the code to normalize these features and define the model structure?\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfeatures = df[['SquareFeet', 'Bedrooms', 'Age']]\nscaler = StandardScaler()\n```\nnormalized_features = ... # put solution in this variable\n\n# Next, define the model structure\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(normalized_features.shape[1],)),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(1)\n])\n```",
    "output": "\n```python\nnormalized_features = scaler.fit_transform(features)\n\n# Next, define the model structure\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(normalized_features.shape[1],)),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(1)\n])\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\niris = load_iris()\nX = iris.data\n\n# Apply PCA to reduce the dimensionality of the dataset to 2 components\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\n\n# Now, I want to plot the first two components of the PCA\n# The plot should have a title \"PCA of Iris Dataset\"\n# The x-axis should be named \"Principal Component 1\"\n# The y-axis should be named \"Principal Component 2\"\n# I want to fill in the blank for the plotting code below:\n\nplt.scatter(X_reduced[:, 0], X_reduced[:, 1], c='blue')\nplt.title(\"PCA of Iris Dataset\")\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\nplt.show()\n# Put your solution in the following variable\nplot_cmd = ...  # Fill this in to display the plot\n```",
    "output": "\n```python\nplot_cmd = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c='blue')\n```"
  },
  {
    "input": "Problem:\nI have a dataset of daily temperatures recorded over a month in a Pandas DataFrame. I want to compute the rolling average temperature over a window of 7 days and visualize it using Matplotlib. Here is a sample DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'Temperature': np.random.randint(low=-10, high=35, size=30)\n}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nUsing the above DataFrame, I want to compute the rolling average and store it in a new column called 'Rolling_Average'. Then, I would like to plot both the 'Temperature' and 'Rolling_Average' on the same graph.\n\nProvide the code to calculate the rolling average:\n\n```python\nwindow_size = 7\n```\n\nrolling_average = ... # put solution in this variable  \nBEGIN SOLUTION  \n<code>",
    "output": "\n```python\nrolling_average = df['Temperature'].rolling(window=window_size).mean()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate random data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # Feature values\ny = 3 * X.squeeze() + np.random.randn(100) * 3  # Target values with noise\n\n# Fit a linear regression model on the generated data\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Make predictions on the data points in X\npredictions = ...  # put solution in this variable\n```",
    "output": "\n```python\n<code>\npredictions = model.predict(X)\n</code>\n```"
  },
  {
    "input": "Problem:\nYou are working on a dataset that contains information about customers' monthly spending on various products. Each row in the dataset contains the following columns: `customer_id`, `product`, and `spending`. You would like to compute the average monthly spending for each product and then visualize this information using a bar chart. \n\nHere is a sample dataframe:\n```\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat line of code should you write to calculate the average spending by product?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.groupby('product')['spending'].mean().reset_index()</code>"
  },
  {
    "input": "### Problem\n\nI have a dataset containing both numerical and categorical features. I would like to apply one-hot encoding to the categorical columns and then standardize the numerical columns. My current approach is running one-hot encoding first, but I\u2019m facing issues combining the transformed data correctly. Here is a snippet of my code:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\ndata = pd.DataFrame({\n    'category': ['A', 'B', 'A', 'C', 'B'],\n    'value1': [10, 20, 15, 10, 25],\n    'value2': [1.5, 2.5, 3.5, 2.0, 5.0]\n})\n\n# Create instances of the transformers\nencoder = OneHotEncoder(sparse=False)\nscaler = StandardScaler()\n\n# Apply one-hot encoding\nencoded_categories = encoder.fit_transform(data[['category']])\n\n# How can I combine `encoded_categories` and the standardized numerical values?\n```\n\nI need the final output to be a single DataFrame that includes the encoded categorical columns and the standardized numerical columns. Please fill in the blank to achieve this.\n\nresult = ...  # Your code here to create the final DataFrame",
    "output": "\n```python\nresult = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out(['category']))\nresult = pd.concat([result, pd.DataFrame(scaler.fit_transform(data[['value1', 'value2']]), columns=['value1', 'value2'])], axis=1)\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# I have a dataset containing the monthly sales of different products in a store.\n# The dataset looks like this:\n#    Month  Product_A  Product_B  Product_C\n# 0  2023-01        200        150        250\n# 1  2023-02        300        130        270\n# 2  2023-03        250        160        290\n# 3  2023-04        400        200        300\n# 4  2023-05        350        180        310\n\n# I want to calculate the yearly sales total for each product.\n# I will create a new DataFrame with the total sales for all months combined into a single row.\n\n# Start with creating the DataFrame\ndata = {'Month': ['2023-01', '2023-02', '2023-03', '2023-04', '2023-05'],\n        'Product_A': [200, 300, 250, 400, 350],\n        'Product_B': [150, 130, 160, 200, 180],\n        'Product_C': [250, 270, 290, 300, 310]}\n\ndf = pd.DataFrame(data)\n\n# Now, I want to sum the sales of each product and store it in a new DataFrame.\n# The result should have a single row that indicates the total sales for each product.\n\ntotal_sales = ... # put solution in this variable\n```",
    "output": "\n```python\ntotal_sales = pd.DataFrame(df[['Product_A', 'Product_B', 'Product_C']].sum()).T\ntotal_sales.insert(0, 'Yearly_Total', '2023')\n```"
  },
  {
    "input": "Problem:\n\nYou are given a dataset with multiple features, specifically a pandas DataFrame containing columns for 'Age', 'Salary', and 'Loan Amount'. You want to apply a scaling technique to the numeric columns (i.e., 'Age', 'Salary', 'Loan Amount') using the StandardScaler from Scikit-learn to normalize the data. After scaling, compute the mean of the normalized 'Salary' column. \n\nThe initial DataFrame looks like this:\n\n```\n    Age  Salary  Loan Amount\n0   25   50000    200000\n1   30   60000    250000\n2   35   65000    150000\n3   40   70000    300000\n4   45   80000    280000\n```\n\nYou can assume that the DataFrame is loaded into the variable `df`. Please define a function that returns the mean of the scaled 'Salary' column.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = load_data()\ndef scaled_salary_mean(df):\n    # your solution here\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n",
    "output": "\n```python\n    scaler = StandardScaler()\n    df[['Age', 'Salary', 'Loan Amount']] = scaler.fit_transform(df[['Age', 'Salary', 'Loan Amount']])\n    return df['Salary'].mean()\n</code>\nresult = scaled_salary_mean(df)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about houses with features including 'size' (in square feet), 'bedrooms', 'bathrooms', and 'price'. I want to create a model that predicts house prices based on these features. I've already split my dataset into training and testing sets and used Scikit-learn's LinearRegression to fit the model. However, now I want to visualize the predicted vs actual prices to evaluate the performance of my model.\n\nHere is a part of my code:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Sample dataset\ndata = {'size': [1500, 2500, 3000, 2000, 3500],\n        'bedrooms': [3, 4, 5, 3, 5],\n        'bathrooms': [2, 3, 4, 2, 4],\n        'price': [300000, 450000, 600000, 350000, 700000]}\ndf = pd.DataFrame(data)\n\nX = df[['size', 'bedrooms', 'bathrooms']]\ny = df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Now, to plot predicted vs actual prices\ny_pred = model.predict(X_test)\n```\n\nWhat line of code should I add to plot the predicted vs actual prices using Matplotlib so that I can easily visualize the model performance?\n\nA:\n<code>\nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual Prices')\nplt.ylabel('Predicted Prices')\nplt.title('Actual Prices vs Predicted Prices')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') # add line of perfect prediction\nplt.show()\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual Prices')\nplt.ylabel('Predicted Prices')\nplt.title('Actual Prices vs Predicted Prices')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--') # add line of perfect prediction\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset containing information about various species of flowers in a pandas DataFrame. The DataFrame, `flowers`, has columns 'species', 'sepal_length', 'sepal_width', 'petal_length', and 'petal_width'. You need to standardize the features of the dataset to prepare it for a machine learning model. You also want to visualize the standardized features using a scatter plot. \n\nHere's the DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\nflowers = pd.DataFrame({\n    'species': ['setosa', 'setosa', 'versicolor', 'versicolor', 'virginica', 'virginica'],\n    'sepal_length': [5.1, 4.9, 7.0, 6.4, 6.3, 5.8],\n    'sepal_width': [3.5, 3.0, 3.2, 3.2, 3.3, 2.7],\n    'petal_length': [1.4, 1.4, 4.7, 5.6, 4.9, 5.1],\n    'petal_width': [0.2, 0.2, 1.4, 2.4, 1.5, 1.8]\n})\n```\n\nYou want to perform the following tasks:\n1. Standardize the features 'sepal_length', 'sepal_width', 'petal_length', and 'petal_width' by using `StandardScaler` from `scikit-learn`.\n2. Create a scatter plot of the standardized 'sepal_length' against 'sepal_width', color-coded by species using `Matplotlib`.\n\nFill in the missing code to achieve this:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Extract the features\nX = flowers[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Standardize the features\nX_scaled = ... # put solution in this variable\n\n# Add the scaled features back to the DataFrame\nflowers[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] = X_scaled\n\n# Create the scatter plot\nplt.figure(figsize=(10, 6))\nplt.scatter(flowers['sepal_length'], flowers['sepal_width'], c=flowers['species'].apply(lambda x: {'setosa': 0, 'versicolor': 1, 'virginica': 2}[x]))\nplt.xlabel('Standardized Sepal Length')\nplt.ylabel('Standardized Sepal Width')\nplt.title('Scatter Plot of Standardized Sepal Dimensions')\nplt.colorbar(ticks=[0, 1, 2], label='Species', format=plt.FuncFormatter(lambda x, _: ['setosa', 'versicolor', 'virginica'][int(x)]))\nplt.show()\n```\n\nFill in the blank for `X_scaled = ...` with the appropriate code for standardizing the features using the `fit_transform` method of `scaler`.",
    "output": "\n```python\nX_scaled = scaler.fit_transform(X)\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer purchases that consists of three columns: 'customer_id', 'purchase_amount', and 'purchase_date'. The dataset is represented as a Pandas DataFrame. You want to analyze the total expenditure of each customer over a specified date range and visualize the results using a bar chart. \n\nThe DataFrame `df` looks like this:\n\n```\n   customer_id  purchase_amount purchase_date\n0            1             45.0    2023-01-01\n1            2             20.0    2023-01-02\n2            1             30.0    2023-01-05\n3            3             25.0    2023-01-07\n4            2             15.0    2023-01-08\n5            3             50.0    2023-01-10\n```\n\nYou need to filter the DataFrame for purchases made in January 2023, then aggregate the total 'purchase_amount' by 'customer_id'. Finally, create a bar plot to visualize the total expenditure of each customer.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 2, 1, 3, 2, 3],\n    'purchase_amount': [45.0, 20.0, 30.0, 25.0, 15.0, 50.0],\n    'purchase_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-07', '2023-01-08', '2023-01-10'])\n}\n\ndf = pd.DataFrame(data)\nstart_date = ...\nend_date = ...\n</code>\ntotals = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n</code>\ndf_filtered = df[(df['purchase_date'] >= start_date) & (df['purchase_date'] <= end_date)]\ntotals = df_filtered.groupby('customer_id')['purchase_amount'].sum().reset_index()\n\nplt.bar(totals['customer_id'], totals['purchase_amount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Expenditure')\nplt.title('Total Expenditure by Customer in January 2023')\nplt.show()\n",
    "output": "\n<code>\nstart_date = '2023-01-01'\nend_date = '2023-01-31'\n</code>"
  },
  {
    "input": "## Problem:\nYou are working with a dataset containing customer purchase records in a Pandas DataFrame. Each record has a customer ID and a list of items they purchased. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    \"customer_id\": [1, 2, 1, 3, 2],\n    \"items\": [\n        [\"apple\", \"banana\"],\n        [\"orange\", \"banana\", \"grape\"],\n        [\"banana\", \"kiwi\"],\n        [\"apple\"],\n        [\"grape\"]\n    ]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to create a new DataFrame that represents each item as a separate column, and for each customer ID, indicate whether they purchased that item (1 for yes, 0 for no). The final DataFrame should look like this:\n\n```\ncustomer_id  apple  banana  orange  grape  kiwi\n1            1      1      0      0      1\n2            0      1      1      1      0\n3            1      0      0      0      0\n```\n\nWhat is the Pandas code that will transform the original DataFrame into this desired format?\n\nA:\n```python\nnew_df = ... # put solution in this variable\n```",
    "output": "\n```python\nnew_df = df.explode('items').groupby('customer_id')['items'].apply(lambda x: x.unique()).reset_index()\nnew_df = new_df.set_index('customer_id').reindex(df['customer_id'].unique()).fillna(0).astype(int)\nnew_df = new_df.join(pd.get_dummies(df.explode('items')['items']).groupby(df['customer_id']).sum()).fillna(0).astype(int)\n```"
  },
  {
    "input": "Problem:\nI want to create a simple feedforward neural network using PyTorch and TensorFlow to predict a target variable based on input features from a synthetic dataset. The dataset is structured as follows: it has three features ('feature1', 'feature2', 'feature3') and a target variable ('target') containing continuous values.\n\nHere\u2019s how I will generate the dataset:\n1. Use NumPy to create a dataset with 100 samples, where 'feature1' is uniformly distributed between 0 and 1, 'feature2' is normally distributed with mean 0.5 and standard deviation 0.1, and 'feature3' is a binary variable (0 or 1) generated randomly.\n2. Then, I will normalize the features using Scikit-learn's `StandardScaler`.\n3. Lastly, I will use TensorFlow to build a Sequential model which consists of one input layer, one hidden layer with 10 units and ReLU activation, and one output layer for the target prediction.\n\nPlease fill in the blank to create the input and hidden layers of this model:\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\n\n# Generate synthetic dataset\nnp.random.seed(0)\nfeature1 = np.random.rand(100)\nfeature2 = np.random.normal(0.5, 0.1, 100)\nfeature3 = np.random.randint(0, 2, 100)\ntarget = feature1 * 10 + feature2 * 5 + feature3  # A synthetic linear relationship\ndata = pd.DataFrame({'feature1': feature1, 'feature2': feature2, 'feature3': feature3, 'target': target})\n\n# Normalize the features\nscaler = StandardScaler()\nX = scaler.fit_transform(data[['feature1', 'feature2', 'feature3']])\ny = data['target'].values\n\n# Define the TensorFlow model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Input(shape=(3,)))\nmodel.add(...)  # fill in with hidden layer\nmodel.add(tf.keras.layers.Dense(1))\n\nA:\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>model.add(tf.keras.layers.Dense(10, activation='relu'))</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing customer reviews with ratings, and I need to preprocess the text data and build a model to predict the ratings based on the reviews. The reviews are stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Review': [\n        'This product is great!',\n        'Worst purchase I ever made.',\n        'I love it, totally recommend!',\n        'It was okay, not what I expected.',\n        'Fantastic quality and fast shipping.'\n    ],\n    'Rating': [5, 1, 5, 3, 5]\n}\ndf = pd.DataFrame(data)\n```\n\nFirst, I want to convert the text reviews into a format suitable for a machine learning model by using a text vectorizer from `sklearn`. Then I will build a simple `TensorFlow` model to predict the ratings based on the processed reviews. \n\nI have set up my `CountVectorizer` as follows:\n\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(df['Review'])\n```\n\nNext, I need to define a simple neural network model using `TensorFlow`. Here is the provided setup for the model creation:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(...)))  # Input shape needs to be defined here\nmodel.add(layers.Dense(1, activation='linear'))  # Output layer for regression\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n```\n\nWhat should I put into the blank at `input_shape=(...)` to correctly define the input shape for the model based on the text vectorization?\n\nA:\n<code>\nmodel.add(layers.Dense(64, activation='relu', input_shape=(...)))  # put solution in this variable\nBEGIN SOLUTION\n<code> X.shape[1], </code>\n",
    "output": "\n<code> X.shape[1], </code>"
  },
  {
    "input": "Problem:\n\nYou have a dataset that records the daily temperatures of a city over the course of a year. The dataset is structured as follows:\n\n```\ndate       | temperature\n-----------|-------------\n2023-01-01 | 5\n2023-01-02 | 6\n...        | ...\n2023-12-30 | 2\n2023-12-31 | 3\n```\n\nYou want to create a list of boolean values indicating whether the temperature was above the average temperature of the year for each respective day. Specifically, if the temperature on a given day is above the yearly average, that day should correspond to `True`, otherwise `False`. \n\nYou will be using NumPy and Pandas libraries for this task, so you import them accordingly. \n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\n# Sample dataFrame creation\ndata = {\n    'date': pd.date_range(start='2023-01-01', end='2023-12-31'),\n    'temperature': np.random.randint(-10, 40, size=365)\n}\ndf = pd.DataFrame(data)\n\n# Calculate the average temperature of the year\naverage_temp = df['temperature'].mean()\n\n# Create a new column with boolean values\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['temperature'] > average_temp\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a Pandas DataFrame that includes features like 'size', 'bedrooms', and 'age'. I want to standardize these features using Scikit-learn's `StandardScaler`. How can I perform this operation and return a standardized DataFrame?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'size': [1500, 1600, 1700, 1400, 1300],\n    'bedrooms': [3, 4, 3, 2, 2],\n    'age': [10, 15, 20, 5, 8]\n}\ndf = pd.DataFrame(data)\nscaler = StandardScaler()\n</code>\nstandardized_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nstandardized_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
  },
  {
    "input": "Problem:\n\nI have a dataset recorded in a CSV file that contains information about various plant species, with features like height, leaf area, and color intensity. After loading it into a Pandas DataFrame, I want to normalize these features to improve the performance of a machine learning model developed using TensorFlow or PyTorch. \n\nHere is how I loaded the data:\n\n```python\nimport pandas as pd\n\ndata = pd.read_csv('plants.csv')\n```\n\nNow I want to use a preprocessing method from Scikit-learn to normalize the features (excluding the species name column) and keep it in a DataFrame format. Specifically, I want to apply `StandardScaler` to my dataset, which will standardize the features so that they have a mean of 0 and a standard deviation of 1. \n\nWhat code will help me achieve this while preserving the original DataFrame format, including the index and column names?\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_data = ...\n```\n",
    "output": "\n```python\nscaled_data = pd.DataFrame(scaler.fit_transform(data.drop(columns=['species_name'])), \n                            index=data.index, \n                            columns=data.columns[1:])\n```"
  },
  {
    "input": "Problem:\nI have a dataset with multiple features, and I want to scale the features using Min-Max normalization and then visualize the results. I am using the following dataset and want to apply Min-Max scaling to it using Scikit-learn:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Feature1': [1, 2, 3, 4, 5],\n    'Feature2': [10, 20, 30, 40, 50],\n    'Feature3': [100, 200, 300, 400, 500]\n}\ndf = pd.DataFrame(data)\n```\n\nAfter scaling, I want to plot the scaled features using Matplotlib. How do I fill in the code to apply Min-Max scaling and then create a line plot of the normalized dataset?\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\nscaled_data = ... # put solution in this variable\n\nplt.plot(scaled_data)\nplt.xlabel('Index')\nplt.ylabel('Scaled Features')\nplt.title('Min-Max Normalized Features')\nplt.legend(['Feature1', 'Feature2', 'Feature3'])\nplt.show()\n```",
    "output": "\n```python\nscaled_data = scaler.fit_transform(df)\n```"
  },
  {
    "input": "## Problem:\nI have a dataset containing information about various products, including their prices and sales data over several months. I want to create a function that takes this dataset, computes the percentage change in sales month-over-month for each product, and then plot the results for visual analysis. \n\nThe dataset is structured as follows:\n\n```python\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [\n        [100, 120, 90, 130, 110],  # Sales for product A over 5 months\n        [200, 210, 190, 220, 230],  # Sales for product B over 5 months\n        [150, 160, 155, 170, 180]   # Sales for product C over 5 months\n    ]\n}\n```\n\nYou need to ensure the output is a Pandas DataFrame that contains the month-over-month percentage changes of sales for each product. The resulting DataFrame should have a new column for each product with these percentage changes.\n\nAdditionally, please produce a Matplotlib line plot that displays the percentage changes over time for each product.\n\nHere is the starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [[100, 120, 90, 130, 110], [200, 210, 190, 220, 230], [150, 160, 155, 170, 180]]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate the percentage change\ndf['percentage_change'] = ...\n```\n\nFill in the blank for `df['percentage_change']` to complete the task.",
    "output": "\n```python\ndf['percentage_change'] = df['sales'].apply(lambda x: np.diff(x) / x[:-1] * 100)\ndf = df.explode('percentage_change').reset_index(drop=True)\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nfor i, product in enumerate(data['product']):\n    plt.plot(df[df['product'] == product].index, df[df['product'] == product]['percentage_change'], label=f'Product {product}')\nplt.title('Month-over-Month Percentage Change in Sales')\nplt.xlabel('Months')\nplt.ylabel('Percentage Change (%)')\nplt.legend()\nplt.grid()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing housing prices in different neighborhoods. The dataset is represented as a Pandas DataFrame with the following structure:\n\n```python\nimport pandas as pd\n\ndata = {'Neighborhood': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n        'Price': [250000, 270000, 300000, 320000, 400000, 420000, 500000, 520000]}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to compute the average price for each neighborhood and then create a new DataFrame that shows the neighborhood and its respective average price, sorted in descending order of the average price.\n\nYour task is to fill in the blank in the following code to achieve this:\n\n```python\naverage_prices = df.groupby('Neighborhood')['Price'].mean().reset_index()\naverage_prices = average_prices.sort_values(by='Price', ascending=False)\nresult = ...\n```\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = average_prices.rename(columns={'Price': 'Average Price'})</code>"
  },
  {
    "input": "Problem:\nI am working with a time series dataset and I want to normalize the values in a pandas DataFrame column using Min-Max scaling. The DataFrame has a column named 'temperature' which I want to scale to a range of 0 to 1. Here is a snippet of my data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'temperature': [22.5, 23.1, 19.8, 24.0, 21.3]\n}\ndf = pd.DataFrame(data)\n```\n\nWhat I want to achieve is to create a new column 'normalized_temperature' containing the normalized values. I found a snippet that almost works, but I'm unsure how to apply the Min-Max formula correctly. Here is what I have so far:\n\n```python\ndf['normalized_temperature'] = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n```\n\nMy expectation is that the 'normalized_temperature' should be calculated using the formula. However, I made this adjustment and I am not seeing the expected results. Can you help me fill in the blank to ensure the normalization works correctly?\n\nA:\n<code>\ndf['normalized_temperature'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['normalized_temperature'] = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Imagine you have the following dataset with 'Year' as the independent variable\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Revenue': [200, 240, 300, 350, 400]\n}\n\ndf = pd.DataFrame(data)\n\n# Prepare the data for linear regression\nX = df[['Year']].values\ny = df['Revenue'].values\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict revenues for years 2005 to 2010\nyears_to_predict = np.array([[2005], [2006], [2007], [2008], [2009], [2010]])\npredicted_revenues = model.predict(years_to_predict)\n\n# Plotting the original revenues and the predictions\nplt.scatter(df['Year'], df['Revenue'], color='blue', label='Original Revenue')\nplt.plot(np.concatenate((df['Year'].values, years_to_predict.flatten())), \n         np.concatenate((y, predicted_revenues)), color='red', label='Predicted Revenue')\n\n# Display the plot\nplt.title('Revenue Prediction')\nplt.xlabel('Year')\nplt.ylabel('Revenue')\nplt.legend()\nplt.show()\n\n# However, I need to gather the predicted revenues into a single dictionary with years as keys,\n# and the predicted revenues as values. Please show how to do this.\n\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = {year[0]: revenue for year, revenue in zip(years_to_predict, predicted_revenues)}\n```"
  },
  {
    "input": "Problem:\nYou are analyzing a dataset representing sales over different days, and you want a way to visualize the trend over time while also applying a moving average to smooth out the noise in the data. You have a Pandas DataFrame, `sales_data`, that contains two columns: `date` (in 'YYYY-MM-DD' format) and `sales` (integer values representing sales on that specific date).\n\nYou need to create a new column in this DataFrame called `moving_average` that calculates a 7-day moving average of the `sales` column. After updating the DataFrame, plot the `sales` and `moving_average` on the same graph using Matplotlib.\n\nHere\u2019s your starting code snippet:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', \n             '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10'],\n    'sales': [200, 220, 230, 210, 220, 250, 270, 240, 300, 290]\n}\nsales_data = pd.DataFrame(data)\nsales_data['date'] = pd.to_datetime(sales_data['date'])\nsales_data.set_index('date', inplace=True)\n```\n\nYou need to fill in the following line of code to create the `moving_average`, and then plot the results:\n\n```python\nsales_data['moving_average'] = ...\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nsales_data['moving_average'] = sales_data['sales'].rolling(window=7).mean()\nresult = sales_data\nplt.figure(figsize=(10, 5))\nplt.plot(sales_data.index, sales_data['sales'], label='Sales', marker='o')\nplt.plot(sales_data.index, sales_data['moving_average'], label='7-Day Moving Average', color='orange')\nplt.title('Sales and 7-Day Moving Average')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales data for various products across different months. The dataset looks like this:\n\n```\n   Product   Jan   Feb   Mar   Apr\n0   A        100   120   130   90\n1   B        150   160   155   140\n2   C        200   210   220   215\n```\n\nI want to calculate the percentage change in sales for each product from one month to the next. The output should retain the same structure, with an additional row for each product indicating the percentage change between months (e.g., from Jan to Feb, Feb to Mar, and so on).\n\nFor example, for product A, the percentage change from Jan to Feb is calculated as follows:\n```\n((Feb - Jan) / Jan) * 100\n```\n\nThe expected output should look like this:\n\n```\n   Product   Jan   Feb   Mar   Apr\n0   A        100   120   130   90\n1   A %Chg   NaN   20.0  8.33 -30.77\n2   B        150   160   155   140\n1   B %Chg   NaN   6.67  -3.12 -9.68\n3   C        200   210   220   215\n4   C %Chg   NaN   5.0   4.76 -2.27\n```\n\nYou are provided with the following code to create the initial DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C'],\n    'Jan': [100, 150, 200],\n    'Feb': [120, 160, 210],\n    'Mar': [130, 155, 220],\n    'Apr': [90, 140, 215]\n}\n\ndf = pd.DataFrame(data)\n```\nNow, insert your code into this variable to perform the required calculations and create the new DataFrame output.\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\npercentage_change = df.iloc[:, 1:].pct_change(axis=1) * 100\npercentage_change.insert(0, 'Product', df['Product'] + ' %Chg')\nresult = pd.concat([df, percentage_change], ignore_index=True)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing the results of a survey regarding customer satisfaction. The dataset is in the following format:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'CustomerID': [1, 2, 3, 4, 5],\n    'Satisfaction': [5, 3, 4, 2, 1],\n    'Recommendation': [4, 3, 2, 4, 1],\n    'Age': [25, 34, 28, 45, 52]\n}\ndf = pd.DataFrame(data)\n```\n\nNext, I want to standardize the 'Satisfaction' and 'Recommendation' columns using `scikit-learn`'s `StandardScaler`, and then visualize the standardized scores using `matplotlib`. \n\nWhat single line of code should I use to scale these columns and create a new DataFrame containing the original `CustomerID`, and the standardized values of `Satisfaction` and `Recommendation`? \n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n",
    "output": "\n<code>\nresult = pd.DataFrame({'CustomerID': df['CustomerID'], 'Satisfaction': scaler.fit_transform(df[['Satisfaction']]), 'Recommendation': scaler.fit_transform(df[['Recommendation']])})\n</code>"
  },
  {
    "input": "Problem:\nI am working on a predictive model for housing prices using a dataset that includes various features such as square footage, number of bedrooms, and location. After conducting feature engineering, I want to ensure that the features have been standardized for better performance with machine learning algorithms. However, I need to apply the same transformation to both the training and testing datasets.\n\nGiven that you have already split your dataset into training and testing subsets, how can you use Scikit-learn's `StandardScaler` to fit the scaler on the training set and then transform both the training and testing sets correspondingly? Here\u2019s a starting point:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\n# Example DataFrames for training and testing features\nX_train = pd.DataFrame({'square_footage': [1500, 2000, 2500],\n                        'num_bedrooms': [3, 4, 5]})\n\nX_test = pd.DataFrame({'square_footage': [1800, 2200],\n                       'num_bedrooms': [3, 4]})\n\nscaler = StandardScaler()\n```\n\nYou need to fill in the blank in the following line to properly fit and transform the training data and then transform the testing data using the same scaling parameters:\n\n```python\nX_train_scaled = ...  # Fit and transform the training data\nX_test_scaled = ...   # Transform the testing data using the fitted scaler\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nX_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\nX_test_scaled = scaler.transform(X_test)         # Transform the testing data using the fitted scaler\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various cities with columns for 'city', 'temperature', and 'humidity'. I need to preprocess this data using Pandas to normalize the 'temperature' values between 0 and 1. The DataFrame is as follows:\n\n+-----------+------------+----------+\n| city      | temperature| humidity |\n+-----------+------------+----------+\n| CityA    | 20         | 30       |\n| CityB    | 25         | 40       |\n| CityC    | 15         | 25       |\n| CityD    | 30         | 50       |\n+-----------+------------+----------+\n\nHow can I calculate the normalized temperature and store the result in a new column called 'normalized_temperature'? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {'city': ['CityA', 'CityB', 'CityC', 'CityD'],\n        'temperature': [20, 25, 15, 30],\n        'humidity': [30, 40, 25, 50]}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['normalized_temperature'] = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information about house sales, and I have already loaded the data into a Pandas DataFrame. The DataFrame has columns 'price' (the sale price), 'area' (square footage of the house), and 'bedrooms' (number of bedrooms). I want to normalize the 'price' column using Min-Max normalization so that the values range between 0 and 1. After normalizing, I wish to visualize the relationship between the normalized prices and the area using Matplotlib.\n\nHere\u2019s the initial setup of my DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'price': [300000, 450000, 200000, 500000, 250000],\n    'area': [1500, 2500, 1000, 3000, 1200],\n    'bedrooms': [3, 4, 2, 5, 3]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI know that Min-Max normalization can be performed by using the formula:\n\\[ X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}} \\]\n\nWhat would be the correct line of code to normalize the 'price' column, and then plot the normalized prices against the area?\n\nA:\n```python\nimport matplotlib.pyplot as plt\n\nnormalized_price = ...  # put solution in this variable\n\nplt.scatter(df['area'], normalized_price)\nplt.xlabel('Area (sq ft)')\nplt.ylabel('Normalized Price')\nplt.title('Normalized House Price vs Area')\nplt.show()\n```",
    "output": "\n```python\nnormalized_price = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing three columns - 'Year', 'Population', and 'GDP'. I want to visualize the growth of Population and GDP over the years using Matplotlib. However, I need to normalize both 'Population' and 'GDP' so that they can be compared on the same graph. I am using Pandas to create the DataFrame. The dataset can be simulated as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Population': [6.12, 6.20, 6.30, 6.39, 6.48],  # in billions\n    'GDP': [10.25, 10.50, 10.75, 11.00, 11.25]  # in trillion USD\n}\ndf = pd.DataFrame(data)\n```\n\nWhat piece of code can I use to normalize both 'Population' and 'GDP' and plot them on a line graph with 'Year' on the x-axis?\n\nA:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Population': [6.12, 6.20, 6.30, 6.39, 6.48],\n    'GDP': [10.25, 10.50, 10.75, 11.00, 11.25]\n}\ndf = pd.DataFrame(data)\n```\nplt.plot(...)  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Population_normalized'] = (df['Population'] - df['Population'].min()) / (df['Population'].max() - df['Population'].min())\ndf['GDP_normalized'] = (df['GDP'] - df['GDP'].min()) / (df['GDP'].max() - df['GDP'].min())\n\nplt.plot(df['Year'], df['Population_normalized'], label='Population (normalized)')\nplt.plot(df['Year'], df['GDP_normalized'], label='GDP (normalized)')\nplt.xlabel('Year')\nplt.ylabel('Normalized Values')\nplt.title('Normalized Population and GDP Over Years')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI am working on a project that involves predicting housing prices using a regression model. After splitting my data into training and testing sets with `train_test_split`, I want to visualize the predicted prices against the actual prices using Matplotlib. Here's what I have so far:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Sample housing data\ndata = {'Size': [1500, 2500, 3500, 4500, 5500],\n        'Price': [300000, 400000, 500000, 600000, 700000]}\ndf = pd.DataFrame(data)\n\nX = df[['Size']]\ny = df['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredicted_prices = model.predict(X_test)\n```\n\nNow, I want to visualize the predicted prices alongside the actual prices in a scatter plot and a line plot. I have set up the following code for plotting:\n\n```python\nplt.scatter(X_test, y_test, color='blue', label='Actual Prices')\nplt.plot(X_test, predicted_prices, color='red', label='Predicted Prices')\nplt.xlabel('Size')\nplt.ylabel('Price')\nplt.title('Actual vs Predicted Prices')\nplt.legend()\nplt.show()\n```\n\nHowever, my line plot is not showing the expected results. How should I modify the code to ensure that the predicted prices line correctly represents the regression line across the entire range of sizes in the training set?\n\nA:\n<code>\nplt.plot(np.sort(X_test.values), model.predict(np.sort(X_test.values).reshape(-1, 1)), color='red', label='Predicted Prices')\n</code>",
    "output": "\n<code>\nplt.plot(np.sort(X_test.values), model.predict(np.sort(X_test.values).reshape(-1, 1)), color='red', label='Predicted Prices')\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products in a retail store, including their prices, categories, and sales figures. I want to compute the z-score of the sales figures for each product to identify which products are performing exceptionally well or poorly. I need to add a new column called \"z_score\" to the dataframe that reflects this calculation. Here is how my dataset looks:\n\n```python\nimport pandas as pd\ndata = pd.DataFrame({'product': ['A', 'B', 'C', 'D', 'E'],\n                     'category': ['Electronics', 'Electronics', 'Clothing', 'Grocery', 'Clothing'],\n                     'price': [150, 200, 50, 30, 25],\n                     'sales': [120, 130, 90, 40, 50]})\ndata.head()\n```\n\nTo compute the z-score, I will use `scipy.stats.zscore`. How do I fill in the following code to get the desired result?\n\n```python\nfrom scipy.stats import zscore\n\ndf = data.copy()\n```\n\ndf['z_score'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>zscore(df['sales'])</code>"
  },
  {
    "input": "Problem:\nYou are working on a machine learning project where you need to preprocess a dataset. The dataset contains features with missing values represented as NaN. You want to fill these missing values with the mean of each column. After filling the missing values, you want to standardize the features (scale them to have a mean of 0 and a standard deviation of 1) using the StandardScaler from Scikit-learn. Finally, you'll need to visualize the distribution of one of the processed features using Matplotlib.\n\nHere's a typical workflow to achieve this:\n1. Load the dataset using Pandas.\n2. Replace the NaN values in the dataset with the mean of their respective columns.\n3. Standardize the features.\n\nWrite the code to perform these steps. You will define the necessary imports and create a function that takes a Pandas DataFrame as input and returns the standardized DataFrame. The last line of your code should plot the distribution of one of the standardized features.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef preprocess_and_visualize(df):\n    df.fillna(df.mean(), inplace=True)\n    scaler = StandardScaler()\n    standardized_df = scaler.fit_transform(df)\n    standardized_df = pd.DataFrame(standardized_df, columns=df.columns)\n    \n    # Plot the distribution of a specified feature, for instance, the first feature\n    plt.hist(standardized_df.iloc[:, 0], bins=30)\n    plt.title('Distribution of Feature 1')\n    plt.xlabel('Standardized Value')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return standardized_df\n\n# You can load the DataFrame from your dataset here \n# df = pd.read_csv('your_dataset.csv')\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = preprocess_and_visualize(df)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about used cars, including their price, mileage, year, and brand stored in a Pandas DataFrame called `cars_df`. I want to perform a linear regression analysis to predict car prices based on mileage. I've already split the dataset into features (X) and target (y) variables. After fitting the model, I want to plot the regression line along with the actual data points in a scatter plot. \n\nHere's the setup of my DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndata = {\n    'price': np.random.randint(5000, 30000, 100),\n    'mileage': np.random.randint(10000, 150000, 100),\n    'year': np.random.randint(2000, 2022, 100),\n    'brand': np.random.choice(['Ford', 'Chevrolet', 'Toyota'], 100)\n}\n\ncars_df = pd.DataFrame(data)\nX = cars_df[['mileage']]\ny = cars_df['price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\n\nNow, I need to plot the regression line using the training data and actual prices. What should I put in the blank to create the plot?\n\n```python\nplt.scatter(X_train, y_train, color='blue')\nplt.plot(X_train, model.predict(X_train), color='red')\nplt.title('Regression Line on Training Data')\nplt.xlabel('Mileage')\nplt.ylabel('Price')\nplt.show()\n```\n\nThe code below is where I will be implementing the rest. \n\n```python\nplt.scatter(X_train, y_train, color='blue')\nplt.plot(X_train, model.predict(X_train), color='red')\n...\n``` \n\nA:\n<code>\n...\n</code>",
    "output": "\n<code>\nplt.title('Regression Line on Training Data')\nplt.xlabel('Mileage')\nplt.ylabel('Price')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing customer purchases with the following columns: `customer_id`, `purchase_amount`, and `purchase_date`. I need to calculate the monthly total purchases for each customer and visualize the data using a line plot where the x-axis represents the months, and the y-axis represents the total purchase amount.\n\nHere is a simplified view of the DataFrame:\n\n```\n   customer_id purchase_amount purchase_date\n0            1            120    2023-01-15\n1            2            150    2023-01-22\n2            1             80    2023-02-10\n3            2            200    2023-02-15\n4            3            220    2023-01-05\n```\n\nMy code so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 2, 1, 2, 3],\n    'purchase_amount': [120, 150, 80, 200, 220],\n    'purchase_date': pd.to_datetime(['2023-01-15', '2023-01-22', '2023-02-10', '2023-02-15', '2023-01-05'])\n}\ndf = pd.DataFrame(data)\n\nmonthly_totals = ... # put solution in this variable\n```\n\nHow can I compute `monthly_totals` and plot the results?",
    "output": "\n```python\nmonthly_totals = df.groupby([df['purchase_date'].dt.to_period('M'), 'customer_id'])['purchase_amount'].sum().unstack(fill_value=0)\n\nmonthly_totals.plot(kind='line', marker='o')\nplt.title('Monthly Total Purchases by Customer')\nplt.xlabel('Month')\nplt.ylabel('Total Purchase Amount')\nplt.xticks(rotation=45)\nplt.legend(title='Customer ID')\nplt.tight_layout()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou are given the task of analyzing a toy dataset representing the heights and weights of a sample of individuals. The dataset is structured in a pandas DataFrame with the following columns: 'Height' (in cm), 'Weight' (in kg), and 'Gender' (with values 'Male' or 'Female'). Based on this dataset, you want to create a function that normalizes the weight values based on the height of individuals. You will use Min-Max normalization. Write code that computes the normalized weights for individuals who are above the average height, and returns these values as a list.\n\nHere is the sample data you will use:\n```python\nimport pandas as pd\n\ndata = {\n    'Height': [180, 165, 170, 175, 160, 185, 155],\n    'Weight': [80, 60, 70, 65, 50, 90, 55],\n    'Gender': ['Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female']\n}\n\ndf = pd.DataFrame(data)\n```\n\nThe function `normalize_weights(df)` should compute the normalized weights for individuals with a height greater than the average height in the dataset and return them.\n\nA:\n<code>\ndef normalize_weights(df):\n    average_height = df['Height'].mean()\n    filtered_df = df[df['Height'] > average_height]\n    normalized_weights = (filtered_df['Weight'] - filtered_df['Weight'].min()) / (filtered_df['Weight'].max() - filtered_df['Weight'].min())\n    return normalized_weights.tolist()\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = normalize_weights(df)\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Given data\ndata = {\n    'Height': [6.0, 5.7, 5.8, 5.5, 6.1],\n    'Weight': [160, 150, 155, 140, 165],\n    'Age': [30, 25, 35, 28, 32]\n}\ndf = pd.DataFrame(data)\n\n# Normalize the Height and Weight using StandardScaler from scikit-learn\n# Fill in the blank to create an instance of StandardScaler and fit_transform on the Height and Weight columns\nscaler = StandardScaler()\ndf[['Height', 'Weight']] = scaler.fit_transform(df[['Height', 'Weight']])\n\n# Now, plot the normalized Height and Weight against Age in a scatter plot\n# Make sure to set the title to \"Normalized Height and Weight vs Age\" \n# and label the x-axis as \"Age\" and y-axis as \"Normalized Value\"\nplt.scatter(df['Age'], df['Height'], label='Height (Normalized)', color='blue')\nplt.scatter(df['Age'], df['Weight'], label='Weight (Normalized)', color='red')\nplt.title(\"Normalized Height and Weight vs Age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Normalized Value\")\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nscaler = StandardScaler()\ndf[['Height', 'Weight']] = scaler.fit_transform(df[['Height', 'Weight']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customers and their purchases. The dataset is a Pandas DataFrame structured like this:\n\n| CustomerID | PurchaseAmount | PurchaseDate |\n|------------|----------------|---------------|\n| 1          | 200            | 2023-01-10    |\n| 2          | 150            | 2023-01-15    |\n| 1          | 300            | 2023-02-10    |\n| 3          | 100            | 2023-02-20    |\n| 2          | 250            | 2023-03-05    |\n| 1          | 400            | 2023-03-10    |\n\nI want to calculate the total amount spent by each customer and plot this information using Matplotlib. The result should be a bar chart where the x-axis represents `CustomerID` and the y-axis represents `TotalAmountSpent`. I have already read the DataFrame and it's named `df`. This is my approach so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'PurchaseAmount': [200, 150, 300, 100, 250, 400]\n})\n\n# Grouping by CustomerID and calculating total amounts\ntotal_spent = df.groupby('CustomerID')['PurchaseAmount'].sum() \n\n# I need to plot the result but I'm not sure how to do it efficiently\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('CustomerID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\nplt.show()\n```\n\nWhat should I add to my code to complete the bar chart creation? \n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'PurchaseAmount': [200, 150, 300, 100, 250, 400]\n})\n\n# Grouping by CustomerID and calculating total amounts\ntotal_spent = df.groupby('CustomerID')['PurchaseAmount'].sum() \n\n# return the solution in this function\n# plt.bar(total_spent.index, total_spent.values)\n### BEGIN SOLUTION",
    "output": "\n<code>\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('CustomerID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of house prices and features given as follows:\n\n```python\nimport pandas as pd\ndata = {\n    'price': [200000, 250000, 300000, 350000, 400000],\n    'size': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'age': [10, 15, 10, 5, 2]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to predict the prices of houses based on their features using a linear regression model from Scikit-learn. First, scale the features using `StandardScaler`, fit the regression model, and predict prices for new data:\n\n```python\nnew_data = pd.DataFrame({\n    'size': [1650, 1750, 1850],\n    'bedrooms': [3, 4, 4],\n    'age': [12, 8, 3]\n})\n```\n\nHowever, you encounter the following error when trying to fit the model:\n\n```\nValueError: Expected 2D array, got 1D array instead:\narray=[...]...\n```\n\nHere is the similar code snippet you tried:\n\n```python\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nX = df[['size', 'bedrooms', 'age']]\ny = df['price']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nmodel = LinearRegression()\nmodel.fit(X_scaled, y)\n\npredictions = model.predict(new_data)  # This causes the ValueError\n```\n\nTo fix this issue, how can you correctly prepare the `new_data` for prediction? \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'price': [200000, 250000, 300000, 350000, 400000],\n    'size': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'age': [10, 15, 10, 5, 2]\n}\ndf = pd.DataFrame(data)\n\nnew_data = pd.DataFrame({\n    'size': [1650, 1750, 1850],\n    'bedrooms': [3, 4, 4],\n    'age': [12, 8, 3]\n})\n</code>\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nnew_data_scaled = scaler.transform(new_data)\npredictions = model.predict(new_data_scaled)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various species of flowers, specifically the `Iris` flower dataset, which includes the following columns: `sepal_length`, `sepal_width`, `petal_length`, and `petal_width`. I want to create a new column called `species` that categorizes the species based on the `petal_length` as follows:\n- If `petal_length` < 2.0, the species is \"setosa\"\n- If 2.0 <= `petal_length` < 5.0, the species is \"versicolor\"\n- If `petal_length` >= 5.0, the species is \"virginica\"\n\nYou can utilize `pandas` for data manipulation and `numpy` for the conditions. The dataframe is already created, and you need to fill in the code to create the new `species` column.\n\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'sepal_length': [5.1, 7.0, 6.3, 5.5, 4.9],\n    'sepal_width': [3.5, 3.2, 3.3, 2.5, 3.0],\n    'petal_length': [1.4, 4.7, 6.0, 1.3, 1.4],\n    'petal_width': [0.2, 1.4, 2.5, 0.2, 0.2]\n}\n\ndf = pd.DataFrame(data)\ndf['species'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['species'] = np.where(df['petal_length'] < 2.0, 'setosa', \n                          np.where(df['petal_length'] < 5.0, 'versicolor', 'virginica'))</code>"
  },
  {
    "input": "Problem:\nI am working on a deep learning model using TensorFlow and I want to visualize the training history after fitting the model. Specifically, I want to plot both the training and validation loss over epochs to understand how well the model is learning.\n\nHere is the code I have so far:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate dummy data for training\nx_train = np.random.rand(1000, 10)\ny_train = np.random.rand(1000, 1)\nx_val = np.random.rand(200, 10)\ny_val = np.random.rand(200, 1)\n\n# Build a simple neural network model\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n                             tf.keras.layers.Dense(1)])\n\nmodel.compile(optimizer='adam', loss='mse')\n\n# Fit the model and store the history\nhistory = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20)\n\n# Now I want to plot the training and validation loss\n# Fill in the blank below to achieve this.\n\nplt.plot(..., label='Training Loss')\nplt.plot(..., label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss over Epochs')\nplt.show()\n```\n\nA:\n<code>\n# put solution in this variable\nBEGIN SOLUTION\n<code>history.history['loss'], history.history['val_loss']</code>",
    "output": "\n<code>\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\n</code>"
  },
  {
    "input": "Problem:\nI am working on a classification problem using PyTorch and Scikit-learn, and I need to evaluate the performance of my model by calculating the F1 score. After fitting my model on the training data, I have the predictions and the actual labels. Here\u2019s the code that I have written so far, but I am unsure how to properly calculate the F1 score from the predictions.\n\nHere are my predictions and actual labels:\npredictions = [0, 1, 0, 1, 1, 0]\nactual_labels = [0, 1, 1, 1, 0, 0]\n\nI want to store the F1 score in a variable called `f1` using Scikit-learn's `f1_score` function. Here's how I'm importing the necessary modules:\n```python\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\npredictions = np.array([0, 1, 0, 1, 1, 0])\nactual_labels = np.array([0, 1, 1, 1, 0, 0])\n```\nNow, I want to compute the F1 score. I need to fill in the blank below:\n\nf1 = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>f1 = f1_score(actual_labels, predictions)</code>"
  },
  {
    "input": "Problem:\nI'm working on a classification task using a dataset of flowers, specifically the famous Iris dataset. I want to build a model that predicts the species of the flower based on its features (sepal length, sepal width, petal length, and petal width). I've already split the data into training and testing sets and standardized the features using `StandardScaler`. Now, I need to fit a Random Forest Classifier and make predictions on the test set. My data looks like this:\n\n```python\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n```\n\nNow I need to fill in the blank for the following code to create and fit the Random Forest Classifier:\n\n```python\nclf = RandomForestClassifier(random_state=42)\nclf.fit(...)\n\npredictions = clf.predict(X_test_scaled)\n```\n\nA:\n<code>\nX_train_scaled  # put solution in this variable\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nX_train_scaled\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\ndf['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n\n# Create a pairplot using seaborn to visualize the relationships between features,\n# but I want to exclude the 'species' variable from the diagonal plots.\n# SOLUTION START\n```",
    "output": "\n```python\nsns.pairplot(df, hue='species', diag_kind='kde', vars=df.columns[:-1])\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of customers' purchase histories stored in a CSV file. Each row in the file represents a transaction, with the following columns: `CustomerID`, `Product`, `Quantity`, and `Price`. You plan to analyze the total expenditure for each customer. Here\u2019s a segment of your dataset:\n\n```\nCustomerID,Product,Quantity,Price\n1,Apple,2,0.5\n1,Banana,1,0.2\n2,Apple,1,0.5\n2,Orange,3,0.3\n1,Orange,2,0.3\n```\n\nYou have the following code to load the dataset:\n```python\nimport pandas as pd\n\ndf = pd.read_csv(\"purchases.csv\")\n```\n\nYou need to calculate the total expenditure for each customer and output it as a new DataFrame with columns `CustomerID` and `TotalExpenditure`. How would you do this?\n\nA:\n<code>\ndf['Total'] = df['Quantity'] * df['Price']\nresult = df.groupby('CustomerID')['Total'].sum().reset_index()\nresult.columns = ['CustomerID', 'TotalExpenditure']\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('CustomerID').apply(lambda x: (x['Quantity'] * x['Price']).sum()).reset_index(name='TotalExpenditure')\n</code>"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various products sold in a store, including their sales data and whether they were discounted. You need to calculate the average sales for each product category and visualize the results using a bar chart. Here's a sample dataframe to help you get started:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'C'],\n    'Category': ['Electronics', 'Clothing', 'Electronics', 'Home', 'Clothing', 'Home', 'Electronics', 'Home'],\n    'Sales': [100, 200, 150, 300, 250, 400, 350, 150],\n    'Discounted': [True, False, True, False, True, False, True, False]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average sales per category and visualize them as a bar chart. Fill in the missing code below to achieve this:\n\n```python\nimport matplotlib.pyplot as plt\n\navg_sales = df.groupby('Category')['Sales'].mean()  # Calculate average sales per category\nplt.bar(avg_sales.index, avg_sales)  # Create a bar chart\nplt.xlabel('Category')\nplt.ylabel('Average Sales')\nplt.title('Average Sales per Category')\nplt.show()  # Display the bar chart\n```\n\nThe filled in line of code below is where you need to focus to complete the average sales calculation and visualization.\n\nA:\n<code>\navg_sales = ... # put solution in this variable\n</code>",
    "output": "\n<code>\navg_sales = df.groupby('Category')['Sales'].mean()  # Calculate average sales per category\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Generate synthetic data\nnp.random.seed(0)\ndata = np.random.rand(100, 2) * 10\n\n# Create a DataFrame\ndf = pd.DataFrame(data, columns=['feature1', 'feature2'])\n\n# Standardize the features in the DataFrame using StandardScaler\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df)\n\n# Plot the original data points and the transformed data points on a scatter plot.\n# Ensure the original data is in blue and the transformed data is in red.\n# Show axis labels and a legend.\n\nplt.scatter(df['feature1'], df['feature2'], color='blue', label='Original Data')\nplt.scatter(scaled_features[:, 0], scaled_features[:, 1], color='red', label='Scaled Data')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\nplt.show()\n```",
    "output": "\n```python\nplt.scatter(df['feature1'], df['feature2'], color='blue', label='Original Data')\nplt.scatter(scaled_features[:, 0], scaled_features[:, 1], color='red', label='Scaled Data')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing information about houses that includes features like 'Size', 'Bedrooms', and 'Price'. You want to standardize the 'Price' feature using `StandardScaler` from `sklearn.preprocessing` and then perform a linear regression on the standardized data. Here\u2019s a simplified view of your DataFrame:\n\n```\n   Size  Bedrooms  Price\n0  1500        3  300000\n1  1600        3  350000\n2  1700        3  400000\n3  1800        4  450000\n4  2000        4  500000\n```\n\nYou have the following lines of code to achieve this:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.DataFrame({'Size': [1500, 1600, 1700, 1800, 2000], \n                   'Bedrooms': [3, 3, 3, 4, 4], \n                   'Price': [300000, 350000, 400000, 450000, 500000]})\nscaler = StandardScaler()\ndf['Price'] = scaler.fit_transform(df[['Price']])\nmodel = LinearRegression()\nmodel.fit(df[['Size', 'Bedrooms']], df['Price'])\n```\n\nHowever, you need to ensure you're correctly transforming the 'Price' column before fitting the model. Your final line returns an error because you're fitting the model with the already standardized 'Price' data, rather than the original. \n\nWhat change do you need to make to the last part of your code?\n\nA:\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\ndf = pd.DataFrame({'Size': [1500, 1600, 1700, 1800, 2000], \n                   'Bedrooms': [3, 3, 3, 4, 4], \n                   'Price': [300000, 350000, 400000, 450000, 500000]})\nscaler = StandardScaler()\ndf['Price'] = scaler.fit_transform(df[['Price']])\nmodel = LinearRegression()\n```\ncorrected_model_fit = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ncorrected_model_fit = model.fit(df[['Size', 'Bedrooms']], df['Price'].values)\n```"
  },
  {
    "input": "Problem:\nYou are analyzing the performance of a machine learning model using a dataset that includes various features. You have split the dataset into training and testing sets, and now you want to visualize the relationship between one of the features and the model predictions. Given the training features and corresponding predictions, you want to create a scatter plot to visualize this relationship.\n\nAssuming you have the following data:\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generating synthetic data\nnp.random.seed(42)\nX_train = np.random.rand(100, 1) * 10  # 100 samples, 1 feature\ny_train = 2.5 * X_train + np.random.randn(100, 1)  # Linear relation with noise\n\n# Creating a DataFrame\ndf = pd.DataFrame(np.hstack((X_train, y_train)), columns=['Feature', 'Prediction'])\n```\nNow, create a scatter plot of 'Feature' vs. 'Prediction' from the DataFrame. The code to initialize the figure is provided below, you just need to fill in the blank to actually create the scatter plot.\n\n```python\nplt.figure(figsize=(10, 6))\n# Fill in the blank with your answer\nplt.scatter(df['Feature'], df['Prediction'], color='blue', alpha=0.6)\nplt.title('Feature vs Prediction')\nplt.xlabel('Feature')\nplt.ylabel('Prediction')\nplt.grid()\nplt.show()\n```\nA:\n<code>\nplt.scatter(df['Feature'], df['Prediction'], color='blue', alpha=0.6)\n</code>",
    "output": "\n<code>\nplt.scatter(df['Feature'], df['Prediction'], color='blue', alpha=0.6)\n</code>"
  },
  {
    "input": "### Problem:\nI have a dataset that contains user activities over time with the following structure:\n\n```\n                           user_id           activity          timestamp\n0                          1              login          2023-01-01 12:00:00\n1                          1              logout         2023-01-01 12:30:00\n2                          2              login          2023-01-01 12:10:00\n3                          2              logout         2023-01-01 12:40:00\n4                          1              login          2023-01-02 13:00:00\n```\n\nI need to group the activities per user and count the number of login and logout events. The desired output should be a DataFrame with columns `user_id`, `logins`, and `logouts`, resulting in something like this:\n\n```\n   user_id   logins   logouts\n0        1        2        1\n1        2        1        1\n```\n\nI've started with the following code but it's not yielding the expected results:\n\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 2, 2, 1],\n    'activity': ['login', 'logout', 'login', 'logout', 'login']\n}\ndf = pd.DataFrame(data)\n\n# Group by user_id and calculate the counts\nresult = df.groupby('user_id')['activity'].value_counts().unstack()\n```\n\nHowever, the `result` DataFrame does not have the expected structure. How can I modify it to achieve the desired output with the correct counts of logins and logouts?\n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('user_id')['activity'].value_counts().unstack(fill_value=0).reset_index()\nresult.columns.name = None\nresult = result.rename(columns={'login': 'logins', 'logout': 'logouts'})\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Generate a sample dataset with random numbers\ndata = np.random.randn(100, 5)\n\n# Create a DataFrame with the generated data\ndf = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(5)])\n\n# Standardize the features using StandardScaler and assign the result to 'scaled_data'\nscaler = StandardScaler()\nscaled_data = ...  # put solution in this variable\n\n# Plot the first two features of the original and scaled data for comparison\nplt.scatter(df['feature_0'], df['feature_1'], label='Original Data', alpha=0.5)\nplt.scatter(scaled_data[:, 0], scaled_data[:, 1], label='Scaled Data', alpha=0.5)\nplt.legend()\nplt.xlabel('Feature 0')\nplt.ylabel('Feature 1')\nplt.title('Original vs Scaled Data')\nplt.show()\n```",
    "output": "\n```python\nscaled_data = scaler.fit_transform(df)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing multiple features regarding the properties of different houses, including their sizes in square feet and prices. I want to standardize the sizes using Scikit-learn's StandardScaler, and then visualize the standardized distribution using Matplotlib. The dataset is in a Pandas DataFrame called `houses` with columns 'size' and 'price'. How can I create a histogram to show the distribution of standardized house sizes?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample DataFrame\nhouses = pd.DataFrame({\n    'size': np.random.randint(1000, 4000, size=100),\n    'price': np.random.randint(200000, 500000, size=100)\n})\n\nscaler = StandardScaler()\nstandardized_sizes = scaler.fit_transform(houses[['size']])\n\n# Create histogram for standardized sizes\nplt.hist(..., bins=20, alpha=0.7, color='blue')\nplt.title('Distribution of Standardized House Sizes')\nplt.xlabel('Standardized Size')\nplt.ylabel('Frequency')\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nplt.hist(standardized_sizes, bins=20, alpha=0.7, color='blue')\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Given a DataFrame 'df' containing numeric features,\n# this code standardizes the features and then applies PCA\n# to reduce the data to 2 dimensions for visualization.\n# Fill in the blank: perform scaling on df using StandardScaler.\n\ndf = pd.DataFrame({'feature1': [1, 2, 3, 4, 5],\n                   'feature2': [5, 4, 3, 2, 1],\n                   'feature3': [2, 3, 4, 5, 6]})\n\nscaler = StandardScaler()\nscaled_data = ... # put solution in this variable\n\n# Now perform PCA and plot the results.\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.title('PCA Result')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.show()\n```",
    "output": "\n```python\nscaled_data = scaler.fit_transform(df)\n```"
  }
]