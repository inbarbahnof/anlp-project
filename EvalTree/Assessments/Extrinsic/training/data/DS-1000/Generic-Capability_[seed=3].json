[
  {
    "input": "Problem:\nYou have a dataset containing the heights and weights of individuals stored in a pandas DataFrame, and you want to predict whether a person is classified as \"underweight,\" \"normal,\" \"overweight,\" or \"obese\" based on their BMI (Body Mass Index). The DataFrame has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'height': [1.75, 1.80, 1.65, 1.70, 1.60],\n    'weight': [70, 85, 55, 65, 50]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to add a new column 'bmi_category' based on the calculated BMI using the following categories:\n- \"underweight\": BMI < 18.5\n- \"normal\": 18.5 <= BMI < 24.9\n- \"overweight\": 25 <= BMI < 29.9\n- \"obese\": BMI >= 30\n\nWrite the code to calculate the BMI and assign the appropriate category to each individual in the new column. You can use the formula for BMI:\n\n\\[ BMI = \\frac{weight}{height^2} \\]\n\nA:\n```python\ndf['bmi'] = ... # Calculate BMI here\ndf['bmi_category'] = ... # Assign categories based on BMI here\n```",
    "output": "\n```python\ndf['bmi'] = df['weight'] / (df['height'] ** 2)\ndf['bmi_category'] = pd.cut(df['bmi'], bins=[0, 18.5, 24.9, 29.9, float('inf')], labels=[\"underweight\", \"normal\", \"overweight\", \"obese\"], right=False)\n```"
  },
  {
    "input": "Problem:  \nI have a time series dataset on daily temperatures over several years stored in a Pandas DataFrame. The columns include 'Date', 'Temperature', and 'City'. I want to resample the temperature data to calculate the monthly average temperature for each city. I've set up the DataFrame and datetime indexing. Now, I need a single line of code to achieve this monthly average aggregation and store it in a new DataFrame called `monthly_avg`.\n\nA:  \n```python\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(10)\ndates = pd.date_range('2010-01-01', periods=365, freq='D')\ncities = ['City A', 'City B']\ndata = {\n    'Date': np.tile(dates, len(cities)),\n    'City': np.repeat(cities, len(dates)),\n    'Temperature': np.random.randint(20, 40, size=len(dates) * len(cities))\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n```\nmonthly_avg = ... # put solution in this variable  \nBEGIN SOLUTION  \n```python",
    "output": "\n```python\nmonthly_avg = df.resample('M').mean()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the Iris dataset and create a DataFrame\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Perform PCA to reduce dimensions to 2 components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(df)\n\n# Create a scatter plot of the PCA result\n# The x-axis should represent the first principal component and the y-axis should represent the second principal component\n# Make sure to label the axes appropriately.\nplt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component')\nplt.title('PCA of Iris Dataset')\n\n# Now you want to show this plot.\n# What command should you use to display the plot?\n# A:\nplot_command = ... # put solution in this variable\n```",
    "output": "\n```python\nplot_command = plt.show()\n```"
  },
  {
    "input": "Problem:\nYou are given a set of numeric data regarding daily sales recorded in a CSV file. Each row represents a single day\u2019s sales across various products. You would like to visualize the total sales for each product over the period.\n\nHere is how you set up the data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample data generation\nnp.random.seed(42)\ndates = pd.date_range(start='2023-01-01', periods=30)\nproduct_a_sales = np.random.randint(50, 100, size=30)\nproduct_b_sales = np.random.randint(30, 90, size=30)\ndata = pd.DataFrame({'Date': dates, 'Product_A': product_a_sales, 'Product_B': product_b_sales})\n```\n\nYou want to create a line plot showing the total sales of Product_A and Product_B over the 30-day period. \n\nWhat command will fill in the blank to create the required plot?\n\n```python\nplt.figure(figsize=(10, 6))\nplt.plot(data['Date'], data['Product_A'], label='Product A', color='blue')\nplt.plot(data['Date'], data['Product_B'], label='Product B', color='orange')\nplt.title('Daily Sales of Products A and B')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n```\n\nA:\n<code>\nplt.plot(...) # put solution in this variable\n</code>",
    "output": "\n<code>\nplt.plot(data['Date'], data['Product_A'].cumsum(), label='Product A', color='blue')\nplt.plot(data['Date'], data['Product_B'].cumsum(), label='Product B', color='orange')\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing historical stock prices in a Pandas DataFrame called `stock_data`, which has columns 'Date', 'Open', 'Close', 'Volume'. You want to compute the daily returns and visualize the distribution of these returns using a histogram.\n\nHere's the setup:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example data (you can take this as a placeholder, you'll have a real dataset)\ndata = {\n    'Date': pd.date_range(start='2021-01-01', periods=5),\n    'Open': [100, 102, 101, 103, 104],\n    'Close': [102, 101, 103, 104, 106],\n    'Volume': [1500, 1600, 1700, 1800, 1900]\n}\nstock_data = pd.DataFrame(data)\n```\n\nYou need to calculate the daily return as `(Close - Open) / Open` for each day and then plot a histogram of the returns. Place your result in the variable `returns_hist`.\n\nA:\n```python\nreturns = ...  # place your solution here\nreturns_hist = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\nreturns = (stock_data['Close'] - stock_data['Open']) / stock_data['Open']\nreturns_hist = plt.hist(returns, bins=10, alpha=0.7, color='blue')\nplt.title('Histogram of Daily Returns')\nplt.xlabel('Daily Returns')\nplt.ylabel('Frequency')\nplt.show()\n</code>\n```"
  },
  {
    "input": "## Problem\nYou have a dataset of student scores in a pandas DataFrame, which includes the following columns: 'Student', 'Subject', and 'Score'. You want to normalize the scores to a range between 0 and 1 for each subject. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science'],\n    'Score': [90, 80, 85, 70, 95]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to compute the normalized score for each student in each subject. The normalized score is calculated using this formula:\n\n\\[\n\\text{Normalized Score} = \\frac{\\text{Score} - \\text{min(Score)}}{\\text{max(Score)} - \\text{min(Score)}}\n\\]\n\nPlease fill in the blank to add the normalized score column to your DataFrame like this:\n\n```python\ndf['Normalized_Score'] = ...\n```\nWhere `...` is the solution to compute the normalized scores using `Scikit-learn`'s `MinMaxScaler`.",
    "output": "\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf['Normalized_Score'] = df.groupby('Subject')['Score'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)))\n```"
  },
  {
    "input": "## Problem\nYou have a dataset of customer transactions that you want to process and analyze. First, you need to create a Pandas DataFrame from a CSV file that contains columns: 'CustomerID', 'TransactionDate', 'Amount'. After reading the data, you want to find the total amount spent by each customer, and then visualize it using a bar chart with Matplotlib.\n\nAssuming the CSV file has been read into a DataFrame called `df`, how can you compute the total amount spent by each customer and create a bar chart to visualize these totals in a variable `result`?\n\nHere\u2019s the structure of the initial DataFrame:\n\n```python\nimport pandas as pd\n\n# Simulating reading a CSV\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'TransactionDate': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-01', '2021-01-03', '2021-01-05'],\n    'Amount': [100, 150, 200, 50, 75, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nYou can compute the totals using the code below, but you need to fill in the missing parts to get the bar chart visualization.\n\n```python\nimport matplotlib.pyplot as plt\n\ntotal_spent = df.groupby('CustomerID')['Amount'].sum()\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('Customer ID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\n\nresult = ... # put your visualization code here\n```",
    "output": "\n```python\nresult = plt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing monthly sales data in a Pandas DataFrame for different products. The DataFrame looks like this:\n\n```\n   Product    Sales\n0  ProductA    150\n1  ProductB    200\n2  ProductC    250\n3  ProductA    300\n4  ProductB    100\n```\n\nI want to compute the average monthly sales for each product and plot these averages in a bar chart using Matplotlib. I have already created the DataFrame, but I need help to obtain the averages and plot them. \n\nHere is the setup:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'Product': ['ProductA', 'ProductB', 'ProductC', 'ProductA', 'ProductB'],\n        'Sales': [150, 200, 250, 300, 100]}\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the blank with the solution that computes the average sales by product and stores the result in a variable called `average_sales`:\n\n```python\naverage_sales = ... # put solution in this variable\n```",
    "output": "\n```python\naverage_sales = df.groupby('Product')['Sales'].mean().reset_index()\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Perform PCA to reduce the data to two dimensions\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(df)\n\n# Create a DataFrame with the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the PCA results\nplt.scatter(pc_df['PC1'], pc_df['PC2'])\nplt.title('PCA of Iris Dataset')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\n# How can I annotate the points with the class labels from the iris dataset?\n# The labels are in iris.target; add labels to the scatter plot accordingly.\n# SOLUTION START\n```",
    "output": "\n```python\nfor i in range(len(pc_df)):\n    plt.annotate(iris.target[i], (pc_df['PC1'][i], pc_df['PC2'][i]))\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing the daily temperature readings for multiple cities over the course of a month, and I would like to visualize the average temperature for each city using a bar plot. The dataset is structured as follows:\n\n```python\ndata = {\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Temperatures': [\n        [30, 32, 33, 29, 28, 31, 30, 29, 35, 36, 37, 38, 39, 30, 28, 30, 29, 31, 33, 32, 30, 31, 29, 30, 31, 33, 35, 36, 37, 38], \n        [70, 68, 71, 69, 72, 73, 75, 74, 76, 77, 78, 79, 80, 81, 82, 80, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65], \n        [25, 27, 26, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 37, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21], \n        [60, 62, 61, 59, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 70, 69, 68, 66, 65, 64, 63, 62, 61, 60, 58, 57, 56, 55], \n        [75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74]\n    ]\n}\n```\n\nThe expected output is a bar plot representing the average temperatures for each city. Below is the initial code you have:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame(data)\n```\n\nNow, I need to calculate the average temperature for each city and create a bar plot. Fill in the blank with the code to achieve this, where `avg_temps` is the variable that holds the average temperatures.\n\n```python\navg_temps = df['Temperatures'].apply(np.mean) # Fill in this line with the correct calculation\nplt.bar(df['City'], avg_temps)\nplt.xlabel('City')\nplt.ylabel('Average Temperature')\nplt.title('Average Temperature by City')\nplt.show()\n```\n\nA:\n<code>\navg_temps = df['Temperatures'].apply(lambda x: np.mean(x)) # Fill in this line with the correct calculation\n</code>",
    "output": "\n<code>\navg_temps = df['Temperatures'].apply(np.mean) # Fill in this line with the correct calculation\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have a dataset comprising various measurements of plants, including height, width, and age, stored in a Pandas DataFrame. You want to normalize the height column using the Min-Max scaling technique to ensure all values are between 0 and 1. Here is your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'height': [15, 20, 35, 50, 10],\n    'width': [3, 7, 5, 10, 2],\n    'age': [1, 2, 1, 3, 4]\n}\nplant_df = pd.DataFrame(data)\n```\n\nYour task is to create a new column named 'normalized_height' that stores the normalized values based on the height column.\n\nA:\n```python\nimport pandas as pd\n\ndata = {\n    'height': [15, 20, 35, 50, 10],\n    'width': [3, 7, 5, 10, 2],\n    'age': [1, 2, 1, 3, 4]\n}\nplant_df = pd.DataFrame(data)\n```\nplant_df['normalized_height'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nplant_df['normalized_height'] = (plant_df['height'] - plant_df['height'].min()) / (plant_df['height'].max() - plant_df['height'].min())\n```"
  },
  {
    "input": "## Problem\nYou have a dataset representing customer purchases with columns for `customer_id` and `purchase_amount`. The purchase amounts are in dollars and you want to analyze this data.\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n    'purchase_amount': [100, 200, 150, 300, 250, 100, 200, 50]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new DataFrame that summarizes the total purchase amount by each `customer_id`, showing the `customer_id` and their corresponding `total_purchase_amount` in descending order.\n\nWhat code should you use to produce the expected result? Store the result in a variable named `summary`.\n\nA:\n```python\nsummary = ...\n```",
    "output": "\n```python\nsummary = df.groupby('customer_id')['purchase_amount'].sum().reset_index(name='total_purchase_amount').sort_values(by='total_purchase_amount', ascending=False)\n```"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I need to preprocess a dataset containing continuous and categorical variables. The dataset is as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'age': [25, 30, 35, 40, 45],\n    'income': [50000, 60000, 70000, 80000, 90000],\n    'gender': ['male', 'female', 'female', 'male', 'female'],\n    'occupation': ['engineer', 'doctor', 'teacher', 'engineer', 'doctor']\n})\n```\n\nI want to apply one-hot encoding to the categorical columns ('gender' and 'occupation') and then standardize the numerical columns ('age' and 'income'). The desired result is a processed DataFrame where the categorical features are transformed into binary columns and the numerical features have mean 0 and variance 1.\n\nI have a code block like:\n\n```python\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# initialize encoders and scalers\nencoder = ...\nscaler = ...\n\n# apply one-hot encoding and standardization\ndf_processed = ...\n```\n\nCan you help me fill in the blanks to achieve this preprocessing task? The resulting DataFrame should contain the one-hot encoded columns followed by the standardized numerical columns. \n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nencoder = OneHotEncoder(sparse=False)\nscaler = StandardScaler()\n\n# apply one-hot encoding and standardization\ndf_encoded = encoder.fit_transform(df[['gender', 'occupation']])\ndf_scaled = scaler.fit_transform(df[['age', 'income']])\n\ndf_processed = pd.concat([pd.DataFrame(df_encoded, columns=encoder.get_feature_names_out()), \n                           pd.DataFrame(df_scaled, columns=['age', 'income'])], axis=1)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing latitudes and longitudes of multiple locations, and I'm trying to calculate the distance of each location from a reference point (latitude, longitude) using the Haversine formula. The dataset is in a Pandas DataFrame format and looks like this:\n\n```\n    id     latitude    longitude\n0   1      34.0522    -118.2437\n1   2      40.7128    -74.0060\n2   3      51.5074    -0.1278\n3   4      48.8566    2.3522\n4   5      35.6895    139.6917\n```\n\nThe reference point I want to calculate the distances from is (34.0522, -118.2437). I'm aware that I can use numpy for mathematical operations involved in the formula. \n\nHere's my starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'id': [1, 2, 3, 4, 5],\n    'latitude': [34.0522, 40.7128, 51.5074, 48.8566, 35.6895],\n    'longitude': [-118.2437, -74.0060, -0.1278, 2.3522, 139.6917]\n}\ndf = pd.DataFrame(data)\n\nreference_point = (34.0522, -118.2437)\n\n# Haversine formula calculations\ndef haversine(lat1, lon1, lat2, lon2):\n    R = 6371  # Earth radius in kilometers\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arcsin(np.sqrt(a))\n    return R * c\n\n# The result variable should contain the distances calculated\n    \n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df.apply(lambda row: haversine(reference_point[0], reference_point[1], row['latitude'], row['longitude']), axis=1)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various fruits including their weights, sweetness levels, and colors in a CSV file named `fruits.csv`, structured as follows: \n\n| Fruit   | Weight (g) | Sweetness (1-10) | Color   |\n|---------|------------|------------------|---------|\n| Apple   | 150        | 8                | Red     |\n| Banana  | 120        | 7                | Yellow  |\n| Cherry  | 50         | 9                | Red     |\n| Grape   | 75         | 6                | Purple  |\n\nYou want to extract the weights of the fruits, normalize them (scale them to a range between 0 and 1), and then visualize the normalized weights using a histogram. Write the code that reads the CSV file into a Pandas DataFrame, normalizes the weights using Min-Max scaling, and plots the histogram of the normalized weights. Assume you have already imported the necessary libraries.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('fruits.csv')\nnormalized_weights = ... # put solution in this variable\nplt.hist(normalized_weights, bins=10)\nplt.title('Normalized Weights of Fruits')\nplt.xlabel('Normalized Weight')\nplt.ylabel('Frequency')\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_weights = scaler.fit_transform(df[['Weight (g)']])\nnormalized_weights = normalized_weights.flatten()\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information about customer transactions, and I want to analyze the total sales by product category over time. Given the following DataFrame, how can I calculate the total sales for each category and add that as a new column?\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\n    'Category': ['A', 'B', 'A', 'B', 'C'],\n    'Sales': [100, 200, 150, 250, 300]\n}\ndf = pd.DataFrame(data)\n\n# I want to calculate the total sales per category and add this as a new column `Total_Sales`.\n```\n\nPlease fill in the missing code below to accomplish this:\n\n```python\ndf['Total_Sales'] = ...\n```",
    "output": "\n```python\ndf['Total_Sales'] = df.groupby('Category')['Sales'].transform('sum')\n```"
  },
  {
    "input": "Problem:\nYou are working on a sentiment analysis project. You need to preprocess your text data stored in a pandas DataFrame. The DataFrame contains two columns: 'id' and 'text'. Your goal is to convert the text to lowercase, remove punctuation, and tokenize the sentences. \n\nHere is the initial DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'id': [1, 2, 3],\n    'text': ['I love Python! It is great.', \n             'Data science with Python is awesome!!!', \n             'Let\\'s build amazing models...']\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter preprocessing, you want to create a new column 'tokens' that contains the list of tokens for each text entry.\n\nTo achieve this, you are using the following setup:\n\n```python\nimport string\n\ndef preprocess_text(text):\n    # Your preprocessing steps will go here\n    pass\n\ndf['tokens'] = df['text'].apply(preprocess_text)\n```\n\nWhat completes the `preprocess_text` function so that it correctly processes the text?\n\nA:\n```python\ntext = ... # put solution in this variable\n```",
    "output": "\n```python\ntext = text.lower()  # Convert to lowercase\ntext = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\ntokens = text.split()  # Tokenize the text\nreturn tokens  # Return the list of tokens\n```"
  },
  {
    "input": "Problem:\nI am working on a project that involves predicting housing prices using a regression model. After splitting my data into training and testing sets with `train_test_split`, I want to visualize the predicted prices against the actual prices using Matplotlib. Here's what I have so far:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Sample housing data\ndata = {'Size': [1500, 2500, 3500, 4500, 5500],\n        'Price': [300000, 400000, 500000, 600000, 700000]}\ndf = pd.DataFrame(data)\n\nX = df[['Size']]\ny = df['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredicted_prices = model.predict(X_test)\n```\n\nNow, I want to visualize the predicted prices alongside the actual prices in a scatter plot and a line plot. I have set up the following code for plotting:\n\n```python\nplt.scatter(X_test, y_test, color='blue', label='Actual Prices')\nplt.plot(X_test, predicted_prices, color='red', label='Predicted Prices')\nplt.xlabel('Size')\nplt.ylabel('Price')\nplt.title('Actual vs Predicted Prices')\nplt.legend()\nplt.show()\n```\n\nHowever, my line plot is not showing the expected results. How should I modify the code to ensure that the predicted prices line correctly represents the regression line across the entire range of sizes in the training set?\n\nA:\n<code>\nplt.plot(np.sort(X_test.values), model.predict(np.sort(X_test.values).reshape(-1, 1)), color='red', label='Predicted Prices')\n</code>",
    "output": "\n<code>\nplt.plot(np.sort(X_test.values), model.predict(np.sort(X_test.values).reshape(-1, 1)), color='red', label='Predicted Prices')\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of individual customer transactions over a week, stored in a Pandas DataFrame (df):\n\n```\n            customer_id  amount\n2023-01-01           1    100\n2023-01-01           2    150\n2023-01-02           1    200\n2023-01-02           3    250\n2023-01-03           2    300\n2023-01-03           3    100\n```\n\nYou need to calculate the total amount spent by each customer across all days and return the result as a new DataFrame with the customer_id and their total spent, sorted in descending order of the total amount spent.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 2, 1, 3, 2, 3],\n    'amount': [100, 150, 200, 250, 300, 100]\n}\ndf = pd.DataFrame(data, index=pd.to_datetime(['2023-01-01', '2023-01-01', \n                                               '2023-01-02', '2023-01-02', \n                                               '2023-01-03', '2023-01-03']))\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('customer_id')['amount'].sum().reset_index().sort_values(by='amount', ascending=False)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing measurements of different species of flowers including their sepal length, sepal width, petal length, and petal width. I want to predict the species of the flower based on these features using a neural network with TensorFlow. \n\nThe training data is split into a training set and a test set. After training the model, I need to predict the classes of the test set and generate a confusion matrix to evaluate the model's performance. There is already a function to train the model and load the test set, but I need help creating the confusion matrix.\n\nHere is how the test set looks like:\n\n```python\nimport pandas as pd\n\ntest_data = pd.DataFrame({\n    'sepal_length': [4.7, 6.0, 5.5, 5.0],\n    'sepal_width': [3.2, 2.7, 2.5, 3.6],\n    'petal_length': [1.3, 1.6, 4.0, 1.4],\n    'petal_width': [0.2, 0.3, 1.3, 0.2],\n    'actual_species': [0, 1, 2, 0]  # Actual species indices\n})\n\n# Assuming 'model' is already trained and 'X_test' is the feature matrix for the test data\nX_test = test_data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\npredictions = model.predict(X_test)\npredicted_classes = np.argmax(predictions, axis=1)  # Get class with highest probability\n```\n\nNow, I need to create the confusion matrix using the predicted classes. How can I fill in the blank below to achieve that?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom sklearn.metrics import confusion_matrix\nresult = confusion_matrix(test_data['actual_species'], predicted_classes)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a large dataset that contains user activity logs collected over a week. Each log entry has a timestamp, user ID, and activity type (e.g., 'login', 'logout', 'purchase'). You need to analyze the daily total of each type of activity.\n\nGiven the following Python code snippet, which uses pandas to load your dataset into a DataFrame, how can you aggregate the daily count of each activity type and store the result in a new DataFrame `daily_activity_counts`?\n\n```python\nimport pandas as pd\n\n# Sample data structure\ndata = {\n    'timestamp': ['2023-10-01 08:00', '2023-10-01 09:00', '2023-10-02 10:15', \n                  '2023-10-02 11:00', '2023-10-01 14:00', '2023-10-03 15:45'],\n    'user_id': ['user1', 'user2', 'user1', 'user3', 'user2', 'user1'],\n    'activity_type': ['login', 'purchase', 'logout', 'login', 'logout', 'purchase']\n}\ndf = pd.DataFrame(data)\n\n# Set the timestamp as datetime\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n```\n\nYou can use the `groupby` method along with `size()` to achieve this. Fill in the blank below:\n\n```python\ndaily_activity_counts = df.groupby([df['timestamp'].dt.date, 'activity_type']).size().unstack(fill_value=0)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = daily_activity_counts</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Create a synthetic dataset with 100 samples and 5 features\nnp.random.seed(42)\ndata = np.random.rand(100, 5)\n\n# Convert the data into a DataFrame\ndf = pd.DataFrame(data, columns=['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])\n\n# Apply PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(df)\n\n# Create a scatter plot of the PCA result with features as labels\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.title('PCA Result')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\n# Show the plot\nplt.show()\n\n# Now, I want to create a DataFrame with the PCA results\n# The DataFrame should have columns 'PC1' and 'PC2' for the PCA results.\n# What would be the code to achieve that?\n\npca_df = ... # put solution in this variable\n```",
    "output": "\n```python\npca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customers and their purchases. The dataset is a Pandas DataFrame structured like this:\n\n| CustomerID | PurchaseAmount | PurchaseDate |\n|------------|----------------|---------------|\n| 1          | 200            | 2023-01-10    |\n| 2          | 150            | 2023-01-15    |\n| 1          | 300            | 2023-02-10    |\n| 3          | 100            | 2023-02-20    |\n| 2          | 250            | 2023-03-05    |\n| 1          | 400            | 2023-03-10    |\n\nI want to calculate the total amount spent by each customer and plot this information using Matplotlib. The result should be a bar chart where the x-axis represents `CustomerID` and the y-axis represents `TotalAmountSpent`. I have already read the DataFrame and it's named `df`. This is my approach so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'PurchaseAmount': [200, 150, 300, 100, 250, 400]\n})\n\n# Grouping by CustomerID and calculating total amounts\ntotal_spent = df.groupby('CustomerID')['PurchaseAmount'].sum() \n\n# I need to plot the result but I'm not sure how to do it efficiently\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('CustomerID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\nplt.show()\n```\n\nWhat should I add to my code to complete the bar chart creation? \n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'PurchaseAmount': [200, 150, 300, 100, 250, 400]\n})\n\n# Grouping by CustomerID and calculating total amounts\ntotal_spent = df.groupby('CustomerID')['PurchaseAmount'].sum() \n\n# return the solution in this function\n# plt.bar(total_spent.index, total_spent.values)\n### BEGIN SOLUTION",
    "output": "\n<code>\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('CustomerID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various products sold in multiple stores, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'store_id': [1, 1, 2, 2],\n    'product_id': ['A', 'B', 'A', 'B'],\n    'sales': [10, 20, 5, 15],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02']\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to aggregate this dataframe to compute the total sales for each product across all stores, and then plot the sales distribution using Matplotlib. Your desired output should be the total sales in a Series format and the corresponding bar chart.\n\nThe series should look like:\n\n```python\nproduct_sales = \n```\n\nAnd the corresponding bar chart should show the product IDs on the x-axis and total sales on the y-axis.\n\nWrite the code to generate both the `product_sales` variable and the bar chart.",
    "output": "\n```python\n<code>\nproduct_sales = df.groupby('product_id')['sales'].sum()\n\nimport matplotlib.pyplot as plt\n\nproduct_sales.plot(kind='bar')\nplt.xlabel('Product ID')\nplt.ylabel('Total Sales')\nplt.title('Total Sales per Product')\nplt.show()\n</code>\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Generate synthetic data\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10\ny = 2.5 * X.flatten() + np.random.randn(100) * 2\n\n# Create a DataFrame from the synthetic data\ndata = pd.DataFrame({'X': X.flatten(), 'y': y})\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['X']], data['y'])\n\n# Make predictions\npredictions = model.predict(data[['X']])\n\n# Calculate the mean squared error\nmse = mean_squared_error(data['y'], predictions)\n\n# Plot the results\nplt.scatter(data['X'], data['y'], color='blue', label='Data Points')\nplt.plot(data['X'], predictions, color='red', label='Regression Line')\nplt.title('Linear Regression Fit')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n# What is the value of MSE calculated from the predictions?\nmse_value = ... # put solution in this variable\n```",
    "output": "\n```python\nmse_value = mse\n```"
  },
  {
    "input": "Problem:\nI'm working on an image processing task where I need to apply a Gaussian blur to a grayscale image represented as a 2D NumPy array. For this, I want to create a function that generates a Gaussian kernel of a specified size and standard deviation. Once I have the kernel, I will use it to convolve with the image using SciPy's `convolve2d` function. \n\nThe function should generate the Gaussian kernel based on these parameters:\n- The size of the kernel (must be an odd integer)\n- The standard deviation for the Gaussian distribution\n\nHere\u2019s my code outline:\n\n```python\nimport numpy as np\nfrom scipy.ndimage import convolve\nfrom scipy.signal import convolve2d\n\ndef gaussian_kernel(size, sigma):\n    ...\n    \nimage = np.random.rand(100, 100)  # Example grayscale image\nkernel_size = 5\nsigma = 1.0\n\nkernel = gaussian_kernel(kernel_size, sigma)\nblurred_image = convolve2d(image, kernel, mode='same')\n```\n\nNow I need to fill in the `...` to compute the Gaussian kernel in my function. \nA:\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\ndef gaussian_kernel(size, sigma):\n    ax = np.linspace(-(size // 2), size // 2, size)\n    xx, yy = np.meshgrid(ax, ax)\n    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n    return kernel / np.sum(kernel)\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate sample data\nnp.random.seed(42)\nx = np.random.rand(100, 1) * 10  # 100 samples, one feature\ny = 2.5 * x + np.random.randn(100, 1)  # Linear relationship with noise\n\n# Convert x and y into a pandas DataFrame\ndf = pd.DataFrame(np.hstack((x, y)), columns=['feature', 'target'])\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df[['feature']], df['target'], test_size=0.2, random_state=42)\n\n# Create a Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Plot the training data and the regression line\nplt.scatter(X_train, y_train, color='blue', label='Training data')\nplt.scatter(X_test, y_test, color='orange', label='Test data')\nplt.plot(X_train, model.predict(X_train), color='red', label='Regression line')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.title('Linear Regression Fit')\nplt.legend()\nplt.show()\n\n# Now, I would like to calculate the R^2 score of the model's predictions on the test set.\n# Please output the R^2 score into the variable 'r_squared'.\n```",
    "output": "\n```python\nfrom sklearn.metrics import r2_score\n\n# Calculate the R^2 score\ny_pred = model.predict(X_test)\nr_squared = r2_score(y_test, y_pred)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing historical stock prices and I want to calculate the moving average for a given window size. Here's how I currently computed the moving average:\n\n```python\nimport pandas as pd\n\ndata = {'Date': pd.date_range(start='1/1/2020', periods=10, freq='D'),\n        'Close': [100, 102, 104, 103, 105, 107, 108, 106, 110, 111]}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\nmoving_average = df['Close'].rolling(window=3).mean()\n```\n\nHowever, I noticed that the first few values of the moving average are NaN due to insufficient data points for the specified window size. I want to fill these NaN values with the first valid moving average value, rather than leaving them as NaN.\n\nHow can I achieve this?\n\nA:\n<code>\ndf['Moving_Average'] = df['Close'].rolling(window=3).mean()\nfiller = ... # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nfiller = df['Moving_Average'].iloc[2]  # Get the first valid moving average value\ndf['Moving_Average'].fillna(filler, inplace=True)  # Fill NaN values with the first valid moving average\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large dataset of house prices and their features. The dataset is stored in a Pandas DataFrame and contains various features including 'square_footage', 'num_bedrooms', and 'price'. You need to create a new column that represents the log-transformed price to help stabilize the variance in your target variable for a machine learning model.\n\nGiven the DataFrame named `housing_data`, fill in the solution to add a new column named 'log_price' which contains the natural logarithm of the 'price' column.\n\nYour code should look like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Assuming housing_data is already defined as a DataFrame\nhousing_data = load_data()\n```\n\nhousing_data['log_price'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nhousing_data['log_price'] = np.log(housing_data['price'])\n```"
  },
  {
    "input": "Problem:\nI am analyzing a dataset that contains information about different species of flowers, specifically the famous Iris dataset. I want to normalize the `sepal_length` feature using Min-Max scaling and train a simple linear regression model to predict `sepal_width` based on the normalized `sepal_length`. However, I'm having trouble chaining these operations together. Below is my code setup, and I would like your help filling in the blank to achieve this.\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the iris dataset\nfrom sklearn.datasets import load_iris\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Normalize the 'sepal_length' feature\nscaler = MinMaxScaler()\ndf['normalized_sepal_length'] = scaler.fit_transform(df[['sepal length (cm)']])\n\n# Now I want to train a linear regression model to predict 'sepal width (cm)'\nX = df[['normalized_sepal_length']]\ny = df['sepal width (cm)']\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# I want to know the coefficients of the trained model\ncoefficients = ...\n```\n",
    "output": "\n```python\ncoefficients = model.coef_\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing daily temperatures measured in degrees Celsius. The dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=7, freq='D'),\n    'temperature': [22, 21, 19, 23, 25, 24, 26]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to normalize the temperature values so that they range between 0 and 1. To achieve this, I am attempting to apply Min-Max normalization. I tried the following code snippet:\n\n```python\ndf['normalized_temp'] = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n```\n\nHowever, I forgot to call a specific function to plot the normalized temperatures using matplotlib. What function should I use to create a line plot of the normalized temperatures against the dates?\n\nExpected output:\n```python\nplt... # put solution in this variable\n```",
    "output": "\n```python\nplt.plot(df['date'], df['normalized_temp'])\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various products, including their names, prices, and quantities sold. The data is in a pandas DataFrame format as shown below:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Price': [10.5, 20.0, 5.0, 15.5, 8.0],\n    'Quantity': [100, 200, 150, 80, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour goal is to compute the total sales for each product, which is defined as the product of the price and quantity sold. You then want to normalize these sales figures to get values between 0 and 1, where the maximum sales value is scaled to 1, and the minimum sales value to 0. The normalized sales should be added as a new column to the DataFrame.\n\nPlease fill in the following code to achieve this:\n\n```python\ndf['Total_Sales'] = df['Price'] * df['Quantity']\nmax_sales = df['Total_Sales'].max()\nmin_sales = df['Total_Sales'].min()\ndf['Normalized_Sales'] = (df['Total_Sales'] - min_sales) / (max_sales - min_sales)\n```\n\nYour task is to calculate the normalized sales and store the result back into the DataFrame `df`. What would be the complete DataFrame after executing the normalization code? \n\nProvide the modified DataFrame below:\n\n```python\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Price': [10.5, 20.0, 5.0, 15.5, 8.0],\n    'Quantity': [100, 200, 150, 80, 300],\n    'Total_Sales': [1050.0, 4000.0, 750.0, 1240.0, 2400.0],\n    'Normalized_Sales': [0.0, 1.0, 0.0, 0.3103448275862069, 0.5862068965517241]\n})\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset that contains information about various products and their sales figures over different months. Here is a sample of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02', '2023-03', '2023-03'],\n    'sales': [200, 150, 240, 180, 300, 220]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the total sales for each product over all months and sort the results in descending order. The final result should be a DataFrame with products and their respective total sales, structured like so:\n\n```\n  product  total_sales\n0      A          740\n1      B          550\n```\n\nHere is my code attempting to achieve this:\n\n```python\ntotal_sales = df.groupby('product')['sales'].sum().reset_index()\ntotal_sales = total_sales.sort_values(by='sales', ascending=False)\n```\n\nHowever, I'm having difficulty specifying the correct column name for sorting. \n\nPlease provide the correct code to complete this task:\n```python\ntotal_sales = ... # put solution in this variable\n```",
    "output": "\n```python\ntotal_sales = df.groupby('product')['sales'].sum().reset_index().rename(columns={'sales': 'total_sales'}).sort_values(by='total_sales', ascending=False)\n```"
  },
  {
    "input": "Problem:\nYou are working on a dataset that contains information about customers' monthly spending on various products. Each row in the dataset contains the following columns: `customer_id`, `product`, and `spending`. You would like to compute the average monthly spending for each product and then visualize this information using a bar chart. \n\nHere is a sample dataframe:\n```\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat line of code should you write to calculate the average spending by product?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.groupby('product')['spending'].mean().reset_index()</code>"
  },
  {
    "input": "Problem:\nGiven a synthetic dataset containing two features (feature1, feature2) created using NumPy, apply a linear regression model using Scikit-learn to predict feature2 based on feature1. Calculate the mean squared error of the model predictions and visualize the results with a scatter plot of the original data points and the regression line using Matplotlib.\n\nHere's how you can create the dataset:\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Create the dataset\nnp.random.seed(0)\nfeature1 = np.random.rand(100, 1) * 10\nfeature2 = 2.5 * feature1 + np.random.randn(100, 1) * 2\n\ndata = pd.DataFrame(data=np.hstack((feature1, feature2)), columns=['feature1', 'feature2'])\n</code>\n# Fill in the blank to create and evaluate the Linear Regression model:\nmodel = LinearRegression().fit(data[['feature1']], data[['feature2']])\npredictions = model.predict(data[['feature1']])\nmse = ... # put solution in this variable\nBEGIN SOLUTION\n<code>mean_squared_error(data[['feature2']], predictions)</code>",
    "output": "\n<code>mean_squared_error(data[['feature2']], predictions)</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products. The dataset is in the form of a pandas DataFrame with the following columns: 'ProductID', 'Category', 'Price', and 'Sales'. I want to normalize the 'Price' column using Min-Max scaling and then visualize the relationship between normalized price and sales using a scatter plot.\n\nHere\u2019s a sample of the dataframe:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': [1, 2, 3, 4, 5],\n    'Category': ['A', 'B', 'A', 'C', 'B'],\n    'Price': [100, 200, 150, 300, 250],\n    'Sales': [10, 15, 12, 20, 18]\n}\n\ndf = pd.DataFrame(data)\n```\n\nTo achieve this, first, normalize the 'Price' column. The formula for Min-Max normalization is:\n\n\\[ \\text{normalized\\_price} = \\frac{\\text{Price} - \\text{min(Price)}}{\\text{max(Price)} - \\text{min(Price)}} \\]\n\nNext, use Matplotlib to create a scatter plot where the x-axis represents the normalized price and the y-axis represents sales.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'ProductID': [1, 2, 3, 4, 5],\n    'Category': ['A', 'B', 'A', 'C', 'B'],\n    'Price': [100, 200, 150, 300, 250],\n    'Sales': [10, 15, 12, 20, 18]\n}\n\ndf = pd.DataFrame(data)\n\n# Normalize the 'Price' column\ndf['normalized_price'] = ... # put solution in this variable\n\n# Create the scatter plot\nplt.scatter(df['normalized_price'], df['Sales'])\nplt.xlabel('Normalized Price')\nplt.ylabel('Sales')\nplt.title('Normalized Price vs Sales')\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['normalized_price'] = (df['Price'] - df['Price'].min()) / (df['Price'].max() - df['Price'].min())\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset representing customer purchases and would like to analyze it using various data science libraries. \n\nYou have a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'customer_id': np.arange(1, 11),\n    'purchase_amount': np.random.randint(100, 1000, size=10),\n    'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='T'),\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new column in the DataFrame that contains the z-scores of the `purchase_amount` values. Z-scores indicate how many standard deviations an element is from the mean. \n\nYou want to compute this using NumPy and add it to a new column named `z_score_purchase_amount`. \n\nHow can you do this?\n\nA:\n```python\ndf['z_score_purchase_amount'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\ndf['z_score_purchase_amount'] = (df['purchase_amount'] - np.mean(df['purchase_amount'])) / np.std(df['purchase_amount'])\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing house prices with various features, and I want to standardize the feature columns using Scikit-learn's preprocessing functionality, but I also want to visualize the distribution of a specific feature before and after standardization using Matplotlib. Here's a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Price': [150000, 200000, 250000, 300000],\n    'Size': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 3, 5],\n    'Age': [10, 15, 20, 5]\n}\n\ndf = pd.DataFrame(data)\n```\n\nHow can I standardize the 'Size' feature and then plot the distribution of 'Size' before and after standardization using Matplotlib?\n\nA:\n<code>\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\nscaler = StandardScaler()\noriginal_size = df['Size'].values.reshape(-1, 1)\n# Fit the scaler and transform 'Size' here\nstandardized_size = ... # put solution in this variable\n\n# Plotting\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.hist(original_size, bins=5, alpha=0.7, color='blue', label='Original Size')\nplt.title('Original Size Distribution')\nplt.subplot(1, 2, 2)\nplt.hist(standardized_size, bins=5, alpha=0.7, color='orange', label='Standardized Size')\nplt.title('Standardized Size Distribution')\nplt.show()\n</code>\n",
    "output": "\n<code>\nstandardized_size = scaler.fit_transform(original_size)\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Given a DataFrame containing sales data with 'Date' and 'Sales' columns,\n# I need to plot the cumulative sales over time. \n# The DataFrame is defined as follows:\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'Sales': np.random.randint(1, 100, size=10)\n}\ndf = pd.DataFrame(data)\n\n# I want to plot the cumulative sales without showing the y-ticks in the plot.\n# The cumulative sales can be calculated using the cumsum method.\n# Here is the beginning of my code:\n\nplt.figure(figsize=(10, 6))\nplt.plot(df['Date'], df['Sales'].cumsum(), marker='o')\n\n# Your code here to complete the plotting (do not display y-ticks)\n\n``` \nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nplt.yticks([])  # Hide y-ticks\nplt.title('Cumulative Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Cumulative Sales')\nplt.grid()\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about customer purchases at a retail store. The data is structured as follows:\n\n```plaintext\nCustomerID, Age, Gender, ProductID, PurchaseAmount\n1, 25, M, A1, 19.99\n2, 30, F, A2, 29.99\n3, 22, M, A1, 9.99\n4, 35, F, A3, 39.99\n5, 45, M, A2, 15.00\n```\n\nI want to calculate the average purchase amount for each product regardless of the customer's details, and I also want to visualize this average purchase amount using a bar chart. \n\nProvide the solution that computes the average purchase amount for each ProductID and stores it in a variable named `average_purchase`, and then uses Matplotlib to plot the averages.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'CustomerID': [1, 2, 3, 4, 5],\n        'Age': [25, 30, 22, 35, 45],\n        'Gender': ['M', 'F', 'M', 'F', 'M'],\n        'ProductID': ['A1', 'A2', 'A1', 'A3', 'A2'],\n        'PurchaseAmount': [19.99, 29.99, 9.99, 39.99, 15.00]}\ndf = pd.DataFrame(data)\n</code>\naverage_purchase = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\naverage_purchase = df.groupby('ProductID')['PurchaseAmount'].mean().reset_index()\nplt.bar(average_purchase['ProductID'], average_purchase['PurchaseAmount'])\nplt.xlabel('ProductID')\nplt.ylabel('Average Purchase Amount')\nplt.title('Average Purchase Amount by Product')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing sales data across various regions. You have a Pandas DataFrame as follows:\n\n```python\ndata = {\n    'region': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West'],\n    'product': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'B'],\n    'sales': [150, 200, 300, 350, 100, 150, 200, 250],\n    'date': pd.date_range(start='2023-01-01', periods=8, freq='D')\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to calculate the total sales for each product across all regions and then prepare the data for visualization by converting it into a wide format where regions are the columns, products are the index, and sales are the values. The expected DataFrame should look like this:\n\n```\nproduct    North  South  East  West\nA          150    200    200    0\nB          0      0      0      350\nC          100    150    0      0\n```\n\nSo far, you have created the following code to work on this:\n\n```python\nresult = df.pivot_table(index='product', columns='region', values='sales', aggfunc='sum').fillna(0)\n```\n\nHowever, you are encountering an issue where you're not able to display regions that did not have sales for certain products.\n\nTo resolve this, what code should you use to ensure that all regions are represented in the final output even if there are no sales for specific products?\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.pivot_table(index='product', columns='region', values='sales', aggfunc='sum', fill_value=0).reindex(columns=['North', 'South', 'East', 'West'], fill_value=0)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the Iris dataset and create a DataFrame\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Apply PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(df)\n\n# Plot the PCA results in a scatter plot\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c=iris.target, cmap='viridis')\nplt.title(\"PCA of Iris Dataset\")\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\n\n# Save the plot to a file\nplt.savefig('pca_iris.png')\n\n# What should I use to display the plot?\n# A:\n<code>\nplt.show()  # put solution in this variable\n</code>\n```",
    "output": "\n<code>\nplt.show()  # put solution in this variable\n</code>"
  },
  {
    "input": "Problem:\nI am working on a sentiment analysis project and have a dataset with user reviews. I want to preprocess the reviews by converting all text to lowercase and removing punctuation. After that, I want to create a word cloud to visualize the most frequent words in the dataset. I already have the DataFrame set up, and now I need a function to preprocess the text and generate the word cloud visualization. I have implemented most of it, but I need help filling in the gaps.\n\nHere is part of the code I've written:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport string\n\ndf = pd.DataFrame({'reviews': ['I love this product!', 'Worst purchase ever...', 'Okay, it\u2019s not bad.']})\n\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    return text\n\n# Apply preprocessing to the reviews\ndf['cleaned_reviews'] = df['reviews'].apply(preprocess_text)\n\n# Generate the word cloud\nwordcloud = WordCloud(width=800, height=400).generate(' '.join(df['cleaned_reviews']))\n\n# Plot the word cloud\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n```\n\nNow, I need to fill in the blank to store the result of the cleaned reviews as a single string, that can be used to generate the word cloud properly. \n\n```python\ncleaned_text = ... # put solution in this variable\n```",
    "output": "\n```python\ncleaned_text = ' '.join(df['cleaned_reviews'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various houses including their prices and features. This dataset is structured as a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'price': [300000, 450000, 500000, 600000, 700000],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'bathrooms': [2, 3, 2, 4, 3],\n    'area': [1500, 2000, 1800, 2500, 2200]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to apply a preprocessing step to normalize the 'price', 'bedrooms', and 'bathrooms' features in the DataFrame before feeding it into a machine learning model in Scikit-learn. Specifically, I want to scale these features such that they have a mean of 0 and a standard deviation of 1. \n\nGiven that I will use `StandardScaler` from Scikit-learn, how can I implement this normalization and add the scaled values back into the DataFrame under new column names prefixed with 'scaled_'?\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n```\ndf[['scaled_price', 'scaled_bedrooms', 'scaled_bathrooms']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf[['scaled_price', 'scaled_bedrooms', 'scaled_bathrooms']] = scaler.fit_transform(df[['price', 'bedrooms', 'bathrooms']])\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily temperature and humidity levels of a city over a period of one month. You want to use this data to predict the temperature of the following day using a simple linear regression model from Scikit-learn. The temperature data is stored in a pandas DataFrame called `weather_df`, and you want to create a new variable `X` containing the humidity levels and a variable `y` containing the temperature levels. However, you need to ensure that `X` has the shape appropriate for fitting the model.\n\nGiven this dataset:\n\n```python\nimport pandas as pd\n\nweather_df = pd.DataFrame({\n    'temperature': [30, 31, 29, 32, 33, 31, 30, 28, 27, 29, 30, 32, 31, 33, 34, 28, 30, 29, 31, 30, 28, 27, 26, 29, 30, 31, 32, 30, 29, 28],\n    'humidity': [70, 65, 80, 75, 72, 68, 71, 74, 73, 70, 67, 68, 69, 74, 75, 72, 70, 69, 68, 67, 72, 71, 73, 70, 66, 65, 68, 69, 70, 72]\n})\n```\n\nHow can you define `X` and `y` such that `X` contains the humidity levels in the correct shape for the regression model?\n\nA:\n<code>\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Create the variable `y` for the temperature levels\ny = weather_df['temperature']\n\n# Create the variable `X` for the humidity levels (ensure it is in the right shape)\nX = ...  # fill in the blank with your code to reshape the humidity data\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nX = weather_df['humidity'].values.reshape(-1, 1)\n</code>"
  },
  {
    "input": "Problem:\nYou are analyzing a dataset that contains the ages and salaries of individuals in a CSV file. You want to identify the correlation between age and salary using a linear regression model from Scikit-learn. After fitting the model, you want to predict salaries for a new array of ages and then visualize the original ages versus salaries along with the predicted salaries using Matplotlib.\n\nHere\u2019s how your initial setup looks:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndata = pd.read_csv('data.csv')  # Assuming data.csv contains columns 'age' and 'salary'\n\nX = data[['age']]\ny = data['salary']\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Now, you have a new array of ages for prediction\nnew_ages = np.array([[25], [35], [45], [55], [65]])\npredicted_salaries = ...\n\n# Create a scatter plot of the original data\nplt.scatter(data['age'], data['salary'], color='blue', label='Original Data')\n\n# Also, plot the predicted salaries\nplt.scatter(new_ages, predicted_salaries, color='red', label='Predicted Salaries')\n\nplt.xlabel('Age')\nplt.ylabel('Salary')\nplt.title('Age vs Salary')\nplt.legend()\nplt.show()\n```\n\nWhat needs to be filled in for `predicted_salaries` to obtain the predictions from the model for `new_ages`? \nA:\n<code>\npredicted_salaries = model.predict(new_ages)\n</code>",
    "output": "\n<code>\npredicted_salaries = model.predict(new_ages)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing three columns - 'Year', 'Population', and 'GDP'. I want to visualize the growth of Population and GDP over the years using Matplotlib. However, I need to normalize both 'Population' and 'GDP' so that they can be compared on the same graph. I am using Pandas to create the DataFrame. The dataset can be simulated as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Population': [6.12, 6.20, 6.30, 6.39, 6.48],  # in billions\n    'GDP': [10.25, 10.50, 10.75, 11.00, 11.25]  # in trillion USD\n}\ndf = pd.DataFrame(data)\n```\n\nWhat piece of code can I use to normalize both 'Population' and 'GDP' and plot them on a line graph with 'Year' on the x-axis?\n\nA:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Population': [6.12, 6.20, 6.30, 6.39, 6.48],\n    'GDP': [10.25, 10.50, 10.75, 11.00, 11.25]\n}\ndf = pd.DataFrame(data)\n```\nplt.plot(...)  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Population_normalized'] = (df['Population'] - df['Population'].min()) / (df['Population'].max() - df['Population'].min())\ndf['GDP_normalized'] = (df['GDP'] - df['GDP'].min()) / (df['GDP'].max() - df['GDP'].min())\n\nplt.plot(df['Year'], df['Population_normalized'], label='Population (normalized)')\nplt.plot(df['Year'], df['GDP_normalized'], label='GDP (normalized)')\nplt.xlabel('Year')\nplt.ylabel('Normalized Values')\nplt.title('Normalized Population and GDP Over Years')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of images stored in a NumPy array (e.g., shape (n_samples, height, width, channels)) that I want to categorize into various labels based on their pixel values. I already have a trained TensorFlow model for classification, and I want to apply this model to predict the labels for my dataset. However, I need a method to preprocess the images by normalizing the pixel values to a range of [0, 1] before feeding them into the model. Given the image data, how can I achieve this normalization?\n\nHere\u2019s my code snippet:\n```python\nimport numpy as np\n\n# Sample dataset of images\nimage_data = np.random.randint(0, 256, (100, 32, 32, 3), dtype=np.uint8)\n\n# To do: normalize image data\nresult = ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = image_data.astype(np.float32) / 255.0\n```"
  },
  {
    "input": "```python\nProblem:\n\nYou have a dataset containing information about various houses, which includes their sizes (in square feet), numbers of bedrooms, and prices. The dataset is stored in a Pandas DataFrame `df`:\n\n```\n   Size (sq ft)  Bedrooms  Price\n0          1500         3  300000\n1          2000         4  400000\n2          2400         4  500000\n3          1800         3  350000\n4          3000         5  600000\n```\n\nYou want to build a linear regression model to predict the house price based on size and number of bedrooms using Scikit-learn. You've already standardized the features and split your dataset into `X` (features) and `y` (target variable). \n\nPlease write the code to fit a linear regression model using scikit-learn and store the trained model in the variable `model`.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndf = pd.DataFrame({\n    'Size (sq ft)': [1500, 2000, 2400, 1800, 3000],\n    'Bedrooms': [3, 4, 4, 3, 5],\n    'Price': [300000, 400000, 500000, 350000, 600000]\n})\nX = df[['Size (sq ft)', 'Bedrooms']]\ny = df['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nmodel = LinearRegression().fit(X_train, y_train)\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset that consists of multiple features, including age, weight, and height of individuals. You want to standardize these features to have a mean of 0 and a standard deviation of 1 using Scikit-learn, and then plot the first two standardized features using Matplotlib for visualization. \n\nHere is the initial dataset represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Age': [25, 30, 35, 40, 45],\n    'Weight': [150, 160, 170, 180, 190],\n    'Height': [65, 67, 70, 72, 74]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNext, you need to standardize the features and store the result back into the DataFrame `df`. After standardization, plot the standardized Age against Standardized Weight.\n\nTo achieve this, please complete the following line of code:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\nscaler = StandardScaler()\nstandardized_features = ... # put solution in this variable\n\ndf[['Age', 'Weight']] = standardized_features\nplt.scatter(df['Age'], df['Weight'])\nplt.xlabel('Standardized Age')\nplt.ylabel('Standardized Weight')\nplt.title('Standardized Age vs Weight')\nplt.show()\n```\n\nPlease provide the solution in the `standardized_features` variable.",
    "output": "\n```python\nstandardized_features = scaler.fit_transform(df[['Age', 'Weight']])\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load iris dataset\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train a RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Generate a classification report and store the result\n# SOLUTION START\n```",
    "output": "\n```python\nreport = classification_report(y_test, y_pred, target_names=data.target_names)\nprint(report)\n# SOLUTION END\n```"
  },
  {
    "input": "Problem:\nI have a dataset in a pandas DataFrame containing temperature readings in degrees Celsius for different cities over a week. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n    'Temperature': [29.0, 25.0, 31.5, 28.0, 30.2, 27.5, 28.0, 26.5],\n    'Day': ['Monday', 'Monday', 'Tuesday', 'Tuesday', 'Wednesday', 'Wednesday', 'Thursday', 'Thursday']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the average temperature for each city across the week and plot the results using Matplotlib. \n\nHere\u2019s the code snippet I have so far to calculate the mean temperature:\n\n```python\nmean_temp = df.groupby('City')['Temperature'].mean()\n```\n\nNow, I wish to plot the average temperature for each city with the following code:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Average temperature\nmean_temp = ...\n# Plotting\nplt.bar(mean_temp.index, mean_temp.values)\nplt.ylabel('Average Temperature (\u00b0C)')\nplt.title('Average Temperature by City')\nplt.show()\n```\n\nWhat should I put in the blank for `mean_temp` so that it correctly computes the average temperature? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n    'Temperature': [29.0, 25.0, 31.5, 28.0, 30.2, 27.5, 28.0, 26.5],\n    'Day': ['Monday', 'Monday', 'Tuesday', 'Tuesday', 'Wednesday', 'Wednesday', 'Thursday', 'Thursday']\n}\n\ndf = pd.DataFrame(data)\n</code>\nmean_temp = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmean_temp = df.groupby('City')['Temperature'].mean()\n```"
  },
  {
    "input": "Problem:\n\nI am working with a dataset containing information about sales transactions. I have a DataFrame that holds transaction data, and I want to normalize the sales amount using `MinMaxScaler` from Scikit-learn. Additionally, I need to plot the original and normalized sales amounts using Matplotlib. Here's my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'sales_amount': [150, 200, 50, 300, 100]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to perform the following actions:\n\n1. Normalize the `sales_amount` column to a scale from 0 to 1 using `MinMaxScaler`.\n2. Create a line plot with the original sales amount and the normalized sales amount on the same graph.\n\nYour task is to fill in the following lines of code to apply normalization and plot the results:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\ndf['normalized_sales'] = ... # put solution in this variable\n\nplt.plot(df['transaction_id'], df['sales_amount'], label='Original Sales', marker='o')\nplt.plot(df['transaction_id'], df['normalized_sales'], label='Normalized Sales', marker='x')\nplt.title('Sales Amount Normalization')\nplt.xlabel('Transaction ID')\nplt.ylabel('Sales Amount')\nplt.legend()\nplt.show()\n```\n\nFill in the blank with the correct code to create the `normalized_sales` column.",
    "output": "\n```python\ndf['normalized_sales'] = scaler.fit_transform(df[['sales_amount']])\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate random data for a simple linear regression\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Now we want to plot the original data points and the best-fitted line.\n# Create a scatter plot of the original data points\nplt.scatter(X, y)\n\n# Predict y for the range of X values to draw the line\n# The predicted values should be stored in the variable 'predictions'\npredictions = ...  # put solution in this variable\n\n# Now plot the best fit line using the predictions\nplt.plot(X, predictions, color='red', linewidth=2)\n\n# Show the plot\nplt.show()\n```",
    "output": "\n```python\npredictions = model.predict(X)\n```"
  },
  {
    "input": "Problem:\nI have a dataset consisting of several years of daily temperature recordings in a Pandas DataFrame. The DataFrame has two columns: 'date' (datetime objects) and 'temperature' (float values representing degrees Celsius). I need to compute the weekly average temperatures and return them as a new DataFrame with two columns: 'week' (the week number of the year) and 'average_temperature' (the average temperature for that week).\n\nHere's how the data looks:\n\n```\n        date    temperature\n0 2020-01-01           5.0\n1 2020-01-02           6.5\n2 2020-01-07           4.0\n3 2020-01-08           7.0\n4 2020-01-14           8.0\n...\n```\n\nWhat would be the most efficient way to achieve this using Pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2020-01-01', periods=15, freq='D'),\n    'temperature': [5.0, 6.5, 4.0, 7.0, 8.0, 10.0, 9.5, 11.0, 12.0, 10.5, 9.0, 8.5, 7.5, 6.5, 5.5]\n}\ndf = pd.DataFrame(data)\n</code>\nweekly_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['week'] = df['date'].dt.isocalendar().week\nweekly_avg = df.groupby('week')['temperature'].mean().reset_index(name='average_temperature')\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing daily temperatures (in Celsius) and their corresponding dates. You want to predict the next day's temperature using a simple linear regression model. First, you'll need to preprocess the data using pandas and then train a linear model with scikit-learn. Finally, you will create a plot to visualize the original data points and the predicted temperature for the next day.\n\nHere is a sample of the code you have so far:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Sample data\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n}\n\ndf = pd.DataFrame(data)\n\n# Prepare the features and labels\nX = df.index.values.reshape(-1, 1)\ny = df['temperature'].values\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict the temperature for the next day (index 10)\npredicted_temp = ...\n```\n\nHow can you fill in the blank to get the predicted temperature for the next day?",
    "output": "\n```python\npredicted_temp = model.predict(np.array([[10]]))\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# You have a dataset stored in a Pandas DataFrame called 'data' which contains features and a target variable.\n# The target variable is in the 'target' column and the rest are features. \ndata = pd.DataFrame({\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'target': np.random.randint(0, 2, 100)\n})\n\n# You want to scale the features using StandardScaler from scikit-learn.\n# Next, you will use TensorFlow to create a simple model that fits the scaled data.\n# Finally, plot the predictions against the actual target using matplotlib.\n\n# Perform scaling here\nscaler = StandardScaler()\nfeatures = data.drop('target', axis=1)\nscaled_features = ... # put solution in this variable\n\n# Build a simple TensorFlow model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(10, activation='relu', input_shape=(scaled_features.shape[1],)),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile and fit the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(..., ...) # fit the model on scaled_features and data['target']\n\n# Generate predictions\npredictions = model.predict(scaled_features)\n\n# Plot the predictions against the actual target\nplt.scatter(data['target'], predictions)\nplt.xlabel('Actual Target')\nplt.ylabel('Predictions')\nplt.title('Predictions vs Actual Target')\nplt.show()\n```",
    "output": "\n```python\nscaled_features = scaler.fit_transform(features)\n\nmodel.fit(scaled_features, data['target'], epochs=10, batch_size=5)\n```"
  },
  {
    "input": "## Problem:\n\nYou are working on a dataset containing customer reviews for various products. The dataset is loaded into a Pandas DataFrame called `df` with two columns: `review` (string) and `rating` (float). You want to create a function that will process the reviews to extract features such as the average rating of reviews that contain the word \"excellent\". For this, you need to leverage regular expressions along with NumPy and Pandas to perform the filtering and average calculation.\n\nWrite a function named `average_rating_of_excellent_reviews` that takes in a DataFrame and returns the average rating of reviews containing the word \"excellent\" (case insensitive). Make sure to handle cases where there are no such reviews.\n\nA:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport re\n\ndf = pd.DataFrame({'review': ['This product is excellent!', 'Worst purchase ever.', 'Excellent performance in every aspect.', 'Not good, I am disappointed.'],\n                   'rating': [5.0, 1.0, 4.5, 2.0]})\n\ndef average_rating_of_excellent_reviews(reviews_df):\n    # Your code here to calculate the average rating\n    average_rating = ...  # put solution in this variable\n    return average_rating\n```",
    "output": "\n```python\n    excellent_reviews = reviews_df[reviews_df['review'].str.contains(r'\\bexcellent\\b', case=False, na=False)]\n    if excellent_reviews.empty:\n        return np.nan\n    average_rating = excellent_reviews['rating'].mean()\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset that contains temperatures recorded over a week in Celsius, and you need to perform some basic analysis. Given the following list of temperatures:\n\n```python\ntemperatures = [22.5, 23.0, 21.5, 24.5, 23.1, 20.0, 25.0]\n```\n\nYou want to convert these temperatures to Fahrenheit using the formula `F = C * 9/5 + 32` and then calculate the average temperature in Fahrenheit. \n\nTo facilitate this, you want to use NumPy for the conversion and average calculation. \n\nA:\n\n```python\nimport numpy as np\n\ntemperatures = np.array([22.5, 23.0, 21.5, 24.5, 23.1, 20.0, 25.0])\n```\naverage_fahrenheit = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\naverage_fahrenheit = np.mean(temperatures * 9/5 + 32)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset in a pandas DataFrame containing temperature readings for each day of the week, and I want to calculate the moving average for a specified window size. Here's a sample of my DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'day': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n    'temperature': [70, 72, 68, 75, 74, 73, 71]\n}\ndf = pd.DataFrame(data)\n```\n\nNow I want to compute the moving average temperature with a window size of 3 days and store it in a new column called 'moving_avg'. How can I achieve that?\n\nA:\n```python\ndf['moving_avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_avg'] = df['temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset represented as a Pandas DataFrame containing two columns: 'A' and 'B'. Column 'A' consists of random integers between 1 and 100, while column 'B' consists of random floating-point numbers. I need to create a new column 'C' which contains the moving average of column 'B' calculated over a window of 5 rows. Furthermore, I want to drop any rows with NaN values resulting from this operation. How can I achieve this in one line?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(0)\ndf = pd.DataFrame({\n    'A': np.random.randint(1, 101, size=20),\n    'B': np.random.rand(20)\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.assign(C=df['B'].rolling(window=5).mean()).dropna()"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about customers' purchases in a retail store. The dataset is structured like this:\n\n```python\ndata = pd.DataFrame({\n    'customer_id': [1, 1, 2, 3, 2, 3, 1, 4],\n    'purchase_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-02', \n                                      '2023-01-03', '2023-01-04', '2023-01-05',\n                                      '2023-01-05', '2023-01-06']),\n    'amount': [100, 200, 150, 300, 250, 350, 75, 400]\n})\n```\n\nI want to analyze the purchasing behavior of each customer by calculating their total spending and the number of distinct purchase days. The final output should be a DataFrame that includes `customer_id`, total spending, and the count of distinct purchase days for each customer, sorted by total spending in descending order.\n\nHow can I achieve this using Pandas? \n\nA:\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'customer_id': [1, 1, 2, 3, 2, 3, 1, 4],\n    'purchase_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-02', \n                                      '2023-01-03', '2023-01-04', '2023-01-05',\n                                      '2023-01-05', '2023-01-06']),\n    'amount': [100, 200, 150, 300, 250, 350, 75, 400]\n})\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = data.groupby('customer_id').agg(total_spending=('amount', 'sum'),\n                                         distinct_purchase_days=('purchase_date', 'nunique')).reset_index()\nresult = result.sort_values(by='total_spending', ascending=False)\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that contains the weekly sales of various products in a store. The data is stored in a Pandas DataFrame with the following structure:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Week': ['2021-01-01', '2021-01-08', '2021-01-01', '2021-01-08', '2021-01-01', '2021-01-08'],\n    'Sales': [100, 150, 200, 250, 300, 350]\n}\ndf = pd.DataFrame(data)\n```\n\nYou would like to normalize the sales data for each product using min-max normalization so that the sales values scale between 0 and 1 for each product. To achieve this, you can leverage the `MinMaxScaler` from `scikit-learn`. \n\nHow would you fill in the blank below to perform the normalization?\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf['Normalized_Sales'] = ...\n```\n\nThe result should be a new column `Normalized_Sales` in the DataFrame that contains the normalized values for each product's sales over the weeks.",
    "output": "\n```python\ndf['Normalized_Sales'] = df.groupby('Product')['Sales'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)))\n```"
  },
  {
    "input": "Problem:\nContext\nYou have a dataset containing information about house prices, and you are analyzing the data to predict future prices using machine learning. The dataset looks like this:\n\n| Area (sq ft) | Bedrooms | Price |\n|--------------|----------|-------|\n| 1500         | 3        | 300000|\n| 2000         | 4        | 400000|\n| 2500         | 4        | 500000|\n| 1800         | 3        | 350000|\n| 1600         | 2        | 280000|\n\nYou want to create a simple linear regression model using Scikit-learn to predict the house price based on the area of the house.\n\nProblem\nHow do I fit a linear regression model with 'Area (sq ft)' as the feature and 'Price' as the target, and then make a prediction for a house area of 2100 sq ft?\n\nYou've started with:\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Create the DataFrame\ndata = {\n    'Area': [1500, 2000, 2500, 1800, 1600],\n    'Bedrooms': [3, 4, 4, 3, 2],\n    'Price': [300000, 400000, 500000, 350000, 280000]\n}\ndf = pd.DataFrame(data)\n\n# Define feature and target\nX = df[['Area']]\ny = df['Price']\n\n# Splitting the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\n\nYou need to fill in this blank to make the prediction:\n```python\npredicted_price = ... # put the solution in this variable\n```",
    "output": "\n```python\npredicted_price = model.predict([[2100]])[0]  # put the solution in this variable\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# I have a dataset stored in a DataFrame called `data` with columns 'Year' and 'Value'\n# where 'Year' represents the years from 2000 to 2020 and 'Value' contains some numerical value.\n# I want to fit a linear regression model to this dataset and then predict the value for the year 2025.\n\ndata = pd.DataFrame({\n    'Year': np.arange(2000, 2021),\n    'Value': [100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310]\n})\n\n# Now, I need to extract the Year and Value columns as X and y respectively.\n# After preparing the model, I would like to add the prediction for the year 2025 to a variable named `prediction`.\n\nX = ...  # put solution in this variable\ny = ...  # put solution in this variable\nmodel = LinearRegression()\nmodel.fit(X, y)\nprediction = ...  # put the value of the prediction for the year 2025 in this variable\n```",
    "output": "\n```python\nX = data[['Year']]\ny = data['Value']\nprediction = model.predict(np.array([[2025]]))\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing customer reviews for different products in the form of a pandas DataFrame. The DataFrame includes columns for `product_id`, `review_text`, and `rating`. I want to preprocess these reviews by converting the text to lowercase, removing punctuation, and then generating a term-document matrix using Scikit-learn's `CountVectorizer`.\n\nHere is an example DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': ['A', 'A', 'B', 'B', 'C'],\n    'review_text': ['Great product!', 'Not bad...', 'Would not recommend.', 'Excellent quality!', 'Okay.'],\n    'rating': [5, 3, 1, 5, 4]\n})\n```\n\nI need to fill in the blank in the following code segment to create the term-document matrix, which should be stored in the variable `result`.\n\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(df['review_text'])\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = X.toarray()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of customers' purchase histories stored in a CSV file. Each row in the file represents a transaction, with the following columns: `CustomerID`, `Product`, `Quantity`, and `Price`. You plan to analyze the total expenditure for each customer. Here\u2019s a segment of your dataset:\n\n```\nCustomerID,Product,Quantity,Price\n1,Apple,2,0.5\n1,Banana,1,0.2\n2,Apple,1,0.5\n2,Orange,3,0.3\n1,Orange,2,0.3\n```\n\nYou have the following code to load the dataset:\n```python\nimport pandas as pd\n\ndf = pd.read_csv(\"purchases.csv\")\n```\n\nYou need to calculate the total expenditure for each customer and output it as a new DataFrame with columns `CustomerID` and `TotalExpenditure`. How would you do this?\n\nA:\n<code>\ndf['Total'] = df['Quantity'] * df['Price']\nresult = df.groupby('CustomerID')['Total'].sum().reset_index()\nresult.columns = ['CustomerID', 'TotalExpenditure']\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('CustomerID').apply(lambda x: (x['Quantity'] * x['Price']).sum()).reset_index(name='TotalExpenditure')\n</code>"
  },
  {
    "input": "Problem:\nHow can I scale features in a dataset using StandardScaler from Scikit-learn and then visualize the distribution of a specific feature using Matplotlib? Assume you have a DataFrame named `df` with columns `['feature1', 'feature2', 'feature3']`. Your goal is to scale `feature1` and then plot its distribution.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample DataFrame\ndf = pd.DataFrame({\n    'feature1': np.random.rand(100) * 100,\n    'feature2': np.random.rand(100) * 50,\n    'feature3': np.random.rand(100) * 25\n})\n\nscaler = StandardScaler()\nscaled_feature1 = scaler.fit_transform(df[['feature1']])\n</code>\n# Now plot the distribution of the scaled feature1\nplt.hist(..., bins=30, alpha=0.7)\nplt.title('Distribution of Scaled Feature1')\nplt.xlabel('Scaled Feature1')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()  # Make sure to visualize the plot\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nplt.hist(scaled_feature1, bins=30, alpha=0.7)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset represented as a Pandas DataFrame containing historical sales data for a store. The DataFrame has the following structure:\n\n+------------+------------+-------+\n|    Date    | Category   | Sales |\n+------------+------------+-------+\n| 2023-01-01 | Electronics| 1000  |\n| 2023-01-02 | Groceries  | 500   |\n| 2023-01-01 | Groceries  | 300   |\n| 2023-01-03 | Electronics| 2000  |\n| 2023-01-02 | Electronics| 1500  |\n+------------+------------+-------+\n\nI want to calculate the total sales for each category on a daily basis and store the results in a new DataFrame with columns \"Date\", \"Category\", and \"Total_Sales\". How can I achieve this in a concise manner without using explicit loops?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'],\n    'Category': ['Electronics', 'Groceries', 'Groceries', 'Electronics', 'Electronics'],\n    'Sales': [1000, 500, 300, 2000, 1500]\n}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby(['Date', 'Category'], as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a pandas DataFrame containing various attributes of houses, including their features and prices. I want to normalize the 'price' column using MinMaxScaler from scikit-learn so that the values are scaled to the range [0, 1]. After normalization, I plan to visualize the distribution of the normalized prices using Matplotlib. \n\nHere's a brief setup of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'sqft': [1500, 2000, 2500, 3000, 3500],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'price': [300000, 400000, 500000, 600000, 700000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nHow can I normalize the 'price' column and then plot the histogram of the normalized prices? \n\nUse default arguments unless specified.\nFill in the blank for the normalization step.\n\nA:\n\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n</code>\nnormalized_price = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_price = scaler.fit_transform(df[['price']])\n</code>"
  },
  {
    "input": "### Problem\n\nYou have a DataFrame containing daily sales data for a retail store, structured as follows:\n\n|    Date    |  Sales  |  Customers  |\n|------------|---------|-------------|\n| 2023-01-01 |  250.00 |      25     |\n| 2023-01-02 |  300.00 |      30     |\n| 2023-01-03 |  280.00 |      29     |\n| 2023-01-04 |  310.00 |      35     |\n| 2023-01-05 |  320.00 |      32     |\n\nYou want to create a new column called 'Sales_Per_Customer', which calculates the average sales per customer for each day. \n\nYour code so far looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Sales': [250.00, 300.00, 280.00, 310.00, 320.00],\n    'Customers': [25, 30, 29, 35, 32]\n}\n\ndf = pd.DataFrame(data)\n\ndf['Sales_Per_Customer'] = ...\n```\n\nFill in the blank with the correct code to compute the 'Sales_Per_Customer\u2019.",
    "output": "\n```python\ndf['Sales_Per_Customer'] = df['Sales'] / df['Customers']\n```"
  },
  {
    "input": "Problem:\n\nI am working on a predictive modeling project using a dataset related to housing prices. I have this DataFrame containing both numerical and categorical features. Here is a sample of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 3, 5],\n    'Location': ['Urban', 'Suburban', 'Urban', 'Rural'],\n    'Price': [300000, 400000, 500000, 600000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to convert the 'Location' categorical feature into numerical values using one-hot encoding before proceeding to build my model with TensorFlow. However, I need the resulting DataFrame to maintain the 'Size', 'Bedrooms', and 'Price' columns alongside the one-hot encoded 'Location' columns. What line of code should I use to achieve this?\n\nA:\n\n```python\nimport pandas as pd\ndata = {\n    'Size': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 3, 5],\n    'Location': ['Urban', 'Suburban', 'Urban', 'Rural'],\n    'Price': [300000, 400000, 500000, 600000]\n}\ndf = pd.DataFrame(data)\n```\ndf_encoded = ... # put solution in this variable\nBEGIN SOLUTION\n```python",
    "output": "\n<code>\ndf_encoded = pd.get_dummies(df, columns=['Location'], drop_first=True)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of customer purchase behavior that contains the following columns: `customer_id`, `purchase_amount`, and `purchase_date`. I want to analyze this data to determine the average purchase amount per customer for the last month. However, when I group the data, I want to ensure that I only consider customers who made at least one purchase in the last 30 days. My current attempt to achieve this using Pandas seems incorrect.\n\nHere is a snippet of my code:\n```python\nimport pandas as pd\n\ndata = {'customer_id': ['C1', 'C2', 'C1', 'C3', 'C2', 'C1'],\n        'purchase_amount': [100, 150, 200, 300, 250, 50],\n        'purchase_date': ['2023-09-28', '2023-09-29', '2023-10-01', '2023-10-15', '2023-10-10', '2023-10-05']}\n\ndf = pd.DataFrame(data)\ndf['purchase_date'] = pd.to_datetime(df['purchase_date'])\n```\nI would like to compute the average purchase amount for each customer who has made a purchase in the last 30 days. The expected result should be in a new DataFrame containing `customer_id` and `average_purchase_amount`.\n\nHow can I write the code to correctly filter and aggregate the DataFrame? \n\nA:\n<code>\ndf_last_month = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom datetime import datetime, timedelta\n\nlast_30_days = datetime.now() - timedelta(days=30)\ndf_filtered = df[df['purchase_date'] >= last_30_days]\ndf_last_month = df_filtered.groupby('customer_id')['purchase_amount'].mean().reset_index(name='average_purchase_amount')\n</code>"
  },
  {
    "input": "Problem:\nI am working with a machine learning problem where I have a dataset of houses containing several features such as the square footage, number of bedrooms, and price. I've split the dataset into training and testing sets. Now, I want to normalize the training features using Min-Max scaling and apply the same transformation to the test features. I have the training features in a Pandas DataFrame named `train_df` and the test features in `test_df`.\n\nThe following code snippet shows how to use the `MinMaxScaler` from Scikit-learn to perform the normalization:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Example DataFrames\ntrain_df = pd.DataFrame({\n    'square_footage': [1500, 1800, 2400, 1200],\n    'num_bedrooms': [3, 4, 5, 2],\n    'price': [300000, 400000, 500000, 250000]\n})\n\ntest_df = pd.DataFrame({\n    'square_footage': [1600, 2000],\n    'num_bedrooms': [3, 4]\n})\n\nscaler = MinMaxScaler()\n# Fit the scaler to the training data\nscaler.fit(train_df[['square_footage', 'num_bedrooms']])\n```\n\nNow, how should I normalize both the training and test features to get the normalized DataFrames?\n\nA:\n```python\n# Normalize the training data and assign to a variable named 'train_normalized'\ntrain_normalized = ...\n# Normalize the test data and assign to a variable named 'test_normalized'\ntest_normalized = ...\n```",
    "output": "\n```python\n# Normalize the training data and assign to a variable named 'train_normalized'\ntrain_normalized = scaler.transform(train_df[['square_footage', 'num_bedrooms']])\n# Normalize the test data and assign to a variable named 'test_normalized'\ntest_normalized = scaler.transform(test_df[['square_footage', 'num_bedrooms']])\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict on new data points\nX_new = np.array([[0], [2]])\ny_predict = ... # put solution in this variable\n```",
    "output": "\n```python\ny_predict = model.predict(X_new)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses which includes features like size, number of bedrooms, age, and price. I want to normalize these features using Min-Max Scaling. The features I have in a DataFrame `df` are as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 2000, 2500, 3000, 3500],\n    'Bedrooms': [3, 4, 3, 5, 4],\n    'Age': [10, 15, 5, 20, 30],\n    'Price': [300000, 400000, 350000, 500000, 600000]\n}\ndf = pd.DataFrame(data)\n```\n\nI need to normalize the features except for the 'Price' column and create a new DataFrame `normalized_df` where the Min-Max scaling is applied to 'Size', 'Bedrooms', and 'Age'. How can I achieve this?\n\nA:\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nfeature_columns = df.columns.difference(['Price'])\nnormalized_df = ... # put solution in this variable\n</code>",
    "output": "\n<code>\nnormalized_df = pd.DataFrame(scaler.fit_transform(df[feature_columns]), columns=feature_columns)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer transactions for a retail company. The dataset is stored in a pandas DataFrame, and you need to normalize the sales figures in the `sales` column using Min-Max scaling, then visualize the results using a Matplotlib bar chart. The DataFrame consists of the following columns: `CustomerID`, `Product`, and `sales`.\n\nHere is the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 3, 4, 5],\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'sales': [150, 200, 50, 300, 400]\n}\ndf = pd.DataFrame(data)\n```\n\nYou should fill in the blank below to achieve normalization and create a bar chart of the normalized sales.\n\nA:\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\n# Initialize MinMaxScaler\nscaler = MinMaxScaler()\n\n# Normalize the sales column\nnormalized_sales = scaler.fit_transform(df[['sales']])\n\n# Create a bar chart\nplt.bar(df['Product'], ...) # fill in the solution here\nplt.xlabel('Products')\nplt.ylabel('Normalized Sales')\nplt.title('Bar Chart of Normalized Sales')\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>normalized_sales.flatten()</code>",
    "output": "\n<code>normalized_sales.flatten()</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing various features of houses, stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'area': [1500, 1800, 2400, 3000],\n    'bedrooms': [3, 4, 3, 5],\n    'price': [300000, 400000, 500000, 650000]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to standardize the 'price' column using `scikit-learn`'s `StandardScaler`, which will transform the 'price' values to have a mean of 0 and a standard deviation of 1. After applying the scaler, I would like to append the standardized 'price' values as a new column named 'standardized_price' to the original DataFrame.\n\nHere\u2019s the code I\u2019m currently using to create and fit the scaler:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(df[['price']])\n```\n\nHow can I extract the standardized values and add them back to the `df` DataFrame under the 'standardized_price' column?\n\nA:\n```python\n# put solution in this variable\ndf['standardized_price'] = ... \n```",
    "output": "\n```python\ndf['standardized_price'] = scaler.transform(df[['price']])\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'feature1': [10, 20, 30, 40],\n    'feature2': [1, 2, 3, 4],\n    'label': [0, 1, 0, 1]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to fit a logistic regression model using Scikit-learn to predict the 'label' based on 'feature1' and 'feature2', and store the fitted model in a variable named `model`. Here's what I have so far:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX = df[['feature1', 'feature2']]\ny = df['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n```\n\nWhat code should I use to fit the logistic regression model?\n\nA:\n```python\nfrom sklearn.linear_model import LogisticRegression\nmodel = ... # put solution in this variable\n```",
    "output": "\n```python\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Generate a DataFrame with 100 samples and 5 features, filled with random numbers\ndata = pd.DataFrame(np.random.rand(100, 5), columns=list(\"ABCDE\"))\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n\n# Apply PCA to reduce dimensions to 2\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(scaled_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Create a scatter plot of the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'])\nplt.title('PCA of Random Data')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.axhline(0, color='black',linewidth=0.5, ls='dashed')\nplt.axvline(0, color='black',linewidth=0.5, ls='dashed')\nplt.grid()\n\n# Show the plot and return the explained variance ratio\nexplained_variance = pca.explained_variance_ratio_\n\n# Insert your code here to generate the explained variance values \n# as a numpy array or similar output\nsolution = ...  # put your solution here\n```",
    "output": "\n```python\nsolution = np.array(explained_variance)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales information for a product over a week. The data looks like this:\n\n```\n   Day      Sales\n0  Mon      120\n1  Tue      150\n2  Wed      130\n3  Thu      170\n4  Fri      160\n5  Sat      180\n6  Sun      190\n```\n\nI want to calculate the moving average of sales over a period of 3 days, starting from the first day of data. I wrote the following code:\n\n```python\nimport pandas as pd\n\ndata = {'Day': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n        'Sales': [120, 150, 130, 170, 160, 180, 190]}\ndf = pd.DataFrame(data)\n```\n\nThen I tried to calculate the moving average using:\n```python\ndf['Moving_Average'] = df['Sales'].rolling(window=3).mean()\n```\n\nHowever, I need the `Moving_Average` computed to only show values starting from the third day, meaning the first two entries should be NaN. My goal is to achieve this while also plotting both `Sales` and `Moving_Average` using Matplotlib.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'Day': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n        'Sales': [120, 150, 130, 170, 160, 180, 190]}\ndf = pd.DataFrame(data)\n\ndf['Moving_Average'] = ...\n# Plotting code follows\nplt.plot(df['Day'], df['Sales'], label='Sales')\nplt.plot(df['Day'], df['Moving_Average'], label='Moving Average', color='orange')\nplt.legend()\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['Moving_Average'] = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\n\n# Assume we have the following DataFrame that includes some numerical data\ndata = {'A': [1, 2, 3, 4, 5],\n        'B': [10, 20, 30, 40, 50],\n        'C': [100, 200, 300, 400, 500]}\ndf = pd.DataFrame(data)\n\n# First, standardize the columns A and B\nscaler = StandardScaler()\ndf[['A', 'B']] = scaler.fit_transform(df[['A', 'B']])\n\n# Now let's visualize the standardized data with a scatter plot\nplt.scatter(df['A'], df['B'])\nplt.title('Standardized A vs B')\nplt.xlabel('A')\nplt.ylabel('B')\nplt.show()\n\n# Finally, create a simple TensorFlow model that predicts an outcome, assuming 'C' is the target\nX = df[['A', 'B']]\ny = df['C']\n\n# Define a simple model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(5, activation='relu', input_shape=(X.shape[1],)),\n    tf.keras.layers.Dense(1)\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# To fit the model we need to transform the data into the correct format\n# Fit model will be done here\nmodel.fit(X.values, y.values, epochs=5)\n\n# Predict the outcomes\npredictions = model.predict(X.values)\n\n# What should be placed in the result variable to store predictions?\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = predictions.flatten()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing measurements from a sensor that has a known sampling frequency of 100 Hz. The data might have some missing values. My goal is to interpolate the missing values, apply a low-pass filter to smooth the data, and then visualize the result. The data contains timestamps and corresponding sensor readings. After filling the missing values, I want to plot the original and the smoothed sensor readings for comparison.\n\nGiven the following code to create a sample DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\ntimestamps = pd.date_range('2023-01-01', periods=100, freq='10ms')\ndata = np.random.randn(100) * 10\ndata[::5] = np.nan  # introduce NaN values\ndf = pd.DataFrame({'timestamp': timestamps, 'sensor_readings': data})\n```\n\nI want to perform interpolation to fill the missing values. Replace the `...` with the appropriate function to fill the missing values.\n\nA:\n```python\nresult = df['sensor_readings'].interpolate(method='...')  # put solution in this variable\n```",
    "output": "\n```python\nresult = df['sensor_readings'].interpolate(method='linear')  # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing the sales of products in different regions over several months:\n\n```python\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Region': ['North', 'South', 'North', 'South', 'North', 'South'],\n    'Sales': [200, 150, 300, 250, 100, 50],\n    'Month': ['2023-01', '2023-01', '2023-01', '2023-01', '2023-01', '2023-01']\n}\n```\n\nYou want to pivot this dataset to create a matrix where each product's sales are displayed for each region, and the months become the index. The desired output should look like:\n\n```\nRegion    A    B    C\nNorth   200  300  100\nSouth   150  250   50\n```\n\nYou started with:\n```python\nimport pandas as pd\ndf = pd.DataFrame(data)\n```\n\nWhat should follow to achieve the pivoted DataFrame? \nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = df.pivot_table(index='Region', columns='Product', values='Sales', aggfunc='sum', fill_value=0)</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing sales data of a product over a period of time with columns for 'Date', 'Product', 'Quantity', and 'Price'. The DataFrame is as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\n    'Product': ['A', 'B', 'A', 'B', 'A'],\n    'Quantity': [10, 20, 15, 10, 5],\n    'Price': [2.0, 3.0, 2.0, 3.0, 2.0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to calculate the total revenue for each product across all days, where revenue is defined as `Quantity * Price`. The result should be a DataFrame with columns 'Product' and 'Total_Revenue'. \n\nTo achieve this, you want to use a method that avoids explicit loops and instead utilizes Pandas functions. What code would fill in the blank to compute this efficiently?\n\nA:\n```python\nresult = df.groupby('Product').apply(lambda x: (x['Quantity'] * x['Price']).sum()).reset_index(name='Total_Revenue')\n```",
    "output": "\n```python\nresult = df.groupby('Product').apply(lambda x: (x['Quantity'] * x['Price']).sum()).reset_index(name='Total_Revenue')\n```"
  },
  {
    "input": "Problem:\nI am working on a classification problem using a dataset that contains features of different flowers. The dataset looks like this:\n\n| SepalLength | SepalWidth | PetalLength | PetalWidth | Species  |\n|--------------|-------------|--------------|-------------|----------|\n| 5.1          | 3.5         | 1.4          | 0.2         | Setosa   |\n| 7.0          | 3.2         | 4.7          | 1.4         | Versicolor |\n| 6.3          | 3.3         | 6.0          | 2.5         | Virginica |\n| ...          | ...         | ...          | ...         | ...      |\n\nI would like to use Scikit-learn to train a decision tree model on this dataset and then predict the species of a new flower with the following features: [5.4, 3.9, 1.7, 0.4]. However, I am getting an error with data types because my input data is stored in a Pandas DataFrame.\n\nThis is how my preliminary code looks:\n\n```python\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = {\n    'SepalLength': [5.1, 7.0, 6.3],\n    'SepalWidth': [3.5, 3.2, 3.3],\n    'PetalLength': [1.4, 4.7, 6.0],\n    'PetalWidth': [0.2, 1.4, 2.5],\n    'Species': ['Setosa', 'Versicolor', 'Virginica']\n}\n\ndf = pd.DataFrame(data)\nX = df[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\ny = df['Species']\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X, y)\n\nnew_flower = pd.DataFrame({'SepalLength': [5.4], 'SepalWidth': [3.9], 'PetalLength': [1.7], 'PetalWidth': [0.4]})\nprediction = ...\n```\n\nFill in the blank where I try to predict the species of the new flower using the trained model. \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata = {\n    'SepalLength': [5.1, 7.0, 6.3],\n    'SepalWidth': [3.5, 3.2, 3.3],\n    'PetalLength': [1.4, 4.7, 6.0],\n    'PetalWidth': [0.2, 1.4, 2.5],\n    'Species': ['Setosa', 'Versicolor', 'Virginica']\n}\n\ndf = pd.DataFrame(data)\nX = df[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\ny = df['Species']\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X, y)\n\nnew_flower = pd.DataFrame({'SepalLength': [5.4], 'SepalWidth': [3.9], 'PetalLength': [1.7], 'PetalWidth': [0.4]})\n</code>\nprediction = ... # put solution in this variable",
    "output": "\n<code>\nprediction = model.predict(new_flower)\n</code>"
  },
  {
    "input": "## Problem\nYou have a dataset of house prices in a Pandas DataFrame called `df`, containing columns for square footage (`sqft`), number of bedrooms (`bedrooms`), and the price of the house (`price`). You want to create a scatter plot comparing square footage and price to visualize the relationship between these variables. You also want to include a linear regression line on this scatter plot using Scikit-learn's `LinearRegression` model.\n\nHere's the initial code you've written:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Example data\ndata = {\n    'sqft': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'price': [300000, 320000, 340000, 360000, 380000]\n}\ndf = pd.DataFrame(data)\n\n# Scatter plot\nplt.scatter(df['sqft'], df['price'], color='blue')\n\n# Fit the linear regression model\nX = df[['sqft']]\nY = df['price']\nmodel = LinearRegression().fit(X, Y)\n\n# Predict prices based on the sq ft\npredicted_prices = model.predict(X)\n\n# _______ (fill in the blank) _______\n```\n\nWhat should you put in place of the blank to plot the regression line on the scatter plot?\n\nA:\n\n<code>\nplt.plot(df['sqft'], predicted_prices, color='red')\n</code>",
    "output": "\n<code>\nplt.plot(df['sqft'], predicted_prices, color='red')\nplt.xlabel('Square Footage')\nplt.ylabel('Price')\nplt.title('Scatter Plot of House Prices vs. Square Footage')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing various measurements of a substance over time represented as a Pandas DataFrame. I want to calculate the rolling mean of a specified window size for one of the columns in this DataFrame and also plot this result alongside the original data using Matplotlib.\n\nHere's a sample DataFrame:\n```\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'time': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'measurement': np.random.rand(10) * 100\n}\ndf = pd.DataFrame(data)\n```\nNow, I want to compute the rolling mean with a window size of 3 and then plot both the original 'measurement' and the rolling mean on the same graph. \n\nPlease provide me with the code to compute the rolling mean and plot it.\n\nA:\n<code>\nrolling_mean = ... # put solution in this variable\nplt.plot(df['time'], df['measurement'], label='Original Measurement')\nplt.plot(df['time'], rolling_mean, label='Rolling Mean', color='orange')\nplt.xlabel('Time')\nplt.ylabel('Measurement')\nplt.legend()\nplt.show()\n</code>",
    "output": "\n<code>\nrolling_mean = df['measurement'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "```python\nProblem:\n\nI am working on a data preprocessing task where I have a dataset of images and their corresponding labels. I want to normalize the pixel values of the images, ensuring that they fall within the range of 0 to 1. \n\nCurrently, I have the images stored as a NumPy array with the shape (num_images, height, width, channels) and a corresponding labels array. After normalizing the images, I intend to use TensorFlow to convert them to a suitable format for training a model.\n\nHere's my code up to this point:\n\nimport numpy as np\nimport tensorflow as tf\n\ndef normalize_images(images):\n    # Normalize the images here\n    return images\n\n# Example data\nimages = np.random.randint(0, 256, size=(100, 32, 32, 3)).astype(np.float32)  # 100 images, 32x32 size, 3 channels\nlabels = np.random.randint(0, 10, size=(100,))  # 100 labels for 10 classes\n\nnormalized_images = normalize_images(images)\ntf_images = tf.convert_to_tensor(normalized_images)\n\n# Now, I need to scale the pixel values to a range of [0, 1]. \n# What code should I put in the normalize_images function?\nnormalized_images = ... # put solution in this variable\n```",
    "output": "\n```python\n<code>\n    normalized_images = images / 255.0\n</code>\n```"
  },
  {
    "input": "### Problem:\nYou have a dataset containing information about students' scores in Mathematics, Science, and English. The data is structured in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'Math': [88, 92, 85, 78, 90],\n    'Science': [95, 81, 89, 80, 94],\n    'English': [84, 88, 91, 85, 87]\n}\ndf = pd.DataFrame(data)\n```\n\nYou would like to calculate the average score for each student and add a new column named \"Average\" to the DataFrame. To do this, you can use the `mean()` function along the correct axis but ensure you are only taking the mean of the subjects (Math, Science, and English) and not of the index, while keeping the column intact. Finally, you want to round the average scores to two decimal places.\n\nHow can you calculate the average scores and add it to the DataFrame in the new column \"Average\"?\n\n```python\ndf['Average'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Average'] = df[['Math', 'Science', 'English']].mean(axis=1).round(2)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about the heights and weights of various individuals. I want to train a simple linear regression model using TensorFlow and then visualize the regression line using Matplotlib.\n\nHere's the data I have:\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndata = {\n    'height': [1.5, 1.7, 1.8, 1.6, 1.9],\n    'weight': [50, 60, 70, 65, 80]\n}\ndf = pd.DataFrame(data)\n```\n\nI need to create and compile a linear regression model using TensorFlow, fitting the model to predict weight based on height. \n\nYour task is to fill in the blank for the model fitting section after creating and compiling the model.\n\nA:\n```python\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Prepare the data\nX = df['height'].values.reshape(-1, 1)\ny = df['weight'].values\n\n# Create the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(1, input_shape=(1,))\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Fit the model\nmodel.fit(X, y, epochs=..., verbose=0)  # Fill in the number of epochs\n\n# Predict values for plotting\npredictions = model.predict(X)\n\n# Plot\nplt.scatter(df['height'], df['weight'], color='blue', label='Data')\nplt.plot(df['height'], predictions, color='red', label='Regression Line')\nplt.xlabel('Height (m)')\nplt.ylabel('Weight (kg)')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nmodel.fit(X, y, epochs=100, verbose=0)  # Fill in the number of epochs\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Generating sample data\ndata = np.random.rand(100, 3) * 100\ncolumns = ['Feature1', 'Feature2', 'Feature3']\ndf = pd.DataFrame(data, columns=columns)\n\n# Standardizing the features\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Converting the standardized data back to a DataFrame\nscaled_df = pd.DataFrame(scaled_data, columns=columns)\n\n# Plotting the original and scaled data for Feature1\nplt.figure(figsize=(10, 5))\nplt.hist(df['Feature1'], alpha=0.5, label='Original Feature1')\nplt.hist(scaled_df['Feature1'], alpha=0.5, label='Scaled Feature1')\nplt.legend()\nplt.title('Comparison of Original and Scaled Feature1')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\n\n# Now, to save this plot to a file named 'feature_comparison.png',\n# fill in the missing code below.\n\nplt.savefig('feature_comparison.png') # fill in the solution here\n```",
    "output": "\n```python\nplt.savefig('feature_comparison.png')\n```"
  },
  {
    "input": "## Problem:\nI have a dataset containing information about various products, including their prices and sales data over several months. I want to create a function that takes this dataset, computes the percentage change in sales month-over-month for each product, and then plot the results for visual analysis. \n\nThe dataset is structured as follows:\n\n```python\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [\n        [100, 120, 90, 130, 110],  # Sales for product A over 5 months\n        [200, 210, 190, 220, 230],  # Sales for product B over 5 months\n        [150, 160, 155, 170, 180]   # Sales for product C over 5 months\n    ]\n}\n```\n\nYou need to ensure the output is a Pandas DataFrame that contains the month-over-month percentage changes of sales for each product. The resulting DataFrame should have a new column for each product with these percentage changes.\n\nAdditionally, please produce a Matplotlib line plot that displays the percentage changes over time for each product.\n\nHere is the starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [[100, 120, 90, 130, 110], [200, 210, 190, 220, 230], [150, 160, 155, 170, 180]]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate the percentage change\ndf['percentage_change'] = ...\n```\n\nFill in the blank for `df['percentage_change']` to complete the task.",
    "output": "\n```python\ndf['percentage_change'] = df['sales'].apply(lambda x: np.diff(x) / x[:-1] * 100)\ndf = df.explode('percentage_change').reset_index(drop=True)\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nfor i, product in enumerate(data['product']):\n    plt.plot(df[df['product'] == product].index, df[df['product'] == product]['percentage_change'], label=f'Product {product}')\nplt.title('Month-over-Month Percentage Change in Sales')\nplt.xlabel('Months')\nplt.ylabel('Percentage Change (%)')\nplt.legend()\nplt.grid()\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing temperatures recorded over multiple days in a city. The data is structured in two NumPy arrays: one for the dates and one for the temperature readings.\n\n```python\nimport numpy as np\ndates = np.array(['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-03'])\ntemperatures = np.array([30, 32, 31, 29, 30, 31])\n```\n\nYou would like to convert this data into a Pandas DataFrame, calculate the average temperature for each date, and then create a new column indicating whether the average temperature is above or below a threshold of 30 degrees Celsius.\n\nWhat is the correct line of code to create the DataFrame `df` that includes columns for the date, average temperature, and a binary column indicating whether the average temperature is above (1) or below (0) the threshold?\n\n```python\nimport pandas as pd\ndates = np.array(['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-03'])\ntemperatures = np.array([30, 32, 31, 29, 30, 31])\n```\n\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf = pd.DataFrame({'date': dates, 'temperature': temperatures}).groupby('date').agg(avg_temp=('temperature', 'mean')).reset_index()\ndf['above_threshold'] = (df['avg_temp'] > 30).astype(int)\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset that contains information about different products and their sales recorded over different quarters. The dataset is in the form of a DataFrame as shown below:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n    'Quarter': ['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', 'Q3', 'Q3', 'Q3'],\n    'Sales': [100, 200, 150, 300, 250, 200, 400, 350, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to compute the cumulative sales for each product across all quarters, and if the cumulative sales exceed a specified threshold of 600, I want to set those values to 600. The final DataFrame needs to retain the original structure with an additional column for adjusted cumulative sales. Here is an example of the desired transformation:\n\n```\n   Product Quarter  Sales  Adjusted_Cumulative_Sales\n0       A      Q1     100                          100\n1       B      Q1     200                          200\n2       C      Q1     150                          150\n3       A      Q2     300                          400 \n4       B      Q2     250                          450\n5       C      Q2     200                          350\n6       A      Q3     400                          600\n7       B      Q3     350                          600\n8       C      Q3     300                          600\n```\n\nPlease complete the following code:\n\n```python\ndf['Adjusted_Cumulative_Sales'] = df.groupby('Product')['Sales'].cumsum().clip(upper=600)\n```\ndf = ... # put solution in this variable",
    "output": "\n```python\ndf = df.assign(Adjusted_Cumulative_Sales=df.groupby('Product')['Sales'].cumsum().clip(upper=600))\n```"
  },
  {
    "input": "Problem:\nYou have a dataset in a Pandas DataFrame that contains height and weight data for a group of individuals along with their respective ages. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Age': [23, 45, 31, 22, 35],\n    'Height': [5.5, 6.1, 5.7, 5.2, 5.8],\n    'Weight': [150, 180, 160, 130, 175]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour task is to standardize the 'Height' and 'Weight' columns using the formula: \n\\[ z = \\frac{x - \\mu}{\\sigma} \\]\nwhere \\( \\mu \\) is the mean and \\( \\sigma \\) is the standard deviation for the respective column. The output should be a new DataFrame that contains the original columns along with two new columns named 'Standardized_Height' and 'Standardized_Weight'.\n\nPlease put the solution in the blank below to achieve this:\n\nA:\n```python\nimport numpy as np\n\ndf['Standardized_Height'] = ...  # put solution in this variable\ndf['Standardized_Weight'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['Standardized_Height'] = (df['Height'] - df['Height'].mean()) / df['Height'].std()\ndf['Standardized_Weight'] = (df['Weight'] - df['Weight'].mean()) / df['Weight'].std()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about different products, including their sales in multiple regions. The dataset is in a Pandas DataFrame and looks like this:\n\n```\n   Product   Region   Sales\n0  ProductA  Region1   200\n1  ProductA  Region2   150\n2  ProductB  Region1   300\n3  ProductB  Region2   250\n```\n\nI would like to calculate the total sales for each product across all regions and then visualize the total sales using a bar chart with Matplotlib. Please show me how I can compute the total sales and put the result in a variable. \n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Product': ['ProductA', 'ProductA', 'ProductB', 'ProductB'],\n    'Region': ['Region1', 'Region2', 'Region1', 'Region2'],\n    'Sales': [200, 150, 300, 250]\n}\ndf = pd.DataFrame(data)\n</code>\ntotal_sales = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ntotal_sales = df.groupby('Product')['Sales'].sum().reset_index()"
  },
  {
    "input": "Problem:\nYou are working on a machine learning project where you need to preprocess a dataset before feeding it into a model. The dataset is a Pandas DataFrame that includes numerical features with some NaN values, and a categorical feature that needs to be one-hot encoded.\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\ndf = pd.DataFrame({\n    'feature1': np.random.randint(1, 10, size=10),\n    'feature2': [np.nan, 'A', 'B', 'A', 'B', np.nan, 'C', 'C', 'B', 'A'],\n    'feature3': np.random.rand(10)\n})\n```\n\nYour task is to create a function `preprocess_data` that:\n1. Fills NaN values in 'feature2' with the string \"Unknown\".\n2. One-hot encodes the 'feature2' column.\n3. Normalizes the 'feature3' column to be between 0 and 1.\n\nThe function should return the processed DataFrame.\n\nYou can start your function like this:\n\n```python\ndef preprocess_data(df):\n    # Fill NaN values in 'feature2'\n    # One-hot encode 'feature2'\n    # Normalize 'feature3'\n    \n    return df  # this should be the processed DataFrame\n```\n\nResult of processing should be assigned to `result`:\n```python\nresult = ...\n``` \n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef preprocess_data(df):\n    # Fill NaN values in 'feature2'\n    df['feature2'].fillna('Unknown', inplace=True)\n    \n    # One-hot encode 'feature2'\n    df = pd.get_dummies(df, columns=['feature2'], drop_first=True)\n    \n    # Normalize 'feature3'\n    df['feature3'] = (df['feature3'] - df['feature3'].min()) / (df['feature3'].max() - df['feature3'].min())\n    \n    return df  # this should be the processed DataFrame\n\nresult = preprocess_data(df)\n```"
  },
  {
    "input": "## Problem\n\nYou are working with a dataset that consists of features about different houses and their sale prices. You want to create a predictive model to determine the sale price based on house features using a neural network approach with TensorFlow.\n\nYou have the following data in a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Square_Feet': [1500, 1800, 2400, 3000, 3500],\n    'Bedrooms': [3, 3, 4, 5, 5],\n    'Age': [10, 15, 20, 5, 1],\n    'Sale_Price': [300000, 350000, 500000, 600000, 650000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to define a simple feedforward neural network model to predict the sale price. Define a model with one hidden layer having 5 neurons with `relu` activation and output layer for sale price prediction.\n\nPlease fill in the line marked with \"...\" to create the neural network model using TensorFlow's Keras API.\n\n```python\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(3,)),  # input layer corresponding to 3 features\n    tf.keras.layers.Dense(5, activation='relu'),  # hidden layer\n    ...\n])\n```\n",
    "output": "\n```python\n    tf.keras.layers.Dense(1)  # output layer for sale price prediction\n```"
  },
  {
    "input": "Problem:\nGiven the following dataset containing the daily temperatures and corresponding ice cream sales in the summer months, I want to analyze the relationship between temperature and sales using a simple linear regression model. \n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport io\n\ndata = \"\"\"Temperature,Sales\n25,100\n30,150\n35,200\n40,300\n45,400\"\"\"\ndf = pd.read_csv(io.StringIO(data))\n```\n\nI want to perform a linear regression using the temperature as the independent variable and sales as the dependent variable. After training the model, I need to visualize the regression line along with the data points. \n\nFill in the following code to run a linear regression and plot the results:\n\n```python\nX = df[['Temperature']]\ny = df['Sales']\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predicting values\npredictions = model.predict(X)\n\n# Plotting the results\nplt.scatter(X, y, color='blue')\nplt.plot(X, predictions, color='red')\n\nplt.xlabel('Temperature')\nplt.ylabel('Sales')\nplt.title('Temperature vs Ice Cream Sales')\nplt.show()\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\npredictions = model.predict(X)\n</code>",
    "output": "\n<code>\nresult = predictions\n</code>"
  },
  {
    "input": "Problem:\n\nYou are given a dataset with multiple features, specifically a pandas DataFrame containing columns for 'Age', 'Salary', and 'Loan Amount'. You want to apply a scaling technique to the numeric columns (i.e., 'Age', 'Salary', 'Loan Amount') using the StandardScaler from Scikit-learn to normalize the data. After scaling, compute the mean of the normalized 'Salary' column. \n\nThe initial DataFrame looks like this:\n\n```\n    Age  Salary  Loan Amount\n0   25   50000    200000\n1   30   60000    250000\n2   35   65000    150000\n3   40   70000    300000\n4   45   80000    280000\n```\n\nYou can assume that the DataFrame is loaded into the variable `df`. Please define a function that returns the mean of the scaled 'Salary' column.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = load_data()\ndef scaled_salary_mean(df):\n    # your solution here\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n",
    "output": "\n```python\n    scaler = StandardScaler()\n    df[['Age', 'Salary', 'Loan Amount']] = scaler.fit_transform(df[['Age', 'Salary', 'Loan Amount']])\n    return df['Salary'].mean()\n</code>\nresult = scaled_salary_mean(df)\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that represents sales information for a retail store. The data is contained in a pandas DataFrame with the following columns: `Product`, `Quantity_Sold`, `Price_per_Unit`, and `Sales_Date`. You want to forecast next month's sales for each product using linear regression.\n\nYour task is to write code that:\n1. Prepares the data by calculating the total sales for each product for the past three months.\n2. Splits the dataset into training and testing datasets.\n3. Trains a linear regression model to predict future sales based on the total sales from the previous three months.\n\nYou are provided with the following DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'A', 'B', 'C'],\n    'Quantity_Sold': [15, 20, 25, 10, 15, 10, 5, 12, 8, 7],\n    'Price_per_Unit': [3.0, 3.5, 4.0, 2.5, 3.0, 4.5, 5.0, 3.5, 2.5, 4.8],\n    'Sales_Date': pd.date_range(start='2023-01-01', periods=10, freq='M')\n}\ndf = pd.DataFrame(data)\n```\n\nFill in a piece of code to calculate the total sales for the past three months like this:\n\n```python\ndf['Total_Sales'] = ...\n```\nWhere `Total_Sales` should be calculated as the product of `Quantity_Sold` and `Price_per_Unit`. \n\nBEGIN SOLUTION\n```python\ndf['Total_Sales'] = df['Quantity_Sold'] * df['Price_per_Unit']\n```",
    "output": "\n```python\ndf['Total_Sales'] = df['Quantity_Sold'] * df['Price_per_Unit']\n```"
  },
  {
    "input": "Problem:\nYou are analyzing a dataset containing information about customer purchases from a retail store. The dataset consists of columns including 'CustomerID', 'PurchaseAmount', and 'PurchaseDate'. You need to calculate the average purchase amount by customer per month. However, you also want to make sure to visualize this data alongside a trend line representing the overall average monthly purchase amount across all customers. \n\nGiven the following imports and sample data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'CustomerID': [1, 1, 2, 2, 3, 3, 3],\n    'PurchaseAmount': [100, 200, 150, 300, 400, 250, 100],\n    'PurchaseDate': [\"2023-01-15\", \"2023-01-20\", \"2023-01-18\", \"2023-02-01\", \"2023-02-12\", \"2023-02-15\", \"2023-02-20\"]\n}\ndf = pd.DataFrame(data)\n\ndf['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'])\n```\n\nYou need to create a new DataFrame to summarize the average purchase amount by CustomerID per month and create a plot. Fill in the blank in the following code to achieve the summary DataFrame:\n\n```python\nmonthly_avg = df.groupby([df['PurchaseDate'].dt.to_period('M'), 'CustomerID'])['PurchaseAmount'].mean().reset_index()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = monthly_avg.rename(columns={'PurchaseDate': 'Month', 'PurchaseAmount': 'AveragePurchaseAmount'})\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the Iris dataset\niris = load_iris()\ndata = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Perform PCA to reduce the dimensions to 2\npca = PCA(n_components=2)\nreduced_data = pca.fit_transform(data)\n\n# Create a scatter plot of the reduced data\nplt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=iris.target, cmap='viridis')\n\n# Add labels for the axes\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\n# Show the grid and set x-ticks to range from -2 to 2 at intervals of 0.5\n# SOLUTION START\n```",
    "output": "\n```python\nplt.grid(True)\nplt.xticks(np.arange(-2, 2.5, 0.5))\n# SOLUTION END\n\n# Show the plot\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various species of flowers, specifically the `Iris` flower dataset, which includes the following columns: `sepal_length`, `sepal_width`, `petal_length`, and `petal_width`. I want to create a new column called `species` that categorizes the species based on the `petal_length` as follows:\n- If `petal_length` < 2.0, the species is \"setosa\"\n- If 2.0 <= `petal_length` < 5.0, the species is \"versicolor\"\n- If `petal_length` >= 5.0, the species is \"virginica\"\n\nYou can utilize `pandas` for data manipulation and `numpy` for the conditions. The dataframe is already created, and you need to fill in the code to create the new `species` column.\n\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'sepal_length': [5.1, 7.0, 6.3, 5.5, 4.9],\n    'sepal_width': [3.5, 3.2, 3.3, 2.5, 3.0],\n    'petal_length': [1.4, 4.7, 6.0, 1.3, 1.4],\n    'petal_width': [0.2, 1.4, 2.5, 0.2, 0.2]\n}\n\ndf = pd.DataFrame(data)\ndf['species'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['species'] = np.where(df['petal_length'] < 2.0, 'setosa', \n                          np.where(df['petal_length'] < 5.0, 'versicolor', 'virginica'))</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing features of different cars in a CSV file as follows:\n\n```\nmodel,horsepower,weight,year,mileage\nCivic,158,2876,2020,28.0\nAccord,192,3051,2019,30.0\nMustang,450,3300,2020,15.0\nCorolla,139,2855,2021,33.0\nCamry,203,3310,2018,24.0\n```\n\nYour goal is to perform the following tasks:\n1. Load the dataset into a Pandas DataFrame.\n2. Normalize the values of horsepower and weight using Min-Max scaling.\n3. Train a simple linear regression model to predict mileage based on horsepower and weight using Scikit-learn.\n4. Visualize the correlation between horsepower and mileage with a scatter plot using Matplotlib.\n\nAfter performing these tasks, you need to output the model's coefficients and intercept in the following format:\n\ncoefficients = [...]\nintercept = ...\n\nPlease fill in the code for the indicated section below:\n<code>\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the data\ndf = pd.read_csv('cars.csv')\n\n# Normalize the horsepower and weight\nscaler = MinMaxScaler()\nnormalized_features = ... # fill in this part\n\n# Train the linear regression model\nmodel = ... # fill in this part\n\n# Output coefficients and intercept\ncoefficients = ... # fill in this part\nintercept = ... # fill in this part\n\n# Create a scatter plot\nplt.scatter(df['horsepower'], df['mileage'])\nplt.xlabel('Horsepower')\nplt.ylabel('Mileage')\nplt.title('Horsepower vs Mileage')\nplt.show()\n</code>",
    "output": "\n<code>\nnormalized_features = scaler.fit_transform(df[['horsepower', 'weight']])\nmodel = LinearRegression().fit(normalized_features, df['mileage'])\ncoefficients = model.coef_\nintercept = model.intercept_\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily temperature of a city over a month, which is stored in a Pandas DataFrame. You want to compute the moving average of the daily temperatures over a 7-day window and then plot the original temperature data alongside the moving average.\n\nGiven the following example data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndate_range = pd.date_range(start='2023-01-01', periods=30)\ntemperatures = np.random.uniform(low=10, high=30, size=(30,))\ndf = pd.DataFrame({'date': date_range, 'temperature': temperatures})\n```\n\nFill in the blank to compute the moving average and create a plot:\n\n```python\ndf['moving_average'] = df['temperature'].rolling(window=7).mean()\nplt.plot(df['date'], df['temperature'], label='Daily Temperature')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.title('Daily Temperature and Moving Average')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\ndf['moving_average'] = df['temperature'].rolling(window=7).mean()\nplt.plot(df['date'], df['temperature'], label='Daily Temperature')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.title('Daily Temperature and Moving Average')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "### Problem\nYou have a dataset containing information on housing prices with features like size, number of bedrooms, and location. You aim to build a predictive model using Scikit-learn to predict prices based on these features. However, first, you need to preprocess the data. \n\nThe dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 1600, 1700, 1400, 1800],\n    'Bedrooms': [3, 3, 4, 2, 4],\n    'Location': ['Suburb', 'City', 'City', 'Suburb', 'Suburb'],\n    'Price': [300000, 350000, 400000, 250000, 450000]\n}\ndf = pd.DataFrame(data)\n```\n\nTo prepare this data for training a model, the `Location` column needs to be converted into numerical format using one-hot encoding. After that, you will split the dataset into features (X) and target (y).\n\nPlease fill in the missing code below to perform these preprocessing steps:\n\n```python\nfrom sklearn.model_selection import train_test_split\n\n# One-hot encode the 'Location' column\ndf_encoded = ...\n\n# Split the dataframe into features (X) and target (y)\nX = df_encoded.drop(columns=['Price'])\ny = df_encoded['Price']\n```\n\nThe resulting DataFrame `df_encoded` should include the encoded `Location` along with `Size` and `Bedrooms` columns, while `Price` should be excluded from the features. \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 1600, 1700, 1400, 1800],\n    'Bedrooms': [3, 3, 4, 2, 4],\n    'Location': ['Suburb', 'City', 'City', 'Suburb', 'Suburb'],\n    'Price': [300000, 350000, 400000, 250000, 450000]\n}\ndf = pd.DataFrame(data)\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf_encoded = pd.get_dummies(df, columns=['Location'], drop_first=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customers and their purchase amounts, structured as follows:\n\n| customer_id | purchase_date | amount |\n|-------------|---------------|--------|\n| c1          | 2023-01-05    | 150    |\n| c2          | 2023-01-05    | 300    |\n| c1          | 2023-01-06    | 200    |\n| c2          | 2023-01-07    | 350    |\n| c3          | 2023-01-05    | 450    |\n| c3          | 2023-01-08    | 150    |\n\nI want to calculate the total purchase amount for each customer over the entire period. The output should be a new DataFrame that includes the customer_ids and their corresponding total purchase amounts.\n\nHow can I achieve this in Python?\nI would like to use pandas for this operation and provide the code/solution with details on the Python version.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': ['c1', 'c2', 'c1', 'c2', 'c3', 'c3'],\n    'purchase_date': ['2023-01-05', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-05', '2023-01-08'],\n    'amount': [150, 300, 200, 350, 450, 150]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('customer_id')['amount'].sum().reset_index()\nresult.columns = ['customer_id', 'total_amount']\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing features related to houses, including their square footage, number of bedrooms, and prices. I want to train a regression model to predict house prices based on these features. First, I load the dataset using Pandas, then I scale the feature values to a range between 0 and 1 using MinMaxScaler from Scikit-learn. After scaling, I want to split the data into training and testing sets, where 80% of the data is for training. I need a single line of code that performs this splitting and assigns the results to variables `X_train`, `X_test`, `y_train`, and `y_test`.\n\nHere is a sample of the dataset and the necessary imports:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Sample data\ndata = {\n    'square_footage': [1500, 2000, 2500, 3000, 3500],\n    'num_bedrooms': [3, 4, 4, 5, 5],\n    'price': [300000, 400000, 500000, 600000, 700000]\n}\ndf = pd.DataFrame(data)\n\n# Scaling features\nscaler = MinMaxScaler()\nfeatures = df[['square_footage', 'num_bedrooms']]\nscaled_features = scaler.fit_transform(features)\n\n# Target variable\ntarget = df['price']\n```\n\nYou should add your solution below this line:\n\n```python\nX_train, X_test, y_train, y_test = ...  # put solution in this variable\n```",
    "output": "\n```python\nX_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n```"
  },
  {
    "input": "Problem:\nI have a dataset with information about houses represented as a Pandas DataFrame, which contains the following columns: 'Size' (in square feet), 'Bedrooms', 'Age' (in years), and 'Price' (in thousands). I want to standardize the 'Size' and 'Price' features using Scikit-learn's `StandardScaler` for further analysis and modeling. The DataFrame is as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 2000, 2500, 1800, 1600],\n    'Bedrooms': [3, 4, 5, 3, 2],\n    'Age': [10, 15, 8, 20, 5],\n    'Price': [300, 400, 500, 350, 320]\n}\ndf = pd.DataFrame(data)\n```\n\nI need to fill in the blank to standardize the 'Size' and 'Price' columns and store the results back in the DataFrame under the same column names.\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n# Fit and transform the 'Size' and 'Price' columns\ndf[['Size', 'Price']] = ...\n```",
    "output": "\n```python\ndf[['Size', 'Price']] = scaler.fit_transform(df[['Size', 'Price']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing observations of different fruits and their weights over multiple days. I would like to calculate the daily average weight of each fruit and visualize the results using a line plot. The dataset looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'fruit': ['apple', 'apple', 'banana', 'banana', 'banana', 'apple', 'orange', 'orange'],\n    'weight': [150, 160, 120, 130, 125, 170, 200, 210],\n    'date': ['2023-09-01', '2023-09-01', '2023-09-01', '2023-09-01', '2023-09-01', '2023-09-02', '2023-09-02', '2023-09-02']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the average weight for each fruit and store the result in a new DataFrame. Then, I want to plot this average weight for each fruit over the date. What code can I use to achieve this? \n\n### Output your answer into variable 'result'\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\naverage_weight = df.groupby(['date', 'fruit'])['weight'].mean().reset_index()\nimport matplotlib.pyplot as plt\n\nfor fruit in average_weight['fruit'].unique():\n    subset = average_weight[average_weight['fruit'] == fruit]\n    plt.plot(subset['date'], subset['weight'], label=fruit)\n\nplt.xlabel('Date')\nplt.ylabel('Average Weight')\nplt.title('Average Weight of Fruits Over Time')\nplt.legend()\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset of daily temperatures in a Pandas DataFrame, structured as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=7),\n    'temperature': [30, 32, 34, 31, 29, 33, 35]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate a rolling average of the temperature for a 3-day window and visualize the original temperature data alongside the rolling average. Your final output should include the original DataFrame with an additional column `rolling_avg` for the rolling average and a plot showing both the temperatures and the rolling average.\n\nThe resulting DataFrame should look like this:\n```\n        date  temperature  rolling_avg\n0 2023-01-01           30           NaN\n1 2023-01-02           32           NaN\n2 2023-01-03           34          32.0\n3 2023-01-04           31          32.0\n4 2023-01-05           29          31.0\n5 2023-01-06           33          31.0\n6 2023-01-07           35          32.0\n```\n\nThe plot should show the `temperature` on the primary y-axis and the `rolling_avg` on the secondary y-axis. \n\nA:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=7),\n    'temperature': [30, 32, 34, 31, 29, 33, 35]\n}\ndf = pd.DataFrame(data)\n```\ndf['rolling_avg'] = ... # put solution in this variable\nplt.plot(df['date'], df['temperature'], label='Temperature')\nplt.plot(df['date'], df['rolling_avg'], label='Rolling Average', linestyle='--')\nplt.legend()\nplt.show()\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various fruits, including their names, quantities sold, and prices. You need to analyze the dataset using Pandas and create a scatter plot visualizing the relationship between price and quantity sold. However, you want to include a regression line to represent the trend in the sales data visually. The dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    \"Fruit\": [\"Apple\", \"Banana\", \"Cherry\", \"Date\", \"Elderberry\"],\n    \"Quantity Sold\": [50, 200, 150, 80, 60],\n    \"Price per Unit\": [1.2, 0.5, 2.5, 3.0, 5.0]\n})\n```\n\nYour task is to generate the code that, after importing the necessary libraries (seaborn and matplotlib), fills in the blank to create the scatter plot with the regression line. Make sure to label the axes appropriately.\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Your code here\n...\nplt.title(\"Price vs Quantity Sold\")\nplt.xlabel(\"Price per Unit ($)\")\nplt.ylabel(\"Quantity Sold\")\nplt.show()\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = pd.DataFrame({\n    \"Fruit\": [\"Apple\", \"Banana\", \"Cherry\", \"Date\", \"Elderberry\"],\n    \"Quantity Sold\": [50, 200, 150, 80, 60],\n    \"Price per Unit\": [1.2, 0.5, 2.5, 3.0, 5.0]\n})\n\n# Your code here\nsns.regplot(x=\"Price per Unit\", y=\"Quantity Sold\", data=data)\n</code>",
    "output": "\n<code>\nsns.regplot(x=\"Price per Unit\", y=\"Quantity Sold\", data=data)\n</code>"
  },
  {
    "input": "Problem:\nYou're analyzing a dataset of movie ratings and want to determine the average rating per genre. The dataset is in the form of a Pandas DataFrame with two columns: \"genre\" (which may contain multiple genres separated by commas) and \"rating\". You need to compute the average rating for each unique genre, taking into account that a movie may belong to multiple genres. The expected output should be a DataFrame with two columns: \"genre\" and \"average_rating\".\n\nHere\u2019s a snippet of the DataFrame you have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'genre': ['Action,Adventure', 'Action', 'Drama', 'Adventure', 'Action,Drama', 'Comedy'],\n    'rating': [5, 6, 7, 8, 5, 9]\n}\ndf = pd.DataFrame(data)\n```\n\nTo transform this DataFrame, you need to fill in the blank with the correct code to produce the desired output. \n\nA:\n<code>\naverage_ratings = ... # put solution in this variable\n</code>",
    "output": "\n<code>\naverage_ratings = df.explode('genre').groupby('genre')['rating'].mean().reset_index(name='average_rating')\n</code>"
  },
  {
    "input": "Problem:\nContext\nI have a dataset that represents various products sold by a store, with their respective sales information. I want to perform some analysis on this data to predict future sales based on historical data.\n\nProblem\nSuppose I have the following Pandas DataFrame containing historical sales data for different products:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': [1, 2, 1, 2, 3, 1, 3, 2],\n    'Sales': [100, 150, 120, 130, 160, 190, 175, 200],\n    'Date': pd.to_datetime(['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02',\n                            '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-05'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to create a time series forecasting model using Facebook's Prophet library to predict sales for the next week. The 'Sales' column should be the target variable, while 'Date' should be the datetime index.\n\nYou've already imported Prophet like this:\n```python\nfrom prophet import Prophet\n```\n\nWhat I need is to prepare the DataFrame such that it has the columns 'ds' for dates and 'y' for sales, which is required by Prophet. Here's the provided code to start:\n\n```python\n# Renaming the columns to fit the Prophet requirement\nprophet_df = df[['Date', 'Sales']].rename(columns={'Date': 'ds', 'Sales': 'y'})\n```\n\nNow, please fill in the integer number of unique products in the `data` DataFrame, so that I can set the model to fit one model for each product based on the unique 'ProductID'.\n\nresult = ... # put your solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df['ProductID'].nunique()\n```"
  },
  {
    "input": "Problem:\n\nYou are analyzing a dataset containing information about different species of flowers. You want to build a neural network to classify flower species based on their sepal and petal dimensions. Once your model is trained, you would like to save it and later load it for predictions without retraining.\n\nHere is a simplified example of how you have defined your model using TensorFlow:\n\n```python\nimport tensorflow as tf\nfrom sklearn.datasets import load_iris\n\n# Load the iris dataset\ndata = load_iris()\nX, y = data.data, data.target\n\n# Define a simple neural network\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X, y, epochs=5)\n```\n\nNow, you want to save the trained model so that you can use it later to make predictions. \n\nPlease fill in the blank to save the model to the file named \"flower_model.h5\":\n\n```python\nmodel.____(filepath='flower_model.h5', save_format='h5')\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmodel.save(filepath='flower_model.h5', save_format='h5')\n```"
  },
  {
    "input": "Problem:\nYou have collected sales data from two different stores in a DataFrame, and you want to perform some analyses. The data is represented in two DataFrames: `store_a` and `store_b`. Each DataFrame contains sales figures and dates. Your goal is to merge these two DataFrames on the date column, filling any missing sales data with zero. After that, you want to plot the total sales from both stores over time using Matplotlib.\n\nThe DataFrames are as follows:\n\n```python\nimport pandas as pd\n\nstore_a = pd.DataFrame({\n    'date': ['2021-01-01', '2021-01-02', '2021-01-03'],\n    'sales': [150, 200, 250]\n})\n\nstore_b = pd.DataFrame({\n    'date': ['2021-01-02', '2021-01-03', '2021-01-04'],\n    'sales': [100, 300, 150]\n})\n```\n\nYou need to create a DataFrame `merged_sales` that contains the dates and the total sales from both stores, and then generate a plot titled \"Total Sales Over Time\".\n\nmerged_sales = ... # put solution in this variable\n\n### Plotting Code:\nplt.figure(figsize=(10, 5))\nplt.plot(merged_sales['date'], merged_sales['total_sales'], marker='o')\nplt.title('Total Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Total Sales')\nplt.xticks(rotation=45)\nplt.tight_layout() \nplt.show()",
    "output": "\n```python\nmerged_sales = pd.merge(store_a, store_b, on='date', how='outer', suffixes=('_a', '_b')).fillna(0)\nmerged_sales['total_sales'] = merged_sales['sales_a'] + merged_sales['sales_b']\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about used cars, including their price, mileage, year, and brand stored in a Pandas DataFrame called `cars_df`. I want to perform a linear regression analysis to predict car prices based on mileage. I've already split the dataset into features (X) and target (y) variables. After fitting the model, I want to plot the regression line along with the actual data points in a scatter plot. \n\nHere's the setup of my DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndata = {\n    'price': np.random.randint(5000, 30000, 100),\n    'mileage': np.random.randint(10000, 150000, 100),\n    'year': np.random.randint(2000, 2022, 100),\n    'brand': np.random.choice(['Ford', 'Chevrolet', 'Toyota'], 100)\n}\n\ncars_df = pd.DataFrame(data)\nX = cars_df[['mileage']]\ny = cars_df['price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\n\nNow, I need to plot the regression line using the training data and actual prices. What should I put in the blank to create the plot?\n\n```python\nplt.scatter(X_train, y_train, color='blue')\nplt.plot(X_train, model.predict(X_train), color='red')\nplt.title('Regression Line on Training Data')\nplt.xlabel('Mileage')\nplt.ylabel('Price')\nplt.show()\n```\n\nThe code below is where I will be implementing the rest. \n\n```python\nplt.scatter(X_train, y_train, color='blue')\nplt.plot(X_train, model.predict(X_train), color='red')\n...\n``` \n\nA:\n<code>\n...\n</code>",
    "output": "\n<code>\nplt.title('Regression Line on Training Data')\nplt.xlabel('Mileage')\nplt.ylabel('Price')\nplt.show()\n</code>"
  },
  {
    "input": "## Problem:\nYou are working with a dataset containing customer purchase records in a Pandas DataFrame. Each record has a customer ID and a list of items they purchased. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    \"customer_id\": [1, 2, 1, 3, 2],\n    \"items\": [\n        [\"apple\", \"banana\"],\n        [\"orange\", \"banana\", \"grape\"],\n        [\"banana\", \"kiwi\"],\n        [\"apple\"],\n        [\"grape\"]\n    ]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to create a new DataFrame that represents each item as a separate column, and for each customer ID, indicate whether they purchased that item (1 for yes, 0 for no). The final DataFrame should look like this:\n\n```\ncustomer_id  apple  banana  orange  grape  kiwi\n1            1      1      0      0      1\n2            0      1      1      1      0\n3            1      0      0      0      0\n```\n\nWhat is the Pandas code that will transform the original DataFrame into this desired format?\n\nA:\n```python\nnew_df = ... # put solution in this variable\n```",
    "output": "\n```python\nnew_df = df.explode('items').groupby('customer_id')['items'].apply(lambda x: x.unique()).reset_index()\nnew_df = new_df.set_index('customer_id').reindex(df['customer_id'].unique()).fillna(0).astype(int)\nnew_df = new_df.join(pd.get_dummies(df.explode('items')['items']).groupby(df['customer_id']).sum()).fillna(0).astype(int)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various fruits and their characteristics, including weight, sweetness level, and price per pound, organized in a pandas DataFrame. You want to build a machine learning model using TensorFlow to predict the price of the fruits based on their weight and sweetness level.\n\nHere is your DataFrame:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'weight': [0.5, 0.75, 1.0, 1.25, 1.5],\n    'sweetness': [7, 8, 9, 6, 5],\n    'price_per_pound': [3.5, 4.5, 5.0, 4.0, 3.75]\n})\n```\n\nWrite a function `build_model` that creates a simple Neural Network model with TensorFlow to predict `price_per_pound` using `weight` and `sweetness` as inputs. The function should return a compiled model.\n\nThe model architecture can be:\n- An input layer with 2 neurons (for weight and sweetness)\n- One hidden layer with 5 neurons and ReLU activation\n- An output layer with 1 neuron (for price)\n\nThe return statement should position the model in the variable `model`.\n\n```python\nimport tensorflow as tf\n\ndef build_model():\n    model = ...  # put solution in this variable\n    return model\n```",
    "output": "\n```python\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(2,)),\n        tf.keras.layers.Dense(5, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    model.compile(optimizer='adam', loss='mean_squared_error')\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing historical stock prices, and I want to calculate the 30-day rolling average closing price of a stock using Pandas. Additionally, I want to visualize this rolling average compared to the actual closing prices using Matplotlib.\n\nThe DataFrame looks like this (assuming it has been loaded into a variable named `df`):\n\n```\n             Date    Close\n0  2020-01-01   100.00\n1  2020-01-02   101.50\n2  2020-01-03   102.00\n...\n29 2020-01-30   110.00\n30 2020-01-31   111.50\n...\n```\n\nI want to create a new column in `df` for the rolling average and then plot both the actual closing prices and the 30-day rolling average on a line chart.\n\nHere's the setup:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2020-01-01', periods=100, freq='D'),\n    'Close': ...\n})\n\n# Ensure 'Date' is the index\ndf.set_index('Date', inplace=True)\n```\n\nThe code to calculate the rolling average should be placed in the variable `rolling_avg`:\n\n```python\nrolling_avg = ... # put solution in this variable\n```\n\nAfter calculating the rolling average, I want to execute the following code to plot them together:\n\n```python\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['Close'], label='Close Price')\nplt.plot(df.index, rolling_avg, label='30-Day Rolling Average', color='orange')\nplt.title('Stock Prices and 30-Day Rolling Average')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n```\nComplete the code by filling in the blank for `rolling_avg`.",
    "output": "\n```python\nrolling_avg = df['Close'].rolling(window=30).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing user reviews for a product. Each review has been scored from 1 to 5 and your task is to analyze the distribution of the scores using NumPy, visualize it with Matplotlib, and then produce a histogram to show the frequency of each score. The dataset is as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Review': ['Great product!', 'Not worth the money', 'Satisfactory', 'I love it', 'It broke after a week', \n               'Could be better', 'Fantastic!', 'Terrible', 'Just okay', 'Would buy again'],\n    'Score': [5, 2, 3, 5, 1, 3, 5, 1, 3, 4]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, you want to compute the mean score and create a histogram of the scores. Please complete this line of code to achieve that:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nmean_score = ...  # Calculate the mean score using NumPy\nplt.hist(df['Score'], bins=np.arange(1, 7) - 0.5, edgecolor='black')  # Create a histogram\nplt.xticks(np.arange(1, 6))  # Set the ticks for the x-axis\nplt.xlabel('Scores')\nplt.ylabel('Frequency')\nplt.title('Distribution of Product Scores')\nplt.show()\n```\n\nresult = ... # put solution in this variable",
    "output": "\n```python\nmean_score = np.mean(df['Score'])  # Calculate the mean score using NumPy\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about students' exam scores across multiple subjects. The dataset is structured as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n        'Math': [85, 90, 78, 88, 92],\n        'Science': [80, 85, 88, 90, 94],\n        'English': [78, 82, 91, 86, 85]}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average score for each student across all subjects and create a new column in the DataFrame to store these average scores. The output should be a DataFrame that looks like this:\n\n```\n    Student  Math  Science  English  Average\n0     Alice    85       80       78     ...\n1       Bob    90       85       82     ...\n2   Charlie    78       88       91     ...\n3     David    88       90       86     ...\n4       Eva    92       94       85     ...\n```\n\nTo calculate the average scores along the proper axis, you can use the appropriate Pandas method. \n\nA:\n```python\ndf['Average'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['Average'] = df[['Math', 'Science', 'English']].mean(axis=1)\n```"
  },
  {
    "input": "Problem:\nI am working on a natural language processing task and have created a dataset containing sentences. I would like to convert these sentences into numerical representations using a pre-trained TensorFlow embedding model. Specifically, the goal is to obtain the embeddings for each sentence and then compute the cosine similarity between the first and second sentence embeddings. \n\nHere\u2019s how my dataset looks:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'sentences': [\n        \"I love programming in Python\",\n        \"Python is my favorite language\"\n    ]\n})\n```\n\nI have already loaded a pre-trained embedding model from TensorFlow. In order to compute the cosine similarity between the first and second sentence, I need to fill in the blank in the following code:\n\n```python\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load your pre-trained embedding model here\nmodel = load_model('path/to/your/embedding/model')\n\n# Assume the function 'get_embeddings' retrieves embeddings from the model\nembeddings = get_embeddings(data['sentences'].tolist())\n\n# Compute cosine similarity\ncosine_sim = cosine_similarity(embeddings[0:1], embeddings[1:2])\n```\n\nThe placeholder for embedding computation is represented by `get_embeddings`. How can I implement the `get_embeddings` function to correctly convert the sentences into their corresponding embeddings using the loaded model?\n\nA:\n<code>\ndef get_embeddings(sentences):\n    # process sentences and return their embeddings\n    embeddings = ... # put solution in this variable\n    return embeddings\n</code>",
    "output": "\n<code>\ndef get_embeddings(sentences):\n    # Tokenize and pad the sentences\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(sentences)\n    sequences = tokenizer.texts_to_sequences(sentences)\n    padded_sequences = pad_sequences(sequences)\n\n    # Get embeddings from the model\n    embeddings = model.predict(padded_sequences)\n    return embeddings\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing sales data for a retail store represented as a Pandas DataFrame. Each row in the DataFrame corresponds to a sale and contains the following columns: 'item', 'quantity', 'price', and 'date' (the date of the sale). You want to calculate the total revenue generated from each item, grouped by month.\n\nConsider the following sample DataFrame:\n\n```python\nimport pandas as pd\nfrom datetime import datetime\n\ndata = {\n    'item': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C'],\n    'quantity': [1, 2, 3, 1, 1, 2, 1, 4],\n    'price': [10, 20, 10, 15, 20, 10, 15, 15],\n    'date': [\n        datetime(2023, 1, 15),\n        datetime(2023, 1, 20),\n        datetime(2023, 2, 5),\n        datetime(2023, 2, 12),\n        datetime(2023, 2, 18),\n        datetime(2023, 3, 10),\n        datetime(2023, 3, 20),\n        datetime(2023, 3, 25)\n    ]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour task is to fill in the blank below to compute the total revenue generated from each item grouped by month. The expected result is a new DataFrame that shows the item, month, and total revenue.\n\n```python\ndf['revenue'] = df['quantity'] * df['price']\nresult = df.groupby([df['item'], df['date'].dt.to_period('M')])['revenue'].sum().reset_index(name='total_revenue')\n```\n\nFill in the code below to get the `result` DataFrame as described:\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.groupby(['item', df['date'].dt.to_period('M')])['revenue'].sum().reset_index(name='total_revenue')\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing the sales figures for different products over time, stored in a pandas DataFrame with the following structure:\n\n```\n   Product   Date      Sales\n0  A        2023-01-01  150\n1  A        2023-01-02  200\n2  A        2023-01-03  180\n3  B        2023-01-01  90\n4  B        2023-01-02  120\n5  B        2023-01-03  160\n```\n\nI want to calculate the moving average of sales for each product over a window of 2 days, then plot the results using Matplotlib. The final output DataFrame should retain all original columns and include a new column 'Moving_Avg' for the moving average.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'Product': ['A', 'A', 'A', 'B', 'B', 'B'],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', \n                            '2023-01-01', '2023-01-02', '2023-01-03']),\n    'Sales': [150, 200, 180, 90, 120, 160]\n})\n\ndf['Moving_Avg'] = ...  # put solution in this variable\n\n# Plotting\nfor product in df['Product'].unique():\n    plt.plot(df[df['Product'] == product]['Date'], \n             df[df['Product'] == product]['Moving_Avg'], label=product)\nplt.legend()\nplt.title('Moving Average Sales')\nplt.xlabel('Date')\nplt.ylabel('Moving Average Sales')\nplt.show()\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['Moving_Avg'] = df.groupby('Product')['Sales'].transform(lambda x: x.rolling(window=2).mean())\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset and apply PCA to reduce it to 2 dimensions\niris = load_iris()\ndata = pd.DataFrame(data=iris.data, columns=iris.feature_names)\npca = PCA(n_components=2)\ntransformed_data = pca.fit_transform(data)\n\n# Now, I want to visualize the two principal components with a scatter plot.\n# The desired output is to plot the transformed data with matplotlib while coloring points by their iris species.\n# The variable 'species' should hold the species labels (0, 1, 2), mapped from the iris target.\n\nspecies = iris.target\nplt.scatter(..., ...)  # put solution in this line to plot the data\n```",
    "output": "\n```python\nplt.scatter(transformed_data[:, 0], transformed_data[:, 1], c=species, cmap='viridis')\n```"
  }
]