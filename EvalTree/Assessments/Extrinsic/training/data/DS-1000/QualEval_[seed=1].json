[
  {
    "input": "Problem:\n\nIn a time series forecasting project using TensorFlow, you have a dataset containing daily temperatures over a year, represented as a 365 x 1 tensor. You are tasked with building a simple LSTM model to predict the next day's temperature based on the previous five days' temperatures. After preparing your dataset, you pass the data through the LSTM layers and obtain output predictions stored in a tensor of shape [num_samples, 1]. \n\nNow, you want to compute the root mean square error (RMSE) of your predictions compared to the actual temperatures which are stored in a tensor of the same shape. The formula for RMSE is:\n\n\\[ \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2} \\]\n\nWhere \\( y_i \\) are the actual values and \\( \\hat{y_i} \\) are the predicted values. \n\nYou have already defined your predictions and actual values like this:\n\n```python\nimport tensorflow as tf\n\npredictions = tf.constant([...], shape=(365, 1))\nactuals = tf.constant([...], shape=(365, 1))\n```\n\nWhat code can be used to compute the RMSE and store the result in a variable named `rmse`?\n\nA:\n```python\nrmse = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nrmse = tf.sqrt(tf.reduce_mean(tf.square(actuals - predictions)))\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily sales data for different products over a period of time. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [10, 15, 5, 20, 25]\n})\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI need a way to resample this data to get the total weekly sales for each product, filling in missing days with zeros for sales, and using the sum of sales for the product within that week. The expected output for the week starting from 2023-01-01 should look like this:\n\n```\n        date product  sales\n0 2023-01-01       A     10\n1 2023-01-01       B      0\n2 2023-01-08       A     35\n3 2023-01-08       B     25\n```\n\nPlease fill in the missing code in the following statement to achieve this output:\n\n```python\nweekly_sales = df.resample('W-Mon', on='date').______\n```\n",
    "output": "\n```python\nweekly_sales = df.resample('W-Mon', on='date').apply(lambda x: x.groupby('product')['sales'].sum()).reset_index().fillna(0)\n```"
  },
  {
    "input": "Problem:\nYou have a dataframe representing sales data, shown below:\n\n```python\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\n\nYou want to create a new column called `total_sales`, which is calculated as `quantity * price`. However, if the total sales for any row is less than 50, you want to set it to 0. Your goal is to implement a custom function to achieve this. \n\nWhat should you write to obtain the modified dataframe with the new column?\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n```python\ndef calculate_total_sales(row):\n    total = row['quantity'] * row['price']\n    return total if total >= 50 else 0\n\ndf['total_sales'] = df.apply(calculate_total_sales, axis=1)\n```",
    "output": "\n```python\ndf['total_sales'] = df.apply(lambda row: max(row['quantity'] * row['price'], 0) if row['quantity'] * row['price'] >= 50 else 0, axis=1)\n```"
  },
  {
    "input": "Problem:\nI have a dataframe that contains a column of addresses in the following format:\n```plaintext\naddress\n0  1234 Elm Street, Springfield, IL 62704\n1  5678 Oak Avenue; Townsville; NY 12345\n2  9101 Maple Blvd - Metropolis - CA 90210\n```\nI want to extract the city and state from each address and create a new dataframe with just these two columns. The desired output should look like this:\n```plaintext\ncity        state\n0 Springfield  IL\n1 Townsville   NY\n2 Metropolis   CA\n```\nI tried using `df['address'].apply()` to apply regex for extraction but I'm not getting the desired results. How can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'address': ['1234 Elm Street, Springfield, IL 62704', \n                               '5678 Oak Avenue; Townsville; NY 12345', \n                               '9101 Maple Blvd - Metropolis - CA 90210']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['address'].str.extract(r'(?P<city>[\\w\\s]+)[,; -]+(?P<state>[A-Z]{2})')\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of employees in a company represented as a Pandas dataframe with their details as shown below:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [101, 102, 103, 104, 105],\n    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'salary': [70000, 80000, 60000, 75000, 85000],\n    'department': ['HR', 'Engineering', 'HR', 'Marketing', 'Engineering']\n})\n```\n\nYou need to create a function called `average_salary_by_department` that takes this dataframe as an input and returns a new dataframe showing the average salary for each department. The resulting dataframe should have two columns: `department` and `average_salary`.\n\nFor example, the output should look like this:\n\n```\n    department  average_salary\n0  Engineering         82500.0\n1             HR         65000.0\n2      Marketing         75000.0\n```\n\nPlease fill in the code below to complete your solution.\n\n```python\nresult = ...\ndef average_salary_by_department(df):\n    ...\n```",
    "output": "\n```python\nresult = df.groupby('department')['salary'].mean().reset_index(name='average_salary')\ndef average_salary_by_department(df):\n    return result\n```"
  },
  {
    "input": "Problem:\nI have a collection of images represented as a 3D tensor in PyTorch, where the shape of the tensor is (number_of_images, height, width). However, the images have been padded with zeros to make them the same size, which I now want to compress into a sparse representation. The images tensor looks like this:\n\n```\ntensor([\n    [[0, 0, 0], [1, 2, 3], [0, 0, 0]],\n    [[4, 5, 0], [0, 0, 0], [0, 0, 0]],\n    [[0, 0, 0], [6, 7, 8], [0, 0, 0]]\n])\n```\n\nI want to create a sparse tensor from this 3D tensor that retains the non-zero values. How would I generate this sparse tensor using PyTorch?\n\nA:\n<code>\nimport torch\n\nimages = torch.tensor([\n    [[0, 0, 0], [1, 2, 3], [0, 0, 0]],\n    [[4, 5, 0], [0, 0, 0], [0, 0, 0]],\n    [[0, 0, 0], [6, 7, 8], [0, 0, 0]]\n])\n</code>\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsparse_tensor = images.to_sparse()\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a large dataset represented as a sparse tensor in PyTorch, which I need to convert to a dense tensor format in order to perform certain calculations. My sparse tensor has a shape of (5, 5, 5) with a few non-zero entries. I want to transform this sparse tensor into a dense tensor format while ensuring that it maintains the same data values and locations for the non-zero elements.\n\nHere is how my sparse tensor looks:\n\n```python\nimport torch\n\nsparse_tensor = torch.zeros((5, 5, 5))\nsparse_tensor[0, 1, 2] = 3.5\nsparse_tensor[2, 3, 4] = 2.0\nsparse_tensor[4, 0, 1] = 1.0\n```\n\nWhat is the correct way to convert this sparse tensor into a dense tensor format?\n\nA:\n```python\nimport torch\nimport sparse\n\nsparse_tensor = sparse.COO(indices=[[0, 2, 4], [1, 3, 0], [2, 4, 1]], values=[3.5, 2.0, 1.0], shape=(5, 5, 5))\n```\ndense_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndense_tensor = sparse_tensor.to_dense()\n```"
  },
  {
    "input": "Problem:\nSuppose you have a sparse tensor representing a 3D data structure for image features, stored in a PyTorch SparseTensor. The tensor is of size (5, 5, 5), with a few non-zero entries. You want to create a dense representation of this sparse tensor, but only for a specific slice along the first dimension (batch). You need the slice for the first two batches (i.e., `tensor[0:2, :, :]`).\n\nA:\n<code>\nimport torch\nindices = torch.tensor([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\nvalues = torch.tensor([10.0, 20.0, 30.0])\nsize = (5, 5, 5)\nsparse_tensor = torch.sparse_coo_tensor(indices.t(), values, size)\n</code>\ndense_slice = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_slice = sparse_tensor.to_dense()[0:2, :, :]"
  },
  {
    "input": "Problem:\nI have been working with a sparse tensor in PyTorch that represents a 3D grid of data, where most of the values are zero. The tensor has a shape of (20, 30, 40), and I need to perform an operation to sum the non-zero elements across the first dimension (axis 0) while retaining the sparse structure. Additionally, I need to normalize the summed tensor by dividing by the number of non-zero elements along the first dimension, effectively creating an average for each (x, y) location in the grid. \n\nHere's how my sparse tensor looks:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 5, 8, 10], [1, 2, 3, 4], [5, 6, 7, 8]]),\n    values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n    size=(20, 30, 40)\n)\n```\n\nHow would I compute the normalized average tensor, ensuring the result remains sparse? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nnon_zero_count = sparse_tensor.coalesce().values().new_zeros(sparse_tensor.size()[1:])\nfor i in range(sparse_tensor.size(0)):\n    non_zero_count += (sparse_tensor[i].coalesce().values() != 0).sum(dim=0)\n\nsummed_tensor = sparse_tensor.sum(dim=0)\nnormalized_tensor = summed_tensor / non_zero_count.unsqueeze(0)\nresult = normalized_tensor.to_sparse()\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset that I want to prepare for training a model using TensorFlow. The dataset consists of a 2D tensor where each row represents a sample and each column corresponds to a feature. I need to standardize this tensor (subtract the mean and divide by the standard deviation) feature-wise. Given a TensorFlow tensor `data` with shape (100, 20), how can I perform this operation?\n\nA:\n<code>\nimport tensorflow as tf\nimport numpy as np\n\n# Create a sample data tensor\ndata = tf.constant(np.random.rand(100, 20), dtype=tf.float32)\n</code>\nstandardized_data = ... # put solution in this variable",
    "output": "\n<code>\nmean = tf.reduce_mean(data, axis=0)\nstddev = tf.math.reduce_std(data, axis=0)\nstandardized_data = (data - mean) / stddev\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for various products over several months:\n\n| product_id | month      | sales |\n|------------|------------|-------|\n| 1          | 2023-01   | 100   |\n| 1          | 2023-02   | 150   |\n| 1          | 2023-03   | 120   |\n| 2          | 2023-01   | 200   |\n| 2          | 2023-03   | 250   |\n| 3          | 2023-02   | 300   |\n| 3          | 2023-03   | 200   |\n\nI want to create a custom function that takes this DataFrame and generates a new DataFrame that shows the average monthly sales for each product. The resulting DataFrame should look like this:\n\n| product_id | average_sales |\n|------------|---------------|\n| 1          | 123.33        |\n| 2          | 225.00        |\n| 3          | 250.00        |\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 1, 2, 2, 3, 3],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-03', '2023-02', '2023-03'],\n    'sales': [100, 150, 120, 200, 250, 300, 200]\n}\ndf = pd.DataFrame(data)\n\ndef calculate_average_sales(df):\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    average_sales = df.groupby('product_id')['sales'].mean().reset_index()\n    average_sales.columns = ['product_id', 'average_sales']\n    return average_sales\n\nresult = calculate_average_sales(df)\n</code>"
  },
  {
    "input": "## Problem:\n\nSuppose you are working with a sparse tensor representing user interactions on a website, where each slice of the tensor represents a different month. Your tensor `user_interactions` is in the form of a 3D sparse tensor with dimensions `[num_users, num_pages, num_months]`. There are many users and pages, but most interactions are zero, making it sparse.\n\nYou need to calculate the total number of interactions for each user across all months and return it as a 2D dense array with the shape `[num_users, 1]`.\n\nYou can use the `torch.sparse` functionality to handle the sparse tensor. \n\nHere's a snippet where `user_interactions` is defined as a sparse tensor. How can you compute the total interactions for each user and store the result in a variable named `total_interactions`?\n\n```python\nimport torch\n\n# Create a sparse tensor representing user interactions\nuser_interactions = torch.sparse.FloatTensor(\n    torch.LongTensor([[0, 1, 2], [0, 1, 2]]),  # Indices for non-zero interactions\n    torch.FloatTensor([5, 10, 3]),             # Corresponding interaction values\n    torch.Size([3, 4, 2])                       # Shape: 3 users, 4 pages, 2 months\n)\n\n# Total interactions initialization\ntotal_interactions = ... # put solution in this variable\n```",
    "output": "\n```python\ntotal_interactions = user_interactions.sum(dim=(1, 2)).to_dense().view(-1, 1)\n```"
  },
  {
    "input": "## Problem\nI need to analyze customer transaction data from a CSV file that contains columns: `customer_id`, `transaction_date`, and `amount`. I want to compute the total spending of each customer per month and return a DataFrame that shows `customer_id`, `month`, and `total_spending`. \n\nI started by grouping the DataFrame but I'm struggling to implement a custom function to calculate this total on a month-to-month basis. \n\nHere's an example of how my DataFrame looks:\n\n```\n   customer_id transaction_date  amount\n0           1      2023-01-15     100\n1           1      2023-01-20     50\n2           2      2023-01-25     200\n3           1      2023-02-01     150\n4           2      2023-02-15     300\n```\n\nIn order to do this, I need to define a function that computes the monthly spending and apply it to the DataFrame. \n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 1, 2],\n    'transaction_date': ['2023-01-15', '2023-01-20', '2023-01-25', '2023-02-01', '2023-02-15'],\n    'amount': [100, 50, 200, 150, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')\nresult = df.groupby(['customer_id', 'month'])['amount'].sum().reset_index(name='total_spending')\n</code>"
  },
  {
    "input": "Problem:\nI am working with a sparse matrix in the context of a recommendation system. I have a sparse matrix representing user interactions with items, where the rows correspond to users and the columns correspond to items. The matrix is represented in Compressed Sparse Row (CSR) format. I wish to efficiently extract the indices of the non-zero elements from a specific user's interactions.\n\nFor example, if the sparse matrix looks like:\n```\nfrom scipy import sparse\ndata = sparse.csr_matrix([[0, 1, 0], [0, 0, 2], [1, 0, 0]])\n```\nI want to extract the item indices for user 2 (zero-based index), which has interactions.\n\nHow do I achieve that?\n\nA:\n<code>\nfrom scipy import sparse\ninteraction_matrix = sparse.csr_matrix([[0, 1, 0], [0, 0, 2], [1, 0, 0]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = interaction_matrix[1].nonzero()[1]\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a sparse tensor representing a multi-dimensional dataset where I need to efficiently compute the sum of elements along a specific axis while maintaining the sparsity of the tensor. \n\nGiven a sparse tensor with non-zero elements defined in a dictionary format where keys are tuples representing the indices of the non-zero elements and values are the corresponding non-zero values, I want to compute the summed values along a specified axis.\n\nFor example, if my sparse tensor is represented as follows for a 3D tensor:\n\n```python\nsparse_tensor = {\n    (0, 0, 0): 1,\n    (0, 1, 2): 3,\n    (1, 0, 0): 2\n}\n```\n\nAnd I want to sum it along axis 0, the output should be a new tensor represented as a dictionary with the summed values for the remaining axes:\n\n```python\n{\n    (0, 0, 0): 3,  # 1 from (0,0,0) + 2 from (1,0,0)\n    (0, 1, 2): 3   # 3 from (0,1,2), no contribution from (1,1,2)\n}\n```\n\nWrite a function that receives the sparse tensor and the axis along which to sum and returns the resulting sparse tensor as a dictionary. The function header is as follows:\n\n```python\ndef sum_sparse_tensor(sparse_tensor, axis):\n    # Your code goes here\n    ...\n```\n\nMake sure to handle cases where the specified axis might not have dimensions to sum over correctly.\n\nA:\n\n<code>\nsparse_tensor = {(0, 0, 0): 1, (0, 1, 2): 3, (1, 0, 0): 2}\naxis = 0\n\ndef sum_sparse_tensor(sparse_tensor, axis):\n    # Your code goes here\n    ...\n</code>",
    "output": "\n<code>\ndef sum_sparse_tensor(sparse_tensor, axis):\n    result = {}\n    for indices, value in sparse_tensor.items():\n        new_indices = list(indices)\n        new_indices.pop(axis)\n        new_indices = tuple(new_indices)\n        if new_indices in result:\n            result[new_indices] += value\n        else:\n            result[new_indices] = value\n    return result\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset represented as a pandas DataFrame that contains the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A'],\n    'Value': [10, 20, 15, 30, 25, 5, 10]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average Value for each Category and then create a new column in the DataFrame that shows how much each Value deviates from its Category's average. This deviation should be positive if the Value is greater than the average and negative if it is less than the average.\n\nYour expected output DataFrame should look like this:\n\n```python\n  Category  Value  Deviation\n0        A     10        -5.0\n1        B     20         0.0\n2        A     15         0.0\n3        C     30         10.0\n4        B     25         5.0\n5        C      5        -5.0\n6        A     10        -5.0\n```\n\nFill in the blank to accomplish this task:\n\n```python\ncategory_avg = df.groupby('Category')['Value'].mean()\ndf['Deviation'] = df['Value'] - _________\n```",
    "output": "\n```python\ncategory_avg[df['Category']].values\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse tensor in PyTorch that represents a 3D grid of size (10, 10, 10), where most of the elements are zeros. You need to extract the non-zero elements from this sparse tensor and their corresponding indices in a sparse format. \n\nHere is how you have initialized the sparse tensor:\n\n<code>\nimport torch\n\n# Create a sparse tensor with random non-zero elements\nindices = torch.tensor([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\nvalues = torch.tensor([5.0, 3.0, 1.0, 4.0, 2.0])\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size=(10, 10, 10))\n</code>\n\nUsing this sparse tensor, fill in the blank for the code that extracts the non-zero values and their indices:\n\nA:\n\n<code>\nnon_zero_values, non_zero_indices = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnon_zero_values = sparse_tensor.values()\nnon_zero_indices = sparse_tensor.indices()\n</code>"
  },
  {
    "input": "Problem:\nI have a data frame containing a single column with mixed strings and I want to extract the numeric part and the alphabetical part into two new columns called 'number' and 'text'. The data frame looks like this:\n\n```\nmixed_data\n0  123abc\n1  45xyz\n2  789pqr\n3  1123\n4  abc456\n```\n\nI want to extract the numbers and text and fill the new columns accordingly. I know I can use `df['new_col'] = df['mixed_data'].str.extract(...)`, but I'm unsure how to properly use regex to achieve this.\n\nfilling the data frame should look like this:\n\n```\nmixed_data   number  text\n0  123abc        123    abc\n1  45xyz         45     xyz\n2  789pqr        789     pqr\n3  1123          1123   NaN\n4  abc456        456     abc\n```\n\nHow can I accomplish this? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'mixed_data': ['123abc', '45xyz', '789pqr', '1123', 'abc456']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['number', 'text']] = df['mixed_data'].str.extract(r'(\\d+)([a-zA-Z]*)')"
  },
  {
    "input": "Problem:\n\nI am working on a voice recognition project using PyTorch. I have a training dataset where each input sample is a spectrogram tensor of shape (50, 30), representing frequencies over time, and the corresponding labels are in a tensor of shape (50,) containing class indices. I want to transform these spectrograms to eliminate any silence regions so that the output tensor retains only the relevant frequencies that have non-zero values, while preserving the original shape's aspect ratio. The silence regions are represented by zeros. \n\nHere's how I have my tensors set up:\n\nspectrograms: shape (50, 30)\nlabels: shape (50,)\n\nI want to perform this operation using a masking technique that results in a tensor that retains only the non-zero entries while keeping them structured as a 2D tensor.\n\nFill in the code below to accomplish this task:\n\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = ...\n</code>\n",
    "output": "\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = spectrograms[mask].view(-1, spectrograms.size(1))\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of sales transactions in a DataFrame format with columns including 'Transaction_ID', 'Date', 'Product', 'Quantity', and 'Total_Sale'. Here's a sample of your data:\n\n```\n   Transaction_ID       Date     Product  Quantity  Total_Sale\n0               1 2023-01-01    Apples        5        15.0\n1               2 2023-01-01   Oranges        3        6.0\n2               3 2023-01-02    Apples        2         6.0\n3               4 2023-01-02   Bananas        1         1.0\n4               5 2023-01-03   Oranges        4        12.0\n```\n\nYou would like to create a custom function that takes a DataFrame as input and a product name as a string. The function should output a DataFrame containing only the rows where the specified product was sold, along with a new column that calculates the sales amount (`Total_Sale / Quantity`) for each transaction.\n\nHere\u2019s the DataFrame you created:\n\n```\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Transaction_ID': [1, 2, 3, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\n    'Product': ['Apples', 'Oranges', 'Apples', 'Bananas', 'Oranges'],\n    'Quantity': [5, 3, 2, 1, 4],\n    'Total_Sale': [15.0, 6.0, 6.0, 1.0, 12.0]\n})\n```\n\nYou need to define your function as follows:\n```python\ndef filter_sales_by_product(df, product_name):\n    # Your code here\n```\n\ndf_filtered = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef filter_sales_by_product(df, product_name):\n    filtered_df = df[df['Product'] == product_name].copy()\n    filtered_df['Sales_Amount'] = filtered_df['Total_Sale'] / filtered_df['Quantity']\n    return filtered_df\n\ndf_filtered = filter_sales_by_product(df, 'Apples')\n```"
  },
  {
    "input": "Problem:\nYou have a dataframe containing timestamps in a string format, which includes both the date and time. The format looks like this: \"2023-10-15 14:25:00\" or \"2023/10/15 14:25:00\". You need to split this column into two new columns: one for the date and another for the time.\n\nGiven the following dataframe:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'timestamp': ['2023-10-15 14:25:00', '2023/10/16 15:30:00', '2023-10-17 16:45:00']})\n```\n\nYou want to create a new dataframe that looks like this:\n```\n       date      time\n0  2023-10-15  14:25:00\n1  2023-10-16  15:30:00\n2  2023-10-17  16:45:00\n```\n\nI started with this code but it doesn't work properly:\n```python\ndf['date'], df['time'] = df['timestamp'].str.split(' ', expand=True)\n```\n\nWhat can I do to make it work? \n\nA:\n<code>\ndf = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf[['date', 'time']] = df['timestamp'].str.replace('/', '-').str.split(' ', expand=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for different products across several months. I would like to create a custom function that computes the total sales for each product over a specified range of months. The DataFrame looks like this:\n\n```\n   Month  Product_A  Product_B  Product_C\n0      1         200        150        300\n1      2         250        200        350\n2      3         300        250        400\n3      4         350        300        450\n4      5         400        350        500\n```\n\nThe function should take the month range as input (e.g., from month 2 to month 4) and return the total sales for each product in that range. I want to call this function that I will define as `calculate_total_sales(df, start_month, end_month)`. Here\u2019s how you can initialize the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': [1, 2, 3, 4, 5],\n    'Product_A': [200, 250, 300, 350, 400],\n    'Product_B': [150, 200, 250, 300, 350],\n    'Product_C': [300, 350, 400, 450, 500]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, write the function call to compute the total sales from month 2 to month 4:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df, start_month, end_month):\n    filtered_df = df[(df['Month'] >= start_month) & (df['Month'] <= end_month)]\n    total_sales = filtered_df[['Product_A', 'Product_B', 'Product_C']].sum()\n    return total_sales\n\nresult = calculate_total_sales(df, 2, 4)\n```"
  },
  {
    "input": "Problem:\nI have a list of numerical values representing daily sales data over a period of time, and I want to create a custom function to categorize each sales figure into specific revenue brackets. \n\nThe categories should be as follows:\n- \"Low\" for values less than 500\n- \"Medium\" for values between 500 and 1500\n- \"High\" for values greater than 1500\n\nI would like to create a function called `categorize_sales` that takes a list of sales figures as input and returns a new list with the appropriate categorizations for each sales figure.\n\nHere's a sample of my sales data:\nsales_data = [450, 780, 1250, 3000, 600, 150, 1800]\n\nI would like to achieve the following output:\n['Low', 'Medium', 'Medium', 'High', 'Low', 'Low', 'High']\n\nA:\n<code>\nsales_data = [450, 780, 1250, 3000, 600, 150, 1800]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef categorize_sales(sales):\n    categories = []\n    for sale in sales:\n        if sale < 500:\n            categories.append(\"Low\")\n        elif 500 <= sale <= 1500:\n            categories.append(\"Medium\")\n        else:\n            categories.append(\"High\")\n    return categories\n\nresult = categorize_sales(sales_data)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset of sales records, structured as follows:\n\n   OrderID   CustomerID   Product   Quantity   Price\n0      101         C001     WidgetA        2     10.00\n1      102         C002     WidgetB        1     20.00\n2      103         C001     WidgetA        3     10.00\n3      104         C003     WidgetC        5     15.00\n4      105         C002     WidgetB        2     20.00\n\nI want to create a new column that calculates the total price for each order, which is derived by multiplying the 'Quantity' and 'Price' columns for each row. I'm trying to use a custom function for this task.\n\nWhat I started with:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'OrderID': [101, 102, 103, 104, 105],\n    'CustomerID': ['C001', 'C002', 'C001', 'C003', 'C002'],\n    'Product': ['WidgetA', 'WidgetB', 'WidgetA', 'WidgetC', 'WidgetB'],\n    'Quantity': [2, 1, 3, 5, 2],\n    'Price': [10.00, 20.00, 10.00, 15.00, 20.00]\n})\n```\nNow, I want to calculate the total price and store it in the 'TotalPrice' column:\n\ntotal_price_function = ... # put your function here\ndf['TotalPrice'] = df.apply(total_price_function, axis=1) # put solution in the 'TotalPrice' column\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ntotal_price_function = lambda row: row['Quantity'] * row['Price']\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing monthly sales data for a retail store over two years, structured as follows:\n\n```\n           month   sales\n0    2022-01-01    5000\n1    2022-02-01    6000\n2    2022-03-01    7000\n3    2022-04-01    8000\n4    2022-05-01    9000\n5    2022-06-01    10000\n6    2022-07-01    11000\n7    2022-08-01    12000\n8    2022-09-01    13000\n9    2022-10-01    14000\n10   2022-11-01    15000\n11   2022-12-01    16000\n12   2023-01-01    17000\n13   2023-02-01    18000\n14   2023-03-01    19000\n15   2023-04-01    20000\n```\n\nYou wish to calculate the moving average of sales over the last three months while ensuring that the DataFrame keeps the same length and that NaN values are filled with the average of the available previous figures when not enough data points exist. What code would fill in the blank below to accomplish this?\n\n```python\nimport pandas as pd\n\ndata = {\n    'month': pd.date_range(start='2022-01-01', periods=16, freq='MS'),\n    'sales': [5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000]\n}\ndf = pd.DataFrame(data)\n\nmoving_average = df['sales'].__________\nprint(moving_average)\n```\nA:\n<code>\n",
    "output": "\n```python\nmoving_average = df['sales'].rolling(window=3, min_periods=1).mean()\n```"
  },
  {
    "input": "### Problem:\nYou have a pandas DataFrame that contains sales information for various products over different months, structured as follows:\n\n```\n   Month  ProductA  ProductB  ProductC\n0      1       500       300       200\n1      2       450       320       250\n2      3       600       280       300\n3      4       700       350       350\n4      5       750       400       370\n```\n\nNow, you want to create a new column that calculates the total sales for each month across all products. In order to keep your code reusable and modular, you would like to define a custom function that takes the DataFrame as an argument and returns a new DataFrame with the additional column named 'TotalSales'.\n\nThe DataFrame has already been created using:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Month': [1, 2, 3, 4, 5],\n    'ProductA': [500, 450, 600, 700, 750],\n    'ProductB': [300, 320, 280, 350, 400],\n    'ProductC': [200, 250, 300, 350, 370]\n})\n```\n\nHow can you implement a function called `calculate_total_sales` that accurately computes the total sales?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Month': [1, 2, 3, 4, 5],\n    'ProductA': [500, 450, 600, 700, 750],\n    'ProductB': [300, 320, 280, 350, 400],\n    'ProductC': [200, 250, 300, 350, 370]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndef calculate_total_sales(dataframe):\n    dataframe['TotalSales'] = dataframe[['ProductA', 'ProductB', 'ProductC']].sum(axis=1)\n    return dataframe\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a recommendation system where user-item interactions are represented as a sparse tensor. The shapes of the tensors for users and items are both (num_users, num_items, num_features). I need to compute a similarity score for each user against all items based on the non-zero interactions in this sparse tensor. \n\nGiven the sparse interaction tensor `interaction_tensor`, how would I create a mask that represents only the non-zero interactions for all users and items, where the tensor components are in the form:\n\ninteraction_tensor[user_index, item_index, feature_index] = value\n\nFor example:\n\ninteraction_tensor = [[[[0, 0], [1, 0]], [[0, 0], [0, 2]]], \n                      [[[0, 3], [0, 0]], [[4, 0], [0, 0]]]]\n\nI want to get a mask like this:\n\nmask = [[[[0, 0], [1, 0]], [[0, 0], [0, 1]]], \n        [[[0, 1], [0, 0]], [[1, 0], [0, 0]]]]\n\nA:\n<code>\nimport numpy as np\nimport torch\ninteraction_tensor = load_data()\n</code>\nmask = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmask = (interaction_tensor != 0).int()\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a PyTorch tensor `x` that contains the outputs of a model, and you want to apply softmax to the last dimension to convert the raw scores into probabilities. How can you achieve this using PyTorch?\n\nA:\n```python\nimport torch\n\nx = torch.randn((5, 10, 20))  # A tensor of shape (batch_size, sequence_length, num_classes)\n```\nprobabilities = ... # put solution in this variable",
    "output": "\n```python\nprobabilities = torch.softmax(x, dim=-1)\n```"
  },
  {
    "input": "Problem:\nI am working with a sparse matrix in Python using SciPy and I need to perform a matrix multiplication with another matrix. I have a sparse matrix named `A` of shape (5, 5) in COO format and a dense matrix `B` of shape (5, 3). I want to compute the resulting matrix `C` from the multiplication of `A` and `B`, while keeping `C` in CSR (Compressed Sparse Row) format, which is more efficient for arithmetic operations. Here is a snippet of my code:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Initialize a sparse matrix A in COO format\ndata = np.array([1, 2, 3])\nrow_indices = np.array([0, 2, 4])\ncol_indices = np.array([0, 2, 4])\nA = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n\n# Create a dense matrix B\nB = np.array([[1, 0, 2],\n              [0, 1, 0],\n              [3, 0, 1],\n              [0, 0, 0],\n              [1, 2, 0]])\n\n# Now, compute the result C\nC = ...\n```\n\nHow can I fill in the blank `C = ...` to get the result of `A` multiplied by `B` while ensuring `C` is in CSR format?",
    "output": "\n```python\nC = A.dot(B).tocsr()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing daily temperature records for a city over a month, as shown below:\n\n```\n+------------+----------+\n|    Date    |  Temp    |\n+------------+----------+\n| 2023-01-01 |    23    |\n| 2023-01-02 |    25    |\n| 2023-01-03 |    21    |\n| 2023-01-04 |    20    |\n| 2023-01-05 |    22    |\n| ...        |   ...    |\n| 2023-01-30 |    19    |\n| 2023-01-31 |    18    |\n+------------+----------+\n```\n\nYou need to compute a new column called `Rolling Avg` that represents the 7-day rolling average of the temperature. The rolling average should be calculated such that the first six entries in the `Rolling Avg` column will be NaN (since there are not enough previous days to calculate the average).\n\nComplete the following code to calculate and add the `Rolling Avg` column to the DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Create the DataFrame\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=31, freq='D'),\n    'Temp': [23, 25, 21, 20, 22, np.nan, 24, 26, 27, 21, \n             20, 19, 18, 26, 23, 27, 29, 30, 31, 28,\n             24, 22, 25, 26, 20, 19, 18, 17, 16, 15, \n             19, 18, 19]\n}\ndf = pd.DataFrame(data)\n\n# Add rolling average calculation\ndf['Rolling Avg'] = df['Temp'].rolling(window=7).mean()\n\n# Show the updated DataFrame\nprint(df)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\nYou are analyzing a time series of daily temperatures over a month. You have a DataFrame that records the date and temperature for each day, but there are some missing days. Your goal is to fill in the missing dates and impute the temperature on those dates with the average temperature of their neighboring dates. \n\nHere is the DataFrame you start with:\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05', '2023-01-07', '2023-01-08'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nYou need to expand the DataFrame to include all dates from `2023-01-01` to `2023-01-08`, filling the missing dates with the average temperature of their immediate neighbors.\n\nFill in the following line with the required code to achieve this:\n```python\nfilled_df = ... # insert your solution here\n```",
    "output": "\n```python\nfilled_df = df.set_index('date').reindex(pd.date_range(start='2023-01-01', end='2023-01-08')).interpolate(method='linear').reset_index()\n```"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.10.0.\nI have two tensors, one for features and another for labels, and I want to perform a linear regression using these tensors. The feature tensor has the shape (100, 1), and the label tensor has the shape (100,). \nHow can I define a simple linear regression model and compute the predictions for the features tensor?\n\nA:\n<code>\nimport torch\n\n# Define feature and label tensors\nfeatures = torch.randn(100, 1)\nlabels = torch.randn(100)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch.nn as nn\n\n# Define a simple linear regression model\nmodel = nn.Linear(1, 1)\n\n# Compute predictions\nresult = model(features)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a sparse tensor representing a collection of images in a batch of size `10`, each with a height of `32` pixels, width of `32` pixels, and `3` color channels. The tensor uses a coordinate format and has only a few values set. You want to replace all values in this tensor that are below a certain threshold (e.g., `0.5`) with a set value, `1.0`.\n\nGiven your sparse tensor and threshold, how can you fill in the gaps with `1.0` for all elements below this threshold without modifying the existing values above the threshold?\n\nYour starting code looks like this:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse.FloatTensor(\n    torch.tensor([[0, 0, 1], [1, 2, 3]]), \n    torch.tensor([0.1, 0.8, 0.4, 0.7])\n)\nthreshold = 0.5\n```\n\nYou need to fill the sparse tensor. \n\nPlease complete the following line of code to achieve this:\n\n```python\nfilled_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\nfilled_tensor = sparse_tensor.to_dense().clamp(min=threshold).masked_fill(sparse_tensor.to_dense() < threshold, 1.0)\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset with daily sales figures for a retail store, structured like this:\n\n```\n                 Sales\nDate               \n2023-01-01     150\n2023-01-02     200\n2023-01-03     100\n2023-01-04     180\n2023-01-05     220\n```\n\nNow, I want to calculate a rolling 3-day average of the sales data to smooth out the daily fluctuations. I've attempted to use the `.rolling()` method to achieve this, but I'm not sure how to fill in the gap for the rolling average right. \n\nHere is the initial code I have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Sales': [150, 200, 100, 180, 220]\n}\nindex = pd.date_range(start='2023-01-01', periods=len(data['Sales']))\ndf = pd.DataFrame(data, index=index)\n\n# Calculate the rolling average\nrolling_avg = df['Sales'].______ # put solution in this variable\n```\n\nWhat should I put in the blank to calculate the rolling average?",
    "output": "\n```python\nrolling_avg = df['Sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing daily sales data of a retail store, with each row representing sales for a specific date. The DataFrame looks like this:\n\n```\n           Date     Sales\n0    2023-01-01    200\n1    2023-01-02    220\n2    2023-01-03    250\n3    2023-01-04    240\n4    2023-01-05    260\n5    2023-01-06    300\n```\n\nYou want to calculate the 3-day rolling average of sales, ensuring that the resulting DataFrame retains the original dates and fills in the rolling average where applicable. The first two rows should result in `NaN` since there aren't enough preceding values to compute the average.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n    'Sales': [200, 220, 250, 240, 260, 300]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nrolling_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nrolling_avg = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch. You have a tensor `outputs` representing the prediction scores from your model, which has the shape `[64, 5]` for 64 samples and 5 classes. You also have a tensor `labels` that contains the true class indices for each sample, with a shape of `[64]`. \n\nYou want to calculate the number of correct predictions by comparing the predicted class indices with the true labels. However, first, you need to convert the `outputs` tensor to a tensor that contains the indices of the maximum scores across the classes for each sample.\n\nHow can you perform this operation in a single line? \n\nA:\n<code>\nimport torch\noutputs, labels = load_data()\n</code>\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>predictions = torch.argmax(outputs, dim=1)</code>"
  },
  {
    "input": "## Problem:\nSuppose you have a pandas DataFrame that contains a list of emails, and you'd like to extract the domain names from these emails. Your DataFrame looks like this:\n\n```python\nemail_df = pd.DataFrame({'email':['john.doe@example.com', 'jane.smith@domain.org', 'bob.brown@mail.com', 'charlie@example.com']})\n```\n\nYou want to create a new column in the DataFrame that contains just the domain names (the part after '@') in the following format:\n```python\n       email              domain\n0  john.doe@example.com       example.com\n1  jane.smith@domain.org      domain.org\n2  bob.brown@mail.com         mail.com\n3  charlie@example.com        example.com\n```\n\nHowever, you are unsure how to extract the domain names properly and incorporate them into your DataFrame. \n\nA:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email':['john.doe@example.com', 'jane.smith@domain.org', 'bob.brown@mail.com', 'charlie@example.com']})\n```\nemail_df['domain'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nemail_df['domain'] = email_df['email'].str.split('@').str[1]\n```"
  },
  {
    "input": "### Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, height, width, channels) and I want to normalize each image along the height and width dimensions (i.e., per image). Given that my tensor has a shape of (2, 4, 4, 3), how can I perform this normalization using TensorFlow and PyTorch?\n\nHere's an example tensor:\n\n```python\nimport torch\nimport tensorflow as tf\n\n# Example tensor for PyTorch\nt = torch.tensor([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n\n# Equivalent tensor for TensorFlow\nx = tf.constant([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n```\n\nNormalize this tensor to have values between 0 and 1 for each image. Fill in the code to achieve this normalization for both TensorFlow and PyTorch.\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nimport tensorflow as tf\nt, x = load_data()\n```\nnormalized_t = ... # put solution in this variable for PyTorch\nnormalized_x = ... # put solution in this variable for TensorFlow\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\nnormalized_t = (t - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0]) / (t.max(dim=2, keepdim=True)[0].max(dim=3, keepdim=True)[0] - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0])\nnormalized_x = (x - tf.reduce_min(x, axis=[1, 2], keepdims=True)) / (tf.reduce_max(x, axis=[1, 2], keepdims=True) - tf.reduce_min(x, axis=[1, 2], keepdims=True))\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor in PyTorch representing some raw input data:\n\ntensor([[0.1, 0.2, 0.3],\n        [0.4, 0.5, 0.6],\n        [0.7, 0.8, 0.9]])\n\nI would like to normalize this tensor along the second dimension (columns), so that each element is divided by the maximum element of its column. How can I achieve this without using a loop?\n\nA:\n\n<code>\nimport torch\ndata = torch.tensor([[0.1, 0.2, 0.3],\n                     [0.4, 0.5, 0.6],\n                     [0.7, 0.8, 0.9]])\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \n\n",
    "output": "\n<code>\nnormalized_data = data / data.max(dim=0, keepdim=True).values\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix in a Scipy environment, and you would like to efficiently find the non-zero elements and their indices. Let's say you have a sparse matrix `sparse_matrix` created using `scipy.sparse.csr_matrix`. You want to extract the indices of the non-zero elements in a way that they can be represented as a coordinate tensor. How can you achieve this?\n\nHere\u2019s a small snippet for context:\n\n```python\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\n# Sample sparse matrix\ndata = np.array([1, 2, 3, 4])\nrow_indices = np.array([0, 0, 1, 2])\ncol_indices = np.array([0, 2, 2, 1])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n```\n\nYou need to fill in the blank to extract the indices of the non-zero elements in `sparse_matrix`:\n\nnon_zero_indices = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>non_zero_indices = sparse_matrix.nonzero()</code>"
  },
  {
    "input": "Problem:\nI have a dataframe with a column containing text containing URLs, and I want to extract just the domain names from those URLs. Here is the initial dataframe:\n\n  urls\n0 https://www.example.com/path/to/page\n1 http://subdomain.example.org\n2 https://www.test.com\n3 ftp://files.test.com/resource\n\nI want to transform this dataframe to only contain the domain names like this:\n\n  domain\n0 example.com\n1 example.org\n2 test.com\n3 files.test.com\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'urls': ['https://www.example.com/path/to/page', 'http://subdomain.example.org', 'https://www.test.com', 'ftp://files.test.com/resource']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['domain'] = df['urls'].str.extract(r'://(?:www\\.)?([^/]+)')[0]\ndf['domain'] = df['domain'].str.replace(r'^[^.]+\\.', '', regex=True)\ndf = df[['domain']]\n</code>"
  },
  {
    "input": "### Problem:\nYou are given a DataFrame that contains daily sales data for a retail store over a month, structured as follows:\n\n```python\n                 sales\ndate\n2023-01-01    100\n2023-01-02    150\n2023-01-03    200\n2023-01-04    250\n2023-01-05    300\n2023-01-06    350\n2023-01-07    400\n2023-01-08    450\n2023-01-09    500\n2023-01-10    550\n```\n\nYou need to create a new column in the DataFrame that represents a 3-day rolling average of sales, where the average is calculated based on the current day and the two preceding days.\n\nPlease provide the line of code that will create this new column called '3_day_avg'.\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data).set_index('date')\n```\n\ndf['3_day_avg'] = ... # put solution in this variable",
    "output": "\n```python\ndf['3_day_avg'] = df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nI'm working with a sparse tensor representation of a dataset, where each entry corresponds to a count of some event in a 3D space (e.g., time, user ID, and item ID). The tensor is initialized to zero, and I receive updates in the form of a list of tuples that indicate which indices to increment.\n\nSuppose I have a 3D sparse tensor initialized with size (5, 5, 5) and I receive an update list as follows:\n\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n\nI want to update the tensor so that each specified index in the updates list has its count incremented by 1.\n\nHow can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\nsparse_tensor = torch.zeros((5, 5, 5))\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n</code>\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfor update in updates:\n    sparse_tensor[update] += 1\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset representing sales transactions for various products, structured as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'Product': ['A', 'B', 'A', 'C', 'B'],\n    'Quantity': [2, 1, 3, 4, 2],\n    'Price': [10, 20, 10, 30, 20]\n})\n```\n\nYou want to create a function that calculates the total sales for each product based on the Quantity and Price columns. The desired output should be a dictionary with product names as keys and total sales as values.\n\n```python\ntotal_sales = ... # Write your function and assign the output here\n```\n\nMake sure the function is reusable and can handle different DataFrames structured like the provided one.",
    "output": "\n```python\ndef calculate_total_sales(dataframe):\n    sales = {}\n    for index, row in dataframe.iterrows():\n        product = row['Product']\n        total = row['Quantity'] * row['Price']\n        if product in sales:\n            sales[product] += total\n        else:\n            sales[product] = total\n    return sales\n\ntotal_sales = calculate_total_sales(df)\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a neural network model using PyTorch and TensorFlow. You initially implemented your model in PyTorch, but you want to convert it to TensorFlow for deployment. The model takes a 2D tensor as input, processes it through a linear layer, and applies a ReLU activation. Write the TensorFlow code to define a model that replicates this behavior.\n\nGiven the following PyTorch implementation:\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        self.fc = nn.Linear(10, 5)  # 10 input features, 5 output features\n\n    def forward(self, x):\n        return torch.relu(self.fc(x))\n```\n\nTranslate this model into TensorFlow 2.x format. Your solution should define the model as a class inheriting from `tf.keras.Model` and should include the appropriate methods.\n\nA:\n<code>\nimport tensorflow as tf\n\nclass SimpleModel(tf.keras.Model):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        self.fc = tf.keras.layers.Dense(5)  # 5 output features\n\n    def call(self, inputs):\n        return tf.nn.relu(self.fc(inputs))\n\nmodel = SimpleModel()\n\n</code>\noutput = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\noutput = model(tf.random.normal((1, 10)))  # Example input tensor with shape (1, 10)\n</code>"
  },
  {
    "input": "Problem:  \nI have a pandas dataframe that contains a column of email addresses. I would like to extract the domain name part from each email address while disregarding the subdomains (if any). The dataframe looks like this:\n\n| Email                      |\n|----------------------------|\n| john.doe@example.com       |\n| jane.smith@mail.co.uk      |\n| info@subdomain.domain.org   |\n| user123@yahoo.com          |\n| no-reply@service.global.com |\n\nI need to create a new column called 'Domain' that contains just the main domain (e.g., `example.com`, `mail.co.uk`, `domain.org`, `yahoo.com`, `global.com`) for each email address. I attempted using `.str.split()` with indexes but I'm having trouble getting just the relevant part.\n\nA:  \n```python\nimport pandas as pd\n\ndata = {'Email': ['john.doe@example.com',\n                  'jane.smith@mail.co.uk',\n                  'info@subdomain.domain.org',\n                  'user123@yahoo.com',\n                  'no-reply@service.global.com']}\ndf = pd.DataFrame(data)\n```  \ndf['Domain'] = ... # put solution in this variable  \nBEGIN SOLUTION  \n```python",
    "output": "\n```python\ndf['Domain'] = df['Email'].str.split('@').str[1].str.split('.').str[-2:].str.join('.')\n```"
  },
  {
    "input": "Problem:\nYou have a dataset represented as a list of dictionaries containing information about various products in an e-commerce store. Each dictionary has the following structure: `{'product_name': str, 'price': float, 'category': str, 'quantity': int}`. You want to create a function that, given this dataset, will return a new list of dictionaries that contains only the products in a specified category and includes an additional field `total_value` which is calculated as `price * quantity`.\n\nYour list of products looks like this:\n\n```python\nproducts = [\n    {'product_name': 'Laptop', 'price': 999.99, 'category': 'Electronics', 'quantity': 10},\n    {'product_name': 'Headphones', 'price': 199.99, 'category': 'Electronics', 'quantity': 5},\n    {'product_name': 'Desk', 'price': 149.99, 'category': 'Furniture', 'quantity': 2},\n    {'product_name': 'Chair', 'price': 89.99, 'category': 'Furniture', 'quantity': 4}\n]\n```\n\nWrite a function `filter_products_by_category(products, category)` that filters the products by the given category and calculates the `total_value` for each product. Use the function to call `filter_products_by_category(products, 'Electronics')`.\n\nA:\n```python\ndef filter_products_by_category(products, category):\n    # Your code here\n    return filtered_products\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef filter_products_by_category(products, category):\n    filtered_products = []\n    for product in products:\n        if product['category'] == category:\n            product['total_value'] = product['price'] * product['quantity']\n            filtered_products.append(product)\n    return filtered_products\n\nresult = filter_products_by_category(products, 'Electronics')\n```"
  },
  {
    "input": "## Problem:\nI have a dataframe with a column containing dates in various formats mixed with their respective timestamps. The goal is to extract only the date part without the time and convert it to the format \"dd-mm-yyyy\". Here's an example of what the dataframe looks like:\n\n| datetime                |\n|-------------------------|\n| 2023-10-12 14:23:44     |\n| 2023/11/01 10:05:22     |\n| October 15, 2023 03:12  |\n\nI wish to create a new column `formatted_date` that contains the dates extracted and formatted as specified. I started with the following code but I'm not sure how to parse the varying formats.\n\n```python\ndf['formatted_date'] = df['datetime'].str[...] \n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'datetime': ['2023-10-12 14:23:44', '2023/11/01 10:05:22', 'October 15, 2023 03:12']}\ndf = pd.DataFrame(data)\n</code>\ndf['formatted_date'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['formatted_date'] = pd.to_datetime(df['datetime'], errors='coerce').dt.strftime('%d-%m-%Y') \n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset that records daily sales of a product over several months. The data is organized in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=60, freq='D'),\n        'sales': np.random.poisson(lam=200, size=60)}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\n\nYou want to calculate a moving average of the sales data over a 7-day window. However, you also want to exclude the moving average for days where the sales count is below 150. Fill in the blank with the correct code to create a new column in the DataFrame that contains the desired moving average, ensuring that it doesn't include values below 150:\n\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean() # fill in this code to apply the condition\n```\n\nWhat code would replace the `# fill in this code to apply the condition` comment? \n\nA:\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean().where(df['sales'] >= 150)\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].where(df['sales'] >= 150).rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a time series dataset stored in a DataFrame with the following structure:\n\n| date       | value |\n|------------|-------|\n| 2021-01-01 | 10    |\n| 2021-01-02 | 15    |\n| 2021-01-03 | 13    |\n| 2021-01-04 | 20    |\n| 2021-01-05 | 22    |\n| 2021-01-06 | 25    |\n\nYour goal is to calculate the rolling average of the 'value' column over a window size of 3 days. You also want the result to be in a new column named 'rolling_avg' in the original DataFrame. \n\nHere is the initial setup of your code:\n\n```python\nimport pandas as pd\ndata = {\n    'date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06'],\n    'value': [10, 15, 13, 20, 22, 25]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nThe final code you need to complete is:\n\n```python\ndf['rolling_avg'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['value'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou are analyzing daily stock prices recorded in a pandas DataFrame, and you want to compute the percentage change in closing prices from one day to the next. However, if the closing price was zero on a given day, the percentage change should be set to NaN for that day to avoid division by zero. Additionally, you want to drop any rows that contain NaN values after calculating the percentage change.\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n    'Close': [150, 0, 155, 160, 0]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n```\n\nHow can you calculate the percentage change in 'Close' prices and drop NaN values in a single line of code?\n\nA:\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df['Close'].replace(0, pd.NA).pct_change().dropna()\n```"
  },
  {
    "input": "### Problem\n\nYou are given a dataset representing images, where each image is stored as a 3D tensor in a batch format (batch_size, height, width, channels). You want to preprocess these images using TensorFlow by subtracting the mean pixel value from each channel of the images in the batch. \n\nGiven a batch of images with shape (batch_size, height, width, channels), the goal is to compute a tensor `normalized_images` which contains the images with the mean normalized.\n\nFor example:\n\n```python\nimages = tf.random.normal((10, 64, 64, 3))  # A batch of 10 images of size 64x64 with 3 channels\n```\n\nWrite the code to perform the mean normalization for the images so that `normalized_images` contains the result of subtracting the mean of each channel.\n\n```python\nimport tensorflow as tf\n\nimages = load_data()  # shapes as indicated above\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean_values = tf.reduce_mean(images, axis=[0, 1, 2], keepdims=True)\nnormalized_images = images - mean_values\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains sentences with various punctuation marks. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n```\n\nYour goal is to create a new column in the DataFrame that contains the number of punctuation marks found in each sentence. The final DataFrame should look like this:\n\n```\n                     sentences      punctuation_count\n0                  Hello, world!                     1\n1         Python is great; isn't it?                  3\n2          Let's code: Python is fun!                  3\n3      Data science; is changing the world.          4\n```\n\nTo accomplish this, I've started with the following approach using a lambda function to count the punctuation:\n\n```python\nimport string\ndf['punctuation_count'] = df['sentences'].apply(lambda x: ...)\n```\n\nPlease fill in the blank where the lambda function processes the `x` variable to return the count of punctuation marks. \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n</code>\ndf['punctuation_count'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndf['punctuation_count'] = df['sentences'].apply(lambda x: sum(1 for char in x if char in string.punctuation))\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame with a column containing strings that contain emails and I want to extract the usernames from each email address. The DataFrame looks like this:\n\n```\n       emails\n0   john.doe@example.com\n1   jane_doe123@test.com\n2   user@domain.org\n3   admin@mywebsite.io\n4   contact@service.net\n```\n\nI want to create a new column named 'usernames' that contains only the username part of each email (the part before the '@').\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'emails': ['john.doe@example.com', 'jane_doe123@test.com', \n                               'user@domain.org', 'admin@mywebsite.io', \n                               'contact@service.net']})\ndf['usernames'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['usernames'] = df['emails'].str.split('@').str[0]\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix representing user interactions in a recommendation system. The matrix is stored as a list of tuples, with each tuple containing the row index, column index, and the value (indicating the interaction score). Your task is to convert this sparse representation into a dense matrix using NumPy. Specifically, given a sparse matrix in the form of `sparse_data = [(0, 1, 5), (1, 0, 3), (2, 2, 2)]`, which indicates that user 0 interacted with item 1 with a score of 5, user 1 with item 0 with a score of 3, and user 2 with item 2 with a score of 2, how can you represent this as a dense matrix of shape (3, 3)?\n\nA:\n\n<code>\nimport numpy as np\nsparse_data = load_data()\ndef solve(sparse_data):\n    # return the solution in this function\n    # dense_matrix = solve(sparse_data)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    dense_matrix = np.zeros((3, 3))\n    for row, col, value in sparse_data:\n        dense_matrix[row, col] = value\n    return dense_matrix\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\n\n# Create a DataFrame with a date range of stock prices\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2020-01-01', periods=100, freq='D'),\n    'Price': (100 + pd.Series(range(100)).cumsum() + (np.random.randn(100) * 5))\n})\n\n# I want to resample this DataFrame to get the monthly average price. \n# Fill in the blank to get the resampled DataFrame as `monthly_avg`.\n\nmonthly_avg = df.set_index('Date').resample('M').mean()\n\n# The idea is to be able to see the average stock price at the end of each month.\n```",
    "output": "\n```python\nimport numpy as np\n\nmonthly_avg = df.set_index('Date').resample('M').mean()\n```"
  },
  {
    "input": "Problem:\n\nYou have a sparse matrix representation of a large dataset where the rows represent users and the columns represent items. The users only interact with a small fraction of the items, resulting in a sparse matrix. The goal is to create a function that fills this matrix with a specified value (say 1) for all non-zero entries, effectively transforming it into a binary indicator matrix.\n\nGiven a sparse matrix `sparse_matrix` in the Compressed Sparse Row (CSR) format, write a function `to_binary_matrix(sparse_matrix)` that converts all non-zero elements to 1, preserving the sparse structure.\n\nHere is a sample sparse matrix to start with:\n\n```python\nfrom scipy.sparse import csr_matrix\ndata = [3, 4, 5, 7]\nrow_indices = [0, 0, 1, 2]\ncol_indices = [0, 2, 1, 2]\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n```\n\nNow, you need to implement the function and apply it as follows:\n\n```python\nresult = ...\n``` \n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef to_binary_matrix(sparse_matrix):\n    return sparse_matrix.copy().astype(bool).astype(int)\n\nresult = to_binary_matrix(sparse_matrix)\n```"
  },
  {
    "input": "Problem:\n\nI need to analyze a list of customer purchase records that includes various attributes. Each record is a dictionary with keys: 'customer_id', 'item', 'quantity', and 'price'. I want to create a function that takes this list of records and returns the total revenue generated, which is calculated as the sum of `quantity * price` for each record. \n\nFor example, given the following records:\n\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n\nI would expect your function to return a total revenue of 4.0.\n\nA:\n<code>\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n</code>\ntotal_revenue = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ntotal_revenue = sum(record['quantity'] * record['price'] for record in records)\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor representation for a multi-dimensional dataset, where our data consists of customer purchases across different categories over several months. The shape of my sparse tensor is [30, 12, 5], which represents 30 customers, 12 months, and 5 product categories. I have a tensor containing the actual number of purchases for each customer in each category with the shape [30, 5]. The challenge is to populate the sparse tensor with the corresponding purchase values for each customer and category from the purchase tensor in a way that only the relevant entries are updated.\n\nThe sparse tensor is initialized as follows:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.Variable(tf.zeros((30, 12, 5), dtype=tf.float32))\npurchase_tensor = tf.constant([[2, 0, 5, 3, 1],\n                                [0, 3, 0, 1, 0],\n                                [1, 1, 1, 1, 1], \n                                # ... (and so on for 30 customers)\n                               ])\n```\n\nHow do I fill `sparse_tensor` so that each customer's purchases only fill in their respective category across the months? For instance, for the first customer with purchase values `[2, 0, 5, 3, 1]`, we should populate the sparse tensor accordingly for the available months.\n\nThe specific code line to fill in is:\n\n```python\nsparse_tensor[...] = ...\n```",
    "output": "\n```python\nsparse_tensor[...] = tf.reshape(purchase_tensor, (30, 1, 5)) * tf.ones((1, 12, 1), dtype=tf.float32)\n```"
  },
  {
    "input": "## Problem\n\nYou are building a neural network model using TensorFlow for image classification. The output layer of your model is a dense layer with 10 units (one for each class), activated by the softmax function. After obtaining the class probabilities, you need to create a tensor that will contain the predicted class indices based on the highest probabilities for a batch of images. \n\nGiven the output tensor of your model:\n\n```python\ntf.Tensor(\n    [[0.1, 0.3, 0.1, 0.4, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n     [0.2, 0.2, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1],\n     [0.3, 0.1, 0.1, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]]\n)\n```\n\nYou want to convert this tensor to a one-dimensional tensor that only contains the index of the highest value in each row. For the provided example, the desired output should be:\n\n```\ntf.Tensor([3, 2, 0])\n```\n\nHow can you achieve this?\n\nA:\n```python\nimport tensorflow as tf\n\npredictions = tf.constant(\n    [[0.1, 0.3, 0.1, 0.4, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0],\n     [0.2, 0.2, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1],\n     [0.3, 0.1, 0.1, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]]\n)\n```\npredicted_classes = ... # put solution in this variable",
    "output": "\n```python\npredicted_classes = tf.argmax(predictions, axis=1)\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix in the context of natural language processing where you need to compute the term-document matrix. You have a list of documents represented by the following sparse format:\n\n```\nsparse_matrix = {\n    (0, 1): 3,  # Document 0, Term 1 appears 3 times\n    (0, 3): 2,  # Document 0, Term 3 appears 2 times\n    (1, 0): 1,  # Document 1, Term 0 appears 1 time\n    (1, 2): 4,  # Document 1, Term 2 appears 4 times\n    (2, 1): 5,  # Document 2, Term 1 appears 5 times\n}\n```\n\nThis sparse representation indicates that Document 0 has 3 occurrences of Term 1 and so forth. \n\nYou need to convert this sparse matrix representation into a dense tensor of shape (3, 4) where rows correspond to documents and columns correspond to terms. Unmentioned terms for each document should have 0.\n\nWhat single line of code can you use with PyTorch to achieve this conversion?\n\nA:\n\n<code>\nimport torch\nsparse_matrix = {(0, 1): 3, (0, 3): 2, (1, 0): 1, (1, 2): 4, (2, 1): 5}\ndense_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndense_tensor = torch.sparse_coo_tensor(indices=torch.tensor(list(sparse_matrix.keys())).t(), values=torch.tensor(list(sparse_matrix.values())), size=(3, 4)).to_dense()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix of shape (5, 5) represented in COO format, filled with random integers. I want to convert this sparse matrix to a dense NumPy array and then extract the diagonal elements as a 1D array. Here's the sparse matrix I created:\n\n```\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\n\nGiven the `sparse_matrix`, please provide the code to obtain the diagonal elements in a 1D NumPy array.\n\nA:\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\ndiagonal_elements = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndiagonal_elements = sparse_matrix.toarray().diagonal()\n```"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple feedforward neural network using both TensorFlow and PyTorch. The input to your model is a tensor of shape (batch_size, 10) representing features. You want to create a model that predicts a single output value for regression tasks. First, you need to define the model in TensorFlow. After that, you will define the same model in PyTorch.\n\nHere\u2019s a template for the TensorFlow model definition. Please fill in the blank to define the model properly:\n\n```python\nimport tensorflow as tf\n\ndef create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(10,)),\n        # Fill in this blank to add a Dense layer with 64 units and ReLU activation\n        ...\n        tf.keras.layers.Dense(1)\n    ])\n    return model\n```\n\nA:\n<code>\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntf.keras.layers.Dense(64, activation='relu')\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains product descriptions in one of its columns. The descriptions sometimes include the brand name followed by the product name, and sometimes just the product name. Here is how the DataFrame looks:\n\n   description\n0  Nike Air Max 270\n1  Adidas Ultraboost\n2  Reebok Classic\n3  Puma RS-X\n\nI want to extract the brand name and the product name into two separate columns named \"brand\" and \"product\". The resulting DataFrame should look like this:\n\n   brand      product\n0  Nike      Air Max 270\n1  Adidas    Ultraboost\n2  Reebok    Classic\n3  Puma      RS-X\n\nHow can I achieve this? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'description': ['Nike Air Max 270', 'Adidas Ultraboost', 'Reebok Classic', 'Puma RS-X']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['description'].str.extract(r'(?P<brand>^\\w+)\\s+(?P<product>.+)')"
  },
  {
    "input": "## Problem\nGiven a DataFrame that contains product information with a column named `ProductID` and `Description`, you would like to extract the numeric part of the `ProductID` which follows the format 'PROD-###' (where ### is a numeric sequence) and create a new column called `ProductNumber`. Additionally, you want to concatenate this extracted number with the first 5 characters of the `Description` column to form a new column called `ProductKey`.\n\nFor instance, if your DataFrame looks like this:\n\n```\n   ProductID       Description\n0   PROD-001   Widget A - Red\n1   PROD-002   Widget B - Blue\n2   PROD-003   Gadget C - Green\n3   PROD-004   Device D - Yellow\n```\n\nThe resulting DataFrame should look like:\n\n```\n   ProductID       Description  ProductNumber   ProductKey\n0   PROD-001   Widget A - Red           001         001Wi\n1   PROD-002   Widget B - Blue          002         002Wi\n2   PROD-003   Gadget C - Green         003         003Gad\n3   PROD-004   Device D - Yellow        004         004Dev\n```\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': ['PROD-001', 'PROD-002', 'PROD-003', 'PROD-004'],\n    'Description': ['Widget A - Red', 'Widget B - Blue', 'Gadget C - Green', 'Device D - Yellow']\n}\n\ndf = pd.DataFrame(data)\n```\n\nComplete the following code to derive the `ProductNumber` and `ProductKey` columns:\n\n```python\ndf['ProductNumber'] = df['ProductID'].str.extract('(\\d+)')\ndf['ProductKey'] = df['ProductNumber'] + df['Description'].str[:5]\n```\nImplement the solution by filling in the blank in the provided code:\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame with the following structure:\n\n```\n|   product_id | rating | review_count |\n|--------------|--------|--------------|\n|            1 |      5 |           10 |\n|            2 |      4 |            5 |\n|            3 |      3 |          100 |\n|            4 |      2 |             0 |\n|            5 |      1 |           30 |\n```\n\nI would like to create a new column `quality` that categorizes products based on their `rating` and `review_count`. The criteria are as follows:\n- If the `rating` is 4 or higher and `review_count` is greater than 10, label it as \"High Quality\".\n- If the `rating` is between 3 and 4 (inclusive) and `review_count` is greater than 0, label it as \"Moderate Quality\".\n- Otherwise, label it as \"Low Quality\".\n\nMy current function approach is not very efficient. Here is my code so far:\n\n```python\ndef categorize_quality(row):\n    if row['rating'] >= 4 and row['review_count'] > 10:\n        return 'High Quality'\n    elif 3 <= row['rating'] < 4 and row['review_count'] > 0:\n        return 'Moderate Quality'\n    else:\n        return 'Low Quality'\n\ndf['quality'] = df.apply(categorize_quality, axis=1)\n```\n\nI want to optimize this code to avoid using `apply`. How can I implement a custom function that achieves this more efficiently?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4, 5],\n    'rating': [5, 4, 3, 2, 1],\n    'review_count': [10, 5, 100, 0, 30]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['quality'] = pd.cut(\n    df['rating'].where(df['review_count'] > 10, 0),\n    bins=[-1, 2, 3, 4, 5],\n    labels=['Low Quality', 'Low Quality', 'Moderate Quality', 'High Quality'],\n    right=True\n).fillna('Low Quality')\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame `df` containing daily sales data for multiple products as follows:\n\n```\n           Date       Product  Sales\n0    2023-01-01        A        100\n1    2023-01-01        B        150\n2    2023-01-01        C        200\n3    2023-01-02        A        120\n4    2023-01-02        B        140\n5    2023-01-02        C        210\n6    2023-01-03        A        115\n7    2023-01-03        B        130\n8    2023-01-03        C        230\n```\n\nI want to calculate the daily percentage change in sales for each product, and keep the first row for each product's percentage change as NaN. The expected output should look like this:\n\n```\n           Date       Product  Sales  Percentage_Change\n0    2023-01-01        A        100                NaN\n1    2023-01-01        B        150                NaN\n2    2023-01-01        C        200                NaN\n3    2023-01-02        A        120                0.20\n4    2023-01-02        B        140              -0.07\n5    2023-01-02        C        210                0.05\n6    2023-01-03        A        115              -0.04\n7    2023-01-03        B        130              -0.07\n8    2023-01-03        C        230                0.09\n```\n\nI have initialized the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01',\n             '2023-01-02', '2023-01-02', '2023-01-02',\n             '2023-01-03', '2023-01-03', '2023-01-03'],\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 120, 140, 210, 115, 130, 230]\n}\n\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the following line to calculate the daily percentage change in sales for each product:\n\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(...) \n```",
    "output": "\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(lambda x: x.pct_change())\n```"
  },
  {
    "input": "Problem:\n\nI have a DataFrame with a column of email addresses and I want to extract the domain from each email into a new column called 'domain'. My DataFrame looks like this:\n\n```\n       email\n0  alice@example.com\n1  bob@sample.org\n2  charlie@example.net\n3  dave@website.com\n4  eve@domain.io\n```\n\nI know I can create a new column and populate it with some transformation, but I'm not sure how to extract just the domain from the email addresses using pandas string methods.\n\nCurrent attempts to split the email are returning the full string or parts I'm not interested in. I want the 'domain' column to look like this:\n\n```\n       domain\n0  example.com\n1  sample.org\n2  example.net\n3  website.com\n4  domain.io\n```\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'email': ['alice@example.com', 'bob@sample.org', \n                  'charlie@example.net', 'dave@website.com', \n                  'eve@domain.io']}\ndf = pd.DataFrame(data)\n</code>\ndf['domain'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['domain'] = df['email'].str.split('@').str[1]"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing daily sales data for a retail store. The 'Date' column is the index and the 'Sales' column records the daily sales figures:\n\n```python\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2022-01-01', periods=30, freq='D'),\n    'Sales': [120, 135, 150, 160, 110, 130, 145, 155, 170, 180, 200, 190, 210, 220, 230, 225, 240, 230, 215, 205, 201, 199, 210, 220, 230, 240, 250, 245, 240, 235, 250]\n})\ndf.set_index('Date', inplace=True)\n```\n\nYou want to calculate the rolling average of sales over a 7-day window and store this in a new column named '7-day Avg'. What should you fill in the blank below to achieve this?\n\n```python\ndf['7-day Avg'] = ...\n```",
    "output": "\n```python\ndf['7-day Avg'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nI have a list of employees with their worked hours over a week and I would like to calculate the total hours worked for each employee, but I need to implement a function that takes in a list of tuples where each tuple consists of an employee's name and their corresponding hours for the week. If an employee's total hours exceed 40, only record 40 hours as the maximum limit. I want the function to return a dictionary with the employee's name as the key and their total hours (capped at 40) as the value.\n\nFor example, given the following list:\n\n```python\nhours_list = [('Alice', 10), ('Bob', 20), ('Alice', 35), ('Bob', 25), ('Charlie', 20), ('Alice', 10)]\n```\n\nThe expected output should be:\n```python\n{'Alice': 40, 'Bob': 40, 'Charlie': 20}\n```\n\nYou need to fill in the blank with the appropriate function that processes this data.\n\nA:\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    # Your code goes here\n    return result\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    for name, hours in hours_list:\n        if name in result:\n            result[name] += hours\n        else:\n            result[name] = hours\n    for name in result:\n        if result[name] > 40:\n            result[name] = 40\n    return result\n</code>\nresult = calculate_hours(hours_list)\n</code>"
  },
  {
    "input": "## Problem\nI have a DataFrame containing sales data over several months for a product with daily sales figures. The DataFrame looks like this:\n\n```\n        Date         Sales\n0 2019-01-01           100\n1 2019-01-02           150\n2 2019-01-03           120\n3 2019-01-04           130\n4 2019-01-05           200\n5 2019-02-01           170\n6 2019-02-02           160\n7 2019-02-03           180\n8 2019-02-04           190\n9 2019-02-05           220\n```\n\nI want to resample this DataFrame to get the total sales for each month, but I need to maintain the original date format. I have started by converting the `Date` column to datetime format:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Date': ['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', \n             '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05'],\n    'Sales': [100, 150, 120, 130, 200, 170, 160, 180, 190, 220]\n})\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, what is the code I should use to resample the DataFrame to monthly sales totals while keeping the date format as the first date of the month?\n\n```python\nmonthly_sales = ... # put solution in this variable\n```",
    "output": "\n```python\nmonthly_sales = df.resample('M', on='Date').sum().reset_index()\nmonthly_sales['Date'] = monthly_sales['Date'].dt.to_period('M').dt.to_timestamp()\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer transactions in a DataFrame, where each transaction has a 'price' and a 'quantity' column. You want to create a new column that calculates the total amount spent for each transaction, which is the product of 'price' and 'quantity'. To ensure your code is reusable, you plan to implement a custom function for this calculation.\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'price': [10.5, 20.0, 7.5, 15.0],\n    'quantity': [2, 1, 3, 4]\n})\n```\n\nYou should define a function named `calculate_total` that takes two arguments, `price` and `quantity`, and returns the total spent for that transaction. Then, use this function to apply it to the DataFrame and create a new column called 'total_spent'.\n\n```python\ndf['total_spent'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_total(price, quantity):\n    return price * quantity\n\ndf['total_spent'] = df.apply(lambda row: calculate_total(row['price'], row['quantity']), axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have the following dataframe containing customer data:\n\n```\ncustomer_info\n1   John Doe, 29, New York\n2   Jane Smith, 34, San Francisco\n3   Alice Johnson, 22, Boston\n4   Bob Brown, 45, Chicago\n```\n\nI need to split this `customer_info` column into three separate columns: `name`, `age`, and `city`. The final dataframe should look like this:\n\n```\n      name   age           city\n1  John Doe   29       New York\n2  Jane Smith 34  San Francisco\n3  Alice Johnson 22         Boston\n4  Bob Brown   45        Chicago\n```\n\nI tried to achieve this using the `str.split` method but I'm not getting the expected output. Here is the initial code I have:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'customer_info': ['John Doe, 29, New York', 'Jane Smith, 34, San Francisco', \n                                      'Alice Johnson, 22, Boston', 'Bob Brown, 45, Chicago']})\n```\n\nHow can I correctly extract and separate the name, age, and city into different columns? \n\nA:\n<code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['name', 'age', 'city']] = df['customer_info'].str.split(', ', expand=True)\ndf['age'] = df['age'].astype(int)\ndf = df.drop(columns=['customer_info'])\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user-item interactions in a recommendation system, where a user has interacted with a limited number of items. Given the following components:\n\n1. A sparse matrix `user_item` of shape (1000, 5000) representing interactions, where rows correspond to users and columns to items.\n2. A list `user_ids` containing the indices of users whose interactions you want to extract.\n\nYou need to create a new sparse matrix `selected_users` that contains only the interactions of the specified users.\n\nThe `user_item` matrix is defined as follows:\n\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]  # example user indices\n```\n\nHow can you fill the variable `selected_users` to contain only the rows of `user_item` corresponding to the users in `user_ids`?\n\nA:\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]\n```\nselected_users = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_users = user_item[user_ids, :]\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset consisting of images that you want to preprocess before feeding them into a neural network for classification. The images are stored in a 4D tensor of shape (batch_size, height, width, channels). You would like to normalize the pixel values to be between 0 and 1 using PyTorch. \n\nGiven a 4D tensor `images`, how can you normalize it?\n\nA:\n\n<code>\nimport torch\n\nbatch_size, height, width, channels = 10, 32, 32, 3\nimages = torch.randn(batch_size, height, width, channels) * 255  # Simulated image data with pixel values from 0 to 255\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nnormalized_images = images / 255.0\n</code>",
    "output": "\n<code>\nnormalized_images = images / 255.0\n</code>"
  },
  {
    "input": "## Problem:\nI am working on a classification model using PyTorch, and I've just completed the training phase. Now, I want to evaluate the model on a test dataset. My model outputs a tensor of shape (n, 3) representing the scores for three classes for each input sample. I want to calculate the predicted class label for each sample by taking the index of the maximum value in each output tensor.\n\nFor example, if my model provides the following output:\n\n```\noutput_tensor = torch.Tensor([[0.1, 0.3, 0.6],\n                               [0.8, 0.1, 0.1],\n                               [0.2, 0.7, 0.1]])\n```\n\nI would like to obtain the predicted class labels as a tensor of shape (n,) such that it looks like this:\n```\npredicted_classes = tensor([2, 0, 1])\n```\n\nHow can I achieve this?\n\nA:\n\n<code>\nimport torch\n\noutput_tensor = torch.Tensor([[0.1, 0.3, 0.6],\n                               [0.8, 0.1, 0.1],\n                               [0.2, 0.7, 0.1]])\n</code>\npredicted_classes = ... # put solution in this variable\n### BEGIN SOLUTION",
    "output": "\n<code>\npredicted_classes = torch.argmax(output_tensor, dim=1)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of images represented as a 4D tensor in PyTorch, where the shape is (batch_size, channels, height, width). I want to apply a normalization process such that each image (in the batch) is normalized independently based on its own mean and standard deviation.\n\nHow can I achieve this in PyTorch without using explicit loops?\n\nGiven a 4D tensor `images`, please provide the one-liner solution that normalizes each image across the channels dimension.\n\nExample input:\n```python\nimages = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]], \n                        [[0.5, 0.6], [0.7, 0.8]]],\n                       [[[0.9, 1.0], [1.1, 1.2]], \n                        [[1.3, 1.4], [1.5, 1.6]]]])\n```\n\nThe output should look like this, where each image is normalized:\n```python\nnormalized_images = ...\n```\n\nA:\n```python\nimport torch\nimages = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]], \n                        [[0.5, 0.6], [0.7, 0.8]]],\n                       [[[0.9, 1.0], [1.1, 1.2]], \n                        [[1.3, 1.4], [1.5, 1.6]]]])\n```\nnormalized_images = ...  # put solution in this variable\nBEGIN SOLUTION\n```python\nnormalized_images = (images - images.mean(dim=(2, 3), keepdim=True)) / images.std(dim=(2, 3), keepdim=True)\n```",
    "output": "\n```python\nnormalized_images = (images - images.mean(dim=(1, 2), keepdim=True)) / images.std(dim=(1, 2), keepdim=True)\n```"
  },
  {
    "input": "Problem:\nI have a time series dataframe containing daily temperature readings for a city, structured like this:\n\n```\ndate         temperature\n2023-01-01   5.0\n2023-01-02   6.5\n2023-01-03   7.0\n2023-01-04   4.5\n2023-01-05   6.0\n```\n\nI want to calculate the rolling average temperature over a 3-day window. However, I also want the first two rows to be left as `NaN` since there are insufficient previous days to calculate the average for those dates. I tried using the `pandas.DataFrame.rolling()` function, but I'm not sure how to implement this correctly.\n\nHere is my setup:\n\n```python\nimport pandas as pd\n\ndata = {'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n        'temperature': [5.0, 6.5, 7.0, 4.5, 6.0]}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n```\n\nI want to replace the following line to calculate the rolling average:\n\n```python\ndf['rolling_avg'] = ...\n```\n\nPlease put the solution in the `...` variable.",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=3, min_periods=3).mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset represented as a list of dictionaries where each dictionary corresponds to an individual's records. Each record includes 'age', 'income', and 'expenses'. I want to create a function that calculates the savings for each record by subtracting expenses from income. The function should return a list of savings. Here\u2019s a sample of my dataset:\n\n```python\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n```\n\nI need a way to efficiently calculate the savings and return them as a list.\n\nA:\n<code>\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n\ndef calculate_savings(records):\n    # return the savings list here\n    savings = ...\n</code>\nsavings = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    savings = [record['income'] - record['expenses'] for record in records]\n    return savings\n</code>"
  },
  {
    "input": "Problem:\nI'm working on a neural network using PyTorch to classify images. I have a batch of images represented as a tensor with shape `[batch_size, channels, height, width]`. My goal is to apply a 2D convolution operation to this tensor using PyTorch. Specifically, I want to use a kernel of size 3x3 and apply a stride of 1 with no padding. How can I achieve this?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\nbatch_size = 8\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\n\nconv_layer = nn.Conv2d(in_channels=channels, out_channels=16, kernel_size=3, stride=1, padding=0)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = conv_layer(images)  \n</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing daily temperature records for a city over several years. The DataFrame has a 'Date' column and a 'Temperature' column. I want to compute the rolling average temperature over a 7-day window for each day. For example, for each day's temperature, the average should include that day and the previous six days. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\n\ndate_range = pd.date_range(start='2020-01-01', end='2020-01-10', freq='D')\ntemperatures = [30, 32, 31, 34, 36, 30, 29, 33, 35, 36]\ndf = pd.DataFrame({'Date': date_range, 'Temperature': temperatures})\ndf.set_index('Date', inplace=True)\n```\n\nNow, I need to create a new column '7_day_avg' in the DataFrame that contains the rolling average temperature. How can I achieve this? \n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "### Problem:\nYou are working on a neural network model using PyTorch to classify images from the CIFAR-10 dataset. After loading and preprocessing the dataset, you have a tensor `images` that represents a batch of images with shape `(batch_size, channels, height, width)`. \n\nTo standardize the images, you need to subtract the mean and divide by the standard deviation, calculated over the channel dimension. The mean and standard deviation tensors have values:\n\nmean = tensor([0.5, 0.5, 0.5])  \nstd = tensor([0.2, 0.2, 0.2])\n\nHow can you express the normalization operation in a single line using broadcasting?\n\nA:\n<code>\nimport torch\n\nimages = torch.rand((32, 3, 32, 32))  # Example images tensor\nmean = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\nstd = torch.tensor([0.2, 0.2, 0.2]).view(1, 3, 1, 1)\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>normalized_images = (images - mean) / std</code>",
    "output": "\n<code>normalized_images = (images - mean) / std</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product information with a column of product codes that includes both letters and numbers, and I want to extract only the numeric part from these codes into a new column. Here\u2019s how my DataFrame looks:\n\n      Product_Code\n0     AB12345\n1     CD67890\n2     EF23456\n3     GH89012\n4     IJ34567\n\nI would like to achieve the following output:\n\n      Product_Code  Numeric_Code\n0     AB12345        12345\n1     CD67890        67890\n2     EF23456        23456\n3     GH89012        89012\n4     IJ34567        34567\n\nHow can I do this using the `str.extract` method in pandas to create the new column?\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Product_Code': ['AB12345', 'CD67890', 'EF23456', 'GH89012', 'IJ34567']})\n</code>\ndf['Numeric_Code'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Numeric_Code'] = df['Product_Code'].str.extract('(\\d+)')"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix represented in Compressed Sparse Row (CSR) format, where I want to perform a matrix-vector multiplication with a dense vector. The sparse matrix and the dense vector are defined as follows:\n\n```python\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\ndata = np.array([1, 2, 3, 4])\nrow_indices = np.array([0, 0, 1, 2])\ncol_indices = np.array([0, 2, 2, 1])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 4))\ndense_vector = np.array([1, 0, 1, 0])\n```\n\nHow can I compute the result of multiplying this sparse matrix with the dense vector and store it as a result variable?\n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = sparse_matrix.dot(dense_vector)\n```"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame with a column 'product_info' that contains strings representing product details in the format: \"ProductName - Brand - Price\". For example:\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n\nI want to create a new DataFrame that extracts the 'ProductName' and 'Price' into separate columns while removing the 'Brand' from 'product_info'. If 'product_info' does not adhere to the expected format, I want it to remain unchanged.\n\nThe expected output is:\n\n  ProductName       Price\n0      Laptop   1200 USD\n1  Smartphone    999 USD\n2   Smartwatch    300 USD\n3      Laptop   1150 USD\n\nHere is my starting point:\n\n<code>\nimport pandas as pd\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n</code>\nnew_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnew_df = product_data['product_info'].str.extract(r'([^ -]+) - [^-]+ - (.+)')[0].rename('ProductName').to_frame().join(\n    product_data['product_info'].str.extract(r'[^ -]+ - [^-]+ - (.+)')[0].rename('Price')\n)\n</code>"
  },
  {
    "input": "### Problem\nI have a dataset containing daily sales data for products over a year. The data is in a DataFrame with two columns: 'Date' and 'Sales'. I would like to analyze trends by calculating a rolling average of sales over the past 7 days for each day in the DataFrame. \n\nHere's an example of what the DataFrame looks like:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', \n             '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10'],\n    'Sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nI want to create a new column 'Rolling_Avg' that contains the 7-day rolling average of sales. The first 6 entries should be NaN since there aren't 7 days to calculate the average yet.\n\nPlease fill in the blank with the appropriate solution.\n\n```python\ndf['Rolling_Avg'] = ...\n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "### Problem:\nI have a time series dataset represented in a Pandas DataFrame where the index is a datetime object. The DataFrame contains daily sales data for a store. I want to calculate a moving average of the sales over a 7-day window, and I also want to retain the original index format.\n\nHere is an example of the DataFrame structure:\n\n```\n             sales\ndate               \n2023-01-01    200\n2023-01-02    210\n2023-01-03    180\n2023-01-04    240\n2023-01-05    220\n2023-01-06    190\n2023-01-07    210\n2023-01-08    250\n2023-01-09    260\n2023-01-10    240\n```\n\nHow can I compute the moving average and save it in a new column named `moving_average` in the same DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'sales': [200, 210, 180, 240, 220, 190, 210, 250, 260, 240]}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\ndf['moving_average'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "## Problem:\nYou have a time series data containing daily stock prices for multiple companies in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': pd.date_range(start='2020-01-01', periods=10),\n        'CompanyA': [100, 102, 101, 103, 105, 107, 106, 108, 110, 111],\n        'CompanyB': [200, 198, 202, 201, 203, 205, 206, 204, 207, 203],\n        'CompanyC': [300, 303, 301, 299, 298, 300, 302, 303, 305, 306]}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nYour task is to calculate the daily percentage change of each company's stock prices relative to their previous day's closing prices. You want to save this as a new DataFrame. \n\nProvide the code to achieve this, filling in the blank below:\n\n```python\nresult = df.______\n```\n",
    "output": "\n```python\nresult = df.pct_change() * 100\n```"
  },
  {
    "input": "### Problem\nYou are given a Pandas DataFrame containing a column with mixed string formats. Your task is to extract the email addresses and count the number of unique email addresses in the 'contacts' column. Each entry in the 'contacts' column can contain multiple email addresses separated by commas.\n\nHere is a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'contacts': [\n        'john.doe@example.com, jane.doe@example.com',\n        'mary.jane@sample.com',\n        'user123@domain.com, john.doe@example.com',\n        'info@service.com, contact@company.org',\n        'invalid-email.com'\n    ]\n})\n```\n\nWrite the code to fill in the blank below that will create a new column 'unique_emails' in that DataFrame, containing the count of unique email addresses for each row.\n\n```python\ndf['unique_emails'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['unique_emails'] = df['contacts'].str.extractall(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})')[0].groupby(level=0).nunique()\n```"
  },
  {
    "input": "### Problem\nI have a dataset representing sales data with the following structure:\n\n```\n   Product    Quantity\n0  Widget A      10\n1  Widget B      5\n2  Widget A      3\n3  Widget C      6\n4  Widget B      7\n5  Widget A      4\n```\n\nI want to create a function that calculates the total quantity sold for each product and returns a DataFrame with the product names and their corresponding total quantities. The output should look like this:\n\n```\n   Product   Total Quantity\n0  Widget A             17\n1  Widget B             12\n2  Widget C              6\n```\n\nHere is what I have so far:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B', 'Widget A'],\n    'Quantity': [10, 5, 3, 6, 7, 4]\n}\n\ndf = pd.DataFrame(data)\n\ndef calculate_total_quantity(df):\n    result = ...  # put solution in this variable\n```\n\nFill in the blank to implement the function that produces the desired output.",
    "output": "\n```python\n    result = df.groupby('Product', as_index=False)['Quantity'].sum().rename(columns={'Quantity': 'Total Quantity'})\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing daily temperature readings as follows:\n\n```\n   Date         Temperature\n0  2022-01-01    30\n1  2022-01-02    28\n2  2022-01-03    32\n3  2022-01-04    35\n4  2022-01-05    29\n5  2022-01-06    31\n```\n\nYou need to calculate the 3-day rolling average temperature. The resulting DataFrame should include a new column for the rolling average, with the first two rows of the new column containing NaN values because there are not enough prior days to compute the average. Furthermore, you want to convert the Date column from a string format to a datetime format before performing the rolling average computation.\n\nThe expected resulting DataFrame should look like this:\n\n```\n   Date         Temperature  Rolling_Avg\n0  2022-01-01    30          NaN\n1  2022-01-02    28          NaN\n2  2022-01-03    32          30.0\n3  2022-01-04    35          31.0\n4  2022-01-05    29          32.0\n5  2022-01-06    31          31.0\n```\n\nHere is the current code snippet that you have, but it is incomplete:\n\n```\nimport pandas as pd\nimport numpy as np\n\ndata = {'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06'],\n        'Temperature': [30, 28, 32, 35, 29, 31]}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date']) \ndf['Rolling_Avg'] = df['Temperature']... # put solution in this variable\n```\n\nFill in the blank to calculate the 3-day rolling average for the temperature readings.",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataframe containing email addresses and I want to extract the username (the part before the '@') and the domain (the part after the '@') from the email addresses. The email addresses are in a column called 'email'. I also want to create a separate column that contains the length of the username. Here\u2019s a sample of my data:\n\n```\n   email\n0  john.doe@example.com\n1  jane_smith@company.org\n2  user123@domain.net\n3  test.user@web-service.com\n```\n\nI want to achieve the following structure:\n\n```\n   email                     username     domain           username_length\n0  john.doe@example.com     john.doe     example.com     8\n1  jane_smith@company.org   jane_smith   company.org     10\n2  user123@domain.net       user123      domain.net      7\n3  test.user@web-service.com test.user    web-service.com 9\n```\n\nHere\u2019s what I have tried so far:\n\n```python\ndf['username'] = df.email.replace(r'(.+)@.+', r'\\1', regex=True)\ndf['domain'] = df.email.replace(r'.+@(.+)', r'\\1', regex=True)\ndf['username_length'] = df.username.map(len)\n```\n\nBut it seems this approach does not work as expected. Can you provide the correct solution for the variables? \n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'email': ['john.doe@example.com', 'jane_smith@company.org', 'user123@domain.net', 'test.user@web-service.com']\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['username'] = df['email'].str.split('@').str[0]\ndf['domain'] = df['email'].str.split('@').str[1]\ndf['username_length'] = df['username'].str.len()\nresult = df\n```"
  },
  {
    "input": "### Problem\nYou have a dataset with multiple sales records, and you want to calculate the total sales per product while ensuring that the code is reusable for any product. You have a DataFrame `df` that contains sales data structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 300, 250, 400, 150, 300, 350],\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a function `calculate_total_sales(product)` that takes a product name as input and returns the total sales for that product. \n\nYour current implementation to call the function looks like this:\n\n```python\ntotal_sales_A = calculate_total_sales('A')\n```\n\nWhat do you need to fill in for the function `calculate_total_sales` to achieve this? \n\n<!-- The variable to put your solution inside -->\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>",
    "output": "\n```python\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a pandas dataframe containing sales data for different products over multiple months. Here is the initial setup:\n\n```python\nimport pandas as pd\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n    'Month': ['2022-01', '2022-02', '2022-01', '2022-02', '2022-01', '2022-02', '2022-01', '2022-02'],\n    'Sales': [100, 150, 200, 250, 300, 350, 400, 450]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a function called `add_sales_totals` that takes a dataframe as input and adds a new column that contains the total sales for each product across all months. The resulting dataframe should look like this:\n\n```\n  Product    Month  Sales  Total_Sales\n0       A  2022-01    100           250\n1       A  2022-02    150           250\n2       B  2022-01    200           450\n3       B  2022-02    250           450\n4       C  2022-01    300           650\n5       C  2022-02    350           650\n6       D  2022-01    400           850\n7       D  2022-02    450           850\n```\n\nYou can assume the `add_sales_totals` function will be called like this:\n\n```python\nresult_df = add_sales_totals(df)\n```\n\nPlease provide the code to define the `add_sales_totals` function that accomplishes this task. \n```python\ndef add_sales_totals(df):\n    ...\n```",
    "output": "\n```python\ndef add_sales_totals(df):\n    total_sales = df.groupby('Product')['Sales'].transform('sum')\n    df['Total_Sales'] = total_sales\n    return df\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix representing the features of a set of textual documents, where each row corresponds to a document and each column corresponds to a unique word. The entries of the matrix are counts of how many times each word appears in each document. Additionally, I have a list of word indices that I want to extract from the matrix into a new dense matrix. \n\nGiven the sparse matrix `X` (in the form of a COO format) and a list of word indices `word_indices`, how can I create a dense matrix `D` that retains only the columns indicated by `word_indices`? The shape of `D` should be `(num_documents, len(word_indices))`.\n\nFor instance, if `X` is defined as:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\n```\n\nAnd the `word_indices` is `[0, 2]`, the desired output for `D` should look like this:\n\n```\n[[0 3]\n [2 0]]\n```\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Given sparse matrix X\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\nword_indices = [0, 2]  # List of indices to extract\n\n# Convert X to a dense format and extract necessary columns\nD = ... # put solution in this variable\n### BEGIN SOLUTION\n```",
    "output": "\n<code>\nD = X[:, word_indices].toarray()\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales of a product over several months, stored in a DataFrame with two columns: 'Date' and 'Sales'. The 'Date' column contains dates in the format 'YYYY-MM-DD', and the 'Sales' column contains the number of products sold on that date. \n\nI need to calculate a moving average of the sales over a 7-day window, ensuring that if there are any gaps in the dates (missing days), those entries are filled with NaN. The result should include the original date and the corresponding moving average in a new DataFrame.\n\nHere's how the DataFrame looks:\n\n```\n          Date    Sales\n0   2023-01-01      10\n1   2023-01-02      15\n2   2023-01-05      25\n3   2023-01-06      20\n4   2023-01-08      30\n5   2023-01-09      40\n```\n\nWhat I'm struggling with is how to properly apply the moving average while handling the missing dates. \nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-06', '2023-01-08', '2023-01-09'],\n                   'Sales': [10, 15, 25, 20, 30, 40]})\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.set_index('Date').asfreq('D')  # Fill missing dates with NaN\nresult = df.assign(Moving_Average=df['Sales'].rolling(window=7).mean()).reset_index()\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains a column of addresses in the following format:\n```plaintext\naddress\n123 Main St, Springfield, IL 62704\n456 Elm St, Smalltown, TX 75000\n789 Oak Ave, Metropolis, NY\n101 Pine Ln, Gotham City, NJ 07001\n```\nI want to extract the street name and city into two separate columns. The final DataFrame should look like this:\n```plaintext\n     street_name        city\n0   123 Main St  Springfield\n1    456 Elm St    Smalltown\n2     789 Oak Ave   Metropolis\n3   101 Pine Ln   Gotham City\n```\nI've tried using regular expressions, but I'm struggling to properly extract these parts. Here's what I have so far:\n```python\nimport pandas as pd\n\ndata = {'address': ['123 Main St, Springfield, IL 62704',\n                    '456 Elm St, Smalltown, TX 75000',\n                    '789 Oak Ave, Metropolis, NY',\n                    '101 Pine Ln, Gotham City, NJ 07001']}\ndf = pd.DataFrame(data)\n```\nWhat should I fill in for the code to achieve this output?\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['street_name', 'city']] = df['address'].str.extract(r'([^,]+),\\s*([^,]+),?\\s*[A-Z]{2}\\s*\\d{0,5}')\nresult = df[['street_name', 'city']]\n</code>"
  },
  {
    "input": "Problem:\nI am working with high-dimensional images and need to perform an operation on a sparse tensor. Specifically, I want to compute the sum of values along the last axis for a 3D sparse tensor representation of images (channels, height, width) using PyTorch. My sparse tensor is created as follows:\n\n```python\nimport torch\nfrom torch.sparse import FloatTensor\n\nindices = torch.tensor([[0, 0, 1], [0, 2, 1]])\nvalues = torch.tensor([3.0, 4.0, 5.0])\nsparse_tensor = FloatTensor(indices, values, size=(2, 3, 3))\n```\n\nI need to fill in the blank to compute the sum across the last axis, resulting in a 2D tensor where each row corresponds to the sum of each channel for all positions in the height and width dimensions.\n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = sparse_tensor.sum(dim=-1).to_dense()\nEND SOLUTION\n```"
  },
  {
    "input": "## Problem\nYou have a dataset where a column named `full_address` contains various address strings with inconsistent formatting, including extra spaces, abbreviations, and missing commas. Your goal is to clean up this column by performing the following transformations:\n\n1. Remove any leading and trailing white spaces.\n2. Replace abbreviations (e.g., \"St\" with \"Street\", \"Ave\" with \"Avenue\", \"Rd\" with \"Road\").\n3. Ensure that each address string has a comma between the street address and the city name, if it isn't already present.\n\nFor example, the original `full_address` data is:\n```\n\" 123 Main St  , Springfield \"\n\"456 Elm Ave,  Greenfield\"\n\"789 Broadway Rd  Springfield\"\n\"1010 Oak St  NewYork \"\n```\n\nWrite the code that correctly transforms the `full_address` column in the pandas DataFrame.\n\n```python\nimport pandas as pd\n\ndata = {'full_address': [\" 123 Main St  , Springfield \",\n                         \"456 Elm Ave,  Greenfield\",\n                         \"789 Broadway Rd  Springfield\",\n                         \"1010 Oak St  NewYork \"]}\n\ndf = pd.DataFrame(data)\n```\n\nYour solution should create a new column called `cleaned_address` that contains the cleaned-up versions of the addresses.\n\n```python\ndf['cleaned_address'] = ...\n# Fill in the '...' with the correct solution\n```",
    "output": "\n```python\ndf['cleaned_address'] = df['full_address'].str.strip() \\\n    .str.replace(r'\\bSt\\b', 'Street', regex=True) \\\n    .str.replace(r'\\bAve\\b', 'Avenue', regex=True) \\\n    .str.replace(r'\\bRd\\b', 'Road', regex=True) \\\n    .str.replace(r'\\s*,\\s*', ', ', regex=True) \\\n    .str.replace(r'\\s+', ' ', regex=True) \\\n    .str.replace(r',\\s*$', '', regex=True)\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains student grades in different subjects, which may contain some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Math': [90, 80, np.nan, 85, np.nan],\n    'Science': [np.nan, 90, 95, np.nan, 85],\n    'English': [80, np.nan, 85, 90, 80]\n}\ndf = pd.DataFrame(data)\n```\n\nYour goal is to create new columns that represent the average grade of each student across the subjects only for the grades that are available (i.e., not NaN). The intended output should look like this:\n\n```\n   Math  Science  English  Average\n0  90.0      NaN     80.0     85.0\n1  80.0     90.0      NaN     85.0\n2   NaN     95.0     85.0     90.0\n3  85.0      NaN     90.0     87.5\n4   NaN     85.0     80.0     82.5\n```\n\nTo achieve this, you want to use a custom function that calculates the average grade for each student while skipping the missing values. Please fill in the blank where `df['Average']` is created based on your custom function.\n\nA:\n```python\ndf['Average'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Average'] = df.mean(axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI'm building a neural network using TensorFlow to classify images from the CIFAR-10 dataset. After training the model, I want to get the predicted probabilities for a batch of images and find the class with the highest probability for each image. My model outputs a tensor with shape (batch_size, 10), where each entry represents the predicted probabilities for each class (0 to 9).\n\nGiven a tensor 'predictions' containing these probabilities, how can I extract a tensor of shape (batch_size, 1) where each entry is the index of the class with the highest probability?\n\nA:\n\n```python\nimport tensorflow as tf\npredictions = load_data()  # let's assume this returns a tensor with shape (batch_size, 10)\n```\nclass_indices = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nclass_indices = tf.argmax(predictions, axis=1, output_type=tf.int32)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing columns with customer feedback where each feedback entry has a customer ID and a review message combined together in a single string. I would like to separate the customer ID and the review message into two different columns named 'Customer ID' and 'Review'. The current DataFrame looks like this:\n\n```\nfeedback\n0  101:Great service, loved the experience!\n1  102:Not satisfied, could be better.\n2  103:Excellent support, very helpful.\n3  104:Horrible experience, would not recommend.\n4  105:Decent food, but the service was slow.\n```\n\nI want to extract the numerical part (customer ID) and everything after the colon (the review message) into their respective new columns. How can I achieve that?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'feedback': ['101:Great service, loved the experience!', \n                                 '102:Not satisfied, could be better.', \n                                 '103:Excellent support, very helpful.', \n                                 '104:Horrible experience, would not recommend.', \n                                 '105:Decent food, but the service was slow.']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['Customer ID', 'Review']] = df['feedback'].str.split(':', expand=True)"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily temperature data for a city over several months, structured like this:\n\n```\n          Date        Temperature\n0   2023-01-01        15.0\n1   2023-01-02        16.5\n2   2023-01-03        15.5\n3   2023-02-01        14.0\n4   2023-02-02        13.5\n5   2023-03-01        16.0\n6   2023-03-02        18.0\n7   2023-03-03        17.5\n```\n\nI want to calculate the rolling average temperature over a window of 7 days and then return the DataFrame with an additional column showing these rolling averages. The resulting DataFrame should look like this:\n\n```\n          Date        Temperature  Rolling_Avg\n0   2023-01-01        15.0            NaN\n1   2023-01-02        16.5            NaN\n2   2023-01-03        15.5            NaN\n3   2023-02-01        14.0            NaN\n4   2023-02-02        13.5            NaN\n5   2023-03-01        16.0          15.2\n6   2023-03-02        18.0          15.8\n7   2023-03-03        17.5          16.5\n```\n\nI've started by creating the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', \n                 '2023-02-01', '2023-02-02', '2023-03-01', \n                 '2023-03-02', '2023-03-03'], \n        'Temperature': [15.0, 16.5, 15.5, 14.0, 13.5, 16.0, 18.0, 17.5]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, I need to compute the rolling average. Can you help me fill in the blank in this code?\n```python\ndf['Rolling_Avg'] = df['Temperature'].___(window=7)\n```\nBEGIN SOLUTION\n<code>rolling</code>",
    "output": "\n<code>rolling</code>"
  },
  {
    "input": "## Problem\nI have a dataset that records the daily temperatures of a city over several years. The data is in a pandas DataFrame with two columns: `Date` and `Temperature`. I want to resample this DataFrame to get the average temperature for each month, and then calculate the rolling average of these monthly averages over a window of 3 months.\n\nThe format of the DataFrame is as follows:\n```\n        Date       Temperature\n0  2018-01-01         5.0\n1  2018-01-02         4.5\n2  2018-01-03         5.5\n3  2018-02-01         6.5\n4  2018-02-02         7.0\n...\n```\nAfter performing the resampling and rolling average calculation, I would like to see the output that only shows the `Date` (as the first day of the month) and the rolling average `Temperature`.\n\nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\n# Sample DataFrame\ndf = pd.DataFrame({\n        'Date': pd.date_range(start='2018-01-01', periods=90, freq='D'),\n        'Temperature': [5.0, 4.5, 5.5, 6.5, 7.0] * 18\n})\n\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmonthly_avg = df.resample('M').mean()\nrolling_avg = monthly_avg.rolling(window=3).mean()\nresult = rolling_avg.reset_index().rename(columns={'Date': 'Date', 'Temperature': 'Rolling_Avg_Temperature'})\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of strings where each string includes a person's full name in the format \"Last, First\". I want to split this column into two new columns: one for the first name and one for the last name. However, I noticed that some names also have a middle name or initial included, and I only want the first name to be extracted, regardless of its presence. \n\nHere\u2019s how my DataFrame looks:\n```\n    Names\n0  Smith, John A.\n1  Doe, Jane\n2  Johnson, Emily R.\n```\nI want to achieve a DataFrame that looks like this:\n```\n    First Name    Last Name\n0      John         Smith\n1      Jane         Doe\n2      Emily        Johnson\n```\nI have the following code, but I am struggling to properly extract the first and last names:\n```\ndf[['Last Name', 'First Name']] = df['Names'].str.split(',', expand=True)\n```\nThis splits the Last and First names but includes the middle name with the first name. How can I just get the first name?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Names': ['Smith, John A.', 'Doe, Jane', 'Johnson, Emily R.']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['Names'].str.split(',', expand=True)\nresult.columns = ['Last Name', 'First Name']\nresult['First Name'] = result['First Name'].str.split().str[0]\n</code>"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple neural network using TensorFlow. You have a dataset consisting of two features and a binary label indicating whether an instance belongs to class 0 or class 1. After preprocessing your data, you obtain two tensors: `X` of shape (1000, 2) representing the features and `y` of shape (1000, 1) representing the labels. \n\nYou want to create a model that has one hidden layer with 10 units and uses the ReLU activation function. Following model instantiation, your goal is to compile the model with binary cross-entropy loss and the Adam optimizer.\n\nHere is your existing code:\n\n```python\nimport tensorflow as tf\n\n# Load your dataset\nX, y = load_data() \n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(10, activation='...'))  # Fill this blank\n```\n\nWhat should you put in place of the `...` to correctly define the activation function for the hidden layer? \n\nA:\n\n<code>\nmodel.add(tf.keras.layers.Dense(10, activation='...')) # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel.add(tf.keras.layers.Dense(10, activation='relu'))  # Fill this blank\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame with historical daily sales data for a retail store, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2022-01-01', periods=10),\n    'sales': [200, 220, 250, 270, 300, 290, 310, 320, 310, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the rolling average of the sales over a 3-day window and create a new column called `rolling_average` to store these values. However, there should be NaN values for the first two rows as there isn't enough data to compute the average. What would be the appropriate line of code to achieve this rolling average calculation?\n\n```python\ndf['rolling_average'] = ...\n```\n",
    "output": "\n```python\ndf['rolling_average'] = df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou are working with a pandas DataFrame containing daily sales data for a retail store over several months. The DataFrame is structured with date indices and a column for sales figures. Here is a snippet of the data:\n\n```\n                Sales\nDate                 \n2023-01-01    1500\n2023-01-02    1800\n2023-01-03    1700\n2023-01-04    1600\n2023-01-05    1750\n2023-01-06    2000\n2023-01-07    2200\n```\n\nYou want to compute a rolling average of the sales figures over the last 3 days, but you want to include only the sales figures from complete weeks. For example, if there aren't 7 days to form a complete week, the average for that week should not be calculated. \n\nHow would you write the code to achieve this?\n\n<code>\nimport pandas as pd\n\ndata = {'Sales': [1500, 1800, 1700, 1600, 1750, 2000, 2200]}\nindex = pd.date_range(start='2023-01-01', periods=len(data['Sales']))\ndf = pd.DataFrame(data, index=index)\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.resample('W').sum().rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing product descriptions, and I want to extract the brand name and product type from a \"description\" column. The descriptions follow the format \"Brand: [brand name], Type: [product type]\". I would like to create two new columns: \"brand\" and \"type\" filled with the corresponding values.\n\nHere's the DataFrame I have:\n```python\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\n\nWhat is the correct code to parse the \"description\" column and create the new \"brand\" and \"type\" columns?\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\nproduct_df[['brand', 'type']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nproduct_df[['brand', 'type']] = product_df['description'].str.extract(r'Brand: (.*?), Type: (.*)')\n```"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing daily sales data for a store, with the following structure:\n\n```python\nsales_data = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05', '2023-01-07'],\n    'sales': [200, 220, 180, 300, 230]\n})\n```\n\nYou need to fill in the missing dates between the first and last date available in your DataFrame and assume that there were no sales (sales = 0) on those missing days. After that, you should create a new column 'cumulative_sales' that contains the cumulative sales up to each date including those with missing dates.\n\nYour desired output after processing should look like this:\n\n```\n        date  sales  cumulative_sales\n0 2023-01-01    200                200\n1 2023-01-02    220                420\n2 2023-01-03      0                420\n3 2023-01-04    180                600\n4 2023-01-05    300                900\n5 2023-01-06      0                900\n6 2023-01-07    230               1130\n```\n\nProvide the code to fill in the blank below to achieve this:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05', '2023-01-07'],\n    'sales': [200, 220, 180, 300, 230]\n})\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nfull_date_range = pd.date_range(start=sales_data['date'].min(), end=sales_data['date'].max())\nresult = sales_data.set_index('date').reindex(full_date_range, fill_value=0).reset_index()\nresult.columns = ['date', 'sales']\nresult['cumulative_sales'] = result['sales'].cumsum()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains daily temperature recordings as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n        'Temperature': [30, 32, None, 29, 31]}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the missing temperature value on '2023-01-03' by taking the average of the temperatures before and after it, rounding to the nearest whole number. Then, provide the DataFrame with the filled values in order of their dates.\n\nThe expected output should look like this:\n\n```python\n        Date  Temperature\n0 2023-01-01          30.0\n1 2023-01-02          32.0\n2 2023-01-03          30.0\n3 2023-01-05          29.0\n4 2023-01-06          31.0\n```\n\nYou are currently getting the DataFrame like this:\n```python\ndf['Temperature'].fillna(...) \n```\nFill in the blank to complete the code that accurately replaces the missing temperature value:\n\nresult = ...  # put solution in this variable",
    "output": "\n```python\nresult = df['Temperature'].fillna(round((df['Temperature'].shift(1) + df['Temperature'].shift(-1)) / 2))\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing product descriptions in the following format:\nproduct_df = pd.DataFrame({'description':['Laptop - Intel i7 - 16GB RAM - 512GB SSD', \n                                           'Smartphone - Snapdragon 888 - 128GB Storage', \n                                           'Tablet - Apple M1 - 8GB RAM', \n                                           'Monitor - 27\" - 144Hz - 1ms Response']})\n\nI want to separate the description into columns 'product_type', 'processor', 'memory', and 'storage' where applicable. The final DataFrame should look like this:\n\n  product_type                processor     memory      storage\n0     Laptop                 Intel i7      16GB RAM    512GB SSD\n1   Smartphone             Snapdragon 888    128GB Storage   NaN\n2       Tablet                    Apple M1        8GB RAM           NaN\n3     Monitor                         NaN         NaN           NaN\n\nI've been trying to accomplish this by utilizing regular expressions to extract the necessary parts of the description, but I'm having difficulty structuring the logic to handle cases where certain components might be missing. Here's what I've come up with so far:\n\ndef extract_product_info(description: str) -> tuple:\n    # Extraction logic would go here\n    pass\n\nAny guidance on how to effectively implement this function and apply it to the DataFrame would be appreciated!\n\nA:\n<code>\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'description':['Laptop - Intel i7 - 16GB RAM - 512GB SSD', \n                                           'Smartphone - Snapdragon 888 - 128GB Storage', \n                                           'Tablet - Apple M1 - 8GB RAM', \n                                           'Monitor - 27\" - 144Hz - 1ms Response']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nimport re\n\ndef extract_product_info(description: str) -> tuple:\n    pattern = r'(?P<product_type>[\\w\\s]+) - (?P<processor>[\\w\\s]+(?:\\d+)?(?:\\s\\w+)?(?:\\s\\w+)?)?(?: - (?P<memory>\\d+\\s\\w+))?(?: - (?P<storage>[\\d\\w\\s]+))?'\n    match = re.match(pattern, description)\n    if match:\n        return match.group('product_type'), match.group('processor'), match.group('memory'), match.group('storage')\n    return None, None, None, None\n\nproduct_df[['product_type', 'processor', 'memory', 'storage']] = product_df['description'].apply(extract_product_info).apply(pd.Series)\ndf = product_df\n```"
  },
  {
    "input": "Problem:\nYou are working with a historical weather dataset that contains daily temperature records. The dataset is represented as a Pandas DataFrame with a datetime index and a single column called 'temperature' that holds the recorded temperatures in degrees Celsius. You want to calculate the rolling average of the temperature over a given 7-day window.\n\nHere is an example of your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'temperature': [22, 21, 19, 23, 30, 18, 26, 28, 27, 24, 25, 20, 21]\n}\ndates = pd.date_range(start='2023-01-01', periods=len(data['temperature']), freq='D')\ndf = pd.DataFrame(data, index=dates)\n```\n\nTo compute the rolling average for the temperature over a 7-day window, you can use the `rolling()` method. Complete the following line of code to store the result in a new column called 'rolling_avg' in the DataFrame.\n\n```python\ndf['rolling_avg'] = ...\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['rolling_avg'] = df['temperature'].rolling(window=7).mean()"
  },
  {
    "input": "## Problem:\nYou have a 2D tensor representing image data in PyTorch, where each element represents a pixel value. The tensor shape is `(batch_size, height, width)`. You want to normalize the pixel values in the tensor to a range between 0 and 1 using Min-Max normalization. Specifically, the normalization formula you want to apply is:\n\n\\[ \\text{normalized\\_value} = \\frac{\\text{value} - \\text{min}}{\\text{max} - \\text{min}} \\]\n\nHow can you perform this operation on a given tensor `image_tensor` using PyTorch? \n\nA:\n```python\nimport torch\n\nimage_tensor = load_data()  # Assume this gives a tensor of shape (batch_size, height, width)\nmin_val = image_tensor.min()\nmax_val = image_tensor.max()\n# Fill in the blank below to get the normalized image tensor\nnormalized_image = ...  # put solution in this variable\n```",
    "output": "\n```python\nnormalized_image = (image_tensor - min_val) / (max_val - min_val)\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user interactions in a recommendation system using PyTorch. The sparse matrix is defined by its indices and values, such as:\n\n```python\nindices = torch.tensor([[0, 1, 1], [0, 2, 0]])\nvalues = torch.tensor([5.0, 3.0, 4.0])\n```\n\nThis signifies that user 0 interacted with item 0 with a score of 5.0, user 1 interacted with item 2 with a score of 3.0, and user 1 interacted with item 0 with a score of 4.0. \n\nHow can you construct a dense tensor `interaction_matrix` of shape (2, 3) from the sparse representation while filling the missing interactions with zeros?\n\nA:\n```python\nimport torch\n\nindices = torch.tensor([[0, 1, 1], [0, 2, 0]])\nvalues = torch.tensor([5.0, 3.0, 4.0])\n```\ninteraction_matrix = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ninteraction_matrix = torch.zeros((2, 3))\ninteraction_matrix[indices[0], indices[1]] = values\n```"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame containing a column with product descriptions and I need to clean it up. Here is the DataFrame I started with:\n\n```\n                   description\n0  The red dress @Fashionista #Style2023\n1  New shoes -Available Now! #ShopHere\n2  Summer sale (50% OFF!) --> Dress4Less\n3  Check out our @store for new arrivals! \n```\n\nI want to extract only the alphanumeric words and keep everything as lowercase, resulting in the following cleaned column:\n\n```\n             cleaned_description\n0      the red dress fashionista style2023\n1          new shoes available now shophere\n2            summer sale 50 off dress4less\n3           check out our store for new arrivals \n```\n\nThe current code I have only returns the original descriptions without cleaning them properly. \n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'description': [\n        'The red dress @Fashionista #Style2023',\n        'New shoes -Available Now! #ShopHere',\n        'Summer sale (50% OFF!) --> Dress4Less',\n        'Check out our @store for new arrivals!'\n    ]\n})\n\ndf['cleaned_description'] = ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['cleaned_description'] = df['description'].str.lower().str.replace(r'[^a-z0-9\\s]', '', regex=True)"
  },
  {
    "input": "Problem:\n\nI am working with a sparse tensor representation of a high-dimensional dataset where many values are zero. I have a sparse tensor of shape (3, 4, 5) that I want to convert into a dense representation, but it only contains a few non-zero elements. How can I correctly convert this sparse tensor back to a dense tensor while preserving only the non-zero values and their respective indices?\n\nHere is the setup for my sparse tensor:\n\n```python\nimport torch\n\n# Assume this is the sparse tensor with the same shape\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 1, 2], [0, 2, 3]]),\n    values=torch.tensor([3.0, 4.0, 5.0]),\n    size=(3, 4, 5)\n)\n```\n\nI would like to produce a dense tensor and store it in the variable `dense_tensor` as follows:\n\nA:\n\n```python\ndense_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\ndense_tensor = sparse_tensor.to_dense()\n```"
  },
  {
    "input": "Problem:\nYou have a list of dictionaries representing sales data from a store. Each dictionary contains information about the product sold, quantity sold, and price per unit. You want to implement a function that calculates the total revenue generated for each product and returns a list of dictionaries with the product name and the calculated total revenue.\n\nFor example:\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nYour desired output should be:\n[\n    {'product': 'apple', 'total_revenue': 19.5},\n    {'product': 'banana', 'total_revenue': 3.75},\n    {'product': 'orange', 'total_revenue': 8.0}\n]\n\nDefine your function below:\n<code>\ndef calculate_revenue(sales_data):\n    revenue_dict = {}\n    for sale in sales_data:\n        product = sale['product']\n        total = sale['quantity'] * sale['price_per_unit']\n        # Your code here\n    return [{'product': product, 'total_revenue': revenue} for product, revenue in revenue_dict.items()]\n\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n        if product in revenue_dict:\n            revenue_dict[product] += total\n        else:\n            revenue_dict[product] = total\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of email addresses, and I need to extract the usernames (the part before the '@') and create a new column for them. Here's the DataFrame I have:\n\n```\n      Email\n0  john.doe@example.com\n1  jane.smith@website.org\n2  test.user123@gmail.com\n3  sample@domain.com\n```\n\nI want to create a new column called 'Username' that contains just the usernames extracted from the 'Email' column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Email': ['john.doe@example.com', 'jane.smith@website.org', 'test.user123@gmail.com', 'sample@domain.com']})\n</code>\ndf['Username'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Username'] = df['Email'].str.split('@').str[0]"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing hourly temperature readings for a city over several days. The DataFrame looks like this:\n\n```\n+---------------------+----------+\n|       Timestamp     | Temperature |\n+---------------------+----------+\n| 2023-01-01 00:00:00 |     30   |\n| 2023-01-01 01:00:00 |     32   |\n| 2023-01-01 02:00:00 |     33   |\n| 2023-01-02 00:00:00 |     31   |\n| 2023-01-02 01:00:00 |     35   |\n| 2023-01-02 02:00:00 |     36   |\n| 2023-01-03 00:00:00 |     34   |\n| 2023-01-03 01:00:00 |     32   |\n| 2023-01-03 02:00:00 |     30   |\n+---------------------+----------+\n```\n\nYou want to calculate the daily average temperature and create a new DataFrame that summarizes this data. The resulting DataFrame should have a 'Date' column and an 'Average Temperature' column. What code can you use to achieve this?\n\n```\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00',\n        '2023-01-03 00:00:00', '2023-01-03 01:00:00', '2023-01-03 02:00:00'\n    ],\n    'Temperature': [30, 32, 33, 31, 35, 36, 34, 32, 30]\n}\n\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\ndf.set_index('Timestamp', inplace=True)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.resample('D').mean().reset_index()\nresult['Date'] = result['Timestamp'].dt.date\nresult = result[['Date', 'Temperature']].rename(columns={'Temperature': 'Average Temperature'})\n```"
  },
  {
    "input": "Problem:\nSuppose you have a pandas DataFrame that contains product reviews with metadata. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review_text': [\n        'I love the coffee! It is great, good smell.',\n        'The tea was okay, not the best, I prefer another brand.',\n        'Fantastic chocolate flavor, would definitely buy again!',\n        'I really disliked the texture and the taste.'\n    ],\n    'rating': [5, 3, 4, 1]\n})\n```\n\nYou want to extract keywords (nouns) from the review_text column and create a new column called keywords that concatenates these keywords using a comma as a separator. For this demonstration, you can consider keywords as the words with lengths greater than 3 characters. You can create a simple function to filter and join these keywords.\n\nHere's where you're stuck. You want to apply this custom keyword extraction function to each review and populate the keywords column accordingly.\n\n```python\ndef extract_keywords(text):\n    # Replace this comment with your logic to extract words longer than 3 characters\n    pass\n\ndf['keywords'] = df['review_text'].apply( ... ) # fill in the blank to complete the DataFrame modification\n```\n\nFill in the blank to complete the code that applies your function to the review_text and updates the keywords column in the DataFrame.",
    "output": "\n```python\ndef extract_keywords(text):\n    return ', '.join([word for word in text.split() if len(word) > 3])\n\ndf['keywords'] = df['review_text'].apply(extract_keywords)\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset in a DataFrame with two columns: \"Timestamp\" and \"Temperature\". The \"Timestamp\" column contains timestamps at minute intervals and the \"Temperature\" column contains temperature readings in Celsius. I need to calculate the rolling average temperature over a 5-minute window and create a new column \"Rolling_Avg\" to store these averages.\n\nHere is the initial DataFrame:\n\n```\n  Timestamp           Temperature\n0 2023-10-01 00:00:00      20.3\n1 2023-10-01 00:01:00      21.0\n2 2023-10-01 00:02:00      20.8\n3 2023-10-01 00:03:00      19.9\n4 2023-10-01 00:04:00      20.1\n5 2023-10-01 00:05:00      20.6\n6 2023-10-01 00:06:00      21.2\n7 2023-10-01 00:07:00      21.1\n8 2023-10-01 00:08:00      20.8\n9 2023-10-01 00:09:00      20.5\n```\n\nYou can achieve this with a rolling average function. Here's how you can fill in the blank for the creation of the \"Rolling_Avg\" column:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': pd.date_range(start='2023-10-01', periods=10, freq='T'),\n    'Temperature': [20.3, 21.0, 20.8, 19.9, 20.1, 20.6, 21.2, 21.1, 20.8, 20.5]\n})\n\ndf['Rolling_Avg'] = ...\n```\n\ndf = ... # put solution in this variable  \nBEGIN SOLUTION\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window='5T').mean()\n</code>",
    "output": "\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window='5T').mean()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch and have the following prediction tensor from your model:\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\nEach row in the predictions tensor represents the probabilities of three classes for a batch of four examples. Your goal is to convert these probabilities into predicted class indices, which means identifying the index of the highest probability in each row. \n\nHow would you fill in this code to achieve this?\n\n```python\nimport torch\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\npredicted_classes = ... # fill in with the correct code to get the index of max probability in each row\n```\n",
    "output": "\n```python\npredicted_classes = torch.argmax(predictions, dim=1)\n```"
  },
  {
    "input": "Problem:\n\nYou have a pandas DataFrame that contains daily sales data for a store over a period of time, structured as follows:\n\n```plaintext\nID   date       sales\n1    2022-01-01 100\n2    2022-01-02 150\n3    2022-01-01 200\n4    2022-01-03 250\n5    2022-01-03 100\n6    2022-01-04 300\n```\n\nYou want to analyze the total sales by day, where if multiple entries exist for the same date, they should be summed together. Your goal is to compute this total and output a new DataFrame containing the unique dates and their corresponding total sales.\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ID': [1, 2, 3, 4, 5, 6],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-01', '2022-01-03', '2022-01-03', '2022-01-04'],\n    'sales': [100, 150, 200, 250, 100, 300]\n})\n\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nThe result should be a DataFrame `result` that contains the total sales for each unique date:\n\n```plaintext\n        date  total_sales\n0 2022-01-01          300\n1 2022-01-02          150\n2 2022-01-03          350\n3 2022-01-04          300\n```\n\nFill in the missing part of the code to achieve this.\n\n```python\nresult = df.groupby('date').agg(total_sales=('sales', 'sum')).reset_index()\n```",
    "output": "\n```python\nresult = df.groupby('date').agg(total_sales=('sales', 'sum')).reset_index()\n```"
  },
  {
    "input": "Problem:\nI have a dataset where I want to predict house prices based on certain features. I have a PyTorch tensor that represents the features of the houses:\n\ntensor([[1500, 3, 2], \n        [1200, 2, 1], \n        [1800, 4, 3], \n        [2000, 4, 2]])\n\nI also have the corresponding prices in a NumPy array:\n\n[300000, 250000, 400000, 450000]\n\nI would like to create a linear regression model using PyTorch to predict house prices from these features. However, I need to reshape my features tensor to be compatible for model training. Specifically, I need to add a new dimension to the tensor so that its shape changes from (4, 3) to (4, 3, 1).\n\nHere's the starting code:\n\n<code>\nimport torch\nimport numpy as np\n\nfeatures = torch.tensor([[1500, 3, 2], \n                          [1200, 2, 1], \n                          [1800, 4, 3], \n                          [2000, 4, 2]])\nprices = np.array([300000, 250000, 400000, 450000])\n</code>\nreshaped_features = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>reshaped_features = features.unsqueeze(-1)</code>"
  },
  {
    "input": "Problem:\n\nI'm working with a dataset where I need to preprocess the images into a normalized format for training a neural network using TensorFlow. The images are represented as a 4D tensor with the shape [batch_size, height, width, channels]. I want to normalize the pixel values of these images to be in the range [0, 1]. For this, I need to divide all pixel values by 255. \n\nGiven a tensor representing a batch of images:\n\n```python\nimages = tf.constant([[[[0, 128, 255], [255, 128, 0]], \n                        [[0, 255, 128], [128, 0, 255]]],\n                       \n                       [[[128, 0, 255], [255, 255, 0]], \n                        [[255, 128, 128], [0, 0, 0]]]])\n```\n\nHow can I normalize this tensor so that the pixel values are in the range [0, 1]?\n\nA:\n```python\nimport tensorflow as tf\n\nimages = tf.constant([[[[0, 128, 255], [255, 128, 0]], \n                        [[0, 255, 128], [128, 0, 255]]],\n                       \n                       [[[128, 0, 255], [255, 255, 0]], \n                        [[255, 128, 128], [0, 0, 0]]]])\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nnormalized_images = images / 255.0\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset containing timestamps and sales transactions in a DataFrame:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   100\n1 2023-01-01 10:05:00   150\n2 2023-01-01 10:10:00   200\n3 2023-01-01 10:15:00   50\n4 2023-01-01 10:20:00   300\n5 2023-01-01 10:40:00   120\n6 2023-01-01 10:50:00   180\n7 2023-01-01 11:00:00   250\n```\n\nWhat I want to achieve is resampling this data to 15-minute intervals and calculating the sum of sales for each interval. If there are any intervals with no sales data, they should still appear in the final output with a sales value of 0.\n\nThe desired output format should look like this:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   450\n1 2023-01-01 10:15:00   0\n2 2023-01-01 10:30:00   0\n3 2023-01-01 10:45:00   180\n4 2023-01-01 11:00:00   250\n```\n\nHere's the starting point of the code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': ['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:10:00', \n                  '2023-01-01 10:15:00', '2023-01-01 10:20:00', '2023-01-01 10:40:00', \n                  '2023-01-01 10:50:00', '2023-01-01 11:00:00'],\n    'Sales': [100, 150, 200, 50, 300, 120, 180, 250]\n})\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYour task is to fill in the blank to complete the code for the resampling and summing of sales:\n\n```python\ndf.set_index('Timestamp', inplace=True)\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = df.resample('15T').sum().fillna(0).reset_index()\ndf['Sales'] = df['Sales'].astype(int)\n```"
  },
  {
    "input": "Problem:\nI have the following DataFrame with a column containing URLs that include user IDs. Here\u2019s how the DataFrame looks:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nI want to extract the user IDs from the URLs in the 'url' column and create a new column called 'user_id' that contains only these IDs. If there is no user ID in the URL, the new column should contain `NaN`.\n\nHere\u2019s the DataFrame before extraction:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nAfter extraction, the new DataFrame should look like this:\n\n```\n        url                user_id\n0  https://example.com/user/12345/profile   12345\n1  https://example.com/user/67890/dashboard  67890\n2  https://example.com/page/abc/def         NaN\n3  https://example.org/user/54321           54321\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'url': ['https://example.com/user/12345/profile',\n                 'https://example.com/user/67890/dashboard',\n                 'https://example.com/page/abc/def',\n                 'https://example.org/user/54321']}\ndf = pd.DataFrame(data)\n</code>\ndf['user_id'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['user_id'] = df['url'].str.extract(r'user/(\\d+)')\n</code>"
  }
]