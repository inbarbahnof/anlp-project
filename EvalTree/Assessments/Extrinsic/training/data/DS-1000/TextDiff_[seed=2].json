[
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am implementing a custom loss function for a regression task using the Mean Absolute Percentage Error (MAPE) as it gives more interpretation on percentage error. My model predicts outputs (e.g., `y_pred`), and I have the true target values (e.g., `y_true`). The MAPE is given by the formula: \n\n$$ MAPE = \\frac{100}{N} \\sum_{i=1}^{N} \\left| \\frac{y_{true}^i - y_{pred}^i}{y_{true}^i} \\right| $$\n\nto avoid division by zero, the absolute percentage error should be computed using `tf.where`.\n\nI need to implement this custom loss function. Here is how I have started:\n\n<code>\nimport tensorflow as tf\n\ndef mean_absolute_percentage_error(y_true, y_pred):\n    # Implement the MAPE calculation here\n    ### BEGIN SOLUTION\n\n</code>",
    "output": "\n<code>\n    epsilon = tf.keras.backend.epsilon()\n    y_true = tf.convert_to_tensor(y_true)\n    y_pred = tf.convert_to_tensor(y_pred)\n    \n    diff = tf.abs(y_true - y_pred)\n    percentage_error = diff / tf.where(tf.abs(y_true) > epsilon, tf.abs(y_true), epsilon)\n    \n    mape = 100 * tf.reduce_mean(percentage_error)\n    return mape\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to implement a custom loss function that computes the mean squared error (MSE) between predicted and true values, but with a twist: I want to give more weight to the errors of a specific class (e.g., class index 2) during the calculation. \nThe predictions and true values are both represented as 2D tensors. Given a list of true labels (e.g., [0, 2, 1, 2, 0]) and a constant weight (e.g., 2.0) for the specific class, how can I achieve this?\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = [0, 2, 1, 2, 0]\npredictions = tf.constant([[0.1, 0.5, 0.4], [0.2, 0.1, 0.7], [0.3, 0.3, 0.4], [0.4, 0.2, 0.4], [0.1, 0.6, 0.3]])\nweight_class_index = 2\nclass_weight = 2.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(true_labels, predictions)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    weights = tf.where(tf.equal(tf.argmax(y_true, axis=1), weight_class_index), class_weight, 1.0)\n    weighted_mse = mse * weights\n    return tf.reduce_mean(weighted_mse)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am developing a custom loss function for a regression problem where I want to penalize large errors more than small errors. Specifically, I want to implement a modified mean squared error (MMSE) loss function where the squared errors are weighted by a factor that increases as the absolute error grows. Given a list of predicted values and a list of true values, how can I compute the MMSE loss?\n\nGiven the true values and predicted values:\n```python\ntrue_values = [3.0, -0.5, 2.0, 7.0]\npredicted_values = [2.5, 0.0, 2.0, 8.0]\n```\nHow can I fill in the blank below to calculate the MMSE loss? \nThe MMSE loss function can be defined as:\n```python\ndef mmse_loss(y_true, y_pred):\n    errors = y_true - y_pred\n    squared_errors = tf.square(errors)\n    weight = tf.maximum(tf.abs(errors), 1.0)  # increasing weight for larger errors\n    weighted_squared_errors = squared_errors * weight\n    return tf.reduce_mean(weighted_squared_errors)\n```\n\nA:\n```python\nimport tensorflow as tf\n\ntrue_values = tf.constant([3.0, -0.5, 2.0, 7.0])\npredicted_values = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nmmse = ... # put solution in this variable",
    "output": "\n```python\nmmse = mmse_loss(true_values, predicted_values)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like this:\n\n```python\nimport pandas as pd\n\nx = pd.DataFrame({\n    'product': ['A', 'A', 'B', 'B', 'C'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-02', '2023-01-05', '2023-01-01'],\n    'sales': [100, 150, None, None, 300]\n})\n```\n\nI want to ensure that the 'date' column contains all dates from the minimum to the maximum for each product, and fill missing sales with the average sales for that product. The expected output should maintain the order defined by 'date' with each product having its sales uniformly averaged during the missing periods.\n\nThe resulting DataFrame should look like this:\n\n```\n    date product  sales\n0 2023-01-01      A  100.0\n1 2023-01-02      A  100.0\n2 2023-01-03      A  150.0\n3 2023-01-04      A  100.0\n4 2023-01-05      A  100.0\n5 2023-01-01      B    0.0\n6 2023-01-02      B    0.0\n7 2023-01-03      B    0.0\n8 2023-01-04      B    0.0\n9 2023-01-05      B  150.0\n10 2023-01-01     C  300.0\n11 2023-01-02     C  300.0\n```\n\nI have tried using forward fill but it doesn't give the desired results. What code can I use to achieve this?\n\n```python\nx['date'] = pd.to_datetime(x['date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (x.set_index('date')\n          .groupby('product')\n          .resample('D')\n          .mean()\n          .fillna(0)\n          .reset_index()\n          .sort_values(by=['product', 'date']))\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nYou are given a DataFrame that tracks daily sales across multiple stores, with some gaps in the data. The DataFrame looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Store': ['Store A', 'Store A', 'Store B', 'Store B', 'Store C'],\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'Sales': [200, None, 150, 300, None]\n})\n```\n\nYour goal is to fill in the missing sales figures using forward filling for each store while ensuring that if a store has no sales recorded for a day, it should still show up in the DataFrame with 0 sales for that date. The expected output format should include all unique dates for each store, even if no sales were recorded, with sales data filled accordingly.\n\nWrite the following code to achieve this goal:\n\n```python\nimport pandas as pd\n\nsales_data['Date'] = pd.to_datetime(sales_data['Date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (sales_data.set_index(['Store', 'Date'])\n          .resample('D')\n          .sum()\n          .fillna(0)\n          .groupby(level=0)\n          .ffill()\n          .reset_index())\n```"
  },
  {
    "input": "Problem:\nYou have the following dataframe which records temperature readings over time:\n\ndf:\n|   id |   city |   date       |   temperature |\n|------|--------|--------------|---------------|\n|    1 |   NY   |  2020-01-01  |           32  |\n|    2 |   NY   |  2020-01-02  |          NaN  |\n|    3 |   NY   |  2020-01-03  |           30  |\n|    4 |   LA   |  2020-01-01  |           70  |\n|    5 |   LA   |  2020-01-02  |          NaN  |\n|    6 |   LA   |  2020-01-03  |           68  |\n\nYou want to perform a forward filling of the missing temperature data so that every city has a complete set of temperature readings for each date, while also ensuring that if a city does not have a reading for a particular date, the last known temperature is carried forward. The expected output should look something like this:\n\n|   id |   city |   date       |   temperature |\n|------|--------|--------------|---------------|\n|    1 |   NY   |  2020-01-01  |           32  |\n|    2 |   NY   |  2020-01-02  |           32  |\n|    3 |   NY   |  2020-01-03  |           30  |\n|    4 |   LA   |  2020-01-01  |           70  |\n|    5 |   LA   |  2020-01-02  |           70  |\n|    6 |   LA   |  2020-01-03  |           68  |\n\nYou can start with the following code to create the initial dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'id': [1, 2, 3, 4, 5, 6],\n    'city': ['NY', 'NY', 'NY', 'LA', 'LA', 'LA'],\n    'date': pd.to_datetime(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-02', '2020-01-03']),\n    'temperature': [32, None, 30, 70, None, 68]\n})\n```\n\nFill in the blank below with the appropriate method call for forward filling the temperature data:\n\n```python\ndf['temperature'] = ...\n```",
    "output": "\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill()\n```"
  },
  {
    "input": "## Problem:\n\nI have a PyTorch tensor `data` of shape (50, 3) which represents 50 samples, each with 3 features. I also have a tensor `weights` of shape (3, 1) representing the weights for each feature. I want to compute the weighted sum for each sample in `data` such that the resulting tensor `result` has the shape (50, 1). \n\nGiven the tensors:\n\n```python\ndata.size() == torch.Size([50, 3])\nweights.size() == torch.Size([3, 1])\n```\n\nWhat code can I use to perform this operation?\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\ndata, weights = load_data()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = data @ weights\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am trying to create a composite transformation:\n\n```python\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\n# Assuming 'image' is a PIL Image that I want to transform\naugmented_image = transform(image)\n```\n\nHowever, I forgot to import the necessary library to handle image loading. \n\nA:\n<code>\nfrom PIL import Image\nimage = Image.open('path/to/image.jpg')\n</code>\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n\n",
    "output": "\n<code>\nresult = augmented_image\n</code>"
  },
  {
    "input": "Problem:\n\nI need to normalize a batch of images represented as a PyTorch tensor. The images are stored in a tensor with shape `[batch_size, channels, height, width]`, and I would like to perform a per-channel normalization using the mean and standard deviation for each channel. Here is a snippet of my code that loads the images:\n\n```python\nimport torch\n\nimages = load_data()  # Assuming images is a tensor of shape [batch_size, channels, height, width]\n```\n\nHow can I apply this normalization? The expected output should also be a tensor of the same shape `[batch_size, channels, height, width]`.\n\nA:\n\n```python\nnormalized_images = ...  # put solution in this variable\n```",
    "output": "\n```python\nmean = images.mean(dim=[0, 2, 3], keepdim=True)\nstd = images.std(dim=[0, 2, 3], keepdim=True)\nnormalized_images = (images - mean) / std\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function for a regression problem where I need to calculate the Mean Absolute Percentage Error (MAPE) instead of the traditional mean squared error. The MAPE is defined as the average of the absolute percentage differences between the predicted and actual values. My inputs are two tensors: `y_true` for actual values and `y_pred` for predicted values. How can I calculate MAPE using TensorFlow operations?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef mape(y_true, y_pred):\n    # return MAPE calculation here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    diff = tf.abs((y_true - y_pred) / y_true)\n    return tf.reduce_mean(diff) * 100\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a neural network model using PyTorch, where I need to normalize the output of each layer. Given an n x m tensor representing the output of my layer, I want to compute the z-score normalization for each feature (column) individually. The z-score is defined as (X - mean) / stddev, where X is the input tensor, mean is the mean value of the column, and stddev is the standard deviation of the column.\n\nHere's a sample output tensor:\n\n[[1.0, 2.0, 3.0],\n [4.0, 5.0, 6.0],\n [7.0, 8.0, 9.0]]\n\nI need to return the z-score normalized tensor with the same dimensions. How can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\noutput_tensor = load_data()\ndef z_score_normalization(output_tensor):\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    mean = output_tensor.mean(dim=0)\n    stddev = output_tensor.std(dim=0)\n    normalized_tensor = (output_tensor - mean) / stddev\n    return normalized_tensor\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomRotation(degrees=30),\n            transforms.RandomHorizontalFlip(),\n            # Fill in the blank with the correct rotation implementation\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image()  # This will load an image tensor\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nresult = ...\n</code>",
    "output": "\n<code>\nresult = self.transform(image)\n</code>"
  },
  {
    "input": "### Problem:\nContext\nI have two dataframes that contain information about products and their sales.\n\nDataFrame `products` looks like this:\n```\n   ProductID ProductName  Category\n0          1      Apple       Fruits\n1          2      Banana      Fruits\n2          3      Carrot      Vegetables\n3          4      Broccoli    Vegetables\n```\n\nDataFrame `sales` looks like this:\n```\n   SaleID ProductID Quantity SaleDate\n0      101          1       50  2023-01-01\n1      102          2       30  2023-01-02\n2      103          3       20  2023-01-01\n3      104          4      100  2023-01-03\n4      105          5       60  2023-01-04\n```\n\nI want to merge these two dataframes based on `ProductID`. However, if a product in the `sales` dataframe does not exist in the `products` dataframe (like ProductID 5), I would like to drop that entire row in the final dataframe.\n\nThe desired output should look like this:\n```\n   SaleID ProductID Quantity SaleDate ProductName  Category\n0      101          1       50  2023-01-01       Apple      Fruits\n1      102          2       30  2023-01-02      Banana      Fruits\n2      103          3       20  2023-01-01      Carrot  Vegetables\n3      104          4      100  2023-01-03   Broccoli  Vegetables\n```\n\nSo far, I've merged the dataframes like this:\n```python\ndf = pd.merge(sales, products, on='ProductID', how='inner')\n```\n\nWhat change should I make to correctly reflect the required output, ensuring that rows in `sales` with non-existent `ProductID`s in `products` are dropped?\n\nA:\n<code>\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'ProductID': [1, 2, 3, 4],\n    'ProductName': ['Apple', 'Banana', 'Carrot', 'Broccoli'],\n    'Category': ['Fruits', 'Fruits', 'Vegetables', 'Vegetables']\n})\n\nsales = pd.DataFrame({\n    'SaleID': [101, 102, 103, 104, 105],\n    'ProductID': [1, 2, 3, 4, 5],\n    'Quantity': [50, 30, 20, 100, 60],\n    'SaleDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-04']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(sales, products, on='ProductID', how='inner')\n```"
  },
  {
    "input": "## Problem\nYou are working with two pandas DataFrames that represent sales data across different regions. The first DataFrame `sales` contains information about sales transactions, while the second DataFrame `regions` provides the corresponding region names.\n\n```python\nimport pandas as pd\n\n# Creating the sales DataFrame\nsales_data = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'region_id': [101, 102, 103, 101, 103],\n    'amount': [250, 150, 200, 300, 100]\n}\nsales = pd.DataFrame(sales_data)\n\n# Creating the regions DataFrame\nregions_data = {\n    'region_id': [101, 102, 103],\n    'region_name': ['North', 'South', 'East']\n}\nregions = pd.DataFrame(regions_data)\n```\n\nYou want to create a new DataFrame that combines both `sales` and `regions`, where each transaction is associated with its region name. The resulting DataFrame should look like this:\n\n```\n   transaction_id  region_id  amount region_name\n0               1        101     250        North\n1               2        102     150        South\n2               3        103     200         East\n3               4        101     300        North\n4               5        103     100         East\n```\n\nIn terms of code, how do you achieve this merging operation?\n\n```python\nmerged_df = ... # put solution in this variable\n```",
    "output": "\n```python\nmerged_df = pd.merge(sales, regions, on='region_id')\n```"
  },
  {
    "input": "Problem:\n\nI am working with a sequence of input features in a PyTorch tensor that represent time series data. Each feature is a vector of size 10, and my dataset contains 100 samples, resulting in a tensor of shape (100, 10). I want to compute the element-wise mean of the features across all samples and return a single tensor of shape (10,), which represents the average feature values over all samples.\n\nHere is the tensor containing my data:\n\n```python\ninput_tensor = load_data()  # Load the (100, 10) tensor\n```\n\nHow can I compute the mean of the features effectively using PyTorch?\n\nA:\n\n```python\nmean_tensor = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nmean_tensor = input_tensor.mean(dim=0)  # Compute the mean across the samples\nEND SOLUTION\n```"
  },
  {
    "input": "### Problem\nI have the following DataFrame representing daily temperature data for different cities, but some entries are missing:\n\n```python\ndata = {\n    'city': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'temperature': [30, 70, None, None, 65, 60]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to fill in the missing temperature values by using forward fill within each city group. Additionally, any missing values that are still present after forward filling should be imputed with the average temperature of each city.\n\nWhat I need is to obtain the following final DataFrame:\n\n```\n         city        date  temperature\n0   New York  2023-01-01         30.0\n1  Los Angeles  2023-01-01         70.0\n2   New York  2023-01-02         30.0\n3     Chicago  2023-01-01         65.0\n4  Los Angeles  2023-01-02         65.0\n5     Chicago  2023-01-02         60.0\n```\n\nSo far, I have tried the following code but it's not working as expected:\n\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill().fillna(df.groupby('city')['temperature'].mean())\n```\n\nHow should I adjust my code to achieve the desired DataFrame? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'temperature': [30, 70, None, None, 65, 60]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n",
    "output": "\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill()\ndf['temperature'] = df.groupby('city')['temperature'].fillna(df.groupby('city')['temperature'].transform('mean'))\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI am working with a PyTorch tensor representing a batch of images from the MNIST dataset. The tensor has the shape (batch_size, 1, 28, 28), where each image is a grayscale image of size 28x28 pixels. I want to apply a transformation to normalize the pixel values of each image to the range [0, 1].\n\nThe pixel values are currently in the range [0, 255], so I need to divide all the pixel values by 255. However, I also want to ensure that I retain the original tensor shape. \n\nHow can I achieve this normalization using PyTorch, while ensuring that the output tensor maintains the same shape after the operation?\n\nTo illustrate, if my input tensor is:\n\ntensor([[[[255, 0, 127, ..., 30],\n          [50, 255, 255, ..., 10],\n          ...\n          [255, 0, 10, ..., 0]]]])\n\nI want my output tensor to be:\n\ntensor([[[[1.0, 0.0, 0.4980, ..., 0.1176],\n          [0.1961, 1.0, 1.0, ..., 0.0392],\n          ...\n          [1.0, 0.0, 0.0392, ..., 0.0]]]])\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n\ninput_tensor = load_data() # shape should be (batch_size, 1, 28, 28)\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = input_tensor / 255.0\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes, sales and returns, representing transactions in a retail store. The sales dataframe contains information on items sold, while the returns dataframe contains information on items returned. Both dataframes share a common column named 'item_id' and you want to merge them such that you can analyze both sold and returned items side by side. Here are the dataframes:\n\n```python\nimport pandas as pd\n\nsales_data = {\n    'item_id': [1, 2, 3, 4, 5],\n    'item_name': ['Shirt', 'Pants', 'Shoes', 'Hat', 'Belt'],\n    'amount_sold': [100, 150, 200, 50, 60]\n}\nsales = pd.DataFrame(data=sales_data)\n\nreturns_data = {\n    'item_id': [2, 4, 3, 5, 5],\n    'returned_amount': [10, 5, 20, 15, 5]\n}\nreturns = pd.DataFrame(data=returns_data)\n```\n\nI need to merge these dataframes based on 'item_id' and include the total sold and returned amounts in the resulting dataframe consolidating the information, ensuring that for items without returns, the returned_amount should be 0. The desired output should look like this:\n\n```\n   item_id item_name  amount_sold  returned_amount\n0        1     Shirt           100                0\n1        2     Pants           150               10\n2        3     Shoes           200               20\n3        4      Hat            50                5\n4        5      Belt           60               20\n```\n\nWhat is the correct way to merge these two dataframes using pandas?\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(sales, returns.groupby('item_id', as_index=False).sum(), on='item_id', how='left').fillna({'returned_amount': 0})\n```"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor that represents a grayscale image, and I want to apply a dynamic resizing operation based on the percentage of the original image dimensions. The target size should be calculated as a fraction of the original size. For example, if the original dimensions are (H, W) and the resize percentage is 50%, the new dimensions should be (H * 0.5, W * 0.5).\n\nHere's my starting code, but I'm unsure how to implement the resizing part correctly using PyTorch dynamic tensor operations:\n\nimport torch\n\noriginal_image = torch.randn(1, 1, 100, 200)  # Simulated grayscale image\nresize_percentage = 0.5\n\n# Calculate the new dimensions\nnew_height = int(original_image.size(2) * resize_percentage)\nnew_width = int(original_image.size(3) * resize_percentage)\n\n# How do I resize the tensor to the new dimensions?\nresized_image = ...\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\noriginal_image, resize_percentage = load_data()\n</code>\nresized_image = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresized_image = torch.nn.functional.interpolate(original_image, size=(new_height, new_width), mode='bilinear', align_corners=False)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that tracks the weekly sales of different products in a store, and it looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'Week': [1, 1, 1, 2, 2, 2],\n    'Sales': [20, np.nan, 15, np.nan, 25, np.nan]\n})\n```\n\nThe DataFrame has missing values in the Sales column for some products in week 2. I want to fill in these missing values based on the average sales of the same products from the previous week (week 1). The expected output should fill the missing Sales values accordingly.\n\nWhat I would like to achieve is to replace the missing values in the Sales column for week 2 with the average sales from week 1 for the respective products.\n\nYour current approach might involve using `apply`, but I'm looking for a more efficient way to achieve this using pandas' built-in functions.\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.copy()\navg_sales_week1 = df[df['Week'] == 1].set_index('Product')['Sales']\nresult.loc[result['Week'] == 2, 'Sales'] = result.loc[result['Week'] == 2, 'Sales'].fillna(avg_sales_week1)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a collection of images represented as a 4D tensor for a deep learning task. The tensor has a shape of [batch_size, channels, height, width]. I would like to apply a dynamic scaling operation on this tensor such that each image within the batch is scaled by a corresponding factor provided in a 1D tensor. The scaling factors have a shape of [batch_size].\n\nHere's what I have so far:\n\n```python\nimport torch\n\nbatch_size = 4\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\nscaling_factors = torch.tensor([0.5, 1.0, 1.5, 2.0])  # Scaling factors for each image\n\n# Now, I want to scale each image in the batch without using a for loop.\n```\n\nWhat would be the appropriate way to scale the images dynamically based on the scaling factors?\n\nA:\n\n<code>\nscaled_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaled_images = images * scaling_factors.view(batch_size, 1, 1, 1)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am developing a custom loss function to evaluate the performance of a neural network that predicts continuous values. I want to implement a custom loss that calculates the Mean Absolute Error (MAE) only for predictions that exceed a certain threshold. For the loss function, if the absolute error is less than the threshold, the contribution should be zero. How can I implement this as a custom loss function?\n\nHere is a sample implementation of your function:\n\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        # return the solution in this function\n        pass\n    return loss\n```\n\nIn the `loss` function, you will receive the ground truth values `y_true` and the predicted values `y_pred`. Complete the implementation based on the above requirements.",
    "output": "\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        absolute_error = tf.abs(y_true - y_pred)\n        mask = tf.cast(absolute_error > threshold, tf.float32)\n        return tf.reduce_mean(mask * absolute_error)\n    return loss\n```"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing sales data for a retail store as follows:\n\n```\ndf:\n   ProductID   Sales   Date\n0        101      50  2023-01-01\n1        102      20  2023-01-01\n2        103      NaN  2023-01-01\n3        101      30  2023-01-02\n4        102      NaN  2023-01-02\n5        103      15  2023-01-02\n```\n\nYour goal is to fill in the missing sales figures in the `Sales` column using forward-fill for the same `ProductID` by day. Specifically, if a product's sales are missing on a specific day, you want to fill it with the sales figure from the previous available day for that product. The expected DataFrame should be as follows:\n\n```\n   ProductID   Sales       Date\n0        101    50.0  2023-01-01\n1        102    20.0  2023-01-01\n2        103    15.0  2023-01-01\n3        101    30.0  2023-01-02\n4        102    20.0  2023-01-02\n5        103    15.0  2023-01-02\n```\n\nYou have imported the necessary libraries and created the DataFrame. Your task is to complete the following line of code to achieve this:\n\n```python\ndf['Sales'] = df.groupby('ProductID')['Sales'].___\n```\n",
    "output": "\n```python\ndf['Sales'] = df.groupby('ProductID')['Sales'].ffill()\n```"
  },
  {
    "input": "Problem:\nYou have two pandas dataframes containing sales data from two different regions. The first dataframe (df1) has information about sales in Region A, while the second dataframe (df2) has details from Region B. The structure of the dataframes is as follows:\n\ndf1:\n```\n   product_id    region  sales    date\n0          1     A      150  2023-01-01\n1          2     A      200  2023-01-02\n2          3     A      300  2023-01-03\n```\n\ndf2:\n```\n   product_id    region  sales    date\n0          2     B      100  2023-01-01\n1          3     B      250  2023-01-02\n2          4     B      300  2023-01-03\n```\n\nYou need to merge these two dataframes on the 'product_id' column, ensuring that the sales values from both regions are retained alongside their corresponding dates. If a product is present in one dataframe but not the other, that product should still appear in the final merged dataframe, with missing values filled with NaN. The final output should then be sorted by 'product_id'.\n\nYour current attempt with pd.merge() gives you quite a bit of unstructured data. \n\nYou can begin with the following code:\n\n```python\nimport pandas as pd\n\ndf1 = pd.DataFrame({'product_id': [1, 2, 3],\n                    'region': ['A', 'A', 'A'],\n                    'sales': [150, 200, 300],\n                    'date': ['2023-01-01', '2023-01-02', '2023-01-03']})\n\ndf2 = pd.DataFrame({'product_id': [2, 3, 4],\n                    'region': ['B', 'B', 'B'],\n                    'sales': [100, 250, 300],\n                    'date': ['2023-01-01', '2023-01-02', '2023-01-03']})\n```\n\nWhat line of code would you use to achieve the desired merged output in a new variable called `result`? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(df1, df2, on='product_id', how='outer', suffixes=('_A', '_B')).sort_values('product_id')\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing sales data for a retail store structured as follows:\n\n```\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 104, 105, 101, 102, 103],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', \n             '2023-01-03', '2023-01-03', '2023-01-04'],\n    'units_sold': [23, 45, np.nan, np.nan, 30, 12, np.nan, np.nan]\n})\n```\n\nSome rows in the `units_sold` column have missing values (NaNs), and you want to fill these missing values using the mean of `units_sold` for the same `product_id`, but only considering previous dates. Your goal is to ensure that when a product has missing sales in a certain date, it is filled with the average sales of the previous entries for that product.\n\nPlease provide the code that accomplishes this task and fills the NaN values accordingly, while keeping the remaining data intact. The final DataFrame should reflect the updated sales data with the NaN values filled. \n\nFill in the blank:\n```python\nimport pandas as pd\nimport numpy as np\n\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 104, 105, 101, 102, 103],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', \n             '2023-01-03', '2023-01-03', '2023-01-04'],\n    'units_sold': [23, 45, np.nan, np.nan, 30, 12, np.nan, np.nan]\n})\n\n# Convert 'date' to datetime\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group['units_sold'].fillna(group['units_sold'].expanding().mean())).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI have two DataFrames, invoices and payments, structured as follows:\n\ninvoices\n```\n   invoice_id  amount       date     customer\n0           1     300 2023-01-15      Customer A\n1           2     500 2023-01-16      Customer B\n2           3     200 2023-01-17      Customer A\n3           4     700 2023-01-18      Customer C\n```\n\npayments\n```\n   invoice_id  payment_date  payment_amount\n0           1     2023-01-20             300\n1           2     2023-01-17             300\n2           3     2023-01-19             200\n3           5     2023-01-21             150\n```\n\nI need to create a DataFrame that merges the invoices and payments on the `invoice_id` and fills in the `payment_amount` from the payments DataFrame where it matches. If there is no matching record in payments, the original invoice information should be retained. The merged DataFrame should also include a status column that indicates whether the invoice has been fully paid, partially paid, or is unpaid.\n\nThe expected output should look like this:\n\n```\n   invoice_id  amount       date     customer  payment_amount  status\n0           1     300 2023-01-15      Customer A           300.0  Fully Paid\n1           2     500 2023-01-16      Customer B             NaN  Unpaid\n2           3     200 2023-01-17      Customer A           200.0  Fully Paid\n3           4     700 2023-01-18      Customer C             NaN  Unpaid\n```\n\nIf an invoice has a payment amount that equals the invoice amount, the status should be \"Fully Paid\". If there is a payment amount present but less than the invoice amount, the status should be \"Partially Paid\". If there is no payment for that invoice, the status should be \"Unpaid\".\n\nA:\n```python\nimport pandas as pd\n\ninvoices = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 4],\n    'amount': [300, 500, 200, 700],\n    'date': ['2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18'],\n    'customer': ['Customer A', 'Customer B', 'Customer A', 'Customer C']\n})\n\npayments = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 5],\n    'payment_date': ['2023-01-20', '2023-01-17', '2023-01-19', '2023-01-21'],\n    'payment_amount': [300, 300, 200, 150]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = invoices.merge(payments, on='invoice_id', how='left')\nresult['status'] = result.apply(lambda x: 'Fully Paid' if x['payment_amount'] == x['amount'] else \n                                  ('Partially Paid' if pd.notna(x['payment_amount']) and x['payment_amount'] < x['amount'] else 'Unpaid'), axis=1)\n```"
  },
  {
    "input": "Problem:\nI have two dataframes that record sales information. The first dataframe contains the product IDs and their respective sales in quantity per day, while the second dataframe contains product IDs and their corresponding prices. \n\nHere are the dataframes:\n\ndf_sales:\n| product_id | sales_quantity | sales_date  |\n|------------|----------------|--------------|\n| A          | 5              | 2023-01-01   |\n| B          | 3              | 2023-01-01   |\n| A          | 2              | 2023-01-02   |\n| B          | 1              | 2023-01-02   |\n| C          | 4              | 2023-01-01   |\n\ndf_prices:\n| product_id | price |\n|------------|-------|\n| A          | 10    |\n| B          | 15    |\n| C          | 20    |\n\nI want to create a new dataframe that summarizes the total sales value for each product per day, calculated by multiplying the sales quantity by the product price. The resulting dataframe should include these columns: `sales_date`, `product_id`, `total_sales_value`.\n\nHow can I achieve this in a single merging operation?\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': ['A', 'B', 'A', 'B', 'C'],\n    'sales_quantity': [5, 3, 2, 1, 4],\n    'sales_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01']\n})\n\ndf_prices = pd.DataFrame({\n    'product_id': ['A', 'B', 'C'],\n    'price': [10, 15, 20]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_prices, on='product_id').assign(total_sales_value=lambda x: x.sales_quantity * x.price)[['sales_date', 'product_id', 'total_sales_value']]\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset of shape (batch_size, features) where each feature is represented as a 1D tensor and I want to transform these feature tensors into a thicker tensor by applying a linear transformation and an activation function. \n\nThe linear transformation is defined by weights and biases where weights are of shape (input_features, output_features) and biases are of shape (output_features). After applying the linear transformation, I want to apply the ReLU activation function.\n\nHere\u2019s the linear transformation function definition:\n\n```python\ndef linear_transform(features, weights, biases):\n    # apply the linear transformation\n    return torch.matmul(features, weights) + biases\n```\n\nI need to fill in the process to create the final transformed tensor that includes the ReLU activation. If the input tensor is:\n\n```python\nfeatures = torch.Tensor([[1, 2], [3, 4]])\nweights = torch.Tensor([[0.5, -0.5], [2, 0]])\nbiases = torch.Tensor([1, -1])\n```\n\nMy task is to transform the tensor using the linear transformation followed by the ReLU activation, then return the result.\n\nHow can I achieve this in PyTorch?\n\nA:\n\n```python\nimport torch\nfeatures, weights, biases = load_data()\ndef transform(features, weights, biases):\n    linear_output = linear_transform(features, weights, biases)\n    # Here is where you will apply the ReLU activation function\n    result = ...  # put solution in this variable\n    return result\n```",
    "output": "\n```python\n    result = torch.relu(linear_output)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\n<rotation_transformation_here>\n</code>\nresult = ...  # put solution in this variable",
    "output": "\n<code>\ntransforms.RandomRotation(degrees=30)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 4D tensor representing a batch of images, where the dimensions are (batch_size, channels, height, width). For instance, imagine the tensor shape is (5, 3, 32, 32), which corresponds to 5 images, each with 3 color channels (RGB) and a resolution of 32x32 pixels. \n\nI want to normalize each channel of each image independently across the height and width dimensions such that the mean of each channel becomes 0 and the standard deviation becomes 1. How can I achieve this normalization for the entire batch using PyTorch?\n\nTo illustrate, if I have the following image tensor:\n\n```\nimages = torch.rand(5, 3, 32, 32)  # Example images tensor\n```\n\nThe output should provide a tensor of the same shape, where each channel is independently normalized.\n\nA:\n\n<code>\nimport torch\nimages = torch.rand(5, 3, 32, 32)\nnormalized_images = ...  # put solution in this variable\n### BEGIN SOLUTION",
    "output": "\n<code>\nmean = images.mean(dim=(2, 3), keepdim=True)\nstd = images.std(dim=(2, 3), keepdim=True)\nnormalized_images = (images - mean) / std\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am not sure how to apply this function to each image in the tensor while handling the probability condition. I tried using a for loop but wasn't able to do it efficiently.\n\nA:\n\n<code>\nimport torch\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images\n\ndef flip_image(image):\n    return torch.flip(image, dims=[1])  # Flip the image vertically\n\n# Implement the augmentation logic here\nresult = ...\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = torch.where(torch.rand(images.size(0), 1, 1, 1) < 0.5, flip_image(images), images)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations.\n\nHere\u2019s a partial implementation:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\n```\n\nWhat function should I use to complete the `transform` to resize the images to 128x128 pixels before applying other augmentations?\n\nA:\n\n<code>\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.Resize((128, 128)).\n",
    "output": "\n<code>\ntransforms.Resize((128, 128)),\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am developing a custom loss function that penalizes predictions based on the mean squared error of the predictions and an added constant to encourage predictions to be further away from zero. The formula for the custom loss function will be: \n\n\\[\n\\text{custom\\_loss}(y_{\\text{true}}, y_{\\text{pred}}) = \\text{mean}((y_{\\text{true}} - y_{\\text{pred}})^2) + 0.5\n\\]\n\nNow, I need to implement this custom loss function in TensorFlow. How should I define the custom loss function that takes in true and predicted values?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Implement the custom loss function\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n    return mse + 0.5\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 4D tensor representing a batch of images, where each image has dimensions: (batch size, channels, height, width). The tensor is of shape (32, 3, 128, 128), and I want to apply a dynamic thresholding operation along the channel dimension. Specifically, I want to set all pixel values to 1 if they are greater than a certain threshold and to 0 otherwise. \n\nHow can I accomplish this operation using PyTorch?\n\nHere is my current setup for the tensor and threshold:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n\nimages_tensor = torch.rand((32, 3, 128, 128))  # Simulate a batch of images\nthreshold = 0.5\n</code>\nthresholded_tensor = ... # put solution in this variable\n### BEGIN SOLUTION",
    "output": "\n<code>\nthresholded_tensor = (images_tensor > threshold).float()\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains monthly sales data for several products over a period of time. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndata = {\n    'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n    'month': ['2023-01', '2023-02', '2023-01', '2023-02', '2023-01', '2023-02', '2023-01', '2023-02'],\n    'sales': [100, None, 150, None, None, 80, None, 95]\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to fill in the missing `sales` values using forward fill for each `product_id` so that if a product had sales in previous months, it carries over to the missing months. The resulting DataFrame should look like this:\n\n```\n   product_id   month  sales\n0           1  2023-01  100.0\n1           1  2023-02  100.0\n2           2  2023-01  150.0\n3           2  2023-02  150.0\n4           3  2023-01   80.0\n5           3  2023-02   80.0\n6           4  2023-01   95.0\n7           4  2023-02   95.0\n```\n\nWhat is the piece of code you would use to achieve this result? \n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('product_id')['sales'].ffill().fillna(method='ffill')\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to apply this function to each image in the dataset based on the provided probability.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flip the image vertically (along height)\n```\n\nYou need to fill in the following code to apply the augmentation:\n\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>\n```\n\nresult = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>flip_image(images[i])</code>",
    "output": "\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>flip_image(images[i])</code>\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly flip images horizontally and also add Gaussian noise to them before passing them to my model. With the following functions provided, I am trying to create a composite transformation in PyTorch.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndef random_horizontal_flip(image):\n    # Applies horizontal flip to the image with 50% chance\n    return transforms.RandomHorizontalFlip()(image)\n\ndef add_gaussian_noise(image, mean=0.0, std=0.1):\n    noise = torch.randn(image.size()) * std + mean\n    return image + noise\n\n# Sample tensor representing an image\nimage = torch.randn(3, 64, 64)  # A random image tensor with 3 channels (RGB) and 64x64 pixels\n\n# Applying the composite transformations\naugmented_image = ...\n```\n\nA:\n\n<code>\naugmented_image = random_horizontal_flip(image)\naugmented_image = add_gaussian_noise(augmented_image)\n</code>",
    "output": "\n<code>\naugmented_image = add_gaussian_noise(random_horizontal_flip(image))\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a PyTorch tensor representing the features of several samples for a machine learning model. The tensor has the shape (500, 20) where 500 is the number of samples and 20 is the number of features. You need to apply a non-linear activation function (specifically the ReLU function) on this tensor to introduce non-linearity for a neural network. The ReLU function should set all negative values to zero while keeping the positive values unchanged.\n\nGiven the tensor `features`, apply the ReLU function to it.\n\nA:\n\n<code>\nimport torch\nfeatures = load_data()\n</code>\nactivated_features = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nactivated_features = torch.relu(features)\n</code>"
  },
  {
    "input": "Problem:\n\nI'm working with time series data represented as a tensor. Each point in time has multiple features, and I want to compute the moving average for each feature over a specific window size. However, I'm encountering issues when applying the moving average function due to the dimension mismatch.\n\nHere's my code snippet where I'm defining the tensor and trying to reshape it for the moving average calculation:\n\n```python\nimport torch\n\nwindow_size = 3\n# Simulating a 2D time series tensor with shape (time_steps, features)\ndata = torch.randn(10, 4)  # 10 time steps, 4 features\n\n# Reshape for moving average; trying to create sliding window view\ndata_reshaped = data.unfold(0, window_size, 1)  # This is where I'm running into trouble\n```\n\nI need to compute the moving average but keep getting errors regarding the dimensions. How can I fix my approach?\n\nA:\n\n<code>\ndata_moving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndata_moving_avg = data_reshaped.mean(dim=2)  # Compute the mean across the window dimension\n```"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor representing some image data in the form of mini-batches. I need to perform a series of operations on it, specifically, I want to normalize this tensor by subtracting the mean and dividing by the standard deviation for each channel. \n\nHere is my current code:\n\n```python\nimport torch\n\n# Simulated image data with 10 samples and 3 channels (RGB)\nimage_tensor = torch.randn(10, 3, 32, 32) \n```\n\nHow do I compute the normalized tensor using the mean and standard deviation for each channel?\n\nA:\n\n```python\nchannel_means = ... # put solution in this variable\nnormalized_tensor = (image_tensor - channel_means) / channel_stds\n```\nBEGIN SOLUTION\n",
    "output": "\n```python\nchannel_means = image_tensor.mean(dim=(0, 2, 3), keepdim=True)\nchannel_stds = image_tensor.std(dim=(0, 2, 3), keepdim=True)\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor that represents a sequence of time-series data with shape (100, 5), where each row corresponds to a different time point, and each column corresponds to a feature. I want to create a sliding window effect where I extract overlapping segments of this tensor. Specifically, I want to define a window of size 3 that slides over the tensor with a stride of 1.\n\nFor each segment extracted, I want to compute the mean across the feature dimension (columns). The final result should be a tensor with shape (98, 5), where each row represents the mean of the previous 3 rows for each feature.\n\nCan anyone help me formulate the code to achieve this?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\ndata = load_data()  # Assuming load_data() fetches the (100, 5) tensor\nresult = ...  # Compute the means of the sliding windows here\nBEGIN SOLUTION",
    "output": "\n<code>\nwindow_size = 3\nstride = 1\nnum_windows = data.shape[0] - window_size + 1\nresult = torch.empty((num_windows, data.shape[1]))\n\nfor i in range(num_windows):\n    result[i] = data[i:i + window_size].mean(dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is where I need help.\n```\n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\nresult = images\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes representing sales transactions and customer information. The first dataframe (sales) contains customer IDs, purchase amounts, and the date of purchase. The second dataframe (customers) lists customer IDs and their corresponding names. I want to merge these two dataframes such that for each transaction, I can see not only the customer ID and purchase amount but also the customer's name. If a transaction does not have a matching customer in the customers dataframe, the name should appear as NaN.\n\nHere\u2019s the data:\n\nsales dataframe:\n```\n   customer_id  amount      date\n0            1     100 2023-01-01\n1            2     150 2023-01-02\n2            3     200 2023-01-03\n3            4     250 2023-01-04\n```\n\ncustomers dataframe:\n```\n   customer_id     name\n0            1   John Doe\n1            2   Jane Smith\n2            5   Alice Brown\n```\n\nThe resulting merged dataframe should have the following structure:\n```\n   customer_id  amount      date         name\n0            1     100 2023-01-01     John Doe\n1            2     150 2023-01-02   Jane Smith\n2            3     200 2023-01-03         NaN\n3            4     250 2023-01-04         NaN\n```\n\nHow can I achieve this with Python code using pandas? You can use the `merge` function from pandas.\n\nA:\n<code>\nimport pandas as pd\n\nsales = pd.DataFrame({'customer_id': [1, 2, 3, 4],\n                      'amount': [100, 150, 200, 250],\n                      'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04']})\n\ncustomers = pd.DataFrame({'customer_id': [1, 2, 5],\n                          'name': ['John Doe', 'Jane Smith', 'Alice Brown']})\n</code>\nmerged_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmerged_df = pd.merge(sales, customers, on='customer_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes containing sales data from different regions. The first dataframe contains regional sales and is structured like this:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Sales': [200, 150, 300, 250],\n    'Q2_Sales': [250, 200, 350, 300]\n})\n```\n\nThe second dataframe contains regional targets for the quarters, structured as follows:\n\n```python\ndf_targets = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Target': [220, 160, 320, 260],\n    'Q2_Target': [270, 210, 360, 310]\n})\n```\n\nI want to merge these two dataframes on the 'Region' column, resulting in a single dataframe that contains all sales and target data by region. The merged dataframe should look like this:\n\n```\n  Region  Q1_Sales  Q2_Sales  Q1_Target  Q2_Target\n0  North       200       250        220        270\n1  South       150       200        160        210\n2   East       300       350        320        360\n3   West       250       300        260        310\n```\n\nHow can I achieve this? \n\nA:\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Sales': [200, 150, 300, 250],\n    'Q2_Sales': [250, 200, 350, 300]\n})\n\ndf_targets = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Target': [220, 160, 320, 260],\n    'Q2_Target': [270, 210, 360, 310]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_targets, on='Region')\n```"
  },
  {
    "input": "Problem:\n\nI have a 4D tensor that represents batches of images with shape (batch_size, channels, height, width), and I want to normalize the pixel values of each image in the batch independently. The tensor is defined as:\n\nimages = torch.rand((16, 3, 64, 64))\n\nI will also have a tensor representing the mean and standard deviation for each channel:\n\nmean = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\nstd = torch.tensor([0.2, 0.2, 0.2]).view(1, 3, 1, 1)\n\nTo normalize the images, I want to subtract the mean and divide by the standard deviation for each channel across all images.  What code fills in the blank to achieve this normalization?\n\nA:\n\n<code>\nimport torch\nimages = torch.rand((16, 3, 64, 64))\nmean = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\nstd = torch.tensor([0.2, 0.2, 0.2]).view(1, 3, 1, 1)\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_images = (images - mean) / std\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor representing a batch of grayscale images with the shape (batch_size, channels, height, width), specifically (16, 1, 28, 28). You want to apply a series of transformations to this tensor, specifically normalizing it by subtracting the mean and dividing by the standard deviation across the channel dimension.\n\nGiven the following code:\n\n```python\nimport torch\n\nimages = torch.randn(16, 1, 28, 28)\n```\n\nYou need to fill in the blank to calculate the normalized tensor so that `normalized_images` has the same shape but the values are normalized. The mean and standard deviation should be computed along the correct dimension, ensuring that the values remain as floats.\n\n```python\nnormalized_images = (images - images.mean(dim=1, keepdim=True)) / images.std(dim=1, keepdim=True)\n```\n\nWhat should this blank be filled with to store the tensor of normalized images?\n\nA:\n\n```python\nnormalized_images = ...  # fill in the solution\n```",
    "output": "\n```python\nnormalized_images = (images - images.mean(dim=1, keepdim=True)) / images.std(dim=1, keepdim=True)\n```"
  },
  {
    "input": "### Problem\nI have a DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'product_id': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'sales': [100, np.nan, 200, np.nan, np.nan, 300],\n    'profit': [50, 40, np.nan, 80, 30, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nThe sales data for some products is missing (NaN values), and I would like to perform advanced imputation to fill in these missing values. Specifically, I want to fill the missing sales values with the mean sales of each product, and for the profit column, I want to fill the missing values with the median profit of the respective product.\n\nAdditionally, I want to add a new column named `total_trade`, which represents the total trade calculated as `sales + profit`. \n\nAfter all these operations, the expected DataFrame should have all NaN values filled as described.\n\nWhat code can I use to achieve this transformation?\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['sales'] = df.groupby('product_id')['sales'].transform(lambda x: x.fillna(x.mean()))\ndf['profit'] = df.groupby('product_id')['profit'].transform(lambda x: x.fillna(x.median()))\ndf['total_trade'] = df['sales'] + df['profit']\nresult = df\n```"
  },
  {
    "input": "Problem:\nI have a dataset that summarizes temperature readings for different cities on various days:\n\n```python\nimport pandas as pd\n\ndata = {\n    'city': ['New York', 'New York', 'Los Angeles', 'Los Angeles', 'Chicago', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'temperature': [25.0, None, None, 70.0, None, 32.0]\n}\n\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI would like to fill in the missing `temperature` values for each city using the average temperature of that city across its available days. The expected output should replace the `None` values accordingly. \n\nWhat code would you use to achieve this result?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.groupby('city')['temperature'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\n\nI have a 3D PyTorch tensor representing image batches, where the shape is (batch_size, channels, height, width). The tensor is initialized with random values, like this:\n\n```python\nimages = torch.rand((32, 3, 224, 224))\n```\n\nI want to normalize the pixel values of the tensor along the 'channels' dimension (the second dimension) such that the mean of each channel is 0 and the standard deviation is 1. After normalization, I want to set the values of each pixel in the 'channels' dimension to 0.5 after a specific index based on the mean of the channel, which is calculated across the batch. How can I achieve this for the first input channel?\n\nHere are the details:\n\n```python\nmean = images[:, 0, :, :].mean()  # Mean for the first channel\nstd = images[:, 0, :, :].std()    # Std deviation for the first channel\n```\n\nI want to modify the tensor as follows:\n\n```python\nimages[:, 0, :, :] = (images[:, 0, :, :] - mean) / std\nimages[:, 0, :, :][some_condition] = 0.5  # Fill this part\n```\n\nWhat should I put in `some_condition` to correctly set the appropriate pixels to 0.5?\n\nA:\n\n<code>\nimport torch\nimages = torch.rand((32, 3, 224, 224))\nmean = images[:, 0, :, :].mean()\nstd = images[:, 0, :, :].std()\n</code>\ncondition = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncondition = images[:, 0, :, :] > mean\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "### Problem:\nI have two DataFrames representing sales information of products across different regions. The first DataFrame contains the sales data for 2021, while the second one contains the sales data for 2022. Here are their structures:\n\nDataFrame 1 (sales_2021):\n```\n   product_id   region    sales\n0          1   North      500\n1          2   South      300\n2          3   East       400\n3          4   West       600\n```\n\nDataFrame 2 (sales_2022):\n```\n   product_id   region    sales\n0          1   North      700\n1          2   South      200\n2          3   East       500\n3          5   Central    300\n```\n\nI want to merge these two DataFrames such that I can see the sales of each product for both years, while also including regions. If a product only appears in one of the DataFrames, its sales in the other year should show as NaN. The expected structure looks like this:\n\n```\n   product_id   region    sales_2021    sales_2022\n0          1   North        500              700\n1          2   South        300              200\n2          3   East         400              500\n3          4   West         600              NaN\n4          5   Central      NaN              300\n```\n\nHow can I achieve this in Python using pandas? \n\nA:\n<code>\nimport pandas as pd\n\nsales_2021 = pd.DataFrame({\n    'product_id': [1, 2, 3, 4],\n    'region': ['North', 'South', 'East', 'West'],\n    'sales': [500, 300, 400, 600]\n})\n\nsales_2022 = pd.DataFrame({\n    'product_id': [1, 2, 3, 5],\n    'region': ['North', 'South', 'East', 'Central'],\n    'sales': [700, 200, 500, 300]\n})\n</code>\nmerged_result = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nmerged_result = pd.merge(sales_2021, sales_2022, on=['product_id', 'region'], how='outer', suffixes=('_2021', '_2022'))\n</code>"
  },
  {
    "input": "Problem:\nYou have two Pandas DataFrames as follows:\n\nDataFrame A:\n| id | name   | salary |\n|----|--------|--------|\n| 1  | John   | 50000  |\n| 2  | Jane   | 60000  |\n| 3  | Mike   | 45000  |\n\nDataFrame B:\n| id | department | location      |\n|----|------------|---------------|\n| 1  | HR         | New York      |\n| 2  | Engineering| San Francisco  |\n| 4  | Marketing  | Los Angeles   |\n\nYou need to merge these two DataFrames on the 'id' column, such that the resulting DataFrame includes all records from DataFrame A and only the matching records from DataFrame B. If there is no matching record in DataFrame B, the result should include NaN for the columns from DataFrame B. However, you want to drop the 'location' column from the final merged DataFrame. \n\nThe expected structure should look like this:\n\n| id | name   | salary | department  |\n|----|--------|--------|-------------|\n| 1  | John   | 50000  | HR          |\n| 2  | Jane   | 60000  | Engineering  |\n| 3  | Mike   | 45000  | NaN         |\n\nHow can you achieve this using Pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf_a = pd.DataFrame({'id': [1, 2, 3],\n                     'name': ['John', 'Jane', 'Mike'],\n                     'salary': [50000, 60000, 45000]})\n\ndf_b = pd.DataFrame({'id': [1, 2, 4],\n                     'department': ['HR', 'Engineering', 'Marketing'],\n                     'location': ['New York', 'San Francisco', 'Los Angeles']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(df_a, df_b[['id', 'department']], on='id', how='left')"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have two pandas DataFrames: `products` and `sales`. The `products` DataFrame contains information about products with columns `product_id`, `product_name`, and `category`, while the `sales` DataFrame records sales transactions with columns `sale_id`, `product_id`, `quantity`, and `date`. I want to merge these DataFrames such that for each sale, I have access to both the product information and the total quantity sold for each product, while maintaining the original order of the `sales` DataFrame.\n\nHere are the DataFrames:\n\n`products`:\n```\n   product_id        product_name      category\n0          1               Widget A          Gadgets\n1          2               Widget B          Widgets\n2          3               Widget C          Gadgets\n```\n\n`sales`:\n```\n   sale_id  product_id  quantity       date\n0        1           1        3  2023-10-01\n1        2           2        2  2023-10-02\n2        3           3        5  2023-10-02\n3        4           1        1  2023-10-03\n```\n\nThe expected merged DataFrame should look like this:\n```\n   sale_id  product_id  quantity       date      product_name      category\n0        1           1        3  2023-10-01          Widget A          Gadgets\n1        2           2        2  2023-10-02          Widget B          Widgets\n2        3           3        5  2023-10-02          Widget C          Gadgets\n3        4           1        1  2023-10-03          Widget A          Gadgets\n```\n\nI've attempted using `pd.merge(sales, products, on='product_id')`, but it seems that I'm missing a way to keep the original order of `sales` intact.\n\nA:\n<code>\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n    'category': ['Gadgets', 'Widgets', 'Gadgets']\n})\n\nsales = pd.DataFrame({\n    'sale_id': [1, 2, 3, 4],\n    'product_id': [1, 2, 3, 1],\n    'quantity': [3, 2, 5, 1],\n    'date': ['2023-10-01', '2023-10-02', '2023-10-02', '2023-10-03']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = sales.merge(products, on='product_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset that contains information about daily sales for different products in a store. The dataset looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-02'],\n    'Sales': [10, None, 20, None, 15, None]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nSome sales data for products are missing (represented as `None`). You want to fill in these missing values. The logic is to fill the missing sales values for each product with the sales value from the previous day. If there is no previous value available, fill it with zero.\n\nYour output dataframe should look like this:\n\n```\n  Product       Date  Sales\n0       A 2023-01-01   10.0\n1       B 2023-01-01    0.0\n2       C 2023-01-01   20.0\n3       A 2023-01-02   10.0\n4       B 2023-01-02   15.0\n5       C 2023-01-02   20.0\n```\n\nImplement the code to achieve this without using any explicit loops.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Sales'] = df.groupby('Product')['Sales'].fillna(method='ffill').fillna(0)\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\nI have two separate pandas DataFrames that need to be merged based on a common column, while ensuring that I keep specific columns from each DataFrame. The first DataFrame contains customer details, while the second contains order details. \n\nHere's what they look like:\n\nCustomer DataFrame:\n```\ncustomer_id    name     age\n0           101   Alice      30\n1           102     Bob      22\n2           103   Charlie    35\n```\n\nOrder DataFrame:\n```\norder_id    customer_id   amount\n0        1001           101      250\n1        1002           102      150\n2        1003           103      450\n3        1004           101      300\n```\n\nI want to merge them such that I get a DataFrame with `customer_id`, `name`, and `amount`, but I do not want the `age` from the first DataFrame or the `order_id` from the second DataFrame in the final result.\n\nCan you provide the code necessary to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ncustomers = pd.DataFrame({'customer_id': [101, 102, 103],\n                          'name': ['Alice', 'Bob', 'Charlie'],\n                          'age': [30, 22, 35]})\n\norders = pd.DataFrame({'order_id': [1001, 1002, 1003, 1004],\n                       'customer_id': [101, 102, 103, 101],\n                       'amount': [250, 150, 450, 300]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = pd.merge(customers[['customer_id', 'name']], orders[['customer_id', 'amount']], on='customer_id')\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working on a neural network that requires the concatenation of two tensors, `tensor1` and `tensor2`, both of size (5, 3). However, they are being produced at different times in your data pipeline, and `tensor2` may come in as a (2, 3) tensor (representing a batch of inputs) due to variable input sequences in your data. You want to ensure that both tensors are compatible in shape for concatenation by padding `tensor2` with zeros if it has fewer than 5 rows.\n\nWrite a code snippet to concatenate `tensor1` and `tensor2` along the first dimension after appropriate padding so the resulting tensor has a shape of (7, 3).\n\nA:\n\n<code>\nimport torch\ntensor1 = load_data()\ntensor2 = load_data()\n</code>\nresult_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nif tensor2.size(0) < 5:\n    padding = (0, 0, 0, 5 - tensor2.size(0))  # (padding_left, padding_right, padding_top, padding_bottom)\n    tensor2 = torch.nn.functional.pad(tensor2, padding)\nresult_tensor = torch.cat((tensor1, tensor2), dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a natural language processing task where I need to implement a simple attention mechanism using PyTorch. The attention scores are computed using a similarity measure between a query vector and a set of key vectors, producing a tensor of attention weights. The size of my query vector is (batch_size, query_dim) and the size of my key vectors is (batch_size, num_keys, key_dim).\n\nTo compute attention weights, I plan to calculate the dot product between the query and keys and then apply a softmax to get normalized attention weights. However, I am encountering an issue with the dimensions while trying to perform the dot product.\n\nHere's my current attempt:\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef compute_attention(query, keys):\n    # query: (n, d), keys: (n, k, d)\n    scores = ...  # fill in this part to compute attention scores\n    attention_weights = F.softmax(scores, dim=1)  # normalize the scores\n    return attention_weights\n\nquery = torch.randn(5, 10)  # (batch_size=5, query_dim=10)\nkeys = torch.randn(5, 4, 10)  # (batch_size=5, num_keys=4, key_dim=10)\n```\n\nHow can I fill in the blank in my code to correctly compute the attention scores?\n\nA:\n\n<code>\nscores = torch.matmul(query.unsqueeze(1), keys.transpose(1, 2)).squeeze(1)\n</code>",
    "output": "\n<code>\nscores = torch.bmm(query.unsqueeze(1), keys).squeeze(1)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with two pandas DataFrames that represent sales data from different regions. The first DataFrame, `sales_data`, contains sales figures for the first half of the year, and the second DataFrame, `returns_data`, contains return figures for the same items. You need to merge these two DataFrames on the 'Item' column while retaining all sales data and adding return data where available. Additionally, you wish to include a new column, 'Returned', which indicates whether any items were returned (True) or not (False).\n\nHere are the DataFrames:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Item': ['A', 'B', 'C', 'D'],\n    'Sales_Q1': [100, 200, 150, 300],\n    'Sales_Q2': [120, 210, 180, 250]\n})\n\nreturns_data = pd.DataFrame({\n    'Item': ['B', 'D', 'E'],\n    'Returns': [20, 10, 5]\n})\n```\n\nThe expected output should include all rows from `sales_data`, with the return figures along with an indication of whether there were any returns for each item. If there were no returns for an item, the Returns column should show NaN, and the 'Returned' column should indicate False.\n\nA:\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Item': ['A', 'B', 'C', 'D'],\n    'Sales_Q1': [100, 200, 150, 300],\n    'Sales_Q2': [120, 210, 180, 250]\n})\n\nreturns_data = pd.DataFrame({\n    'Item': ['B', 'D', 'E'],\n    'Returns': [20, 10, 5]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = pd.merge(sales_data, returns_data, on='Item', how='left')\nresult['Returned'] = result['Returns'].notna()\n```"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor containing the pixel values of an image in the shape of (3, 256, 256), representing RGB channels. I want to normalize each channel independently so that the pixel values fall within the range of [0, 1]. Given the tensor `img_tensor`, how can I accomplish this in one line of code?\n\nA:\n\n<code>\nimport torch\nimg_tensor = load_data()\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = (img_tensor - img_tensor.min(dim=(1, 2), keepdim=True).values) / (img_tensor.max(dim=(1, 2), keepdim=True).values - img_tensor.min(dim=(1, 2), keepdim=True).values)\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that tracks sales data for different products over several months. Some sales data are missing or represented as null values in specific months. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Month': ['2021-01', '2021-02', '2021-01', '2021-02', '2021-01', '2021-02'],\n    'Sales': [200, np.nan, np.nan, 300, 400, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nYour task is to intelligently fill the missing sales data in such a way that:\n1. If sales for the previous month (same product) are available, fill the current month with the previous month's sales if it is missing.\n2. If there is no previous month data available for a product, fill it with the average sales for that product across the months.\n\nYou should return the DataFrame after filling in the missing values.\n\nCurrent DataFrame:\n```\n  Product    Month  Sales\n0       A  2021-01  200.0\n1       A  2021-02    NaN\n2       B  2021-01    NaN\n3       B  2021-02  300.0\n4       C  2021-01  400.0\n5       C  2021-02    NaN\n```\n\nUse the following code to fill in the missing values:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('Product').apply(lambda group: group['Sales'].fillna(method='ffill').fillna(group['Sales'].mean())).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI have two dataframes containing customer transaction data from different quarters. The first dataframe, `df_q1`, contains customer IDs and their corresponding purchase amounts in the first quarter, while the second dataframe, `df_q2`, contains the same information for the second quarter. \n\ndf_q1:\n```\n   customer_id  purchase_amount\n0           1              250\n1           2              150\n2           3              300\n3           4              400\n```\n\ndf_q2:\n```\n   customer_id  purchase_amount\n0           3              200\n1           4              350\n2           5              150\n3           1              300\n```\n\nI want to merge these two dataframes on `customer_id` using an outer join, keeping all customers and summing their `purchase_amounts`. If a customer appears in both quarters, their amounts should be added together. If a customer is only present in one quarter, the other amount should default to 0. \n\nThe expected resultant dataframe should look like this:\n```\n   customer_id  total_purchase\n0           1              550\n1           2              150\n2           3              500\n3           4              750\n4           5              150\n```\n\nBelow is the setup for the dataframes:\n```\nimport pandas as pd\n\ndf_q1 = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'purchase_amount': [250, 150, 300, 400]\n})\n\ndf_q2 = pd.DataFrame({\n    'customer_id': [3, 4, 5, 1],\n    'purchase_amount': [200, 350, 150, 300]\n})\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(df_q1, df_q2, on='customer_id', how='outer', suffixes=('_q1', '_q2')).fillna(0)\nresult['total_purchase'] = result['purchase_amount_q1'] + result['purchase_amount_q2']\nresult = result[['customer_id', 'total_purchase']]\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes as follows:\n\ndf1:\n```\n   product_id   name      price\n0          1  apple        1.0\n1          2  banana       0.5\n2          3  cherry       2.0\n```\n\ndf2:\n```\n   product_id   quantity   store\n0          1       100    store_a\n1          2        50    store_b\n2          3       200    store_a\n3          4        20    store_c\n```\n\nYou need to merge the two dataframes on the `product_id` column. However, for products that do not exist in `df1` (like `product_id` 4), you should still include the row from `df2` but set the `name` and `price` columns to NaN. Finally, the resulting dataframe should be sorted based on `product_id`. \n\nYour solution should look like this:\n```\n   product_id   name      price   quantity   store\n0          1  apple        1.0       100    store_a\n1          2  banana       0.5        50    store_b\n2          3  cherry       2.0       200    store_a\n3          4   NaN         NaN        20    store_c\n```\n\nGiven the dataframes defined as follows:\n<code>\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    \"product_id\": [1, 2, 3],\n    \"name\": [\"apple\", \"banana\", \"cherry\"],\n    \"price\": [1.0, 0.5, 2.0]\n})\n\ndf2 = pd.DataFrame({\n    \"product_id\": [1, 2, 3, 4],\n    \"quantity\": [100, 50, 200, 20],\n    \"store\": [\"store_a\", \"store_b\", \"store_a\", \"store_c\"]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(df2, df1, on='product_id', how='left').sort_values(by='product_id')<code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains temperature data for a city with some missing values. The structure of the DataFrame is as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n    'temperature': [20, None, 25, None, 30, None]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat I would like to do is interpolate the missing temperature values based on the adjacent available values. If the first or last value is missing, please fill it with the average of the remaining values in the column. The expected output should maintain the same structure and format.\n\nYour task is to write one line of code that performs this interpolation and filling.\n\nA:\n```python\ndf['temperature'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['temperature'] = df['temperature'].interpolate().fillna(df['temperature'].mean())\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function to calculate the Hinge loss for my support vector machine model. The Hinge loss is typically used for \"maximum-margin\" classification, especially with \"large-margin\" classifiers. Given the true labels as an array of -1 or 1 (e.g., [-1, 1, -1, 1]) and the predicted labels as an array of floats (e.g., [0.5, -0.8, 0.3, 0.9]), how can I compute the Hinge loss?\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = tf.constant([-1, 1, -1, 1], dtype=tf.float32)\npredicted_labels = tf.constant([0.5, -0.8, 0.3, 0.9], dtype=tf.float32)\n\ndef custom_hinge_loss(y_true=true_labels, y_pred=predicted_labels):\n    # return the solution in this function\n    # result = custom_hinge_loss(y_true, y_pred)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    return tf.reduce_mean(tf.maximum(0.0, 1 - y_true * y_pred))\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames A and B as follows:\nA\n```\n   UserID  Name\n0       1  Alice\n1       2    Bob\n2       3  Carol\n```\nB\n```\n   UserID  Age  City\n0       1   25  New York\n1       3   30  Los Angeles\n2       4   22  Chicago\n```\nI need to merge these DataFrames on 'UserID', ensuring that we keep all records from DataFrame A and only the matching records from DataFrame B. Additionally, I want to rename the columns of DataFrame B when merged to include a prefix \"B_\" for clarity.\n\nThe expected output should look like this:\n```\n   UserID   Name  B_Age          B_City\n0       1  Alice   25.0       New York\n1       2    Bob    NaN            NaN\n2       3  Carol   30.0  Los Angeles\n```\n\nSo far, my attempt using the merge function was like this:\n```python\nresult = pd.merge(A, B, on='UserID', how='left')\n```\nbut I need to add that prefix to the columns from DataFrame B. \n\nA:\n```python\nimport pandas as pd\n\nA = pd.DataFrame({'UserID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Carol']})\nB = pd.DataFrame({'UserID': [1, 3, 4], 'Age': [25, 30, 22], 'City': ['New York', 'Los Angeles', 'Chicago']})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nresult = pd.merge(A, B.rename(columns={'Age': 'B_Age', 'City': 'B_City'}), on='UserID', how='left')\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations, but I'm unsure how to implement the color jitter with the specified parameters.\n\nHere's what I have so far:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    # Fill in the blank with the color jitter transform\n])\n```\n\nI would like to apply color jittering with brightness=0.2, contrast=0.2, saturation=0.2, and hue=0.1.\n\nA:\n\n<code>\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n])\n</code>\nresult = ... # put solution in this variable",
    "output": "\n<code>\nresult = transform\n</code>"
  },
  {
    "input": "Problem:\n\nI have two dataframes that I want to merge, one containing information about students and their scores, and another containing their extra-curricular activities. Here are the dataframes:\n\n```python\nimport pandas as pd\n\ndf_scores = pd.DataFrame({\n    'student_id': [1, 2, 3],\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'score': [88, 92, 85]\n})\n\ndf_activities = pd.DataFrame({\n    'student_id': [1, 2, 4],\n    'activities': [['Soccer', 'Drama'], ['Chess'], ['Music', 'Art']]\n})\n```\n\nI want to perform a merge operation based on `student_id` and keep all students from the scores dataframe, filling in NaNs for those without extra-curricular activities. The resulting dataframe should look like this:\n\n```\n   student_id     name  score          activities\n0           1    Alice     88      [Soccer, Drama]\n1           2      Bob     92              [Chess]\n2           3  Charlie     85                  NaN\n```\n\nWhat code can I write to achieve this result? \n\nA:\n<code>\nimport pandas as pd\n\ndf_scores = pd.DataFrame({\n    'student_id': [1, 2, 3],\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'score': [88, 92, 85]\n})\n\ndf_activities = pd.DataFrame({\n    'student_id': [1, 2, 4],\n    'activities': [['Soccer', 'Drama'], ['Chess'], ['Music', 'Art']]\n})\n\nresult = ... # put solution in this variable\n</code>",
    "output": "\n<code>\nresult = pd.merge(df_scores, df_activities, on='student_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor representing the daily sales figures for items in a store, where each row corresponds to a different item and each column corresponds to a different day. I need to find the daily sales totals for all items combined. Given a tensor named `sales_data`, how can I efficiently compute the sum of sales for each day and return a 1D tensor holding these totals?\n\nA:\n\n<code>\nimport torch\nsales_data = load_data()\n</code>\ndaily_totals = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndaily_totals = sales_data.sum(dim=0)\n</code>"
  },
  {
    "input": "## Problem\nYou have two DataFrames representing customer orders and customer details:\n\n**orders_df**\n```\n   order_id  customer_id  amount\n0        1            1    100.0\n1        2            2    150.0\n2        3            1    200.0\n3        4            3    50.0\n```\n\n**customers_df**\n```\n   customer_id   name         country\n0            1  Alice  United States\n1            2    Bob         Canada\n2            3  Carol         Canada\n3            4  David       Australia\n```\n\nYour task is to merge these two DataFrames to create a new DataFrame that includes all orders along with the corresponding customer name and country, but excluding customers who do not have made any orders. The resulting DataFrame should only include the columns: `order_id`, `customer_id`, `name`, `amount`, and `country`.\n\nYou are currently unsure how to appropriately filter the merged results to meet these requirements. Here's the initial setup:\n\n```python\nimport pandas as pd\n\norders_df = pd.DataFrame({\n    'order_id': [1, 2, 3, 4],\n    'customer_id': [1, 2, 1, 3],\n    'amount': [100.0, 150.0, 200.0, 50.0]\n})\n\ncustomers_df = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Carol', 'David'],\n    'country': ['United States', 'Canada', 'Canada', 'Australia']\n})\n```\n\nNow, fill in the blank to merge the DataFrames and achieve the desired result.\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = orders_df.merge(customers_df, on='customer_id', how='inner')[['order_id', 'customer_id', 'name', 'amount', 'country']]\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to create a custom loss function that calculates the Mean Squared Error (MSE) between the predicted values and actual values, but with a twist: I want to apply a weight that increases the loss based on the value of the predicted output. Specifically, if the predicted value is below a threshold of 0.5, I want to multiply the squared error by a factor of 2. \n\nSuppose you have the following tensors for actual and predicted values:\n```python\nimport tensorflow as tf\n\nactual = tf.constant([0.0, 1.0, 0.0, 1.0])\npredicted = tf.constant([0.1, 0.8, 0.4, 0.6])\n```\n\nPlease define a custom loss function using a lambda function as described above. You will need to fill in the blank for calculating the custom loss:\n```python\ndef custom_loss(y_true, y_pred):\n    return ...  # put solution in this variable\n```\nBEGIN SOLUTION\n```python\n```",
    "output": "\n```python\ndef custom_loss(y_true, y_pred):\n    return tf.reduce_mean(tf.where(y_pred < 0.5, 2 * tf.square(y_true - y_pred), tf.square(y_true - y_pred)))\n```"
  },
  {
    "input": "Problem:\nContext  \nI have two datasets that track product sales from different sources. The first dataset comprises product information, and the second dataset includes sales details.\n\nProblem  \nThe first Pandas DataFrame looks like this:\n\n| ProductID | ProductName   | Price |\n|-----------|---------------|-------|\n| 101       | Widget A      | 25.0  |\n| 102       | Widget B      | 30.0  |\n| 103       | Widget C      | 22.5  |\n\nThe second DataFrame is structured as follows:\n\n| ProductID | SalesDate | Quantity |\n|-----------|-----------|----------|\n| 101       | 2023-01-01| 100      |\n| 101       | 2023-01-02| 120      |\n| 102       | 2023-01-01| 80       |\n| 103       | 2023-01-03| 150      |\n| 103       | 2023-01-02| 90       |\n\nI want to merge these two DataFrames into one that shows each product's name, price, total quantity sold, and the latest sales date, excluding any product IDs not present in both datasets. The desired final DataFrame should look like this:\n\n| ProductID | ProductName | Price | TotalQuantity | LatestSalesDate |\n|-----------|-------------|-------|---------------|------------------|\n| 101       | Widget A    | 25.0  | 220           | 2023-01-02       |\n| 102       | Widget B    | 30.0  | 80            | 2023-01-01       |\n| 103       | Widget C    | 22.5  | 240           | 2023-01-03       |\n\nUsing SQL, I might have written something like:\n```sql\nSELECT p.ProductID, p.ProductName, p.Price, SUM(s.Quantity) AS TotalQuantity, MAX(s.SalesDate) AS LatestSalesDate\nFROM Products AS p \nJOIN Sales AS s ON p.ProductID = s.ProductID \nGROUP BY p.ProductID, p.ProductName, p.Price;\n```\n\nI want to achieve this result in Pandas. Here is what I have tried:\n\n```python\nimport pandas as pd\n\ndf_products = pd.DataFrame({'ProductID': [101, 102, 103], \n                            'ProductName': ['Widget A', 'Widget B', 'Widget C'], \n                            'Price': [25.0, 30.0, 22.5]})\n\ndf_sales = pd.DataFrame({'ProductID': [101, 101, 102, 103, 103], \n                         'SalesDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'], \n                         'Quantity': [100, 120, 80, 150, 90]})\n\n# How can I merge these DataFrames to achieve the final result?\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\nresult = df_products.merge(df_sales.groupby('ProductID').agg(TotalQuantity=('Quantity', 'sum'), LatestSalesDate=('SalesDate', 'max')).reset_index(), on='ProductID')\n```"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor `data` with the shape of (2, 5, 4) representing batches of features, where each batch contains 5 samples with 4 feature values each. Your goal is to perform a dynamic manipulation to calculate the mean across the first dimension (batch dimension) for each feature across all samples.\n\nThe resulting tensor should have a shape of (5, 4), containing the mean feature values for each of the 5 samples.\n\nHere is the setup you have:\n\n```python\nimport torch\ndata = load_data()  # should be a tensor of shape (2, 5, 4)\n```\n\nHow can you compute the means across the batches to achieve the desired shape in a single line of code?\n\nA:\n\n```python\nmeans = ...  # put solution in this variable\n```",
    "output": "\n```python\nmeans = data.mean(dim=0)\n```"
  },
  {
    "input": "Problem:\n\nYou are working with images represented as 4D tensors in PyTorch, with shape (batch_size, channels, height, width). For an image preprocessing step, you want to dynamically resize each image to a fixed size of (height, width) = (128, 128) while maintaining the aspect ratio by padding the shorter dimension with zeros. \n\nAssuming your input tensor `images` has the shape (4, 3, 300, 400), you need to create a new tensor `resized_images` that contains all the images resized to the shape (4, 3, 128, 128) with appropriate padding.\n\nFill in the code to perform this operation.\n\nA:\n\n<code>\nimport torch\nimages = load_data()  # shape: (4, 3, 300, 400)\nresized_images = ...  # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nimport torch\nimport torch.nn.functional as F\n\nimages = load_data()  # shape: (4, 3, 300, 400)\nbatch_size, channels, height, width = images.shape\ntarget_size = (128, 128)\n\n# Calculate the aspect ratio\naspect_ratio = height / width\nif aspect_ratio > 1:  # Height is greater\n    new_height = target_size[0]\n    new_width = int(target_size[0] / aspect_ratio)\nelse:  # Width is greater or equal\n    new_width = target_size[1]\n    new_height = int(target_size[1] * aspect_ratio)\n\n# Resize images\nresized_images = F.interpolate(images, size=(new_height, new_width), mode='bilinear', align_corners=False)\n\n# Pad images to target size\npad_height = target_size[0] - new_height\npad_width = target_size[1] - new_width\nresized_images = F.pad(resized_images, (0, pad_width, 0, pad_height), mode='constant', value=0)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation step.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.to_tensor(transform(image))\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with two pandas dataframes representing sales data for different products. The first dataframe, `df_sales`, contains information about sales transactions and includes the columns `TransactionID`, `ProductID`, and `Amount`. The second dataframe, `df_products`, includes `ProductID`, `ProductName`, and `Category`. \n\nHere are the details of the dataframes:\n\ndf_sales:\n```\n+----------------+------------+--------+\n| TransactionID  | ProductID  | Amount |\n+----------------+------------+--------+\n|        1       |     A      |  250   |\n|        2       |     B      |  400   |\n|        3       |     A      |  150   |\n|        4       |     C      |  300   |\n|        5       |     B      |  200   |\n+----------------+------------+--------+\n```\n\ndf_products:\n```\n+------------+--------------+-----------+\n| ProductID  | ProductName  | Category  |\n+------------+--------------+-----------+\n|     A      | Product A    | Category 1|\n|     B      | Product B    | Category 1|\n|     C      | Product C    | Category 2|\n|     D      | Product D    | Category 2|\n+------------+--------------+-----------+\n```\n\nYour task is to merge these two dataframes so that for each transaction in `df_sales`, you can display the `TransactionID`, `ProductName`, and `Amount`. If a transaction references a `ProductID` that does not exist in `df_products`, the `ProductName` should display `None`. \n\nTo achieve this, fill in the following Python code snippet where `result` will store the merged data:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'ProductID': ['A', 'B', 'A', 'C', 'B'],\n    'Amount': [250, 400, 150, 300, 200]\n})\n\ndf_products = pd.DataFrame({\n    'ProductID': ['A', 'B', 'C', 'D'],\n    'ProductName': ['Product A', 'Product B', 'Product C', 'Product D'],\n    'Category': ['Category 1', 'Category 1', 'Category 2', 'Category 2']\n})\n\nresult = ... # put solution in this variable\n```\n",
    "output": "\n```python\nresult = pd.merge(df_sales, df_products[['ProductID', 'ProductName']], on='ProductID', how='left')[['TransactionID', 'ProductName', 'Amount']]\n```"
  },
  {
    "input": "Problem:\n\nI am working on a PyTorch project where I need to concatenate two tensors along a specified dimension, but I want to avoid errors that arise from mismatched sizes. I have two tensors, `A` and `B`, that I intend to concatenate along the first dimension (0). The tensors are structured like this:\n\n```\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])  # Note: B has a different first dimension size.\n```\n\nBefore concatenating, I want to ensure that `B` has the same number of columns as `A` by possibly reshaping or adjusting it without losing its original data. \n\nHow can I properly concatenate `A` and `B` after making sure their dimensions align? \n\nA:\n\n<code>\nimport torch\nA = load_data()\nB = load_data()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])\n\nif A.size(1) != B.size(1):\n    B = B.expand(-1, A.size(1))\n\nresult = torch.cat((A, B), dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations.\n\nHere\u2019s a partial implementation:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\n```\n\nWhat function should I use to complete the `transform` to resize the images to 128x128 pixels before applying other augmentations?\n\nA:\n\n<code>\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.Resize((128, 128)).\n",
    "output": "\n<code>\ntransforms.Resize((128, 128)),\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\n            transforms.RandomRotation(degrees=30),  # Properly defined rotation transformation\n</code>"
  },
  {
    "input": "## Problem:\n\nI have a 2D tensor representing the features of a dataset, where each row corresponds to a different example and each column corresponds to a different feature. I want to normalize this tensor by subtracting the mean of each column from the respective column values and then dividing by the standard deviation of each column.\n\nI have tried to utilize PyTorch's operations, but I'm unsure of how to compute the mean and standard deviation and apply them to each column. Given the following tensor:\n\ndata: shape (5, 4), for instance, represented as:\n\n```\n[[1.0, 2.0, 3.0, 4.0],\n [5.0, 6.0, 7.0, 8.0],\n [9.0, 10.0, 11.0, 12.0],\n [13.0, 14.0, 15.0, 16.0],\n [17.0, 18.0, 19.0, 20.0]]\n```\n\nI want to compute the normalized tensor using the following code snippet to fill in the blank:\n\n<code>\nimport torch\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean = data.mean(dim=0)\nstd = data.std(dim=0)\nnormalized_data = (data - mean) / std\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like the following:\n\n```python\ndf = pd.DataFrame({\n    'category': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02', '2023-01-03', None],\n    'value': [10, None, 20, 30, None, 50, 60]\n})\n```\n\nI want to ensure that all dates between the minimum and maximum date for each category are present, and any missing values should be filled in with the mean value for that category. The expected output should contain all the missing dates and the corresponding values calculated.\n\nYour task is to fill in the code below to achieve this:\n\n```python\nimport pandas as pd\n\ndf['date'] = pd.to_datetime(df['date'])\ncategory_range = df.groupby('category')['date'].agg(['min', 'max']).reset_index()\n# Your solution should begin after this line\nresult = ...\n```",
    "output": "\n```python\nresult = (\n    category_range\n    .apply(lambda row: pd.date_range(start=row['min'], end=row['max']), axis=1)\n    .explode()\n    .reset_index(name='date')\n    .merge(df.groupby('category').mean().reset_index(), on='category', how='left')\n)\nresult = result.groupby(['category', 'date']).first().reset_index()\nresult['value'] = result['value'].fillna(result.groupby('category')['value'].transform('mean'))\n```"
  },
  {
    "input": "Problem:\n\nYou have a 1D tensor representing a batch of scores from a model, and you want to achieve a specific transformation. The transformation involves expanding this 1D tensor into a 2D tensor where each score is repeated to form a row corresponding to the scores. The goal is to create a 2D tensor where each score has its own column and the rows are filled with the index values of the scores.\n\nFor example, if your 1D tensor is:\n```\nscores = torch.tensor([0.5, 0.1, 0.4])\n```\nThe desired output should be:\n```\ntensor([[0, 1, 2],\n        [0.5, 0.1, 0.4]])\n```\n\nComplete the following code to achieve this transformation:\n\n<code>\nimport torch\nscores = load_data()\n</code>\ntransformed_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nscores = load_data()\ntransformed_tensor = torch.tensor([torch.arange(len(scores)), scores])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame representing sales data with NaN values as follows:\n\n```python\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 4],\n    'sales': [200, np.nan, 150, np.nan, np.nan, 300],\n    'quantity': [5, np.nan, 3, 2, 4, 6],\n    'month': ['2022-01', '2022-01', '2022-02', '2022-02', '2022-03', '2022-03']\n})\n```\n\nI want to use advanced imputation techniques to fill in the missing values in the 'sales' and 'quantity' columns based on the average of each respective product across all months. I've initialized the DataFrame as shown, but how can I efficiently perform this imputation? Please complete the code below:\n```python\nimport pandas as pd\nimport numpy as np\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 4],\n    'sales': [200, np.nan, 150, np.nan, np.nan, 300],\n    'quantity': [5, np.nan, 3, 2, 4, 6],\n    'month': ['2022-01', '2022-01', '2022-02', '2022-02', '2022-03', '2022-03']\n})\n\n# Fill in missing values using the average sales and quantity based on product_id\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.copy()\nresult['sales'] = result.groupby('product_id')['sales'].transform(lambda x: x.fillna(x.mean()))\nresult['quantity'] = result.groupby('product_id')['quantity'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data for a store represented as follows:\n\n```python\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\n\nThe DataFrame has missing values for the `Date` and `Sales` columns. I want to fill in the missing `Sales` values for the same `ProductID` by using the mean sales value of products with the same `ProductID`, while keeping the original `Date` as is. For the missing `Date`, I would like to fill it with the string \"Unknown Date\".\n\nHere is my current DataFrame before processing:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02    NaN\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04    NaN\n6          5        NaN    NaN\n```\n\nWhat I want to achieve is to apply the necessary imputation method to get the following resulting DataFrame:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02  200.0\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04  300.0\n6          5  Unknown Date    NaN\n```\n\nI would like the code that fills in the missing values in `Sales` with the mean sales for the respective `ProductID` and replaces the missing `Date` with \"Unknown Date\".\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n",
    "output": "\n```python\ndf['Date'].fillna('Unknown Date', inplace=True)\nmean_sales = df.groupby('ProductID')['Sales'].transform('mean')\ndf['Sales'].fillna(mean_sales, inplace=True)\nresult = df\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information about daily sales over a few weeks for different products, but there are some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n                           'date': ['2023-10-01', '2023-10-02', '2023-10-01', '2023-10-03',\n                                    '2023-10-01', '2023-10-02', '2023-10-02', None],\n                           'units_sold': [20, None, None, 15, 5, None, None, 10]})\n```\n\nI want to fill in the missing values of `date` and `units_sold` with the appropriate entries based on previous entries for the same `product_id`. Specifically, I want to forward fill the `date` and use the mean of previously available `units_sold` for the respective `product_id` to fill in the missing values.\n\nThe expected DataFrame should look like this:\n\n```plaintext\n   product_id        date  units_sold\n0           1  2023-10-01         20.0\n1           1  2023-10-02         20.0\n2           2  2023-10-01         7.5\n3           2  2023-10-03         15.0\n4           3  2023-10-01         5.0\n5           3  2023-10-02         5.0\n6           4  2023-10-02        10.0\n7           4  2023-10-02        10.0\n```\n\nCurrently, I am trying to fill the missing entries but not succeeding in the way I want. Can you help me with a concise inline code that will accomplish this task?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group.fillna({'date': group['date'].ffill(), 'units_sold': group['units_sold'].fillna(group['units_sold'].mean())})).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes with customer transaction data. The first dataframe, `df_orders`, contains details about each order, including `order_id`, `customer_id`, and `order_total`. The second dataframe, `df_customers`, contains customer information, including `customer_id`, `customer_name`, and `customer_email`. You want to merge these two dataframes to create a new dataframe that displays each order along with the corresponding customer details. If a customer has no orders, their details should still be included with a null value for `order_total`. The dates in `df_orders` should be formatted as 'YYYY-MM-DD'.\n\nHere are the dataframes you are starting with:\n\n```python\ndf_orders = pd.DataFrame({\n    'order_id': [1, 2, 3, 4],\n    'customer_id': [101, 102, 101, 103],\n    'order_total': [250.0, 150.0, 300.0, 400.0]\n})\n\ndf_customers = pd.DataFrame({\n    'customer_id': [101, 102, 103, 104],\n    'customer_name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'customer_email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david@example.com']\n})\n```\n\nWhat command would you use to produce a merged dataframe, `merged_df`, that meets these requirements? Please fill in the blank:\n\n```python\nmerged_df = ...\n```",
    "output": "\n```python\nmerged_df = pd.merge(df_customers, df_orders, on='customer_id', how='left')\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor representing image pixel values with a shape of (batch_size, channels, height, width), where each value is in the range of [0, 255]. I want to normalize each channel of the tensor independently to the range [0, 1]. \n\nThe tensor `images` is of shape (32, 3, 256, 256), where 32 represents the batch size, 3 is the number of channels (e.g., RGB), and 256x256 are the height and width dimensions of the images.\n\nHow can I normalize each channel by subtracting its minimum value and dividing by the range (max - min) for that channel?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.randint(0, 256, (32, 3, 256, 256), dtype=torch.float32)\nnormalized_images = ... # put solution in this variable\n### BEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmin_vals = images.min(dim=(0, 2, 3), keepdim=True)[0]\nmax_vals = images.max(dim=(0, 2, 3), keepdim=True)[0]\nnormalized_images = (images - min_vals) / (max_vals - min_vals)\n</code>"
  },
  {
    "input": "Problem:\nI have two pandas DataFrames representing sales data from two different stores, structured as follows:\n\nstore_a:\n   product_id   store    units_sold      date\n0          1      A          30   2023-01-01\n1          2      A          50   2023-01-01\n2          3      A          20   2023-01-02\n3          4      A          40   2023-01-02\n4          5      A          60   2023-01-03\n\nstore_b:\n   product_id   store    units_sold      date\n0          3      B          25   2023-01-02\n1          4      B          15   2023-01-02\n2          5      B          35   2023-01-03\n3          6      B          10   2023-01-03\n4          7      B          5    2023-01-04\n\nI want to merge these two DataFrames such that all records are included. After merging based on `product_id` and keeping track of which store each sale is from, the resulting DataFrame should also show the sales numbers as zeros for missing values. Finally, I want the `date` column to be formatted as 'dd-MMM-yyyy'.\n\nWhat should the resulting DataFrame look like?\n\nSo far I have done the following operation:\n```python\nresult = pd.merge(store_a, store_b, on='product_id', how='outer')\n```\n\nWhat code should I add to achieve the desired result?\n\n```python\nresult['date'] = ... # Fill in solution here\n```",
    "output": "\n```python\nresult['date'] = pd.to_datetime(result['date']).dt.strftime('%d-%b-%Y')\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing monthly sales data for different products in a grocery store. The data is represented in the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['apple', 'banana', 'apple', 'banana', 'orange', 'orange'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02', '2023-01', '2023-02'],\n    'sales': [150, None, 200, 250, None, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nIn this DataFrame, some sales figures are missing (`None`). I want to fill in these missing values. To fill the missing sales data, I would like to use the sales figures from the previous month for the same product if available. If there are no previous month sales figures, default the missing sales to 0.\n\nThe desired output after filling in the missing values should look like this:\n\n```\n   product    month  sales\n0    apple  2023-01  150.0\n1   banana  2023-01    0.0\n2    apple  2023-02  200.0\n3   banana  2023-02  250.0\n4   orange  2023-01    0.0\n5   orange  2023-02  300.0\n```\n\nWhat code should I use to achieve this? \n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.groupby('product').apply(lambda x: x['sales'].fillna(method='ffill').fillna(0)).reset_index(level=0, drop=True)\ndf['sales'] = result\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[2])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()  # Use clone to avoid modifying the original tensor\n</code>"
  },
  {
    "input": "Problem:\nYou are working with two dataframes representing user activity logs. The first dataframe, `activity`, contains user IDs and timestamps of when they performed actions:\n\n```python\nactivity = pd.DataFrame({\n    'user_id': [1, 1, 2, 2, 3, 3, 3],\n    'timestamp': ['2023-01-01 10:00:00', '2023-01-01 11:00:00', \n                  '2023-01-02 10:30:00', '2023-01-03 12:00:00', \n                  '2023-01-01 09:00:00', '2023-01-02 10:15:00', '2023-01-02 12:00:00']\n})\n\n```\n\nThe second dataframe, `users`, contains user IDs and their respective details such as names and registration dates:\n\n```python\nusers = pd.DataFrame({\n    'user_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'registration_date': ['2022-12-31', '2022-12-30', '2022-11-01', '2022-05-01']\n})\n```\n\nYou need to merge these two dataframes such that the resulting dataframe contains user details from `users`, along with their activities from `activity`. However, for users who do not have any activity, their corresponding rows should retain user details with `NaN` for the activity timestamps. Finally, the output should be ordered by `user_id` and `timestamp`.\n\nThe expected output should look like this:\n\n```\n   user_id     name  registration_date            timestamp\n0       1    Alice          2022-12-31  2023-01-01 10:00:00\n1       1    Alice          2022-12-31  2023-01-01 11:00:00\n2       2      Bob          2022-12-30  2023-01-02 10:30:00\n3       2      Bob          2022-12-30  2023-01-03 12:00:00\n4       3  Charlie          2022-11-01  2023-01-01 09:00:00\n5       3  Charlie          2022-11-01  2023-01-02 10:15:00\n6       3  Charlie          2022-11-01  2023-01-02 12:00:00\n7       4    David          2022-05-01                  NaN\n```\n\nFill in the blank to complete the merging operation:\n\n```python\nimport pandas as pd\n\nactivity = pd.DataFrame({\n    'user_id': [1, 1, 2, 2, 3, 3, 3],\n    'timestamp': ['2023-01-01 10:00:00', '2023-01-01 11:00:00', \n                  '2023-01-02 10:30:00', '2023-01-03 12:00:00', \n                  '2023-01-01 09:00:00', '2023-01-02 10:15:00', '2023-01-02 12:00:00']\n})\n\nusers = pd.DataFrame({\n    'user_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'registration_date': ['2022-12-31', '2022-12-30', '2022-11-01', '2022-05-01']\n})\n\nresult = pd.merge(___, ___, how='left').sort_values(by=['user_id', 'timestamp'])\n```",
    "output": "\n```python\nresult = pd.merge(users, activity, how='left').sort_values(by=['user_id', 'timestamp'])\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame with missing values like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan, 5],\n    'B': [np.nan, 2, np.nan, 4, np.nan],\n    'C': [1, 2, 3, 4, 5]\n})\n```\n\nI would like to use an efficient method to fill the missing values in column 'A' with the mean of the column, and for column 'B', I want to fill the NaN values using forward fill for the first NaN and backward fill for the remaining NaNs. The expected output should look like this:\n\n```\n     A    B  C\n0  1.0  NaN  1\n1  3.0  2.0  2\n2  3.0  2.0  3\n3  4.0  4.0  4\n4  5.0  4.0  5\n```\n\nWhat would be an efficient way to achieve this?\n\nA:\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.copy()\nresult['A'].fillna(result['A'].mean(), inplace=True)\nresult['B'].fillna(method='ffill', limit=1, inplace=True)\nresult['B'].fillna(method='bfill', inplace=True)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am trying to implement a custom loss function to calculate the Hinge loss for a binary classification problem. My predictions are in a tensor format (e.g., [0.6, -0.8, 0.1, -0.3]) and my true labels are in the format [1, -1, 1, -1]. The Hinge loss is calculated as max(0, 1 - true * prediction) for each element. \nI want to compute the average Hinge loss across all samples.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.6, -0.8, 0.1, -0.3])\ntrue_labels = tf.constant([1, -1, 1, -1])\ndef hinge_loss(predictions, true_labels):\n    # return the solution in this function\n    # loss = hinge_loss(predictions, true_labels)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    loss = tf.maximum(0.0, 1 - true_labels * predictions)\n    return tf.reduce_mean(loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\ndef flip_images(images):\n    # Randomly decide if we flip the images or not\n    if <condition>:\n        # Flip the images horizontally\n        return torch.flip(images, [3])  # Here, 3 refers to the width dimension\n    return images\n\nflipped_images = flip_images(images)\n```\n\nWhat should replace `<condition>` to randomly decide whether to flip the images horizontally or not?\n\nA:\n\n<code>\n<condition>\n</code>",
    "output": "\n<code>\ntorch.rand(1).item() > 0.5\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that looks like this:\n\n```python\ndata = {'store_id': [1, 1, 2, 3, 3],\n        'sales': [200, None, 450, None, 300],\n        'month': ['2022-01', '2022-01', '2022-01', '2022-02', '2022-02']}\ndf = pd.DataFrame(data)\n```\n\nThe `sales` column contains some missing values. You need to fill in these missing values using the following conditions:\n\n1. Fill `None` sales with the average sales for the corresponding `store_id`.\n2. Leave the filled values in `sales` with the original data type.\n3. The output `month` column should be formatted to `MMM-YYYY` (e.g., `Jan-2022`).\n\nYour task is to provide one piece of Python code that performs the above transformations on the DataFrame and returns the final DataFrame in the expected format. \n\nThe final DataFrame should look like this:\n```plaintext\n   store_id  sales     month\n0         1  200.0  Jan-2022\n1         1  200.0  Jan-2022\n2         2  450.0  Jan-2022\n3         3  300.0  Feb-2022\n4         3  300.0  Feb-2022\n```\n\nA:\n```python\nimport pandas as pd\n\ndata = {'store_id': [1, 1, 2, 3, 3],\n        'sales': [200, None, 450, None, 300],\n        'month': ['2022-01', '2022-01', '2022-01', '2022-02', '2022-02']}\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['sales'] = df.groupby('store_id')['sales'].transform(lambda x: x.fillna(x.mean()))\ndf['month'] = pd.to_datetime(df['month']).dt.strftime('%b-%Y')\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, channels, height, width). I want to dynamically apply a random horizontal flip to each image in the batch with a probability of 0.5. The images are represented as a PyTorch tensor. Here is a part of my code:\n\nimport torch\n\ndef random_horizontal_flip(images):\n    # images: (n, c, h, w) where n is the batch size, c is the number of channels, h is height, and w is width\n    # Apply horizontal flip with probability 0.5\n    batch_size, channels, height, width = images.size()\n    flip_mask = torch.rand(batch_size) < 0.5  # Create a random mask for flipping\n\n    # Here I want to use the flip_mask to conditionally flip the images\n    flipped_images = images.clone()  # Create a copy of images for manipulation\n    return flipped_images\n\nimages = load_data()  # assumes this returns a tensor of shape (batch_size, channels, height, width)\nflipped_images = random_horizontal_flip(images)\nI want to fill in the blank below to achieve the desired flip functionality:\n\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [2])  # [2] indicates flipping along height\n</code>",
    "output": "\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [3])  # [3] indicates flipping along width\n</code>"
  },
  {
    "input": "Problem:\nI have the following dataset containing temperatures recorded over several days, with some missing values:\n```python\ndates = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\"]\ntemperatures = [30, None, 32, None, 34]\n```\nI want to fill in the missing temperatures using the method of linear interpolation. Additionally, I need to ensure that the dates are formatted as \"DD-Month-YYYY\". \n\nThe expected output should look like this:\n```\n         date  temperature\n0  01-January-2023         30.0\n1  02-January-2023         31.0\n2  03-January-2023         32.0\n3  04-January-2023         33.0\n4  05-January-2023         34.0\n```\n\nWhat code can I use to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ndates = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\"]\ntemperatures = [30, None, 32, None, 34]\ndf = pd.DataFrame({'date': dates, 'temperature': temperatures})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['temperature'] = df['temperature'].interpolate()\ndf['date'] = pd.to_datetime(df['date']).dt.strftime('%d-%B-%Y')\nresult = df\n</code>"
  },
  {
    "input": "Problem:\nSuppose I have a dataset represented as a DataFrame containing information about the daily sales of various products, with some missing values indicating days when sales were not recorded. The DataFrame is structured like this:\n\n```python\ndf = pd.DataFrame({\n    'product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-01', '2023-01-03', '2023-01-01', \n             '2023-01-02', '2023-01-03', '2023-01-05'],\n    'sales': [100, 150, None, 200, None, None, 50, None, None]\n})\n```\n\nI would like to fill in the missing sales values for each product using the method of forward filling and then backfill on remaining NaNs within the date range of each product. The expected output should fill missing sales values first with the last known value and then with the next known value, resulting in a complete sales record for each product over the provided dates.\n\nThe DataFrame after applying this filling technique should look like this:\n\n```plaintext\n  product        date  sales\n0       A  2023-01-01  100.0\n1       A  2023-01-02  150.0\n2       A  2023-01-03  150.0\n3       A  2023-01-04  150.0\n4       B  2023-01-01  200.0\n5       B  2023-01-02  200.0\n6       B  2023-01-03  200.0\n7       C  2023-01-01   50.0\n8       C  2023-01-02   50.0\n9       C  2023-01-03   50.0\n10      C  2023-01-04   50.0\n11      C  2023-01-05   50.0\n```\n\nHow can I achieve this result using pandas? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-01', '2023-01-03', '2023-01-01', \n             '2023-01-02', '2023-01-03', '2023-01-05'],\n    'sales': [100, 150, None, 200, None, None, 50, None, None]\n}\ndf['date'] = pd.to_datetime(df['date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.sort_values(by=['product', 'date'])\ndf['sales'] = df.groupby('product')['sales'].ffill().bfill()\nresult = df\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that computes the Mean Squared Error (MSE) for a specific class in my multi-class regression dataset. My model predicts an output of shape (batch_size, num_classes), while the true labels are given in a similar shape. For example, if my predicted output is:\n```\npredictions = [[0.5, 0.2, 0.1],\n               [0.4, 0.6, 0.3]]\n```\nand my true labels are:\n```\nlabels = [[0, 1, 0],\n          [1, 0, 0]]\n```\nI need to calculate the MSE for class 1. I am uncertain how to apply the mask properly to only compute the MSE for the specified class index (e.g., class_idx = 1). \n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.5, 0.2, 0.1],\n                            [0.4, 0.6, 0.3]])\nlabels = tf.constant([[0, 1, 0],\n                      [1, 0, 0]])\nclass_idx = 1\n\ndef custom_loss(predictions, labels, class_idx):\n    # return the solution in this function\n    # loss = custom_loss(predictions, labels, class_idx)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mask = tf.equal(tf.argmax(labels, axis=1), class_idx)\n    mse = tf.reduce_mean(tf.square(tf.boolean_mask(predictions[:, class_idx], mask) - \n                                    tf.boolean_mask(labels[:, class_idx], mask)))\n    return mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "## Problem\nI have two DataFrames, `products` and `sales`, defined as follows:\n```python\nproducts\n   product_id product_name  price\n0           1      apples   1.00\n1           2      oranges  1.50\n2           3      bananas  1.20\n\nsales\n   product_id quantity sales_date\n0           1      10  2023-01-01\n1           2      20  2023-01-01\n2           3      15  2023-01-02\n3           1      5   2023-01-02\n4           2      10  2023-01-03\n```\n\nI want to create a new DataFrame that summarizes total sales quantity for each product, including the product name and price. The resulting DataFrame should look like this:\n```\n   product_id product_name  price  total_quantity\n0           1      apples   1.00              15\n1           2      oranges  1.50              30\n2           3      bananas  1.20              15\n```\n\nYou can create the desired DataFrame by merging the two DataFrames and aggregating the total quantity sold for each product. I attempted to do this using `pd.merge()` and `groupby()`, but it did not yield the expected results. \n\nHere is the code to start with:\n```python\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['apples', 'oranges', 'bananas'],\n    'price': [1.00, 1.50, 1.20]\n})\n\nsales = pd.DataFrame({\n    'product_id': [1, 2, 3, 1, 2],\n    'quantity': [10, 20, 15, 5, 10],\n    'sales_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03']\n})\n```\nThe result should be assigned to the variable `result` like this:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = products.merge(sales.groupby('product_id', as_index=False)['quantity'].sum(), on='product_id') \\\n                 .rename(columns={'quantity': 'total_quantity'})\n```"
  },
  {
    "input": "Problem:\n\nYou have two dataframes representing sales data for different regions. The first dataframe, `df_sales`, contains information about each sale, including the `product_id`, `region`, and `quantity_sold`. The second dataframe, `df_products`, contains product details including the `product_id`, `product_name`, and `price`.\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2],\n    'region': ['North', 'South', 'North', 'East', 'West'],\n    'quantity_sold': [10, 15, 5, 7, 3]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n    'price': [20.0, 35.0, 50.0]\n})\n```\n\nYou want to merge these two dataframes on `product_id` and calculate the total revenue generated for each product in each region. The desired output should include `product_name`, `region`, and `total_revenue`, with `total_revenue` being calculated as `quantity_sold * price`.\n\nHow can you achieve this?\n\nA:\n\n```python\ndf_result = ... # put solution in this variable\n```",
    "output": "\n```python\ndf_result = df_sales.merge(df_products, on='product_id') \\\n                     .assign(total_revenue=lambda x: x['quantity_sold'] * x['price']) \\\n                     [['product_name', 'region', 'total_revenue']]\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter( ________ )  # provide the correct parameters for brightness, contrast, saturation, hue\n])\n\nimage = load_image()  # Assume this function loads an image tensor\naugmented_image = data_transforms(image)\n```\n\nA:\n\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a sequence of time series data stored in a 3D tensor with the shape (batch_size, sequence_length, features). You need to extract a sliding window of size `window_size` from this tensor, where each window overlaps with the previous one by `step_size`. Your output should be a 4D tensor containing all the sliding windows, preserving the batch dimension.\n\nFor instance, if you have a tensor of shape (2, 5, 3) and you want to create windows of size 3 with a step size of 1, your output should be a tensor of shape (2, 3, 3, 3), where the second dimension corresponds to the number of windows extracted.\n\nHere's the current setup:\n\n```python\nimport torch\ndata = load_data()  # shape is (batch_size, sequence_length, features)\nwindow_size = 3\nstep_size = 1\n```\n\nHow can you generate the sliding windows and obtain the desired shape? \n\nA:\n\n<code>\nwindows = ... # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nwindows = data.unfold(1, window_size, step_size)  # shape will be (batch_size, num_windows, window_size, features)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am working on a regression problem and I want to create a custom loss function that penalizes predictions based on the squared error, but with an added twist: I want to multiply the squared error by a weight that is based on the absolute value of the true target. This will allow me to place more emphasis on errors for larger target values. For example, if my target values are [2, 3, 5], I want the loss to be calculated as follows:\n\\[ \\text{loss} = \\sum w \\cdot (y_{\\text{true}} - y_{\\text{pred}})^2 \\]\nwhere \\( w = |y_{\\text{true}}| \\).\n\nHere is a basic setup:\n\n```python\nimport tensorflow as tf\n\ndef custom_weighted_mse(y_true, y_pred):\n    # Implement the custom loss function here\n    pass\n\n# Example usage\ny_true = tf.constant([2.0, 3.0, 5.0])\ny_pred = tf.constant([1.0, 2.0, 5.0])\nloss = custom_weighted_mse(y_true, y_pred)\n```\nFill in the custom loss function to compute the weighted mean squared error based on the description above.\n\nA:\n<code>\n### BEGIN SOLUTION",
    "output": "\n<code>\n    w = tf.abs(y_true)\n    squared_error = tf.square(y_true - y_pred)\n    weighted_loss = w * squared_error\n    return tf.reduce_mean(weighted_loss)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor that represents a batch of images with shape (batch_size, channels, height, width). I want to compute the mean across the spatial dimensions (height and width) for each channel in the batch without using loops. The tensor I have is:\n\n```python\nimages = torch.randn(4, 3, 32, 32)  # Example tensor with shape (batch_size=4, channels=3, height=32, width=32)\n```\nMy goal is to return a tensor of shape (batch_size, channels) containing the mean values for each channel across all pixels.\n\nHow can I accomplish this?\n\nA:\n\n```python\nimport torch\nimages = load_data()  # Assuming images is loaded as a tensor of shape (4, 3, 32, 32)\n```\nmean_values = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nmean_values = images.mean(dim=(2, 3))\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to define a custom loss function for a regression model that penalizes predictions more heavily when they are far from the true values. The function should compute the squared error loss and apply an additional factor that increases the penalty based on the distance from the true value. Specifically, if the difference between the predicted value `y_pred` and true value `y_true` exceeds a threshold (e.g., 1.0), the penalty factor should be 2; otherwise, it should be 1. Here's a snippet of my code where I want to implement this logic:\n\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the absolute difference\n    difference = tf.abs(y_true - y_pred)\n    penalty_factor = tf.where(difference > 1.0, 2.0, 1.0)\n    loss = tf.square(difference) * penalty_factor\n    return tf.reduce_mean(loss)\n\n# Example usage with dummy data\ny_true = tf.constant([2.0, 3.0, 5.0])\ny_pred = tf.constant([2.5, 2.0, 7.0])\nloss_value = custom_loss(y_true, y_pred)\n```\n\nIn this snippet, the last line computes the loss, but I need to define the `loss` variable properly with the logic shown. Fill in the blank with the logic to calculate the loss based on the difference and penalty factor. \n\nA:\n<code>\nloss = ...  # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\nloss = tf.square(difference) * penalty_factor\n</code>"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I need to perform element-wise operations on a batch of tensors. Specifically, I want to scale the first dimension of a tensor using a scaling factor that is also a tensor. My current tensor has the shape (N, C, H, W) where N is the batch size, and the scaling factor is simply a 1D tensor of shape (N). \n\nHere is the initial setup I have:\n\n```python\nimport torch\nN, C, H, W = 4, 3, 16, 16\ntensors = torch.randn(N, C, H, W)  # Sample tensor\nscaling_factors = torch.tensor([1, 0.5, 2, 1.5])  # Scaling factors for each batch\n```\n\nI want to apply the scaling factors to each slice of the tensor along the first dimension (N) while maintaining the same dimensions of the tensor. The desired output is a tensor with the same shape as the input tensor but scaled according to the corresponding factor. \n\nHow do I perform this operation? Please provide the code to fill in the blank.\n\nscaled_tensors = ...  # put solution in this variable",
    "output": "\n```python\nscaled_tensors = tensors * scaling_factors.view(N, 1, 1, 1)  # Scale each slice\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to develop a custom loss function to address the specific problem of overfitting in my regression model. In this case, I want to punish predictions that are more than a certain threshold (e.g., 0.5) away from the actual values. My input tensors are the predicted values and the actual values. I wish to compute the loss as follows: if the absolute error surpasses the threshold, the loss should multiply that error by two; if it does not exceed the threshold, the loss should be the error itself. \n\nHere's how to set up my function:\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 0.5\n    # Calculate the absolute error\n    error = tf.abs(y_true - y_pred)\n    # Apply the custom logic to compute the loss\n    loss = ...\n    return loss\n</code>",
    "output": "\n<code>\n    loss = tf.where(error > threshold, error * 2, error)\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI am building a custom loss function based on the mean absolute error (MAE) that incorporates a penalty for predictions that deviate significantly from the actual values. My goal is to multiply the MAE by a penalty factor that ramps up as the error increases. The penalty function is defined as `penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)`, where `threshold` is a fixed value. I want to implement this custom loss function. \n\nGiven `y_true` and `y_pred` as two tensors: \n```python\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nHow can I define the custom loss function that applies the penalty, where `threshold` is set to 1.0?\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\nthreshold = 1.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)\n    return mae * penalty\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 102, 104, 104],\n    'sales': [200, None, 340, None, 300, 400, None],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-01', \n                            '2023-01-02', '2023-01-02', '2023-01-02', '2023-01-03'])\n})\n```\n\nYou would like to forward-fill the missing sales data for each product based on the date, ensuring that every product has sales data for each unique date available in the DataFrame. Therefore, you'll need to produce an output where the sales for each product are filled in consecutively from the last known value.\n\nCurrently, you have this DataFrame:\n\n```python\n   product_id  sales       date\n0         101  200.0 2023-01-01\n1         102    NaN 2023-01-01\n2         103  340.0 2023-01-01\n3         101    NaN 2023-01-02\n4         102  300.0 2023-01-02\n5         104  400.0 2023-01-02\n6         104    NaN 2023-01-03\n```\n\nwhat you need to do is to fill in the missing values in the 'sales' column for each 'product_id' based on the 'date' column.\n\nYour goal is to obtain a compressed DataFrame with no NaN values in 'sales' caused by forward-fill, while maintaining the same format. \n\nPlease provide the correct line of code to achieve this result. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('product_id').apply(lambda group: group.set_index('date').resample('D').ffill()).reset_index()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame with missing values in some columns, which looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'id': [1, 2, 3, 4, 5],\n    'age': [25, np.nan, np.nan, 30, 35],\n    'income': [50000, 60000, np.nan, np.nan, 70000],\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour objective is to fill in the missing values in the 'age' column using the method of forward filling based on the previous non-null value, and the missing values in the 'income' column by filling them with the mean income of the individuals in the DataFrame.\n\nHow can you update the DataFrame accordingly? \n\nPlease provide the line of code that achieves this result and assign it to the variable `result`.",
    "output": "\n<code>\nresult = df.fillna({'age': df['age'].ffill(), 'income': df['income'].mean()})\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor that represents the output of a neural network from a batch of images, and I need to apply a threshold to it. Specifically, I want to create a mask that sets values above a certain threshold to 1 and below or equal to that threshold to 0, effectively binarizing the output.\n\nHere's my current setup:\n\nimport torch\n\noutput_tensor = torch.randn(5, 5)  # Simulated output from a neural network\nthreshold = 0.5\n\nI want to generate a binary mask from this output tensor based on the threshold value.\n\nA:\n\n<code>\nimport torch\noutput_tensor = load_data()  # Simulated output from a neural network\nthreshold = 0.5\nbinary_mask = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nbinary_mask = (output_tensor > threshold).float()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a sequence of time-series data for multiple features, and I want to compute the moving average using PyTorch. The tensor `data` has a shape of `(batch_size, num_features, sequence_length)`, and I want to apply a window size of `k` for the moving average calculation. \n\nHowever, the challenge is to create a new tensor that represents the moving average for each feature across the sequence, which will result in a tensor of shape `(batch_size, num_features, sequence_length - k + 1)`.\n\nGiven the following tensor:\n\n```\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\n```\n\nAnd a moving average window size of `k = 2`, how can I calculate the moving averages efficiently with PyTorch?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nk = 2\nmoving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\nk = 2\nmoving_avg = data.unfold(2, k, 1).mean(dim=3)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe containing sales data as follows:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'store': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-01', '2022-01-03', '2022-01-02', '2022-01-04'],\n    'sales': [100, None, 200, 150, None, 300]\n})\n```\n\nI want to fill in the missing sales values in the `sales` column using the sales values from the same store on other dates, specifically by applying forward fill if earlier sales exist, and backward fill if no earlier sales exist for a specific store. \n\nThus, the desired output for the `sales_data` dataframe should look like this:\n\n```\n  store        date  sales\n0    A  2022-01-01  100.0\n1    A  2022-01-02  100.0\n2    B  2022-01-01  200.0\n3    B  2022-01-03  150.0\n4    C  2022-01-02  300.0\n5    C  2022-01-04  300.0\n```\n\nWhat code can I use to achieve this filling technique?\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.groupby('store')['sales'].apply(lambda x: x.ffill().bfill())\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am working on a regression problem and I need to implement a custom loss function that penalizes predictions based on the squared percentage error (SPE). The SPE is calculated as:\n  \n\\[ \\text{SPE} = \\left( \\frac{|y - \\hat{y}|}{|y|} \\right)^2 \\]\n\nwhere \\( y \\) is the true value and \\( \\hat{y} \\) is the predicted value. If \\( y \\) is 0, the loss should be set to a constant value of 1 for the sake of stability.\n\nI need to apply this loss function on two tensors representing the true values and predicted values. Below is the setup:\n\n```python\nimport tensorflow as tf\n\ntrue_values = tf.constant([10.0, 0.0, 15.0, 25.0], dtype=tf.float32)\npredicted_values = tf.constant([8.0, 1.0, 15.0, 20.0], dtype=tf.float32)\n```\n\nI want to implement the loss function and compute the resulting tensor. \n\nPlease fill in the following code with the correct implementation of the custom loss function:\n\n```python\ndef custom_spe_loss(y_true, y_pred):\n    # Implement the custom squared percentage error loss function here\n    ### BEGIN SOLUTION\n```\n\nEvaluate the loss function using the provided tensors:\n\n```python\nloss_result = custom_spe_loss(true_values, predicted_values)\n```",
    "output": "\n```python\ndef custom_spe_loss(y_true, y_pred):\n    spe = tf.where(tf.equal(y_true, 0.0), 1.0, tf.square(tf.abs(y_true - y_pred) / tf.abs(y_true)))\n    return tf.reduce_mean(spe)\n\nloss_result = custom_spe_loss(true_values, predicted_values)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains the daily sales data for a store with missing values. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n```\n\nMy goal is to use advanced imputation techniques to fill the missing sales data based on the mean of the available sales for the last three days in the respective 'date' order (backward filling). After filling the missing values, I want the DataFrame to look like this:\n\n```\n        date  sales\n0 2023-01-01  250.0\n1 2023-01-02  250.0\n2 2023-01-03  300.0\n3 2023-01-04  316.67\n4 2023-01-05  400.0\n```\n\nWhat would be an efficient way to achieve this using pandas? I am currently considering using the rolling window function but need help to refine my approach.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['sales'] = df['sales'].fillna(df['sales'].rolling(window=3, min_periods=1).mean().shift(1))\nresult = df\n</code>"
  },
  {
    "input": "Problem:\nI've collected two data frames related to my sales data from two different regions:\n\ndf_sales:\n   transaction_id      date  region  amount\n0               1 2022-01-01       A     100\n1               2 2022-01-02       A     150\n2               3 2022-01-03       A     200\n3               4 2022-01-01       B     250\n4               5 2022-01-04       B     300\n\ndf_region_info:\n   region     manager   city\n0      A       John   New York\n1      B       Lisa   Los Angeles\n\nI want to merge these two data frames based on the 'region' column, while keeping all sales data, even if there's no corresponding region information. Additionally, I want the date in the format 'MMM DD, YYYY'. The expected output should look like this:\n\n   transaction_id          date region  amount manager         city\n0               1   Jan 01, 2022      A     100    John     New York\n1               2   Jan 02, 2022      A     150    John     New York\n2               3   Jan 03, 2022      A     200    John     New York\n3               4   Jan 01, 2022      B     250    Lisa  Los Angeles\n4               5   Jan 04, 2022      B     300    Lisa  Los Angeles\n\nI've started by merging the two dataframes using `pd.merge`, but I'm unsure how to format the date correctly and maintain all rows from `df_sales`. So far, I've done:\n\nmerged_df = pd.merge(df_sales, df_region_info, on='region', how='...')\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4, 5],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-01', '2022-01-04'],\n    'region': ['A', 'A', 'A', 'B', 'B'],\n    'amount': [100, 150, 200, 250, 300]\n})\n\ndf_region_info = pd.DataFrame({\n    'region': ['A', 'B'],\n    'manager': ['John', 'Lisa'],\n    'city': ['New York', 'Los Angeles']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmerged_df = pd.merge(df_sales, df_region_info, on='region', how='left')\nmerged_df['date'] = pd.to_datetime(merged_df['date']).dt.strftime('%b %d, %Y')\nresult = merged_df\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames representing customer orders and product details as shown below:\n\nOrders\n```\n   OrderID  CustomerID  ProductID  Quantity\n0      101          1          20         2\n1      102          2          30         1\n2      103          1          20         5\n3      104          3          40         3\n```\n\nProducts\n```\n   ProductID  ProductName  Price\n0         20         Apple   1.00\n1         30        Banana   0.50\n2         40        Cherry   0.75\n```\n\nI need to merge these two DataFrames to create a new DataFrame that includes all columns from Orders and the corresponding ProductName and Price based on ProductID. The resulting DataFrame should only include the orders for which the product exists, and it should retain the original OrderID order.\n\nWhat single line of code can I use to accomplish this merging operation?\n\nA:\n```python\nimport pandas as pd\n\norders = pd.DataFrame({\n    'OrderID': [101, 102, 103, 104],\n    'CustomerID': [1, 2, 1, 3],\n    'ProductID': [20, 30, 20, 40],\n    'Quantity': [2, 1, 5, 3]\n})\n\nproducts = pd.DataFrame({\n    'ProductID': [20, 30, 40],\n    'ProductName': ['Apple', 'Banana', 'Cherry'],\n    'Price': [1.00, 0.50, 0.75]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n",
    "output": "\n```python\nresult = pd.merge(orders, products, on='ProductID', how='inner')\n```"
  },
  {
    "input": "### Problem:\nYou have a dataset detailing sales transactions over several months. The dataset looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\n```\n\nIn the `Sale_Date`, some transactions have missing dates denoted by '0'. Your task is to replace the '0' values in the `Sale_Date` with the average date from the existing sales dates for each product, replacing the '0' values with the average date of their respective `Product_ID`. The average date should be in the format 'YYYY-MM-DD'.\n\nHow would you achieve this in pandas? \n\nPlease fill in the code below to perform the imputation:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\nsales_data['Sale_Date'] = pd.to_datetime(sales_data['Sale_Date'].replace('0', pd.NaT)) \n# Your solution to fill in the blanks\nresult = ... # put your solution in this variable\n```\n",
    "output": "\n```python\nresult = sales_data.groupby('Product_ID')['Sale_Date'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to build a custom mean squared error loss function based on the predictions and true labels of a regression problem, where I want to penalize predictions that are above a certain threshold more heavily. For instance, if the threshold is set to 0.5, predictions above this should have their squared differences multiplied by 2. I have arrays of predictions and true values as follows:\npredictions = [0.1, 0.6, 0.4, 0.9]\ntrue_values = [0.0, 1.0, 0.5, 1.0]\nHow can I implement this custom loss function, such that it returns the computed loss? \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(predictions, true_values, threshold=0.5):\n    # return the loss calculation in this function\n    ### BEGIN SOLUTION\n```",
    "output": "\n<code>\n    squared_differences = tf.square(predictions - true_values)\n    penalty = tf.where(predictions > threshold, 2.0 * squared_differences, squared_differences)\n    return tf.reduce_mean(penalty)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, orders and products, that represent sales data. The orders DataFrame contains order IDs and product IDs, while the products DataFrame contains product IDs along with their names and prices. The task is to merge these two DataFrames on the product ID so that we can analyze which products were sold with their corresponding names and prices in a single DataFrame. The expected output should also contain the total price for each order by multiplying the quantity of products sold by their respective prices.\n\nHere's the setup of the DataFrames:\n\norders:\n```\n   order_id  product_id  quantity\n0        1        101         2\n1        2        102         1\n2        3        101         1\n3        4        103         3\n```\n\nproducts:\n```\n   product_id     name  price\n0        101   WidgetA   10.0\n1        102   WidgetB   15.0\n2        103   WidgetC   20.0\n```\n\nThe desired output DataFrame should include the following columns: order_id, product_id, quantity, name, price, and total_price.\n\nTo achieve this, start with this code snippet:\n```python\nimport pandas as pd\n\norders = pd.DataFrame({\n    'order_id': [1, 2, 3, 4],\n    'product_id': [101, 102, 101, 103],\n    'quantity': [2, 1, 1, 3]\n})\n\nproducts = pd.DataFrame({\n    'product_id': [101, 102, 103],\n    'name': ['WidgetA', 'WidgetB', 'WidgetC'],\n    'price': [10.0, 15.0, 20.0]\n})\n\n# Merge the DataFrames on product_id\nresult = ...\n```\nFill in the blank to obtain the desired output.",
    "output": "\n```python\nresult = orders.merge(products, on='product_id')\nresult['total_price'] = result['quantity'] * result['price']\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.12.0. I want to implement a custom loss function to penalize predictions based on their absolute differences from the true values. The loss should be calculated as the mean of the absolute differences for a batch of predictions and true targets. My predictions are a tensor of shape (batch_size, number_of_classes), and the true values are given as a tensor of the same shape. I want to create a function that computes this custom loss function efficiently. \n\nHere is the setup for my predictions and true values:\n```python\npredictions = tf.constant([[0.1, 0.4, 0.5],\n                            [0.2, 0.2, 0.6],\n                            [0.7, 0.1, 0.2]])\ntrue_values = tf.constant([[0, 1, 0],\n                            [0, 0, 1],\n                            [1, 0, 0]])\n```\nWhat is the correct implementation of my custom loss function, which should return a single scalar value representing the average of the absolute differences?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(predictions, true_values):\n    # Implement the loss function here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    absolute_differences = tf.abs(predictions - true_values)\n    mean_loss = tf.reduce_mean(absolute_differences)\n    return mean_loss\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have two pandas DataFrames: one contains product information and the other contains sales data. The product DataFrame, `df_products`, includes the columns 'ProductID' and 'ProductName', while the sales DataFrame, `df_sales`, includes 'SaleID', 'ProductID', 'Quantity', and 'SaleDate'. You want to combine these two DataFrames to generate a single DataFrame that contains 'SaleID', 'ProductName', 'Quantity', and 'SaleDate'. \n\nHere's the setup:\n\n```python\nimport pandas as pd\n\ndf_products = pd.DataFrame({\n    'ProductID': [1, 2, 3],\n    'ProductName': ['Widget', 'Gadget', 'Sprocket']\n})\n\ndf_sales = pd.DataFrame({\n    'SaleID': [101, 102, 103, 104],\n    'ProductID': [1, 1, 2, 3],\n    'Quantity': [4, 2, 5, 1],\n    'SaleDate': ['2023-10-01', '2023-10-02', '2023-10-03', '2023-10-04']\n})\n\n# Use the following line to merge the two DataFrames to get the desired output\nresult = ... # put solution in this variable\n```\n\nThe expected output should look like this:\n\n```\n   SaleID ProductName  Quantity    SaleDate\n0     101      Widget         4   2023-10-01\n1     102      Widget         2   2023-10-02\n2     103      Gadget         5   2023-10-03\n3     104     Sprocket         1   2023-10-04\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_products, on='ProductID')[['SaleID', 'ProductName', 'Quantity', 'SaleDate']]\n```"
  },
  {
    "input": "Problem:\nYou are working on a data analysis project where you have two datasets that need to be merged based on a common column. The first dataset (`sales_data`) contains information about sales, including the date and product ID, while the second dataset (`product_info`) contains details about the products, including product ID and category.\n\nHere is the `sales_data` DataFrame:\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'product_id': [101, 102, 101, 103],\n    'amount': [250, 300, 150, 400]\n})\n\nproduct_info = pd.DataFrame({\n    'product_id': [101, 102, 103],\n    'category': ['Electronics', 'Toys', 'Books']\n})\n```\n\nYou want to create a new DataFrame (`merged_data`) that includes all columns from `sales_data` and only the `category` column from `product_info`. The result should keep all records from `sales_data` even if a corresponding product ID does not exist in `product_info`.\n\nHow can you accomplish this in pandas?\n\nPlease complete the following line to merge the two DataFrames:\n```python\nmerged_data = ...\n```",
    "output": "\n```python\nmerged_data = pd.merge(sales_data, product_info[['product_id', 'category']], on='product_id', how='left')\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a machine learning model that requires dynamically resizing tensors based on varying input data. You have a tensor `data` with a shape of `[batch_size, features]`, where `data.size() == torch.Size([4, 10])`. The task is to create a new tensor `resized_data` that contains each row of `data` repeated `n` times while keeping the total number of elements constant. The value of `n` will be provided as input which is equal to the length of features minus a specified integer `s`. \n\nFor example, if your input `n` is 5 and `s` is 5, the new shape of the tensor should be `[4, 5]`. If `n` is larger than the remaining features, you should fill the rest with zeros.\n\nHow would you resize the tensor accordingly?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nn = ... # number of times to repeat each element\ns = ... # specified integer to decrease the feature length\n</code>\nresized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nbatch_size, features = data.size()\nnew_features = features - s\nresized_data = torch.zeros(batch_size, new_features)\n\nfor i in range(batch_size):\n    resized_data[i, :min(n, new_features)] = data[i, :min(n, features)]\n</code>\n</code>"
  }
]