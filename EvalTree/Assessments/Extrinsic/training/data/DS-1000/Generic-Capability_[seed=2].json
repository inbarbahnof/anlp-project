[
  {
    "input": "Problem:\nYou have a dataset of a linear regression model, stored in a DataFrame, where you want to visualize the relationship between the predictors and the target variable. The dataset contains a 'Feature1', 'Feature2', and 'Target' column. \n\nHere\u2019s a sample DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    \"Feature1\": np.random.rand(100),\n    \"Feature2\": np.random.rand(100),\n    \"Target\": np.random.rand(100)\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to create a 3D scatter plot that visualizes 'Feature1' and 'Feature2' on the x and y axes, and 'Target' on the z axis, using Matplotlib. \nYou should also set appropriate axis labels that indicate which variable corresponds to which axis.\n\nA:\n<code>\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n</code>\nax.scatter(...), ax.set_xlabel(...), ax.set_ylabel(...), ax.set_zlabel(...)  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nax.scatter(df['Feature1'], df['Feature2'], df['Target'])\nax.set_xlabel('Feature1')\nax.set_ylabel('Feature2')\nax.set_zlabel('Target')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Imagine you have the following dataset with 'Year' as the independent variable\ndata = {\n    'Year': [2000, 2001, 2002, 2003, 2004],\n    'Revenue': [200, 240, 300, 350, 400]\n}\n\ndf = pd.DataFrame(data)\n\n# Prepare the data for linear regression\nX = df[['Year']].values\ny = df['Revenue'].values\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict revenues for years 2005 to 2010\nyears_to_predict = np.array([[2005], [2006], [2007], [2008], [2009], [2010]])\npredicted_revenues = model.predict(years_to_predict)\n\n# Plotting the original revenues and the predictions\nplt.scatter(df['Year'], df['Revenue'], color='blue', label='Original Revenue')\nplt.plot(np.concatenate((df['Year'].values, years_to_predict.flatten())), \n         np.concatenate((y, predicted_revenues)), color='red', label='Predicted Revenue')\n\n# Display the plot\nplt.title('Revenue Prediction')\nplt.xlabel('Year')\nplt.ylabel('Revenue')\nplt.legend()\nplt.show()\n\n# However, I need to gather the predicted revenues into a single dictionary with years as keys,\n# and the predicted revenues as values. Please show how to do this.\n\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = {year[0]: revenue for year, revenue in zip(years_to_predict, predicted_revenues)}\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Generate sample data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # Feature\ny = 2.5 * X.squeeze() + np.random.randn(100) * 2  # Target with some noise\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit a Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict and calculate mean squared error\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\n\n# Plotting the results\nplt.scatter(X_test, y_test, color='blue', label='Actual')\nplt.scatter(X_test, predictions, color='red', label='Predicted')\nplt.title('Linear Regression Predictions')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.legend()\n\n# Save the plot to a file\n# SOLUTION START\nplt.savefig('linear_regression_results.png')\n# SOLUTION END\n```",
    "output": "\n```python\nplt.savefig('linear_regression_results.png')\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Create a sample DataFrame with synthetic data for three features\ndata = pd.DataFrame({\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'feature3': np.random.rand(100)\n})\n\n# Before performing PCA, we need to scale the data.\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n\n# Now we want to apply PCA to reduce the dimensions of this data to 2 principal components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Finally, we want to visualize the first two principal components.\n# Create a scatter plot of the PCA results.\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.title('PCA Result: Scatter Plot of First Two Principal Components')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid()\n\n# What is the next step to save the plot as a file named 'pca_result.png'?\n# Please fill in the blank below.\n\nplt.savefig('...')  # put solution in this variable\n```",
    "output": "\n```python\nplt.savefig('pca_result.png')\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some sample data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # 100 random points in range 0-10\ny = 2.5 * X + np.random.randn(100, 1)  # Linear relation with some noise\n\n# Create a DataFrame\ndf = pd.DataFrame(data=np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['Feature']], df['Target'])\n\n# Plot the data and the regression line\nplt.scatter(df['Feature'], df['Target'], label='Data Points')\nplt.plot(df['Feature'], model.predict(df[['Feature']]), color='red', label='Regression Line')\n\n# Add legend, title, and labels\n# SOLUTION START\n```",
    "output": "\n```python\nplt.legend()\nplt.title('Linear Regression Example')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that has user activity data stored in a Pandas DataFrame. The DataFrame contains a column for user IDs, timestamps of activities, and a column for the actions performed. Here's an example of the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 2, 3, 2, 3, 1, 2],\n    'timestamp': pd.to_datetime([\n        '2023-01-01 12:00:00', '2023-01-01 12:10:00', \n        '2023-01-01 12:05:00', '2023-01-01 12:15:00', \n        '2023-01-01 12:20:00', '2023-01-01 12:25:00', \n        '2023-01-01 12:30:00', '2023-01-01 12:35:00'\n    ]),\n    'action': ['login', 'logout', 'login', 'login', 'logout', 'logout', 'login', 'logout']\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new DataFrame that summarizes the number of actions performed by each user, with a specific filter to only include actions that took place between '2023-01-01 12:00:00' and '2023-01-01 12:30:00'. Additionally, you would like to rename the action counts column to 'action_count'. \n\nA:\n```python\nfiltered_df = df[(df['timestamp'] >= '2023-01-01 12:00:00') & (df['timestamp'] <= '2023-01-01 12:30:00')]\nresult = ... # put solution in this variable\n```\nBEGIN SOLUTION\n```python\n",
    "output": "\n```python\nresult = filtered_df.groupby('user_id').size().reset_index(name='action_count')\n```"
  },
  {
    "input": "Problem:\nI have a dataset of flower measurements stored in a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'species': ['setosa', 'versicolor', 'virginica', 'setosa', 'versicolor', 'virginica'],\n    'sepal_length': [5.1, 7.0, 6.3, 4.9, 6.4, 5.8],\n    'sepal_width': [3.5, 3.2, 3.3, 3.0, 3.2, 2.7],\n    'petal_length': [1.4, 4.7, 6.0, 1.4, 5.0, 5.1],\n    'petal_width': [0.2, 1.4, 2.5, 0.2, 1.5, 1.9]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to standardize the numerical columns in the DataFrame (i.e., scale them to have a mean of 0 and a standard deviation of 1) using Scikit-learn's `StandardScaler`. So far, I have:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n```\n\nWhat I need help with is how to fit the scaler to the DataFrame and transform the numerical columns while keeping the original DataFrame structure intact. Specifically, I want the transformed values in a new DataFrame while retaining the species labels. \n\nPlease provide the code for that:\n\n```python\nscaled_df = ... # put solution in this variable\n```",
    "output": "\n```python\nscaled_values = scaler.fit_transform(df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])\nscaled_df = pd.DataFrame(scaled_values, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\nscaled_df['species'] = df['species'].values\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset that contains information about the daily temperatures and corresponding ice cream sales in a city. I want to investigate the relationship between temperature and sales by fitting a simple linear regression model using Scikit-learn. \n\nMy dataset is in a Pandas DataFrame structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Temperature': [30.5, 32.0, 29.5, 35.0, 28.0, 31.0, 34.0, 36.5],\n    'IceCreamSales': [210, 215, 190, 245, 185, 200, 240, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to predict ice cream sales based on a temperature input using a linear regression model. After fitting the model, I need to create a function that takes a temperature value and returns the predicted ice cream sales. The function should also plot the fitted line against the data points for visualization using Matplotlib.\n\nPlease fill in the missing code for the function `predict_sales_and_plot` which should be defined as follows:\n\n```python\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndef predict_sales_and_plot(df, temperature):\n    X = df[['Temperature']]\n    y = df['IceCreamSales']\n    \n    model = LinearRegression()\n    model.fit(X, y)\n    \n    predicted_sales = model.predict([[temperature]])\n    \n    plt.scatter(X, y, color='blue', label='Actual Sales')\n    plt.plot(X, model.predict(X), color='red', label='Fitted Line')\n    plt.xlabel('Temperature')\n    plt.ylabel('Ice Cream Sales')\n    plt.title('Ice Cream Sales vs Temperature')\n    plt.legend()\n    plt.show()\n    \n    return ...  # put solution in this variable to return the predicted sales\n\n```",
    "output": "\n```python\n    return predicted_sales[0]\n```"
  },
  {
    "input": "Problem:\nI have a dataset of customer transactions over multiple months, and I would like to normalize the transaction amounts. Here is a sample of my dataset:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 1, 2, 2, 3, 3],\n    'TransactionAmount': [150, 200, 300, 400, 500, 600],\n    'TransactionDate': ['2023-01-01', '2023-02-01', '2023-01-15', '2023-02-15', '2023-01-20', '2023-02-20']\n}\ndf = pd.DataFrame(data)\n```\n\nI want to normalize the 'TransactionAmount' column by subtracting the mean and dividing by the standard deviation for each customer. However, I'm stuck on how to apply this operation efficiently to each group and create a new column that reflects the normalized values.\n\nHow can I achieve this?\n\nA:\n```python\ndf['NormalizedAmount'] = ...\n```",
    "output": "\n```python\ndf['NormalizedAmount'] = df.groupby('CustomerID')['TransactionAmount'].transform(lambda x: (x - x.mean()) / x.std())\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing historical stock prices, and I want to calculate the 30-day rolling average closing price of a stock using Pandas. Additionally, I want to visualize this rolling average compared to the actual closing prices using Matplotlib.\n\nThe DataFrame looks like this (assuming it has been loaded into a variable named `df`):\n\n```\n             Date    Close\n0  2020-01-01   100.00\n1  2020-01-02   101.50\n2  2020-01-03   102.00\n...\n29 2020-01-30   110.00\n30 2020-01-31   111.50\n...\n```\n\nI want to create a new column in `df` for the rolling average and then plot both the actual closing prices and the 30-day rolling average on a line chart.\n\nHere's the setup:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2020-01-01', periods=100, freq='D'),\n    'Close': ...\n})\n\n# Ensure 'Date' is the index\ndf.set_index('Date', inplace=True)\n```\n\nThe code to calculate the rolling average should be placed in the variable `rolling_avg`:\n\n```python\nrolling_avg = ... # put solution in this variable\n```\n\nAfter calculating the rolling average, I want to execute the following code to plot them together:\n\n```python\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['Close'], label='Close Price')\nplt.plot(df.index, rolling_avg, label='30-Day Rolling Average', color='orange')\nplt.title('Stock Prices and 30-Day Rolling Average')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n```\nComplete the code by filling in the blank for `rolling_avg`.",
    "output": "\n```python\nrolling_avg = df['Close'].rolling(window=30).mean()\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing information about houses, which includes features such as square footage, number of bedrooms, and sale price. You want to build a simple linear regression model to predict the sale price based on the square footage and number of bedrooms. After fitting the model, you want to visualize the predicted sale prices against the actual sale prices with a scatter plot for better understanding.\n\nGiven the following setup:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Sample data\ndata = {\n    'square_footage': [1500, 1600, 1700, 1800, 1900, 2000],\n    'bedrooms': [3, 3, 4, 4, 5, 5],\n    'price': [300000, 320000, 340000, 360000, 380000, 400000]\n}\ndf = pd.DataFrame(data)\n```\nYou have already split the dataset into training and testing sets:\n```python\nX = df[['square_footage', 'bedrooms']]\ny = df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\nNext, you fit a linear regression model:\n```python\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\nNow you need to get the predicted values for the test set and visualize the results. \n\nYour task is to complete the line of code that generates the scatter plot where the x-axis represents the actual prices and the y-axis represents the predicted prices after making predictions on the test set.\n\nA:\n```python\ny_pred = model.predict(X_test)\n\nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual Prices')\nplt.ylabel('Predicted Prices')\nplt.title('Actual vs Predicted Prices')\nplt.show()\n```\nComplete the following line to fill in the missing part of the function:\n```python\nplt.scatter(... , ...) # put solution in this variable\n```",
    "output": "\n```python\nplt.scatter(y_test, y_pred)\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset of product sales represented by the following columns in a pandas DataFrame:\n- `ProductId`: Unique identifier for a product\n- `SalesAmount`: The total sales amount for each product\n- `Discount`: The discount applied to the product sales\n\nGiven the data:\n```python\nimport pandas as pd\ndata = {\n    'ProductId': [101, 102, 103, 104, 105],\n    'SalesAmount': [250, 150, 200, 300, 120],\n    'Discount': [0.1, 0.15, 0.2, 0.05, 0.1]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to calculate the net sales after discount for each product and then plot a bar chart to visualize the ProductId against the net sales. Fill in the blank where indicated.\n\nThe net sales can be calculated as follows:\n- Net Sales = Sales Amount - (Sales Amount * Discount)\n\nHow can you achieve this calculation and the plotting in Matplotlib?\n\nPlease use the following variable to store your result:\n```python\nnet_sales = ...  # Store the net sales calculation here\n```\nThen, create a bar chart using Matplotlib.\n\nBEGIN SOLUTION\n```python\nimport matplotlib.pyplot as plt\n\n# Calculate net sales\ndf['NetSales'] = df['SalesAmount'] - (df['SalesAmount'] * df['Discount'])\n\n# Plotting\nplt.bar(df['ProductId'], df['NetSales'])\nplt.xlabel('Product ID')\nplt.ylabel('Net Sales')\nplt.title('Net Sales by Product ID')\nplt.show()\n```",
    "output": "\n```python\nnet_sales = df['SalesAmount'] - (df['SalesAmount'] * df['Discount'])\n```"
  },
  {
    "input": "## Problem\nYou have a dataset representing customer purchases with columns for `customer_id` and `purchase_amount`. The purchase amounts are in dollars and you want to analyze this data.\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n    'purchase_amount': [100, 200, 150, 300, 250, 100, 200, 50]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new DataFrame that summarizes the total purchase amount by each `customer_id`, showing the `customer_id` and their corresponding `total_purchase_amount` in descending order.\n\nWhat code should you use to produce the expected result? Store the result in a variable named `summary`.\n\nA:\n```python\nsummary = ...\n```",
    "output": "\n```python\nsummary = df.groupby('customer_id')['purchase_amount'].sum().reset_index(name='total_purchase_amount').sort_values(by='total_purchase_amount', ascending=False)\n```"
  },
  {
    "input": "Problem:\nI have a dataset with various measurements of some animals, including their species and weights, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Species': ['Lion', 'Tiger', 'Elephant', 'Giraffe', 'Zebra'],\n    'Weight': [420, 390, 6000, 800, 400],\n    'Height': [1.2, 1.1, 3.3, 4.5, 1.5],\n    'Length': [2.5, 2.6, 6.7, 4.6, 2.1]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to build a model to predict animal weight based on height and length. After preparing the data (i.e., splitting into features and target), I would like to fit a linear regression model using Scikit-learn.\n\nCan you help me complete the missing code to fit the model? Here is the partial code:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nX = df[['Height', 'Length']]\ny = df['Weight']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# After fitting the model, I want to print the coefficients of the model.\ncoefficients = ... # put solution in this variable\nprint(coefficients)\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ncoefficients = model.coef_</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information on sales made by a retail store over the last year. My dataset has two columns: \"Date\" and \"Sales\", with dates ranging from \"2022-01-01\" to \"2022-12-31\". I want to calculate the rolling average of the sales over the last 7 days and make a line plot to visualize this trend. I can use Pandas for data manipulation and Matplotlib for plotting, but I need help filling in the code to calculate the rolling average.\n\nHere's a simplified version of my DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2022-01-01', end='2022-12-31'),\n    'Sales': [35, 45, 50, 30, 75, 80, 40, 60, 55, 70, 90] * 30\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a new column in the DataFrame 'df' that contains the 7-day rolling average of 'Sales'. How can I do that?\n\nA:\n```python\ndf['Rolling_Average'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Rolling_Average'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\n\nI am working on a predictive modeling project using a dataset related to housing prices. I have this DataFrame containing both numerical and categorical features. Here is a sample of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 3, 5],\n    'Location': ['Urban', 'Suburban', 'Urban', 'Rural'],\n    'Price': [300000, 400000, 500000, 600000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to convert the 'Location' categorical feature into numerical values using one-hot encoding before proceeding to build my model with TensorFlow. However, I need the resulting DataFrame to maintain the 'Size', 'Bedrooms', and 'Price' columns alongside the one-hot encoded 'Location' columns. What line of code should I use to achieve this?\n\nA:\n\n```python\nimport pandas as pd\ndata = {\n    'Size': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 3, 5],\n    'Location': ['Urban', 'Suburban', 'Urban', 'Rural'],\n    'Price': [300000, 400000, 500000, 600000]\n}\ndf = pd.DataFrame(data)\n```\ndf_encoded = ... # put solution in this variable\nBEGIN SOLUTION\n```python",
    "output": "\n<code>\ndf_encoded = pd.get_dummies(df, columns=['Location'], drop_first=True)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\n\n# You have a DataFrame `df` containing two columns 'x' and 'y'.\n# You need to fit a linear regression model to predict 'y' from 'x'.\n# After fitting, plot the original data and the regression line.\n\ndf = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100) * 10})\n\n# Fit linear regression model\nmodel = LinearRegression().fit(df[['x']], df['y'])\n\n# Predict y values using the model\n# SOLUTION START\n```",
    "output": "\n```python\npredictions = model.predict(df[['x']])\n\n# Plot original data and regression line\nplt.scatter(df['x'], df['y'], color='blue', label='Data points')\nplt.plot(df['x'], predictions, color='red', label='Regression line')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "### Problem\nYou have a dataset containing the heights and weights of different individuals, which you need to preprocess for a machine learning model. The dataset is given as a pandas DataFrame:\n\n```\nimport pandas as pd\n\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n    'Height': [165, 175, 180, None, 160],\n    'Weight': [55, 85, 90, 70, None]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour task is to:\n\n1. Fill any missing values in the 'Height' column with the mean height of the dataset.\n2. Standardize the 'Weight' column (subtract the mean and divide by the standard deviation).\n3. Visualize the distribution of both 'Height' and the standardized 'Weight' in a single figure with two subplots.\n\nThe variable `result` should hold a tuple of (updated DataFrame, matplotlib figure).\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Fill missing values in 'Height' with the mean\ndf['Height'].fillna(df['Height'].mean(), inplace=True)\n\n# Standardize the 'Weight' column\ndf['Weight'] = (df['Weight'] - df['Weight'].mean()) / df['Weight'].std()\n\n# Create subplots for visualization\nfig, axs = plt.subplots(2, 1, figsize=(8, 6))\n\n# Plot distribution of 'Height'\naxs[0].hist(df['Height'], bins=5, color='blue', alpha=0.7)\naxs[0].set_title('Height Distribution')\naxs[0].set_xlabel('Height (cm)')\naxs[0].set_ylabel('Frequency')\n\n# Plot distribution of standardized 'Weight'\naxs[1].hist(df['Weight'].dropna(), bins=5, color='green', alpha=0.7)\naxs[1].set_title('Standardized Weight Distribution')\naxs[1].set_xlabel('Standardized Weight')\naxs[1].set_ylabel('Frequency')\n\nplt.tight_layout()\n\nresult = (df, fig)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Simulate some data\nnp.random.seed(42)\ndata = np.random.rand(100, 5) * 100\ncolumns = [f'feature_{i}' for i in range(5)]\ndf = pd.DataFrame(data, columns=columns)\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Apply PCA to reduce to 2 dimensions\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Create a scatter plot of the PCA results\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.title('PCA of Features')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid()\n\n# Show the plot\nplt.show()\n\n# I want a variable pca_df that contains the PCA transformed data as a Pandas DataFrame with appropriate column names.\n\npca_df = ... # put solution in this variable\n```",
    "output": "\n```python\npca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n```"
  },
  {
    "input": "Problem:\nYou have a Pandas DataFrame `df` containing customer purchase data with the following structure:\n\n| CustomerID | PurchaseAmount | PurchaseDate          |\n|------------|----------------|-----------------------|\n| 1          | 100.50         | 2023-01-01            |\n| 2          | 200.75         | 2023-01-02            |\n| 1          | 150.00         | 2023-01-03            |\n| 3          | 300.00         | 2023-01-01            |\n| 2          | 50.25          | 2023-01-03            |\n\nFurthermore, you are required to create a new column `CumulativeSum` that reflects the cumulative sum of `PurchaseAmount` for each `CustomerID` over the time, sorted by `PurchaseDate`. The expected output for the new DataFrame would include the same columns with an additional `CumulativeSum` column, showing the cumulative totals for each customer. \n\nHow would you compute this cumulative sum, ensuring that it is grouped by `CustomerID` and respect the order of `PurchaseDate`?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    \"CustomerID\": [1, 2, 1, 3, 2],\n    \"PurchaseAmount\": [100.50, 200.75, 150.00, 300.00, 50.25],\n    \"PurchaseDate\": pd.to_datetime([\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-01\", \"2023-01-03\"])\n}\n\ndf = pd.DataFrame(data)\n</code>\ndf['CumulativeSum'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['CumulativeSum'] = df.sort_values('PurchaseDate').groupby('CustomerID')['PurchaseAmount'].cumsum()\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10  # feature values\ny = 2.5 * X + np.random.randn(100, 1) * 2  # target values with some noise\n\n# Convert to DataFrame for further analysis\ndata = pd.DataFrame(np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['Feature']], data['Target'])\n\n# Plotting the data and the regression line\nplt.scatter(data['Feature'], data['Target'], color='blue', label='Data Points')\n# Add the regression line\nplt.plot(data['Feature'], ..., color='red', label='Regression Line') # fill the blank\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.title('Linear Regression Example')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nplt.plot(data['Feature'], model.predict(data[['Feature']]), color='red', label='Regression Line')\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndata = {\n    'years': [1, 2, 3, 4, 5],\n    'sales': [150, 200, 250, 300, 350]\n}\ndf = pd.DataFrame(data)\n\n# Fit a linear regression model to predict sales based on years\nmodel = LinearRegression()\nmodel.fit(df[['years']], df['sales'])\npredictions = model.predict(df[['years']])\n\n# Plot the original sales data and the regression line\nplt.scatter(df['years'], df['sales'], color='blue', label='Actual Sales')\nplt.plot(df['years'], predictions, color='red', label='Predicted Sales')\n\n# Add a title and labels\nplt.title('Sales Over Years and Linear Regression Model')\nplt.xlabel('Years')\nplt.ylabel('Sales')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# What will be the predicted sales for 6 years? (Use the model to calculate and fill in the blank)\n# PREDICTION \n```",
    "output": "\n```python\nprediction_6_years = model.predict([[6]])\nprediction_6_years\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset recorded in a CSV file that contains information about various plant species, with features like height, leaf area, and color intensity. After loading it into a Pandas DataFrame, I want to normalize these features to improve the performance of a machine learning model developed using TensorFlow or PyTorch. \n\nHere is how I loaded the data:\n\n```python\nimport pandas as pd\n\ndata = pd.read_csv('plants.csv')\n```\n\nNow I want to use a preprocessing method from Scikit-learn to normalize the features (excluding the species name column) and keep it in a DataFrame format. Specifically, I want to apply `StandardScaler` to my dataset, which will standardize the features so that they have a mean of 0 and a standard deviation of 1. \n\nWhat code will help me achieve this while preserving the original DataFrame format, including the index and column names?\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_data = ...\n```\n",
    "output": "\n```python\nscaled_data = pd.DataFrame(scaler.fit_transform(data.drop(columns=['species_name'])), \n                            index=data.index, \n                            columns=data.columns[1:])\n```"
  },
  {
    "input": "Problem:\nI am analyzing a dataset using Pandas. The dataset contains sales data with columns: 'Date', 'Product', 'Quantity', and 'Revenue'. I want to calculate the total revenue generated for each product within a specified date range. The quantity of products sold is given, and I need to consider only those records where the 'Revenue' is greater than a specific threshold.\n\nHere's a sample code snippet where I define the start and end dates and filter the dataset based on the revenue threshold of 100. How can I obtain the total revenue for each product in the filtered DataFrame?\n\n```python\nimport pandas as pd\n\n# Sample sales data\ndata = {\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04']),\n    'Product': ['A', 'B', 'A', 'B'],\n    'Quantity': [10, 5, 7, 8],\n    'Revenue': [150, 80, 120, 200]\n}\ndf = pd.DataFrame(data)\n\nstart_date = '2023-01-01'\nend_date = '2023-01-04'\nrevenue_threshold = 100\n```\ntotal_revenue = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nfiltered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date) & (df['Revenue'] > revenue_threshold)]\ntotal_revenue = filtered_df.groupby('Product')['Revenue'].sum()\n</code>\n```"
  },
  {
    "input": "```python\nProblem:\nI have a dataset containing information about houses and their sale prices. I want to build a linear regression model to predict the sale price based on the size of the house. After fitting the model, I would like to visualize the results along with the prediction line.\n\nHere is the dataset provided as a pandas DataFrame:\n\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'size': [1500, 1600, 1700, 1800, 1900, 2000, 2100],\n    'price': [300000, 320000, 340000, 360000, 380000, 400000, 420000]\n}\ndf = pd.DataFrame(data)\n\nI have created a linear model using Scikit-learn:\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n\nI will fit the model using size (as the independent variable) and price (as the dependent variable). After fitting, I want to plot the size against the actual prices and the predicted prices.\n\nHowever, I noticed that I need to reshape the size data to properly fit the model. How can I achieve that using NumPy?\n\nTo illustrate:\nsize = np.array(df['size']).reshape(-1, 1)\n\nNow, I want you to fill in the blank for fitting the model and producing the predictions:\nmodel.fit(____)\npredictions = model.predict(size)\n\nA:\n<code>\n```",
    "output": "\n<code>\nmodel.fit(size, df['price'])\npredictions = model.predict(size)\n</code>"
  },
  {
    "input": "## Problem:\nYou are working with a dataset that contains information about various products sold in a store, and you have it organized in a pandas DataFrame like below:\n\n```python\ndf = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 3],\n    'sales': [150, 200, 50, 300, 100, 400],\n    'discounts': [10, 20, 5, 30, 10, 40]\n})\n```\n\nYou want to calculate the profit for each product. The profit for a product is defined as the total sales minus the total discounts applied to that product. After calculating the profit, you want to create a bar plot to visualize the profit for each product.\n\nYou wrote the following code but got an error about the axis when trying to create the plot:\n\n```python\nprofit = df.groupby('product_id').apply(lambda x: x['sales'].sum() - x['discounts'].sum())\nplt.bar(profit.index, profit.values)\nplt.show()\n```\n\nWhat is needed to replace your current plotting line to ensure the profit is visualized correctly?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 3],\n    'sales': [150, 200, 50, 300, 100, 400],\n    'discounts': [10, 20, 5, 30, 10, 40]\n})\n</code>\nplt.bar(... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nplt.bar(profit.index.astype(str), profit.values)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about housing prices in different neighborhoods, which includes columns for area, number of rooms, and age of the house. I want to visualize the relationship between house prices and area using a scatter plot. However, I also want to fit a linear regression line to the scatter plot to see the trend.\n\nCurrently, I'm using pandas to load the data and Matplotlib for plotting. Here\u2019s a snippet of the code I'm working with:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndata = pd.read_csv(\"housing_data.csv\")\nX = data[[\"area\"]].values\ny = data[\"price\"].values\n\n# Creating a scatter plot\nplt.scatter(X, y)\n```\n\nHow can I complete the code below to fit a linear regression model and plot the regression line on the scatter plot?\n\nA:\n\n```python\nmodel = LinearRegression()\nmodel.fit(X, y)\nplt.plot(X, model.predict(X), color='red')\n```\n\nplt.show()  # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nmodel = LinearRegression()\nmodel.fit(X, y)\nplt.plot(X, model.predict(X), color='red')\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset that contains daily temperatures for several cities over a month. The dataset is stored in a pandas DataFrame called `temperature_data`, which has columns `Date`, `City`, and `Temperature`. I want to calculate the daily average temperature for each city and plot these averages using Matplotlib.\n\nHere is a sample of how the DataFrame looks:\n\n```\n      Date        City  Temperature\n0  2023-01-01    New York         30\n1  2023-01-01      Boston         28\n2  2023-01-02    New York         31\n3  2023-01-02      Boston         27\n...\n```\n\nI want to store the daily averages in a variable called `daily_avg_temp`, and then plot the results with the dates on the x-axis and average temperatures on the y-axis for each city.\n\nHere is the starting code along with imports:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample data construction\ntemperature_data = pd.DataFrame({\n    'Date': pd.date_range(start='2023-01-01', periods=30).tolist() * 2,\n    'City': ['New York'] * 30 + ['Boston'] * 30,\n    'Temperature': np.random.randint(low=20, high=35, size=60)\n})\n```\n\nWhat is the code to calculate the daily average temperature for each city and store it in `daily_avg_temp`?\n\ndaily_avg_temp = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndaily_avg_temp = temperature_data.groupby(['Date', 'City'])['Temperature'].mean().reset_index()\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the Iris dataset and create a DataFrame\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Perform PCA to reduce dimensions to 2 components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(df)\n\n# Create a scatter plot of the PCA result\n# The x-axis should represent the first principal component and the y-axis should represent the second principal component\n# Make sure to label the axes appropriately.\nplt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component')\nplt.title('PCA of Iris Dataset')\n\n# Now you want to show this plot.\n# What command should you use to display the plot?\n# A:\nplot_command = ... # put solution in this variable\n```",
    "output": "\n```python\nplot_command = plt.show()\n```"
  },
  {
    "input": "```python\nProblem:\nI have a dataset that contains information about customers and their purchase amounts in a CSV file. After loading the data, I want to preprocess it by normalizing the purchase amounts using Min-Max scaling and then splitting it into training and testing datasets. Below is the code I have started with:\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load the data\ndf = pd.read_csv(\"customer_data.csv\")\n# I need to normalize the 'purchase_amount' column before splitting\nscaler = MinMaxScaler()\ndf['purchase_amount'] = ...\n\n# Now, I want to split this into training and testing datasets with a split ratio of 80% training and 20% testing.\nX_train, X_test, y_train, y_test = train_test_split(df.drop('purchase_amount', axis=1), df['purchase_amount'], test_size=0.2, random_state=42)\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf = pd.read_csv(\"customer_data.csv\")\nscaler = MinMaxScaler()\ndf['purchase_amount'] = scaler.fit_transform(df[['purchase_amount']])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf = pd.read_csv(\"customer_data.csv\")\nscaler = MinMaxScaler()\ndf['purchase_amount'] = scaler.fit_transform(df[['purchase_amount']])\nX_train, X_test, y_train, y_test = train_test_split(df.drop('purchase_amount', axis=1), df['purchase_amount'], test_size=0.2, random_state=42)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of customers' purchase histories stored in a CSV file. Each row in the file represents a transaction, with the following columns: `CustomerID`, `Product`, `Quantity`, and `Price`. You plan to analyze the total expenditure for each customer. Here\u2019s a segment of your dataset:\n\n```\nCustomerID,Product,Quantity,Price\n1,Apple,2,0.5\n1,Banana,1,0.2\n2,Apple,1,0.5\n2,Orange,3,0.3\n1,Orange,2,0.3\n```\n\nYou have the following code to load the dataset:\n```python\nimport pandas as pd\n\ndf = pd.read_csv(\"purchases.csv\")\n```\n\nYou need to calculate the total expenditure for each customer and output it as a new DataFrame with columns `CustomerID` and `TotalExpenditure`. How would you do this?\n\nA:\n<code>\ndf['Total'] = df['Quantity'] * df['Price']\nresult = df.groupby('CustomerID')['Total'].sum().reset_index()\nresult.columns = ['CustomerID', 'TotalExpenditure']\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('CustomerID').apply(lambda x: (x['Quantity'] * x['Price']).sum()).reset_index(name='TotalExpenditure')\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of customer transactions that you want to process and analyze. First, you need to create a Pandas DataFrame from a CSV file that contains columns: 'CustomerID', 'TransactionAmount', and 'TransactionDate'. The requirement is to filter the DataFrame to select only those transactions above a specific threshold and then compute the average transaction amount for each customer. Finally, you want to visualize the average amounts using a bar plot.\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the data from a CSV file\ndf = pd.read_csv('transactions.csv')\n\n# Filter transactions greater than 50\nfiltered_df = df[?]\n# Group by 'CustomerID' and compute the average transaction amount\naverage_transactions = filtered_df.groupby('CustomerID')['TransactionAmount'].mean()\n\n# Plotting the average transaction amounts\naverage_transactions.plot(kind='bar', title='Average Transaction Amounts by Customer')\nplt.xlabel('Customer ID')\nplt.ylabel('Average Transaction Amount')\nplt.show()\n\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>df['TransactionAmount'] > 50</code>",
    "output": "\n<code>df['TransactionAmount'] > 50</code>"
  },
  {
    "input": "## Problem\n\nYou have a dataset containing daily temperatures in Celsius over a month, represented as a Pandas DataFrame. You want to classify the temperature as 'Cold', 'Warm', or 'Hot' based on the following criteria: temperatures below 15\u00b0C are 'Cold', between 15\u00b0C and 25\u00b0C are 'Warm', and above 25\u00b0C are 'Hot'. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'Temperature_C': [12, 22, 26, 18, 15, 30, 10, 28, 14, 20, 27, 24, 19, 15, 13, 22, 23, 17, 12, 29, 16, 21, 25, 11, 14, 31, 20, 13, 27, 18, 22]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new column in the DataFrame that categorizes each daily temperature. How would you implement this?\n\nPlease provide a solution that fills in the blank below:\n\n```python\ndf['Category'] = ...\n```",
    "output": "\n```python\ndf['Category'] = pd.cut(df['Temperature_C'], bins=[-float('inf'), 15, 25, float('inf')], labels=['Cold', 'Warm', 'Hot'])\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\n# Load the Iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Calculate the mean of the first two features\nmean_values = df.iloc[:, [0, 1]].mean()\n\n# I want to create a new column in the dataframe that contains the mean values of the first two features\n# So I can compare it to the original data later.\n# How can I set the new column name to 'mean_sepal_length_width' and fill it with the computed mean values?\ndf['mean_sepal_length_width'] = ...\n\n# Finally, I want to visualize the first two features against my new mean column using a scatter plot\nplt.scatter(df.iloc[:, 0], df.iloc[:, 1], label='Sepal Length vs Sepal Width')\nplt.axhline(y=mean_values[1], color='r', linestyle='--', label='Mean Sepal Width')\nplt.axvline(x=mean_values[0], color='g', linestyle='--', label='Mean Sepal Length')\nplt.title('Iris Dataset: Sepal Length and Width with Mean Lines')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\ndf['mean_sepal_length_width'] = mean_values.mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing historic temperatures from multiple cities, structured as follows:\n\n```\n   Date       City       Temperature\n0 2021-01-01  New York   30\n1 2021-01-01  Los Angeles 70\n2 2021-01-01  Chicago     25\n3 2021-01-02  New York   32\n4 2021-01-02  Los Angeles 68\n5 2021-01-02  Chicago     28\n6 2021-01-03  New York   31\n7 2021-01-03  Los Angeles 72\n8 2021-01-03  Chicago     26\n```\n\nI would like to compute the moving average temperature for each city over the last two days. The resultant DataFrame should add a new column 'Moving_Avg_Temp' indicating this average. The first two rows for each city should contain `NaN` for the moving average due to insufficient data.\n\nHere's the initial DataFrame setup:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02', '2021-01-02', \n             '2021-01-03', '2021-01-03', '2021-01-03'],\n    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago', \n             'New York', 'Los Angeles', 'Chicago'],\n    'Temperature': [30, 70, 25, 32, 68, 28, 31, 72, 26]\n}\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the blank for the line of code that computes the moving average:\n\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().reset_index(drop=True)\n```\n\nWhat would the complete line look like to create the `Moving_Avg_Temp` column? \n\nA:\n```python\ndf['Moving_Avg_Temp'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().shift(1).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer purchases that consists of three columns: 'customer_id', 'purchase_amount', and 'purchase_date'. The dataset is represented as a Pandas DataFrame. You want to analyze the total expenditure of each customer over a specified date range and visualize the results using a bar chart. \n\nThe DataFrame `df` looks like this:\n\n```\n   customer_id  purchase_amount purchase_date\n0            1             45.0    2023-01-01\n1            2             20.0    2023-01-02\n2            1             30.0    2023-01-05\n3            3             25.0    2023-01-07\n4            2             15.0    2023-01-08\n5            3             50.0    2023-01-10\n```\n\nYou need to filter the DataFrame for purchases made in January 2023, then aggregate the total 'purchase_amount' by 'customer_id'. Finally, create a bar plot to visualize the total expenditure of each customer.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 2, 1, 3, 2, 3],\n    'purchase_amount': [45.0, 20.0, 30.0, 25.0, 15.0, 50.0],\n    'purchase_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-07', '2023-01-08', '2023-01-10'])\n}\n\ndf = pd.DataFrame(data)\nstart_date = ...\nend_date = ...\n</code>\ntotals = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n</code>\ndf_filtered = df[(df['purchase_date'] >= start_date) & (df['purchase_date'] <= end_date)]\ntotals = df_filtered.groupby('customer_id')['purchase_amount'].sum().reset_index()\n\nplt.bar(totals['customer_id'], totals['purchase_amount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Expenditure')\nplt.title('Total Expenditure by Customer in January 2023')\nplt.show()\n",
    "output": "\n<code>\nstart_date = '2023-01-01'\nend_date = '2023-01-31'\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about several products and their attributes. The dataset includes columns such as `Price`, `Rating`, `Category`, and `Sales`. I want to create a machine learning model to predict `Sales` based on the other features. However, I want to visualize the relationship between `Price` and `Sales` with a scatter plot showcasing the actual data points while fitting a linear regression line. \n\nHere is the sample data in a pandas DataFrame format:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Price': [10, 20, 30, 40, 50, 60],\n    'Rating': [4.5, 4.0, 3.5, 4.7, 5.0, 3.0],\n    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Sales': [100, 150, 200, 250, 300, 50]\n}\n\ndf = pd.DataFrame(data)\n```\n\nCan you provide a code snippet that creates a scatter plot of `Price` vs. `Sales`, fits a linear regression line, and displays the plot using Matplotlib? I want the linear regression to be done using Scikit-learn.\n\nThe code should fill in the blank below:\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nX = df[['Price']]\ny = df['Sales']\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nplt.scatter(df['Price'], df['Sales'], color='blue')\nplt.plot(df['Price'], model.predict(X), color='red')\nplt.xlabel('Price')\nplt.ylabel('Sales')\nplt.title('Price vs. Sales')\nplt.grid()\nplt.show()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = plt.scatter(df['Price'], df['Sales'], color='blue'), plt.plot(df['Price'], model.predict(X), color='red'), plt.xlabel('Price'), plt.ylabel('Sales'), plt.title('Price vs. Sales'), plt.grid(), plt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a Pandas DataFrame with columns 'size' (in square feet) and 'price' (in USD). I would like to preprocess this data by standardizing the 'price' column using Scikit-learn's `StandardScaler`. After scaling, I want to visualize the original and standardized price distributions using Matplotlib.\n\nHere is the setup:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'size': [1500, 2000, 2500, 3000, 3500],\n    'price': [300000, 400000, 500000, 600000, 700000]\n}\ndf = pd.DataFrame(data)\nscaler = StandardScaler()\n```\nYou need to fill in the code to scale the 'price' column and create a histogram to compare the original and standardized price distributions.\n\nA:\n```python\nscaled_prices = ... # put solution in this variable\n\n# Visualization code\nplt.hist(df['price'], alpha=0.5, label='Original Price')\nplt.hist(scaled_prices, alpha=0.5, label='Standardized Price')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nscaled_prices = scaler.fit_transform(df[['price']]).flatten()\n\n# Visualization code\nplt.hist(df['price'], alpha=0.5, label='Original Price')\nplt.hist(scaled_prices, alpha=0.5, label='Standardized Price')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset represented as a Pandas DataFrame containing two columns: 'Date' and 'Value'. I want to compute the moving average of the 'Value' column with a window size of 3, and then plot the original 'Value' data alongside the computed moving average using Matplotlib. The DataFrame looks like this:\n\n```\n        Date       Value\n0 2021-01-01  10.0\n1 2021-01-02  20.0\n2 2021-01-03  30.0\n3 2021-01-04  40.0\n4 2021-01-05  50.0\n```\n\nI have successfully created the DataFrame but I am stuck on how to calculate the moving average and plot the results. Here's the setup for the DataFrame:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n    'Value': [10.0, 20.0, 30.0, 40.0, 50.0]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow I need to fill in the blank for calculating the moving average and plotting it:\n\n```python\nmoving_avg = df['Value'].rolling(window=3).mean()\nplt.plot(df['Date'], df['Value'], label='Original Value')\nplt.plot(df['Date'], ___, label='Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Value')\nplt.title('Original Value vs Moving Average')\nplt.legend()\nplt.show()\n```\n\nThe goal is to fill in the blank with the correct variable representing the moving average.",
    "output": "\n```python\nmoving_avg = df['Value'].rolling(window=3).mean()\nplt.plot(df['Date'], df['Value'], label='Original Value')\nplt.plot(df['Date'], moving_avg, label='Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Value')\nplt.title('Original Value vs Moving Average')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different products. The dataset includes columns for 'product_id', 'price', 'quantity_sold', and 'category'. I want to calculate the total sales for each category and visualize the results using a bar chart. What I am struggling with is how to use the Pandas library to group by 'category' and sum the sales, and then use Matplotlib to create the bar chart. \n\nHere\u2019s how my DataFrame looks:\n```\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4, 5],\n    'price': [10, 20, 30, 40, 50],\n    'quantity_sold': [1, 2, 1, 3, 2],\n    'category': ['A', 'B', 'A', 'B', 'C']\n}\ndf = pd.DataFrame(data)\n```\n\nI know I can calculate total sales as `price * quantity_sold`, but I'm unsure how to properly implement the group by operation and create the plot. What command should I use to fill in the blank below?\n\ntotal_sales = ... # fill this with your code\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ntotal_sales = df.groupby('category').apply(lambda x: (x['price'] * x['quantity_sold']).sum()).reset_index(name='total_sales')\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\n# Load the iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n# Add a target column to the dataframe based on the iris dataset\ndf['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n\n# Create a scatter plot of 'sepal length (cm)' vs 'sepal width (cm)' \n# color-coded by species; set the transparency to 0.5\n# SOLUTION START\n```",
    "output": "\n```python\nplt.figure(figsize=(10, 6))\nfor species in df['species'].cat.categories:\n    subset = df[df['species'] == species]\n    plt.scatter(subset['sepal length (cm)'], subset['sepal width (cm)'], \n                label=species, alpha=0.5)\nplt.title('Iris Sepal Length vs Sepal Width')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:  \nI am working with a dataset of adult income information. The dataset is stored in a CSV file called `adult_income.csv` which has two columns: `age` and `income`. I want to standardize the `age` variable to have a mean of 0 and a standard deviation of 1, and create a new column called `age_standardized` to store the results.\n\nHere\u2019s how you can read the data and prepare for the standardization:\n\n```python\nimport pandas as pd\n\n# Read the CSV file\ndf = pd.read_csv('adult_income.csv')\n```\n\nNow, I need to fill in the code to standardize the `age` column. Can you provide the line of code to compute `age_standardized` such that it follows the standardization formula: (value - mean) / standard deviation?\n\nA:  \n```python\ndf['age_standardized'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['age_standardized'] = (df['age'] - df['age'].mean()) / df['age'].std()\n```"
  },
  {
    "input": "Problem:\n\nI'm analyzing a dataset in which I need to identify the most significant features contributing to a linear regression model. I have a DataFrame with various features and a target variable, and I wish to compute the coefficients of the linear regression model using Scikit-learn. After fitting the model, I would like to visualize the coefficients using Matplotlib.\n\nThe DataFrame `df` contains features in the columns and the target variable `y` in a separate series. Here's a snippet of the code I have so far:\n\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Let's assume the DataFrame and target variable are defined as follows:\n# df = pd.DataFrame(...) # DataFrame with features\n# y = df['target_variable'] # Series with the target variable\n\nX = df.drop(columns=['target_variable'])  # Features\nmodel = LinearRegression()\nmodel.fit(X, y)\ncoefficients = model.coef_\n\n# Now I want to visualize the coefficients in a bar chart.\nplt.bar(range(len(coefficients)), coefficients)\nplt.xticks(range(len(coefficients)), X.columns, rotation=90)\nplt.title('Feature Coefficients from Linear Regression')\nplt.ylabel('Coefficient Value')\nplt.show()\n</code>\n\nHow can I properly set the x-values in the plt.bar() function to align with the feature names?\n\nx_values = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nx_values = np.arange(len(coefficients))  # Set x-values to align with feature indices\n</code>"
  },
  {
    "input": "Problem:\nI am currently analyzing a dataset of house prices and I need to create a scatter plot of the prices against the number of bedrooms. The dataset is in a Pandas DataFrame called `df`, which contains two columns: 'bedrooms' and 'price'. I would like to customize the plot by adding labels to the axes, a title, and changing the marker color to blue. Below is the code I've written so far. \n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Example data\ndata = {\n    'bedrooms': [1, 2, 3, 4, 2, 3, 4, 5],\n    'price': [150000, 200000, 250000, 300000, 220000, 275000, 350000, 400000]\n}\ndf = pd.DataFrame(data)\n\nplt.scatter(df['bedrooms'], df['price'], color='red')\n# What should I do next to complete my plot?\n```\nA:\n<code>\n# Add your solution here\nplt.xlabel('Number of Bedrooms')\nplt.ylabel('Price')\nplt.title('House Prices vs. Number of Bedrooms')\nplt.show()\n</code>",
    "output": "\n<code>\nplt.scatter(df['bedrooms'], df['price'], color='blue')\nplt.xlabel('Number of Bedrooms')\nplt.ylabel('Price')\nplt.title('House Prices vs. Number of Bedrooms')\nplt.show()\n</code>"
  },
  {
    "input": "### Problem:\nYou have a DataFrame containing the sales data for a store, structured as follows:\n\n```\n  Product   Date        Sales\n0 A        2023-01-01  100\n1 B        2023-01-01  150\n2 A        2023-01-02  200\n3 C        2023-01-02  250\n4 B        2023-01-03  300\n5 C        2023-01-03  350\n```\n\nYou need to pivot this DataFrame to create a summary table that shows the total sales per product over the entire period. The resulting DataFrame should look like this:\n\n```\n  Product   Total_Sales\n0 A        300\n1 B        450\n2 C        600\n```\n\nYou can achieve this using the `groupby` method from Pandas. You have already created the DataFrame and your task is to fill in the code to calculate the `Total_Sales` for each product.\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-03'],\n    'Sales': [100, 150, 200, 250, 300, 350]\n}\n\ndf = pd.DataFrame(data)\nresult = ...  # Put your solution here\n```\n\nHow would you fill in the blank to get the summarized sales per product?",
    "output": "\n```python\nresult = df.groupby('Product', as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset representing daily sales for a store over a year, and I want to forecast the next month's sales using a simple recurrent neural network (RNN) with Keras, a high-level API of TensorFlow. The sales data is stored in a Pandas DataFrame called `sales_df`, which contains columns \"date\" and \"sales\". I need to preprocess the data to prepare it for the RNN. Specifically, I want to reshape the sales data into a 3D array with shape (samples, time steps, features) before training. Based on my understanding, each time step should be a single day and I want to use the previous 30 days of sales data as input to predict the next day\u2019s sales.\n\nHere\u2019s the code I've started with:\n```python\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\n\n# Assuming sales_df is already loaded\n# Example of sales_df\n#    date       sales\n# 0 2021-01-01   100\n# 1 2021-01-02   150\n# ...\n\n# Preparing input data for RNN\nsales = sales_df['sales'].values\n```\nNow I need to write the code that reshapes the `sales` array into the appropriate 3D format. The blank below should hold the solution for reshaping the array to the required shape:\n```python\ntimesteps = 30  # days\nX = np.array(sales).reshape(______)\n```\nA:\n<code>\nX = np.array([sales[i-timesteps:i] for i in range(timesteps, len(sales))])  # Required shape (number_of_samples, 30, 1)\n</code>",
    "output": "\n<code>\nX = np.array([sales[i-timesteps:i] for i in range(timesteps, len(sales))]).reshape(-1, timesteps, 1)  # Required shape (number_of_samples, 30, 1)\n</code>"
  },
  {
    "input": "Problem:\n\nSuppose you have a dataset containing features related to houses, including their square footage, number of bedrooms, and prices. You have preprocessed the data and split it into training and testing datasets. You want to create a neural network model to predict house prices using TensorFlow and then evaluate its performance using R\u00b2 score from Scikit-learn.\n\nHere\u2019s how your data is structured:\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom tensorflow import keras\n\n# Simulated dataset\ndata = {\n    'square_footage': np.random.randint(500, 5000, 100),\n    'num_bedrooms': np.random.randint(1, 6, 100),\n    'price': np.random.randint(100000, 1000000, 100)\n}\ndf = pd.DataFrame(data)\n\n# Splitting the dataset into features and target\nX = df[['square_footage', 'num_bedrooms']]\ny = df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define the neural network model\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(1)\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Fit the model\nmodel.fit(X_train, y_train, epochs=10, verbose=0)\n\n# Now you want to evaluate the R\u00b2 score of the model predictions\npredictions = model.predict(X_test)\n\n# Find the R\u00b2 score using Scikit-learn\nr_squared = ...  # put solution in this variable\n```\nWhat code would you use to compute the R\u00b2 score and fill in the blank?",
    "output": "\n```python\nr_squared = r2_score(y_test, predictions)\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing information about a series of products, where the data is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [25.50, 45.00, 15.75, 85.00, 20.00],\n    'quantity_sold': [200, 150, 300, 50, 400]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the total revenue generated by each product and add this information as a new column named 'total_revenue' to the existing DataFrame. The total revenue for each product can be calculated using the formula:\n\n```\ntotal_revenue = price * quantity_sold\n```\n\nHow can you achieve this using pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [25.50, 45.00, 15.75, 85.00, 20.00],\n    'quantity_sold': [200, 150, 300, 50, 400]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate total revenue and store it in a new column\n# total_revenue = ...\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['total_revenue'] = df['price'] * df['quantity_sold']\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Create a random dataset with 100 samples and 5 features\ndata = np.random.rand(100, 5)\ndf = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(5)])\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Reduce dimensionality to 2D using PCA\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Create a scatter plot of the PCA result\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA Result')\n\n# How to display the plot\n# SOLUTION START\n\n```",
    "output": "\n```python\nplt.show()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Create a random dataset with 100 samples and 5 features\nnp.random.seed(42)\ndata = np.random.rand(100, 5)\n\n# Convert the data to a pandas DataFrame\ndf = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n\n# Scale the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Perform PCA to reduce dimensions to 2\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Plot the first two principal components\nplt.figure(figsize=(8, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\nplt.title('PCA Result')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n\n# Display the plot\nplt.grid(True)\n# SOLUTION START\n```",
    "output": "\n```python\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset of sales data stored in a CSV file called `sales_data.csv`, which contains the following columns: `Date`, `Product`, `Units Sold`, and `Revenue`. You want to analyze this data by grouping it by `Product` and calculating the total `Units Sold` and total `Revenue` for each product. After that, you need to visualize this aggregated data using a bar plot. \n\nHere is the code snippet for reading the data:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the sales data\ndf = pd.read_csv('sales_data.csv')\n\n# Aggregate the data by calculating the total units sold and total revenue for each product\nagg_data = df.groupby('Product').agg({'Units Sold': 'sum', 'Revenue': 'sum'}).reset_index()\n\n# Now visualize the aggregated data in a bar plot with Product on the x-axis and Units Sold on the y-axis\n# Make sure to set the title of the plot as \"Total Sales by Product\"\n\nplt.figure(figsize=(10, 6))\nplt.bar(agg_data['Product'], agg_data['Units Sold'])\nplt.xlabel('Product')\nplt.ylabel('Total Units Sold')\nplt.title('Total Sales by Product')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n```\n\nWhat I want to fill in is to generate the appropriate code to calculate `agg_data` as described above. \n\n```python\nagg_data = ... # put solution in this variable\n```",
    "output": "\n```python\nagg_data = df.groupby('Product').agg({'Units Sold': 'sum', 'Revenue': 'sum'}).reset_index()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales records with columns for 'Product', 'Sales', and 'Date'. I want to analyze the total sales for each product over time, but currently, my DataFrame looks like this:\n\n```\n      Product  Sales       Date\n0      A       10  2023-01-01\n1      B       15  2023-01-01\n2      A       20  2023-01-02\n3      C       25  2023-01-02\n4      B       30  2023-01-03\n5      C       10  2023-01-03\n```\n\nI wish to create a pivot table to summarize the total sales for each product across the dates. The pivot table's rows should be 'Date', the columns should be 'Product', and the values should be the sum of 'Sales'. I also want to fill in any missing values with 0. \n\nI have imported the necessary libraries and created the DataFrame as shown above. \n\nHere\u2019s where I'm stuck:\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C'],\n    'Sales': [10, 15, 20, 25, 30, 10],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-02', \n                             '2023-01-02', '2023-01-03', '2023-01-03'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nI need to complete the pivot_table function correctly to generate the required pivot table. \n\nThe pivot table should be stored in the variable `pivot_df` as follows:\n```python\npivot_df = ...  # put solution in this variable\n```",
    "output": "\n```python\npivot_df = df.pivot_table(index='Date', columns='Product', values='Sales', aggfunc='sum', fill_value=0)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products including their prices and sales. I want to normalize the price column to a scale of 0 to 1 for better comparison with other features. Given a pandas DataFrame `df` with a column named `'price'`, how can I achieve this normalization? \n\nHere is an example DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['A', 'B', 'C', 'D', 'E'],\n    'price': [200, 150, 300, 250, 100],\n    'sales': [30, 50, 20, 40, 10]\n}\n\ndf = pd.DataFrame(data)\n```\n\nThe resulting normalized price should replace the original price in the DataFrame. \n\nA:\n```python\ndf['normalized_price'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['normalized_price'] = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n```"
  },
  {
    "input": "Problem:\nYou are tasked with building a simple machine learning model that predicts house prices based on various features. You have a DataFrame with the following columns: `['size', 'bedrooms', 'age', 'price']`. Your goal is to:\n1. Prepare the data by splitting it into features (X) and target (y). \n2. Create a linear regression model using Scikit-learn. \n3. Fit the model on the training data and then predict the prices of the houses.\n\nHere's the initial setup:\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.DataFrame({\n    'size': [1500, 2000, 2500, 3000, 3500],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'age': [10, 15, 20, 5, 8],\n    'price': [300000, 400000, 500000, 600000, 700000]\n})\n\nX = df[['size', 'bedrooms', 'age']]\ny = df['price']\n```\nYou need to fill in the blank below to split the data into training and testing sets, and then create and fit the linear regression model:\n```python\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = model.predict(X_test)\n</code>\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset of house prices and their features stored in a CSV file. The dataset has columns for 'Size', 'Bedrooms', 'Age', and 'Price'. Your task is to preprocess this data for a machine learning model in TensorFlow. Specifically, you want to standardize the features using `StandardScaler` from Scikit-learn before converting them into a TensorFlow tensor for model training.\n\nHere is a snippet of how to load the data and the expected preprocessing steps. Fill in the blank for the `X_scaled` variable:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\n\n# Load the dataset\ndata = pd.read_csv('house_prices.csv')\n\n# Selecting features for scaling\nX = data[['Size', 'Bedrooms', 'Age']]\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit and transform the data\nX_scaled = ...  # put solution in this variable\n\n# Convert to TensorFlow tensor\nX_tensor = tf.convert_to_tensor(X_scaled, dtype=tf.float32)\n```\n",
    "output": "\n```python\nX_scaled = scaler.fit_transform(X)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing daily temperatures along with corresponding dates. I want to fit a polynomial regression model to this data in order to predict future temperatures. I have tried using numpy and pandas for data manipulation and Scikit-learn for fitting the model, but I'm unsure how to structure my model fitting code properly. Below is what I have so far:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# Sample temperature data\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': [30, 32, 35, 33, 31, 29, 28, 30, 31, 34]\n}\ndf = pd.DataFrame(data)\n\n# Converting dates to numerical representation\ndf['days'] = (df['date'] - df['date'].min()).dt.days\n\n# Prepare the polynomial features\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(df[['days']])\n\n# Fit the regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, df['temperature'])\n\n# Predict future temperatures using the model for the next 5 days\nfuture_days = np.array([df['days'].max() + i for i in range(1, 6)]).reshape(-1, 1)\nfuture_days_poly = poly.transform(future_days)\npredictions = model.predict(future_days_poly)\nprint(predictions)\n```\n\nThe problem I am facing is how to correctly generate the `future_days_poly` from `future_days` and make predictions. \n\nExpected:\nYou need to place your code for transformation and prediction in the designated area below.\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# Sample temperature data\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': [30, 32, 35, 33, 31, 29, 28, 30, 31, 34]\n}\ndf = pd.DataFrame(data)\n\n# Converting dates to numerical representation\ndf['days'] = (df['date'] - df['date'].min()).dt.days\n\n# Prepare the polynomial features\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(df[['days']])\n\n# Fit the regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, df['temperature'])\n\n# Predict future temperatures using the model for the next 5 days\nfuture_days = np.array([df['days'].max() + i for i in range(1, 6)]).reshape(-1, 1)\nfuture_days_poly = ... # place your solution here\npredictions = model.predict(future_days_poly)\nprint(predictions)\n</code>\nBEGIN SOLUTION\n<code>\nfuture_days_poly = poly.transform(future_days)\n</code>",
    "output": "\n<code>\nfuture_days_poly = poly.transform(future_days)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of customer purchase behavior that contains the following columns: `customer_id`, `purchase_amount`, and `purchase_date`. I want to analyze this data to determine the average purchase amount per customer for the last month. However, when I group the data, I want to ensure that I only consider customers who made at least one purchase in the last 30 days. My current attempt to achieve this using Pandas seems incorrect.\n\nHere is a snippet of my code:\n```python\nimport pandas as pd\n\ndata = {'customer_id': ['C1', 'C2', 'C1', 'C3', 'C2', 'C1'],\n        'purchase_amount': [100, 150, 200, 300, 250, 50],\n        'purchase_date': ['2023-09-28', '2023-09-29', '2023-10-01', '2023-10-15', '2023-10-10', '2023-10-05']}\n\ndf = pd.DataFrame(data)\ndf['purchase_date'] = pd.to_datetime(df['purchase_date'])\n```\nI would like to compute the average purchase amount for each customer who has made a purchase in the last 30 days. The expected result should be in a new DataFrame containing `customer_id` and `average_purchase_amount`.\n\nHow can I write the code to correctly filter and aggregate the DataFrame? \n\nA:\n<code>\ndf_last_month = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom datetime import datetime, timedelta\n\nlast_30_days = datetime.now() - timedelta(days=30)\ndf_filtered = df[df['purchase_date'] >= last_30_days]\ndf_last_month = df_filtered.groupby('customer_id')['purchase_amount'].mean().reset_index(name='average_purchase_amount')\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about users and their associated scores in a pandas DataFrame, shown below:\n\n```python\nimport pandas as pd\n\ndata = {\n    'user': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob'],\n    'score': [85, 90, 75, 95, 88],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01']\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the average score for each user but need to filter out any scores that are below 80 before calculating the mean. The result should be in a new DataFrame with columns `user` and `average_score`, showing only those users who have scores above the threshold. \n\nHow can I accomplish this and create the resulting DataFrame? \n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df[df['score'] >= 80].groupby('user')['score'].mean().reset_index(name='average_score')\n```"
  },
  {
    "input": "Problem:\n\nI am training a neural network using PyTorch to classify images from a dataset. However, I need to perform data augmentation to improve the model's performance. I want to apply a series of transformations such as random rotation, horizontal flip, and normalization to the images. I have already imported the necessary libraries and loaded my dataset, but I'm unsure how to apply these transformations in a single pipeline using `torchvision.transforms`.\n\nHere\u2019s the partial code I have:\n\n```python\nimport torch\nfrom torchvision import transforms\n\n# Define the transformations\ntransform = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load your dataset here\ndataset = load_your_dataset()\n\n# Apply the transformations to the dataset\n```\n\nWhat code should I put in the blank to apply the transformations to the dataset?\n\nA:\n\n<code>\ndataset.transform = transform\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom torchvision.datasets import ImageFolder\n\ndataset = ImageFolder(root='path_to_your_data', transform=transform)\n</code>"
  },
  {
    "input": "Problem:\nI am analyzing a dataset of customer reviews for a product. Each review has a rating from 1 to 5 and a corresponding text. I would like to visualize the distribution of ratings and also apply some natural language processing to analyze the sentiment of the reviews. Here\u2019s the current structure of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Review': [\n        \"Great product and great value!\", \n        \"Did not like it at all.\", \n        \"It's okay, nothing special.\", \n        \"Absolutely loved it!\", \n        \"Would not recommend.\"\n    ],\n    'Rating': [5, 1, 3, 5, 2]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI already imported the necessary libraries and preprocessed the text for sentiment analysis but I'm stuck on how to plot the distribution of ratings. I want to create a bar chart displaying the count of each rating from 1 to 5 along with appropriate labels and a title. \n\nCan you provide the line of code I need to fill in below?\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.bar(df['Rating'].value_counts().index, df['Rating'].value_counts(), color='blue')\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.title('Distribution of Ratings')\nplt.xticks(rotation=0)\nplt.show()\n``` \ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf = df['Rating'].value_counts().sort_index()\n```"
  },
  {
    "input": "## Problem\nYou have a dataset representing historic temperatures from multiple cities in a country, stored in a CSV file named `temperatures.csv`. The columns are structured as follows: `date`, `city`, `temperature`, where `date` is in the format `YYYY-MM-DD`. Your task is to load this dataset using Pandas, calculate the average temperature for each city, and then create a bar plot that displays these averages using Matplotlib, while ensuring the x-axis labels are correctly formatted.\n\nThe code to load the CSV and calculate the averages is started for you, but needs completion. Please fill in the blank to achieve this:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_csv('temperatures.csv')\n\n# Calculate average temperatures per city\naverage_temperatures = data.groupby('city')['temperature'].mean()\n\n# Plotting the averages\naverage_temperatures.plot(kind='bar')\n\nplt.title('Average Temperatures by City')\nplt.xlabel('City')\nplt.ylabel('Average Temperature')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n# Fill in this part to display the average temperatures:\nresult = ...\n```\n",
    "output": "\n```python\nresult = average_temperatures.reset_index()\n```"
  },
  {
    "input": "Problem:  \nI have a dataset containing customer orders with the following structure:  \n```\nCustomerID   OrderDate                    Amount\n01           2020-03-15 09:15:00         150.50\n01           2020-03-20 11:30:00         200.00\n02           2020-03-18 14:05:00         450.25\n02           2020-03-22 10:00:00         100.00\n03           2020-03-19 16:25:00         300.00\n```\n\nI want to add a new column to rank the amounts for each customer such that the highest amount receives rank 1. I tried using:  \n`df['Rank'] = df.groupby('CustomerID')['Amount'].rank(method='min', ascending=False)`  \nbut encountered an issue with the DataFrame format.\n\nHere is an example of how to set up your DataFrame:  \n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['01', '01', '02', '02', '03'],\n    'OrderDate': ['2020-03-15 09:15:00', '2020-03-20 11:30:00', \n                  '2020-03-18 14:05:00', '2020-03-22 10:00:00', \n                  '2020-03-19 16:25:00'],\n    'Amount': [150.50, 200.00, 450.25, 100.00, 300.00]\n}\n\ndf = pd.DataFrame(data)\ndf['OrderDate'] = pd.to_datetime(df['OrderDate'])\n```\n\nFill in the following code to correctly compute the ranks:  \n```python\ndf['Rank'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Rank'] = df.groupby('CustomerID')['Amount'].rank(method='min', ascending=False)\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset of temperatures over a month for multiple cities in a DataFrame called `temperature_data`, structured as follows:\n\n```\n        city   date    temp\n0      New York 2023-10-01  68\n1      Chicago   2023-10-01  70\n2      New York 2023-10-02  65\n3      Chicago   2023-10-02  72\n4      New York 2023-10-03  75\n5      Chicago   2023-10-03  74\n```\n\nYou need to compute the average temperature for each city across the month using Pandas and then visualize the average temperatures using Matplotlib as a bar chart. Your task is to create a Python code that will calculate the average temperatures and fill in the result in the variable `avg_temp_plot` to plot the bar chart correctly.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ntemperature_data = pd.DataFrame({\n    'city': ['New York', 'Chicago', 'New York', 'Chicago', 'New York', 'Chicago'],\n    'date': pd.to_datetime(['2023-10-01', '2023-10-01', '2023-10-02', '2023-10-02', '2023-10-03', '2023-10-03']),\n    'temp': [68, 70, 65, 72, 75, 74]\n})\n</code>\navg_temp_plot = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\navg_temp_plot = temperature_data.groupby('city')['temp'].mean().reset_index()\nplt.bar(avg_temp_plot['city'], avg_temp_plot['temp'])\nplt.xlabel('City')\nplt.ylabel('Average Temperature')\nplt.title('Average Temperature by City')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndata = pd.DataFrame({\n    'feature1': [1.0, 2.0, 3.0, 4.0, 5.0],\n    'feature2': [5.0, 4.0, 3.0, 2.0, 1.0]\n})\n\n# Standardizing features\nscaler = StandardScaler()\nstandardized_data = scaler.fit_transform(data)\n\n# Create a scatter plot to visualize the standardized data\nplt.scatter(standardized_data[:, 0], standardized_data[:, 1])\nplt.title('Scatter plot of standardized features')\nplt.xlabel('Standardized feature1')\nplt.ylabel('Standardized feature2')\n\n# Save the plot as 'scatter_plot.png'\nplt.savefig('scatter_plot.png')\n\n# What is the next line of code to display the plot?\n# A:\ndisplay(plt)  # SOLUTION START\n```",
    "output": "\n```python\nplt.show()  # SOLUTION END\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different types of fruits along with their weights and prices. I would like to understand the relationship between weight and price using linear regression from Scikit-learn while also visualizing the results with Matplotlib. Below is the code snippet where I'm trying to create a scatter plot of weight vs. price. I want to fit a linear regression line to this plot. I need help on how to complete the below section where I'm plotting the regression line after fitting the model.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Sample dataset\ndata = {\n    'fruit': ['apple', 'banana', 'orange', 'grape', 'kiwi'],\n    'weight': [0.2, 0.15, 0.25, 0.3, 0.1],\n    'price': [1.2, 0.8, 1.5, 2.0, 0.5]\n}\ndf = pd.DataFrame(data)\n\n# Prepare data for linear regression\nX = df[['weight']]\ny = df['price']\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Create scatter plot\nplt.scatter(df['weight'], df['price'], color='blue')\n\n# Plot linear regression line\nX_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\ny_pred = ...\nplt.plot(X_range, y_pred, color='red')\n\nplt.xlabel('Weight (kg)')\nplt.ylabel('Price ($)')\nplt.title('Weight vs Price of Fruits')\nplt.show()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ny_pred = model.predict(X_range)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about sales transactions. You want to preprocess this data by normalizing the 'Amount' column, which represents the sales amount, and then visualize the distribution of this normalized data. \n\nSuppose you have the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'TransactionID': [1, 2, 3, 4, 5],\n    'Amount': [100.0, 150.0, 200.0, 250.0, 300.0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to normalize the 'Amount' column using min-max normalization and create a histogram of the normalized values.\n\nFill in the code to normalize the 'Amount' column and create the histogram plot:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Normalization\ndf['Normalized_Amount'] = ...\n# Plot\nplt.hist(df['Normalized_Amount'], bins=5)\nplt.title('Distribution of Normalized Amounts')\nplt.xlabel('Normalized Amount')\nplt.ylabel('Frequency')\nplt.show()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Normalized_Amount'] = (df['Amount'] - df['Amount'].min()) / (df['Amount'].max() - df['Amount'].min())\n```"
  },
  {
    "input": "Problem:\nI'm working on a machine learning project where I have a dataset of house prices along with features like square footage, number of bedrooms, and age of the house. I want to perform a simple linear regression to predict house prices based on the square footage. After fitting the model, I need to visualize the results. \n\nGiven a pandas DataFrame `df` with columns `['square_footage', 'price']`, I have already separated the predictor and target variables as follows:\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'square_footage': [1500, 2000, 2500, 3000, 3500],\n    'price': [300000, 350000, 400000, 450000, 500000]\n})\n\nX = df[['square_footage']].values\ny = df['price'].values\n```\nI now want to fit a linear regression model using `scikit-learn` and plot the regression line along with the data points using `matplotlib`. \n\nWhat I need is to fill in the code to fit the model and create the regression line plot. The code should look something like this:\n```python\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nplt.scatter(X, y, color='blue')  # scatter plot for actual prices\nplt.plot(X, model.predict(X), color='red')  # regression line\nplt.xlabel('Square Footage')\nplt.ylabel('Price')\nplt.title('House Prices vs. Square Footage')\nplt.show()\n```\nThe output variable `result` should store the fitted model after running the fit method. What is the line of code I need to complete this? \n\nA:\n<code>\nresult = ... # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = model.fit(X, y)  # fit the model and store the result in the variable\n</code>"
  },
  {
    "input": "### Problem\nYou have a dataset containing information about house sales, and you need to perform some basic analysis using various data science libraries. The dataset includes columns for 'Price', 'Bedrooms', 'Bathrooms', and 'LotSize'. The dataset is loaded into a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Price': [300000, 450000, 500000, 350000, 600000],\n    'Bedrooms': [3, 4, 4, 3, 5],\n    'Bathrooms': [2, 3, 3, 2, 4],\n    'LotSize': [5000, 7000, 8000, 6000, 10000]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the correlation matrix of the numerical features in the DataFrame using NumPy. The output should only focus on the numeric columns.\n\nWhat is the Pandas code you can use to calculate this correlation matrix?\n\n```python\ncorrelation_matrix = ...\n```\n",
    "output": "\n```python\ncorrelation_matrix = df.corr()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various cars, including their horsepower, weight, and mpg (miles per gallon). You want to standardize the horsepower and weight columns, then create a scatter plot to visualize the relationship between horsepower and mpg. The dataset is stored in a pandas DataFrame called `cars_df`:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ncars_df = pd.DataFrame({\n    'Horsepower': [130, 165, 150, 140, 198],\n    'Weight': [3504, 3693, 3436, 3433, 3701],\n    'MPG': [18, 15, 18, 16, 15]\n})\n```\n\nYou also want to use `StandardScaler` from `scikit-learn` to standardize the horsepower and weight before plotting. Complete the code to create the scatter plot along with proper labels.\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(cars_df[['Horsepower', 'Weight']])\nscaled_df = pd.DataFrame(scaled_features, columns=['Scaled_Horsepower', 'Scaled_Weight'])\n\nplt.scatter(scaled_df['Scaled_Horsepower'], cars_df['MPG'])\nplt.title('Horsepower vs MPG')\nplt.xlabel('Scaled Horsepower')\nplt.ylabel('MPG')\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>plt.show()</code>",
    "output": "\n<code>plt.show()</code>"
  },
  {
    "input": "Problem:\nI have a dataset that contains the ages and corresponding incomes of individuals. I want to normalize the income feature using MinMaxScaler from Scikit-learn. After scaling, I would like to visualize the relationship between the ages and the scaled incomes using a scatter plot with Matplotlib.\n\nHere is how my initial data looks:\n\n```python\nimport pandas as pd\n\ndata = {'age': [25, 30, 35, 40, 45, 50],\n        'income': [50000, 60000, 65000, 70000, 80000, 90000]}\ndf = pd.DataFrame(data)\n```\n\nI would like to fill in the blank in the following code snippet to perform the normalization and plot the data:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\nscaled_income = ...  # put solution in this variable\n\nplt.scatter(df['age'], scaled_income)\nplt.title('Age vs. Scaled Income')\nplt.xlabel('Age')\nplt.ylabel('Scaled Income')\nplt.show()\n```",
    "output": "\n```python\nscaled_income = scaler.fit_transform(df[['income']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales data for multiple products over several months, and I would like to create a model that predicts future sales based on this historical data. I'm using TensorFlow to build a neural network for this purpose, but I need help with how to compile the model. I'm looking to use Mean Squared Error as the loss function and Adam as the optimizer. Here is my setup:\n```python\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(1)\n])\n```\nWhat should I do next to compile this model?\nA:\n<code>\nmodel.compile(optimizer=..., loss=...) # put solution in these variables\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing latitudes and longitudes of multiple locations, and I'm trying to calculate the distance of each location from a reference point (latitude, longitude) using the Haversine formula. The dataset is in a Pandas DataFrame format and looks like this:\n\n```\n    id     latitude    longitude\n0   1      34.0522    -118.2437\n1   2      40.7128    -74.0060\n2   3      51.5074    -0.1278\n3   4      48.8566    2.3522\n4   5      35.6895    139.6917\n```\n\nThe reference point I want to calculate the distances from is (34.0522, -118.2437). I'm aware that I can use numpy for mathematical operations involved in the formula. \n\nHere's my starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'id': [1, 2, 3, 4, 5],\n    'latitude': [34.0522, 40.7128, 51.5074, 48.8566, 35.6895],\n    'longitude': [-118.2437, -74.0060, -0.1278, 2.3522, 139.6917]\n}\ndf = pd.DataFrame(data)\n\nreference_point = (34.0522, -118.2437)\n\n# Haversine formula calculations\ndef haversine(lat1, lon1, lat2, lon2):\n    R = 6371  # Earth radius in kilometers\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arcsin(np.sqrt(a))\n    return R * c\n\n# The result variable should contain the distances calculated\n    \n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df.apply(lambda row: haversine(reference_point[0], reference_point[1], row['latitude'], row['longitude']), axis=1)\n```"
  },
  {
    "input": "Problem:\nI\u2019m working on a machine learning project and I have a dataset containing information on various products. The dataset has the following structure:\n\n| product_id | name       | price | category   | sales |\n|------------|------------|-------|------------|-------|\n| 1          | Product A  | 10.0  | Category 1 | 100   |\n| 2          | Product B  | 20.0  | Category 1 | 150   |\n| 3          | Product C  | 15.0  | Category 2 | 200   |\n| 4          | Product D  | 25.0  | Category 2 | 250   |\n\nI want to create a new DataFrame that shows the average price of products in each category along with total sales in that category. The output DataFrame should have the following structure:\n\n| category   | average_price | total_sales |\n|------------|---------------|-------------|\n| Category 1 |               |             |\n| Category 2 |               |             |\n\nWhat I need help with is calculating the average prices and total sales grouped by the 'category' using pandas. \n\nHere\u2019s the initial setup of the DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4],\n    'name': ['Product A', 'Product B', 'Product C', 'Product D'],\n    'price': [10.0, 20.0, 15.0, 25.0],\n    'category': ['Category 1', 'Category 1', 'Category 2', 'Category 2'],\n    'sales': [100, 150, 200, 250]\n}\n\ndf = pd.DataFrame(data)\n```\nYou need to compute the result and assign it to the variable `result`. \n\nresult = ...  # put your solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('category').agg(average_price=('price', 'mean'), total_sales=('sales', 'sum')).reset_index()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses which includes features like size, number of bedrooms, age, and price. I want to normalize each feature column (except for the price) using Min-Max scaling, but I need help with implementing this. The dataset looks like this:\n\n```\n   Size  Bedrooms  Age  Price\n0   1500         3   10  300000\n1   2000         4   15  400000\n2   1200         2   5   250000\n3   1800         3   20  350000\n4   2200         5   25  500000\n```\n\nI have already created a Pandas DataFrame and now I want to normalize the 'Size', 'Bedrooms', and 'Age' columns. I would like the result to use the following formula for normalization:\n\n\\[ \\text{normalized\\_value} = \\frac{\\text{value} - \\text{min}}{\\text{max} - \\text{min}} \\]\n\nPlease see my DataFrame below:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 2000, 1200, 1800, 2200],\n    'Bedrooms': [3, 4, 2, 3, 5],\n    'Age': [10, 15, 5, 20, 25],\n    'Price': [300000, 400000, 250000, 350000, 500000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nThe variable below should hold the normalized DataFrame after applying the scaling.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmin_values = df[['Size', 'Bedrooms', 'Age']].min()\nmax_values = df[['Size', 'Bedrooms', 'Age']].max()\nresult = df.copy()\nresult[['Size', 'Bedrooms', 'Age']] = (df[['Size', 'Bedrooms', 'Age']] - min_values) / (max_values - min_values)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about different products in a Pandas DataFrame, and you want to create a feature that categorizes the products based on their prices. The DataFrame is structured as follows:\n\n```\n   product_name  price\n0       Laptop  999.99\n1      Smartphone  699.99\n2      Tablet  299.99\n3      Headphones  89.99\n4      Monitor  199.99\n```\n\nYou want to create a new column `price_category` where:\n- Prices above $800 are labeled as 'Premium'\n- Prices between $300 and $800 are labeled as 'Mid-range'\n- Prices below $300 are labeled as 'Budget'\n\nHow can I achieve that?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],\n    'price': [999.99, 699.99, 299.99, 89.99, 199.99]\n}\n\ndf = pd.DataFrame(data)\n</code>\ndf['price_category'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['price_category'] = pd.cut(df['price'], bins=[0, 300, 800, float('inf')], labels=['Budget', 'Mid-range', 'Premium'], right=False)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset of housing prices and their corresponding features stored in a Pandas DataFrame `df`. The features include `\"size\"`, `\"bedrooms\"`, and `\"age\"` of the houses. I want to standardize the feature columns by using the `StandardScaler` from scikit-learn. However, I would like to avoid using any explicit loop for the standardization process. Given that I wish to apply the standardization to the `\"size\"`, `\"bedrooms\"`, and `\"age\"` columns and leave the price column unchanged, what code should I write to achieve this?\n\nHere is how the DataFrame is structured:\n```python\nimport pandas as pd\n\ndata = {\n    \"size\": [1500, 1800, 2400, 3000],\n    \"bedrooms\": [3, 4, 3, 5],\n    \"age\": [10, 15, 20, 5],\n    \"price\": [300000, 450000, 500000, 600000]\n}\ndf = pd.DataFrame(data)\n```\nNow, I want to standardize the specified columns. \n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf[[\"size\", \"bedrooms\", \"age\"]] = ...\n```",
    "output": "\n```python\ndf[[\"size\", \"bedrooms\", \"age\"]] = scaler.fit_transform(df[[\"size\", \"bedrooms\", \"age\"]])\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset containing daily stock prices for multiple companies and I want to perform some analysis to understand correlations between their returns. Specifically, I want to:\n1. Calculate daily returns for each stock based on the prices.\n2. Compute the correlation matrix of the returns.\n\nHere\u2019s the code I have so far that loads the dataset into a Pandas DataFrame:\n\n```python\nimport pandas as pd\ndf = pd.read_csv('stock_prices.csv')  # Assume the CSV has columns 'Date', 'Stock_A', 'Stock_B', ..., 'Stock_N'\n```\n\nNow, what I want is to calculate the daily returns and store them in a new DataFrame called `returns`. The daily return is computed as: \n\\[ \\text{return} = \\frac{\\text{current\\_price} - \\text{previous\\_price}}{\\text{previous\\_price}} \\]\n\nYou can assume that the necessary libraries have been imported and the dataframe setup is correctly in place.\n\nA:\n```python\nreturns = df.pct_change()  # put solution in this variable\n```",
    "output": "\n```python\nreturns = df.set_index('Date').pct_change().dropna()  # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing sales data from a store over a period of time. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'Sales': [215, 250, 230, 275, 300, 260, 280, 295, 310, 320],\n    'Discount': [10, 15, 10, 20, 25, 15, 20, 30, 25, 20]\n}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nYou want to create a new column in the DataFrame called `Net_Sales`, which is calculated by subtracting the `Discount` from `Sales`. After that, plot the `Sales` and `Net_Sales` in a line chart to compare the two.\n\nHow can you achieve this? \n\nA:\n```python\nimport matplotlib.pyplot as plt\n\ndf['Net_Sales'] = ... # put solution in this variable\n\nplt.plot(df.index, df['Sales'], label='Sales', color='blue')\nplt.plot(df.index, df['Net_Sales'], label='Net Sales', color='orange')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\ndf['Net_Sales'] = df['Sales'] - df['Discount']\n```"
  },
  {
    "input": "Problem:\nYou have a dataset where you want to classify different types of fruits based on their features such as weight, color (numerically represented), and sweetness level. You will use a neural network model built with TensorFlow. Given a numpy array `X` representing the features of the fruits and an array `y` containing the corresponding labels, how would you define and compile a simple feedforward neural network model? Additionally, if you want to fit the model with the data, how would you execute this step?\n\nHere is how your data is defined:\n\n```python\nimport numpy as np\n\nX = np.array([[150, 0.8, 0.6],\n              [200, 0.7, 0.8],\n              [120, 0.9, 0.5],\n              [180, 0.6, 0.7]])\n\ny = np.array([0, 1, 0, 1])  # 0 for apple, 1 for orange\n```\n\nWhat is the correct code to define and compile the neural network model and fit it to `X` and `y`?\n\nA:\n```python\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential() \n<code>\n# put solution in this variable\n```",
    "output": "\n```python\nmodel.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(X.shape[1],)))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X, y, epochs=100)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing various features related to housing prices, including features like square footage, number of bedrooms, and age of the house. I want to build a machine learning model to predict the price of houses. However, first, I need to preprocess the categorical variables to one-hot encode them, scale the numerical features, and then fit a linear regression model using scikit-learn. \n\nGiven this DataFrame `df`:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Square_Footage': [1500, 1800, 2400, 3000],\n    'Bedrooms': [3, 4, 5, 4],\n    'Age': [10, 15, 20, 5],\n    'Neighborhood': ['A', 'B', 'A', 'B']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI have already imported the necessary libraries:\n\n```python\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n```\n\nNow, what should I place in the following line to create a complete pipeline for modeling?\n\n```python\npipeline = Pipeline(steps=[\n    ('preprocessor', ColumnTransformer(\n        transformers=[\n            ('num', StandardScaler(), ['Square_Footage', 'Bedrooms', 'Age']),\n            ('cat', OneHotEncoder(), ['Neighborhood'])\n        ])),\n    ('model', LinearRegression())\n])\n```\n\nTo fit the pipeline using the features `X` and taget price `y`, which I will define as `df['Price']`, I would create `y` like this:\n\n```python\n# Let's say we have some target variable 'Price'\ndf['Price'] = [300000, 350000, 450000, 500000]  # Example prices\ny = df['Price']\nX = df.drop('Price', axis=1)\n```\n\nWhat should I include in this variable to fit the model?\n\n```python\nmodel = pipeline.fit(... # put solution in this variable \n```\n\nBEGIN SOLUTION\n<code>\nX, y\n</code>",
    "output": "\n<code>\nX, y\n</code>"
  },
  {
    "input": "### Problem\nProblem:\nYou have a dataset of customer transactions for a retail store that is stored in a Pandas DataFrame. The DataFrame includes columns for 'CustomerID', 'TransactionAmount', and 'TransactionDate'. You want to investigate the total spending by each customer for a specific period and visualize the results in a bar chart. Additionally, any negative transaction amounts should be ignored in the total spending calculation.\n\nHere's a sample of your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n    'TransactionAmount': [100, 200, -50, 150, 300, 50, -10],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the total spending for each customer in January 2023 (you can filter the DataFrame first), create a bar chart showing the total spending by customer, and output the results as a new DataFrame containing 'CustomerID' and 'TotalSpending'.\n\nYour code snippet should initialize the necessary libraries and perform the required calculations. \n\nPlease fill in the blank for the DataFrame containing the total spending per customer:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'CustomerID': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n    'TransactionAmount': [100, 200, -50, 150, 300, 50, -10],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n\n# Filter for January 2023\n# Calculate total spending for each customer, ignoring negative values\ntotal_spending = df[df['TransactionAmount'] > 0].groupby('CustomerID')['TransactionAmount'].sum().reset_index()\n\n# Visualize the total spending\nplt.bar(total_spending['CustomerID'], total_spending['TransactionAmount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Spending')\nplt.title('Total Spending by Customer in January 2023')\nplt.show()\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = total_spending.rename(columns={'TransactionAmount': 'TotalSpending'})\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing the daily temperature readings for multiple cities over the last month, stored in a Pandas DataFrame. I would like to compute the moving average of temperatures over a 7-day window for each city and visualize the results using Matplotlib. The DataFrame has a column for dates and separate columns for each city's temperatures. The variable `city` is provided, which holds the name of the city for which we want to calculate the moving average. What is the correct code to fill in to obtain the moving average?\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'CityA': [15, 16, 14, 18, 20, 22, 21, 19, 18, 17, 15, 16, 14, 18, 20, 22, 21, 19, 18, 17, 15, 16, 14, 18, 20, 22, 21, 19, 18, 17],\n    'CityB': [20, 21, 19, 22, 24, 26, 25, 23, 22, 21, 20, 21, 19, 22, 24, 26, 25, 23, 22, 21, 20, 21, 19, 22, 24, 26, 25, 23, 22, 21]\n}\ndf = pd.DataFrame(data)\ncity = 'CityA'\n    \nmoving_average = ... # put solution in this variable\n\nplt.plot(df['date'], df[city], label=f'Temperature {city}')\nplt.plot(df['date'], moving_average, label=f'Moving Average {city}', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Temperature')\nplt.title('Daily Temperatures and Moving Average')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nmoving_average = df[city].rolling(window=7).mean()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Create a sample dataset with 100 data points\nnp.random.seed(42)\nx = 2 * np.random.rand(100, 1)\ny = 4 + 3 * x + np.random.randn(100, 1)\n\n# Fit a linear regression model to the data\nmodel = LinearRegression()\nmodel.fit(x, y)\n\n# Predict values over the range of x\nx_pred = np.linspace(0, 2, 100).reshape(-1, 1)\ny_pred = model.predict(x_pred)\n\n# Plot the original data and the linear regression line\nplt.scatter(x, y, color='blue', label='Data Points')\nplt.plot(x_pred, y_pred, color='red', label='Regression Line')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression Example')\nplt.legend()\n# SOLUTION START\n```",
    "output": "\n```python\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nI am working on a classification problem using a dataset of various flowers that includes features like petal length and width, and I need to implement a model using Scikit-learn. After fitting the model, I want to visualize the decision boundary of the classifier using Matplotlib. I'm currently using the Iris dataset, which I've already loaded and preprocessed.\n\nHere's my code snippet so far:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load Iris dataset\niris = datasets.load_iris()\nX = iris.data[:, :2]  # using only the first two features\ny = iris.target\n\n# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Fit Random Forest Classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)\n```\n\nI would like to plot the decision boundary of the classifier on the same graph as the training points. Can you help me fill in the code to achieve that? Below is where I am stuck:\n\n```python\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\nZ = clf.predict(...)  # fill in this part\n\n# Plotting the results\nplt.contourf(xx, yy, Z, alpha=0.8)\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o')\nplt.title('Random Forest Decision Boundary')\nplt.xlabel('Petal Length')\nplt.ylabel('Petal Width')\nplt.show()\n```\n\nThe variable `Z` needs to be defined to predict over the meshgrid. What should I put there? \nA:\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load Iris dataset\niris = datasets.load_iris()\nX = iris.data[:, :2]\ny = iris.target\n\n# Splitting the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Fit Random Forest\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)\n\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\nZ = ...  # put solution in this variable\n\nplt.contourf(xx, yy, Z, alpha=0.8)\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o')\nplt.title('Random Forest Decision Boundary')\nplt.xlabel('Petal Length')\nplt.ylabel('Petal Width')\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of sales transactions that includes the following columns: `TransactionID`, `Product`, `Quantity`, and `Price`. The prices are in USD, and I need to convert them into EUR using a provided conversion rate of 0.85. After converting the prices, I want to compute the total revenue for each product and visualize it using a bar chart. How would I go about doing this with the given DataFrame?\n\nGiven the following DataFrame:\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'TransactionID': [1, 2, 3, 4],\n    'Product': ['A', 'B', 'A', 'C'],\n    'Quantity': [2, 1, 3, 5],\n    'Price': [100, 150, 200, 300]\n}\ndf = pd.DataFrame(data)\nconversion_rate = 0.85\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\nresult = df.copy()\nresult['Price_EUR'] = result['Price'] * conversion_rate\nresult['Total_Revenue'] = result['Quantity'] * result['Price_EUR']\ntotal_revenue_per_product = result.groupby('Product')['Total_Revenue'].sum().reset_index()\n\nimport matplotlib.pyplot as plt\n\nplt.bar(total_revenue_per_product['Product'], total_revenue_per_product['Total_Revenue'])\nplt.xlabel('Product')\nplt.ylabel('Total Revenue (EUR)')\nplt.title('Total Revenue per Product in EUR')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndata = pd.DataFrame({\n    'feature1': [1.5, 2.5, 3.5, 4.5, 5.5],\n    'feature2': [10, 20, 30, 40, 50]\n})\n\n# Normalize the features using StandardScaler\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n\n# Plot the first feature against the second feature using the normalized values\nplt.scatter(scaled_data[:, 0], scaled_data[:, 1], color='blue', label='Normalized Data')\n\n# Add a title to the plot\n# SOLUTION START\n```",
    "output": "\n```python\nplt.title('Normalized Feature1 vs Feature2')\n# SOLUTION END\n\n# Show the legend\nplt.legend()\n\n# Display the plot\nplt.show()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some random data\nnp.random.seed(42)\nx = np.random.rand(100, 1) * 10  # 100 data points\ny = 3 * x + np.random.randn(100, 1) * 2  # y = 3x + noise\n\n# Create a DataFrame\ndata = pd.DataFrame(np.hstack((x, y)), columns=['X', 'Y'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['X']], data['Y'])\n\n# Generate predictions\npredictions = model.predict(data[['X']])\n\n# Plot the data points and the regression line\nplt.scatter(data['X'], data['Y'], label='Data Points')\nplt.plot(data['X'], predictions, color='red', label='Regression Line')\nplt.legend()\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression Example')\nplt.show()\n\n# Now, I want to find the model coefficients (slope and intercept)\n# use the model coefficients for further analysis\nslope = ... # needs to extract the slope from the model\n\n```",
    "output": "\n```python\nslope = model.coef_[0][0]  # Extract the slope from the model\n```"
  },
  {
    "input": "Problem:\nYou have collected data on a number of house prices in different neighborhoods along with various features such as size (in square feet), number of bedrooms, and number of bathrooms. You want to build a linear regression model using Scikit-learn to predict house prices based on these features. You have the following datasets:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Size': [1500, 2000, 2500, 3000, 3500],  # in square feet\n    'Bedrooms': [3, 4, 4, 5, 5],\n    'Bathrooms': [2, 3, 2, 3, 4],\n    'Price': [300000, 400000, 500000, 600000, 700000]  # in dollars\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to fit a linear regression model using the `Size`, `Bedrooms`, and `Bathrooms` as input features to predict the `Price`. After fitting the model, you want a function that can return the predicted prices for a given input array of house features. Fill in the blank in the following function:\n\n```python\nfrom sklearn.linear_model import LinearRegression\n\ndef predict_house_prices(input_features):\n    model = LinearRegression()\n    model.fit(df[['Size', 'Bedrooms', 'Bathrooms']], df['Price'])\n    predicted_prices = model.predict(input_features)\n    return predicted_prices\n\n# Example usage\nexample_input = [[1800, 3, 2], [2600, 4, 3]]  # input features\npredicted = ____  # put solution in this variable\n```\n\nHow can you compute `predicted` using the `predict_house_prices` function?",
    "output": "\n```python\npredicted = predict_house_prices(example_input)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset that contains the temperatures recorded in different cities over a week. The data is stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\ndata = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Mon': [30, 75, 28, 80, 85],\n    'Tue': [32, 78, 29, 82, 87],\n    'Wed': [31, 76, 30, 79, 88],\n    'Thu': [29, 77, 31, 81, 90],\n    'Fri': [33, 74, 30, 83, 86],\n    'Sat': [34, 79, 28, 84, 89],\n    'Sun': [35, 80, 33, 80, 91]\n})\n```\n\nI want to compute the average temperature for each city and create a new column 'Average' in the DataFrame to store this value. After that, I want to identify the city with the maximum average temperature and its corresponding average. \n\nHow can I achieve this easily?\n\n```python\n# Start of my code\nimport pandas as pd\ndata = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Mon': [30, 75, 28, 80, 85],\n    'Tue': [32, 78, 29, 82, 87],\n    'Wed': [31, 76, 30, 79, 88],\n    'Thu': [29, 77, 31, 81, 90],\n    'Fri': [33, 74, 30, 83, 86],\n    'Sat': [34, 79, 28, 84, 89],\n    'Sun': [35, 80, 33, 80, 91]\n})\n\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndata['Average'] = data.iloc[:, 1:].mean(axis=1)\nmax_avg_city = data.loc[data['Average'].idxmax(), ['City', 'Average']]\nresult = max_avg_city\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various cities with columns for 'city', 'temperature', and 'humidity'. I need to preprocess this data using Pandas to normalize the 'temperature' values between 0 and 1. The DataFrame is as follows:\n\n+-----------+------------+----------+\n| city      | temperature| humidity |\n+-----------+------------+----------+\n| CityA    | 20         | 30       |\n| CityB    | 25         | 40       |\n| CityC    | 15         | 25       |\n| CityD    | 30         | 50       |\n+-----------+------------+----------+\n\nHow can I calculate the normalized temperature and store the result in a new column called 'normalized_temperature'? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {'city': ['CityA', 'CityB', 'CityC', 'CityD'],\n        'temperature': [20, 25, 15, 30],\n        'humidity': [30, 40, 25, 50]}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['normalized_temperature'] = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing information about various products sold in a store, and you have the following DataFrame created using pandas:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'D'],\n    'Sales': np.random.randint(1, 20, size=10),\n    'Price': np.random.uniform(1.0, 10.0, size=10)\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to calculate the total revenue generated by each product, defined as the product of sales and price. Additionally, you want to visualize this total revenue using a bar plot. \n\nHowever, you want to use the following consolidated DataFrame after calculating the revenue:\n\n```python\nrevenue_df = df.groupby('Product').agg({'Sales': 'sum', 'Price': 'mean'})\nrevenue_df['Total_Revenue'] = ...\n```\n\nYou need to fill in the blank to calculate the total revenue per product and create a bar plot of total revenue using Matplotlib.\n\nA:\n```python\nimport matplotlib.pyplot as plt\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nrevenue_df['Total_Revenue'] = revenue_df['Sales'] * revenue_df['Price']\nresult = revenue_df['Total_Revenue']\nrevenue_df['Total_Revenue'].plot(kind='bar')\nplt.title('Total Revenue by Product')\nplt.xlabel('Product')\nplt.ylabel('Total Revenue')\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a predictive model using a dataset containing both categorical and numerical features. The dataset has a categorical feature \"City\" and numerical features \"Temperature\" and \"Humidity\". To improve the model's performance, you decide to normalize the numerical features and one-hot encode the categorical feature.\n\nGiven the following dataset:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles'],\n    'Temperature': [30, 75, 29, 45, 80],\n    'Humidity': [70, 50, 68, 60, 48]\n})\n```\n\nHow do you apply normalization using `StandardScaler` from `scikit-learn` for the numerical features and one-hot encoding for the \"City\" feature to create a new DataFrame?\n\nA:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles'],\n    'Temperature': [30, 75, 29, 45, 80],\n    'Humidity': [70, 50, 68, 60, 48]\n})\n\n# solution starts here\nnormalized_data = ... # put solution in this variable\n```",
    "output": "\n```python\nscaler = StandardScaler()\ndata[['Temperature', 'Humidity']] = scaler.fit_transform(data[['Temperature', 'Humidity']])\nnormalized_data = pd.get_dummies(data, columns=['City'], drop_first=True)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about different fruits, including their weights and prices. I want to standardize the weights and prices across the dataset to analyze the data more effectively. The dataset is stored in a pandas DataFrame. How can I achieve this using Scikit-learn's StandardScaler?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'fruit': ['apple', 'banana', 'cherry'],\n    'weight': [150, 120, 200],\n    'price': [0.5, 0.3, 0.8]\n}\ndf = pd.DataFrame(data)\n\n# Here, I want to standardize the 'weight' and 'price' columns\nstandardized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaler = StandardScaler()\ndf[['weight', 'price']] = scaler.fit_transform(df[['weight', 'price']])\nstandardized_data = df\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assume we have a DataFrame containing sales data with columns 'Product', 'Year', and 'Sales'.\ndata = {\n    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Year': [2020, 2020, 2021, 2021, 2022, 2022],\n    'Sales': [100, 150, 200, 250, 300, 350]\n}\ndf = pd.DataFrame(data)\n\n# Create a pivot table to aggregate the total sales per product over years.\n# I want to fill in the blank to create the pivot table to show Sales with the appropriate index, columns, and values.\npivot_table = df.pivot_table(__________)\nBEGIN SOLUTION\n```",
    "output": "\n```python\npivot_table = df.pivot_table(index='Year', columns='Product', values='Sales', aggfunc='sum')\n```"
  },
  {
    "input": "Problem:\nYou're analyzing a dataset of movie ratings and want to determine the average rating per genre. The dataset is in the form of a Pandas DataFrame with two columns: \"genre\" (which may contain multiple genres separated by commas) and \"rating\". You need to compute the average rating for each unique genre, taking into account that a movie may belong to multiple genres. The expected output should be a DataFrame with two columns: \"genre\" and \"average_rating\".\n\nHere\u2019s a snippet of the DataFrame you have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'genre': ['Action,Adventure', 'Action', 'Drama', 'Adventure', 'Action,Drama', 'Comedy'],\n    'rating': [5, 6, 7, 8, 5, 9]\n}\ndf = pd.DataFrame(data)\n```\n\nTo transform this DataFrame, you need to fill in the blank with the correct code to produce the desired output. \n\nA:\n<code>\naverage_ratings = ... # put solution in this variable\n</code>",
    "output": "\n<code>\naverage_ratings = df.explode('genre').groupby('genre')['rating'].mean().reset_index(name='average_rating')\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different products, including their prices, categories, and features. I want to normalize the 'price' column values to a range of 0 to 1, while keeping the DataFrame structure intact. Here is the DataFrame I have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': [1, 2, 3, 4],\n    'Category': ['A', 'B', 'A', 'C'],\n    'Price': [100, 200, 150, 300],\n    'Feature1': [5, 7, 6, 9],\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter applying normalization to the 'Price' column, I want the resulting DataFrame to still include the 'ProductID', 'Category', and 'Feature1' columns. \n\nA:\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_prices = ... # put solution in this variable\n```",
    "output": "\n```python\nnormalized_prices = scaler.fit_transform(df[['Price']])\ndf['Price'] = normalized_prices\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information about different products in a store. The dataset has a column for 'product_id', 'price', and 'rating'. I want to use this data to create a neural network model that predicts the price of a product based on its rating. After training the model, I would like to evaluate its performance using Mean Absolute Error (MAE). I have already imported the necessary libraries and loaded the dataset into a Pandas DataFrame named `df`. How can I compute the MAE in this context after fitting the model?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom sklearn.metrics import mean_absolute_error\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 3, 4, 5],\n    'price': [10.99, 12.99, 15.99, 20.99, 18.99],\n    'rating': [4.5, 4.0, 5.0, 3.5, 4.2]\n})\n\nX = df[['rating']]\ny = df['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nmodel.fit(X_train_scaled, y_train, epochs=100, verbose=0)\n\ny_pred = model.predict(X_test_scaled)\n\nmae = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmae = mean_absolute_error(y_test, y_pred)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset comprised of several weather measurements for various regions, including temperature, humidity, and wind speed. The data is stored in a Pandas DataFrame. Your task is to normalize the temperature values (stored in the 'temperature' column) using Min-Max scaling, which transforms the values to a range between 0 and 1. Additionally, after normalization, you want to plot the distribution of the normalized temperature values using a histogram with Matplotlib.\n\nHere is a sample DataFrame to illustrate the input:\n\n```python\nimport pandas as pd\n\ndata = {\n    'region': ['North', 'South', 'East', 'West', 'Central'],\n    'temperature': [32, 45, 30, 40, 38],\n    'humidity': [80, 70, 85, 75, 90],\n    'wind_speed': [5, 7, 6, 8, 4]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to create a function that normalizes the temperature and returns the histogram plot. The completed solution should look like this:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef normalize_and_plot(df):\n    # Normalize the 'temperature' column and save it back to the DataFrame\n    normalized_temperature = ...  # put solution in this variable\n    df['normalized_temperature'] = normalized_temperature\n    \n    # Plot the histogram of the normalized temperatures\n    plt.hist(df['normalized_temperature'], bins=5, color='skyblue', edgecolor='black')\n    plt.title('Normalized Temperature Distribution')\n    plt.xlabel('Normalized Temperature')\n    plt.ylabel('Frequency')\n    plt.show()\n```\n\nYou need to fill in the blank represented by `...`.",
    "output": "\n```python\n    normalized_temperature = (df['temperature'] - df['temperature'].min()) / (df['temperature'].max() - df['temperature'].min())\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing user ratings for different movies, stored in a Pandas DataFrame. Each rating is between 1 and 5. I want to compute the average rating for each movie and create a sorted list of these average ratings in descending order. Here is an example of the DataFrame:\n\n```\n   movie_id  user_id  rating\n0        1        1       5\n1        1        2       4\n2        1        3       3\n3        2        1       2\n4        2        2       5\n5        3        1       4\n```\n\nI need to fill in the blank to compute the average rating for each movie and return a sorted list of these averages. \n\nThe DataFrame is defined as:\n\n```python\nimport pandas as pd\n\ndata = {'movie_id': [1, 1, 1, 2, 2, 3],\n        'user_id': [1, 2, 3, 1, 2, 1],\n        'rating': [5, 4, 3, 2, 5, 4]}\ndf = pd.DataFrame(data)\n```\n\nWhat would be the most efficient way to compute and store the sorted average ratings of the movies?\n\naverage_ratings = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\naverage_ratings = df.groupby('movie_id')['rating'].mean().sort_values(ascending=False).tolist()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different fruits and their respective features. The dataset is a pandas DataFrame with the following structure:\n\n| Fruit        | Color   | Weight (g) | Sweetness (0-10) |\n|--------------|---------|------------|-------------------|\n| Apple        | Red     | 150        | 8                 |\n| Banana       | Yellow  | 120        | 9                 |\n| Cherry       | Red     | 10         | 7                 |\n| Lemon        | Yellow  | 80         | 3                 |\n| Orange       | Orange  | 130        | 8                 |\n\nThe task is to standardize the numerical attributes (Weight and Sweetness) using Scikit-learn's `StandardScaler`, and then visualize the standardized values using Matplotlib.\n\nThe provided code initializes the DataFrame. \n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'Fruit': ['Apple', 'Banana', 'Cherry', 'Lemon', 'Orange'],\n    'Color': ['Red', 'Yellow', 'Red', 'Yellow', 'Orange'],\n    'Weight (g)': [150, 120, 10, 80, 130],\n    'Sweetness (0-10)': [8, 9, 7, 3, 8]\n}\n\ndf = pd.DataFrame(data)\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit and transform the numerical features\nscaled_values = ...\n```\n\nThe variable `scaled_values` should hold the standardized values of the features 'Weight (g)' and 'Sweetness (0-10)' as a NumPy array which has shape (5, 2). After that, create a bar plot to visualize the standardized values for both features.\n\nA:\n<code>\n",
    "output": "\nscaled_values = scaler.fit_transform(df[['Weight (g)', 'Sweetness (0-10)']])\n\n# Create a bar plot\nplt.bar(df['Fruit'], scaled_values[:, 0], label='Weight (g)', alpha=0.6)\nplt.bar(df['Fruit'], scaled_values[:, 1], label='Sweetness (0-10)', alpha=0.6, bottom=scaled_values[:, 0])\nplt.xlabel('Fruit')\nplt.ylabel('Standardized Values')\nplt.title('Standardized Weight and Sweetness of Fruits')\nplt.legend()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a Pandas DataFrame containing information about students and their grades. The DataFrame has columns 'Name' and 'Grades', where 'Grades' contains lists of scores for various subjects. I want to calculate the average grade for each student and create a new column 'Average Grade'. I am currently using the code below, but it results in an error because I don't know how to handle the list of grades in the 'Grades' column properly. \n\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Grades': [[88, 92, 85], [76, 84, 90], [95, 100, 98]]\n})\n\naverage = df['Grades'].apply(np.mean)\n\nHow can I correctly create the new column 'Average Grade' in the DataFrame?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Grades': [[88, 92, 85], [76, 84, 90], [95, 100, 98]]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['Grades'].apply(np.mean)\ndf['Average Grade'] = result\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nimport torch\n\n# Create a pandas DataFrame with random data for three features and a target variable\nnp.random.seed(42)\ndata = pd.DataFrame({\n    'Feature1': np.random.randn(100),\n    'Feature2': np.random.rand(100) * 100,\n    'Feature3': np.random.choice(['A', 'B', 'C'], 100),\n    'Target': np.random.choice([0, 1], 100)\n})\n\n# Convert categorical variable to dummy/indicator variables\ndata = pd.get_dummies(data, columns=['Feature3'], drop_first=True)\n\n# Scale all feature columns\nscaler = StandardScaler()\ndata_scaled = pd.DataFrame(scaler.fit_transform(data.drop('Target', axis=1)), columns=data.columns[:-1])\n\n# Prepare data for a simple linear model\nX = data_scaled.values\ny = data['Target'].values\n\n# Initialize a simple linear model using TensorFlow\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid')])\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model on the scaled data for a specified number of epochs\nmodel.fit(X, y, epochs=10, verbose=0)\n\n# Plot the training process by using Matplotlib to display the loss as a function of epochs\nplt.plot(model.history.history['loss'])\nplt.title('Model Loss During Training')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Now I need to predict the Target variable using the trained model. What code do I need to fill in the blank below?\npredictions = model.predict(X).flatten()\nresult = ...  # fill in the predictions here\n```",
    "output": "\n```python\nresult = (predictions > 0.5).astype(int)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing various measurements of a substance over time represented as a Pandas DataFrame. I want to calculate the rolling mean of a specified window size for one of the columns in this DataFrame and also plot this result alongside the original data using Matplotlib.\n\nHere's a sample DataFrame:\n```\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'time': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'measurement': np.random.rand(10) * 100\n}\ndf = pd.DataFrame(data)\n```\nNow, I want to compute the rolling mean with a window size of 3 and then plot both the original 'measurement' and the rolling mean on the same graph. \n\nPlease provide me with the code to compute the rolling mean and plot it.\n\nA:\n<code>\nrolling_mean = ... # put solution in this variable\nplt.plot(df['time'], df['measurement'], label='Original Measurement')\nplt.plot(df['time'], rolling_mean, label='Rolling Mean', color='orange')\nplt.xlabel('Time')\nplt.ylabel('Measurement')\nplt.legend()\nplt.show()\n</code>",
    "output": "\n<code>\nrolling_mean = df['measurement'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing customer reviews with ratings, and I need to preprocess the text data and build a model to predict the ratings based on the reviews. The reviews are stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Review': [\n        'This product is great!',\n        'Worst purchase I ever made.',\n        'I love it, totally recommend!',\n        'It was okay, not what I expected.',\n        'Fantastic quality and fast shipping.'\n    ],\n    'Rating': [5, 1, 5, 3, 5]\n}\ndf = pd.DataFrame(data)\n```\n\nFirst, I want to convert the text reviews into a format suitable for a machine learning model by using a text vectorizer from `sklearn`. Then I will build a simple `TensorFlow` model to predict the ratings based on the processed reviews. \n\nI have set up my `CountVectorizer` as follows:\n\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(df['Review'])\n```\n\nNext, I need to define a simple neural network model using `TensorFlow`. Here is the provided setup for the model creation:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(...)))  # Input shape needs to be defined here\nmodel.add(layers.Dense(1, activation='linear'))  # Output layer for regression\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n```\n\nWhat should I put into the blank at `input_shape=(...)` to correctly define the input shape for the model based on the text vectorization?\n\nA:\n<code>\nmodel.add(layers.Dense(64, activation='relu', input_shape=(...)))  # put solution in this variable\nBEGIN SOLUTION\n<code> X.shape[1], </code>\n",
    "output": "\n<code> X.shape[1], </code>"
  },
  {
    "input": "Problem:\nI have a dataset that consists of daily temperature readings in Celsius for multiple cities. I want to convert these temperature readings to Fahrenheit, compute the average temperature in Fahrenheit for each city, and then visualize the results using a bar chart. \n\nHere is an example dataset represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n    'temperature_celsius': [22, 28, 15, 30]  # Daily temperatures\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to replace the \"temperature_celsius\" column with a new column \"temperature_fahrenheit\" containing the converted temperature values, calculated using the formula:\n\\[ F = C \\times \\frac{9}{5} + 32 \\]\n\nAfter that, I need to compute the average Fahrenheit temperature for each city and plot these averages.\n\nHow can I accomplish this in a single line of code for the conversion, followed by the average computation, and then create the bar plot?\n\nA:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n    'temperature_celsius': [22, 28, 15, 30]  # Daily temperatures\n}\n\ndf = pd.DataFrame(data)\n```\navg_temps = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['temperature_fahrenheit'] = df['temperature_celsius'] * 9/5 + 32; avg_temps = df.groupby('city')['temperature_fahrenheit'].mean(); avg_temps.plot(kind='bar', title='Average Temperature in Fahrenheit by City'); plt.ylabel('Temperature (\u00b0F)'); plt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of daily temperatures recorded in different cities over a month, and I want to visualize it to identify trends. The dataset is stored in a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'city_1': [30, 32, 28, 33, 31, 29, 35, 36, 30, 28, 27, 29, 31, 32, 35, 34, 30, 29, 33, 30, 28, 26, 27, 29, 30, 31, 32, 35, 33, 31],\n    'city_2': [25, 27, 26, 28, 22, 24, 23, 26, 28, 29, 27, 26, 25, 24, 22, 23, 22, 25, 28, 29, 30, 27, 26, 25, 22, 24, 26, 27, 28, 29]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a line plot to visualize the temperature trends for both cities over the month. The x-axis should represent the date, and the y-axis should represent the temperature. I would like to have a legend indicating which line corresponds to which city.\n\nA:\n```python\nimport matplotlib.pyplot as plt\n\ndf.set_index('date', inplace=True)\nplt.figure(figsize=(10, 5))\n# Fill in the blank for plotting\nresult = ...\nplt.title('Daily Temperatures in City 1 and City 2')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.legend(['City 1', 'City 2'])\nplt.show()\n```",
    "output": "\n```python\nresult = df.plot()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing housing prices with features like size, number of bedrooms, and location. I want to build a predictive model using Scikit-learn, and I also want to visualize the predicted vs actual prices using Matplotlib. I've already preprocessed the data into a DataFrame named `housing_data`, and I have split it into training and test sets. \n\nThe training data consists of features in `X_train` and the target variable (prices) in `y_train`. The model I'm using is a linear regression model from Scikit-learn. \n\nHere\u2019s what I have so far:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Assume housing_data has been defined and contains the relevant features and target variable.\nX = housing_data[['size', 'bedrooms', 'location']]\ny = housing_data['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Now I want to predict the prices for the test set and plot them.\npredicted_prices = ...  # put solution in this variable\n```\n\nWhat should I assign to `predicted_prices` to make predictions on the `X_test` data?",
    "output": "\n```python\npredicted_prices = model.predict(X_test)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset into a Pandas DataFrame\ndf = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n                 header=None, names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n\n# Standardize the features\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df.iloc[:, :-1])\n\n# Perform PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_features)\n\n# Create a scatter plot of the PCA results\nplt.figure(figsize=(8, 6))\nplt.scatter(pca_result[:, 0], pca_result[:, 1], c=df['species'].astype('category').cat.codes)\nplt.title('PCA of Iris Dataset')\nplt.xlabel('PCA Component 1')\nplt.ylabel('PCA Component 2')\n\n# How can I get the variance explained by each principal component?\n# I need to assign this to the variable `explained_variance`\nexplained_variance = ... # put solution in this variable\n```",
    "output": "\n```python\nexplained_variance = pca.explained_variance_ratio_\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about houses, with columns for area, number of bedrooms, and price. You want to normalize the 'area' and 'price' columns to bring their values into a similar range. After normalization, you want to visualize the distributions of the original and normalized prices using Matplotlib.\n\nThe initial setup looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample DataFrame\ndata = {\n    'area': [1500, 2400, 3000, 1800, 2200],\n    'bedrooms': [3, 4, 5, 3, 4],\n    'price': [300000, 500000, 700000, 350000, 450000]\n}\ndf = pd.DataFrame(data)\n```\n\nYou are expected to fill in the code to normalize the 'area' and 'price' columns using Min-Max Scaling and then create a histogram of the original and the normalized prices in a single plot.\n\nFill in the following to get the desired output:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\ndf[['area', 'price']] = scaler.fit_transform(df[['area', 'price']])\n\nplt.hist(df['price'], alpha=0.5, label='Normalized Price', bins=5)\nplt.legend()\nplt.show()\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df['price'].copy()  # Store original prices for comparison\nplt.hist(result, alpha=0.5, label='Original Price', bins=5)\nplt.hist(df['price'], alpha=0.5, label='Normalized Price', bins=5)\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou are tasked with analyzing a dataset of student scores across different subjects for a school project. You have a pandas DataFrame that contains the following data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'Math': [88, 92, 95, 70, 65],\n    'Science': [90, 85, 78, 80, 87],\n    'English': [85, 87, 92, 75, 80],\n}\ndf = pd.DataFrame(data)\n```\n\nYour goal is to calculate the average score for each student across all subjects. Once you compute the average scores, you want to determine which students scored above the general average score for the class. \n\nTo achieve this, you need to fill in the blank for the following code block that calculates the average scores for each student and stores the result in a new column named 'Average':\n\n```python\ndf['Average'] = ...\n```\n\nFinally, create a pandas Series that contains only the names of the students who scored above the class average. The desired output after executing your code should look like this:\n\n```\n0     Alice\n1       Bob\n2   Charlie\n3       NaN\n4       NaN\nName: Student, dtype: object\n```",
    "output": "\n```python\ndf['Average'] = df[['Math', 'Science', 'English']].mean(axis=1)\nclass_average = df['Average'].mean()\nabove_average_students = df.loc[df['Average'] > class_average, 'Student']\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset that records the daily temperatures of a city over the course of a year. The dataset is structured as follows:\n\n```\ndate       | temperature\n-----------|-------------\n2023-01-01 | 5\n2023-01-02 | 6\n...        | ...\n2023-12-30 | 2\n2023-12-31 | 3\n```\n\nYou want to create a list of boolean values indicating whether the temperature was above the average temperature of the year for each respective day. Specifically, if the temperature on a given day is above the yearly average, that day should correspond to `True`, otherwise `False`. \n\nYou will be using NumPy and Pandas libraries for this task, so you import them accordingly. \n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\n# Sample dataFrame creation\ndata = {\n    'date': pd.date_range(start='2023-01-01', end='2023-12-31'),\n    'temperature': np.random.randint(-10, 40, size=365)\n}\ndf = pd.DataFrame(data)\n\n# Calculate the average temperature of the year\naverage_temp = df['temperature'].mean()\n\n# Create a new column with boolean values\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['temperature'] > average_temp\n</code>"
  },
  {
    "input": "Problem:\nYou are working on a time series dataset containing daily stock prices for multiple companies. You have the following DataFrame named `stock_data`:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2020-01-01', periods=10)\ncompanies = ['CompanyA', 'CompanyB', 'CompanyC']\nprices = np.random.rand(10, 3) * 100  # Random stock prices\nstock_data = pd.DataFrame(prices, index=dates, columns=companies)\n```\n\nYou want to calculate the daily returns for each company based on the price changes. The daily return can be calculated using the formula:\n\n\\[ \\text{Return}_t = \\frac{\\text{Price}_t - \\text{Price}_{t-1}}{\\text{Price}_{t-1}} \\]\n\nwhere \\( t \\) is the current day. However, the first row will have `NaN` values since there is no previous price to compare with.\n\nYou are required to compute the daily returns and store them in a new DataFrame called `daily_returns`, which should be structured like this:\n\n```\n            CompanyA  CompanyB  CompanyC\n2020-01-01       NaN       NaN       NaN\n2020-01-02       ...        ...        ...\n...\n```\n\nHow would you achieve that?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2020-01-01', periods=10)\ncompanies = ['CompanyA', 'CompanyB', 'CompanyC']\nprices = np.random.rand(10, 3) * 100  # Random stock prices\nstock_data = pd.DataFrame(prices, index=dates, columns=companies)\n\n# Compute daily returns\ndaily_returns = stock_data.pct_change()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2020-01-01', periods=10)\ncompanies = ['CompanyA', 'CompanyB', 'CompanyC']\nprices = np.random.rand(10, 3) * 100  # Random stock prices\nstock_data = pd.DataFrame(prices, index=dates, columns=companies)\n\n# Compute daily returns\ndaily_returns = stock_data.pct_change()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Given data\ndata = {\n    'Height': [6.0, 5.7, 5.8, 5.5, 6.1],\n    'Weight': [160, 150, 155, 140, 165],\n    'Age': [30, 25, 35, 28, 32]\n}\ndf = pd.DataFrame(data)\n\n# Normalize the Height and Weight using StandardScaler from scikit-learn\n# Fill in the blank to create an instance of StandardScaler and fit_transform on the Height and Weight columns\nscaler = StandardScaler()\ndf[['Height', 'Weight']] = scaler.fit_transform(df[['Height', 'Weight']])\n\n# Now, plot the normalized Height and Weight against Age in a scatter plot\n# Make sure to set the title to \"Normalized Height and Weight vs Age\" \n# and label the x-axis as \"Age\" and y-axis as \"Normalized Value\"\nplt.scatter(df['Age'], df['Height'], label='Height (Normalized)', color='blue')\nplt.scatter(df['Age'], df['Weight'], label='Weight (Normalized)', color='red')\nplt.title(\"Normalized Height and Weight vs Age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Normalized Value\")\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nscaler = StandardScaler()\ndf[['Height', 'Weight']] = scaler.fit_transform(df[['Height', 'Weight']])\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about houses, including their size in square feet, number of bedrooms, and the price. You want to build a simple linear regression model to predict the price based on size and number of bedrooms. You have loaded your dataset into a Pandas DataFrame named `df` which contains the columns `'size'`, `'bedrooms'`, and `'price'`. You want to fit a linear regression model using Scikit-learn and predict the price. How can you fill in the missing code to train the model and make predictions?\n\nA:\n```python\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# Sample data creation\ndata = {\n    'size': [1500, 1800, 2400, 3000, 3500],\n    'bedrooms': [3, 3, 4, 5, 4],\n    'price': [300000, 325000, 400000, 500000, 550000]\n}\ndf = pd.DataFrame(data)\n\n# Define input features and target variable\nX = df[['size', 'bedrooms']]\ny = df['price']\n\n# Create linear regression model\nmodel = LinearRegression()\n\n# Fit the model to the data\nmodel.fit(X, y)\n\n# Make predictions for the given sizes and bedrooms\npredictions = ...  # put solution in this variable\n```",
    "output": "\n```python\npredictions = model.predict(X)\n```"
  },
  {
    "input": "Problem:\nYou are working with time-series data of temperatures recorded over a week. You have a Pandas DataFrame with two columns: 'Date' and 'Temperature', where 'Temperature' can sometimes have missing values (NaNs). Your goal is to fill these missing values using linear interpolation and then visualize the resulting time series with Matplotlib.\n\nHere's a sample DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=7),\n    'Temperature': [20.5, np.nan, 21.0, np.nan, 22.5, 23.0, 23.5]\n}\ndf = pd.DataFrame(data)\n```\n\nAfter filling the missing values, how can you create a line plot of the 'Temperature' over 'Date' using Matplotlib?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=7),\n    'Temperature': [20.5, np.nan, 21.0, np.nan, 22.5, 23.0, 23.5]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Temperature'] = df['Temperature'].interpolate()\nplt.plot(df['Date'], df['Temperature'])\nplt.xlabel('Date')\nplt.ylabel('Temperature')\nplt.title('Temperature over Time')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing temperature data for different cities over a week. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\ndata = {\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Day_1': [30, 75, 28, 85, 90],\n    'Day_2': [32, 78, 30, 87, 95],\n    'Day_3': [31, 76, 29, 84, 92],\n    'Day_4': [29, 77, 31, 89, 91],\n    'Day_5': [33, 79, 30, 86, 93],\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to normalize the temperature values for each city across the week to a scale of 0 to 1, that is, the minimum temperature becomes 0 and the maximum becomes 1. Fill in the blank to achieve this normalization using pandas:\n\n```python\nnormalized_df = df.copy()\nnormalized_df.iloc[:, 1:] = (df.iloc[:, 1:] - df.iloc[:, 1:].min()) / (df.iloc[:, 1:].max() - df.iloc[:, 1:].min())\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>normalized_df</code>",
    "output": "\n<code>normalized_df</code>"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a Pandas DataFrame that includes features like square footage, number of bedrooms, and an indicator for whether the house has a swimming pool. I want to standardize these features using Scikit-learn's `StandardScaler` to prepare for training a machine learning model. \nHere is how my DataFrame looks:\n\n```\n   sqft  bedrooms  pool  price\n0  1400        3    1   300000\n1  1600        4    0   400000\n2  1800        4    1   500000\n3  1200        2    0   250000\n4  2000        5    1   600000\n```\n\nI also want to visualize the standardized features using Matplotlib. \nCan you help me with the code that applies `StandardScaler` to the features and then plots the results?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'sqft': [1400, 1600, 1800, 1200, 2000],\n    'bedrooms': [3, 4, 4, 2, 5],\n    'pool': [1, 0, 1, 0, 1],\n    'price': [300000, 400000, 500000, 250000, 600000]\n})\n\nscaler = StandardScaler()\n# put solution in this variable\nstandardized_features = ... \nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nstandardized_features = scaler.fit_transform(df[['sqft', 'bedrooms', 'pool']])\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 3, 1)\nplt.hist(standardized_features[:, 0], bins=10, alpha=0.7, color='blue')\nplt.title('Standardized Square Footage')\nplt.subplot(1, 3, 2)\nplt.hist(standardized_features[:, 1], bins=10, alpha=0.7, color='green')\nplt.title('Standardized Bedrooms')\nplt.subplot(1, 3, 3)\nplt.hist(standardized_features[:, 2], bins=10, alpha=0.7, color='red')\nplt.title('Standardized Pool Indicator')\nplt.tight_layout()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou are working on a binary classification problem where you want to evaluate how well a logistic regression model performs. You have a dataset containing features and the target variable indicating whether an individual has a specific disease.\n\nYour dataset looks like this:\n\n| Age | Cholesterol | Blood Pressure | Target |\n|-----|-------------|----------------|-------|\n| 25  | 200         | 120            | 0     |\n| 30  | 220         | 130            | 1     |\n| 22  | 180         | 110            | 0     |\n| 35  | 250         | 140            | 1     |\n| 28  | 230         | 135            | 1     |\n\nYou will use the following libraries: Pandas for data manipulation, NumPy for numerical operations, and Scikit-learn for creating and evaluating the model.\n\nAfter splitting the dataset into training and testing sets, you want to train a logistic regression model and compute the accuracy on the testing set. Given the code snippet below, fill in the blank to get the correct accuracy result.\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndata = {\n    'Age': [25, 30, 22, 35, 28],\n    'Cholesterol': [200, 220, 180, 250, 230],\n    'Blood Pressure': [120, 130, 110, 140, 135],\n    'Target': [0, 1, 0, 1, 1]\n}\n\ndf = pd.DataFrame(data)\nX = df[['Age', 'Cholesterol', 'Blood Pressure']]\ny = df['Target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\naccuracy = accuracy_score(y_test, model.predict(X_test))\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = accuracy\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing the sales data of a retail store, which includes columns for 'Product', 'Units Sold', and 'Sales Amount'. You want to normalize the 'Sales Amount' column values so that they have a mean of 0 and a standard deviation of 1 while handling any missing values appropriately.\n\nHere's a snippet of your DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Units Sold': [250, 150, np.nan, 400, 300],\n    'Sales Amount': [5000, 3000, 4000, np.nan, 6000]\n}\ndf = pd.DataFrame(data)\n```\n\nTo accomplish this normalization, you plan to use the `StandardScaler` from scikit-learn. However, you need to fill in the blank to apply the normalization to the 'Sales Amount' column.\n\nA:\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf['Sales Amount Normalized'] = ... # put solution in this variable\n```\nBEGIN SOLUTION\n```python\n",
    "output": "\n```python\ndf['Sales Amount Normalized'] = scaler.fit_transform(df[['Sales Amount']].fillna(df['Sales Amount'].mean()))\n```"
  },
  {
    "input": "Problem:\nI have a dataset stored in a Pandas DataFrame that contains user ratings for items. The DataFrame has columns: 'user_id', 'item_id', and 'rating'. I want to implement a simple collaborative filtering recommendation system using the Cosine similarity metric to suggest items to a specific user based on their ratings. I also want to visualize the top suggested items using a bar plot. For that I want to compute the Cosine similarity matrix after filtering the DataFrame for the specified user.\n\nHere's a sample DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 1, 2, 2, 3, 3, 3],\n    'item_id': [101, 102, 103, 101, 104, 102, 103, 104],\n    'rating': [4, 5, 3, 4, 2, 5, 4, 1]\n}\ndf = pd.DataFrame(data)\n```\nYou should create a function `get_recommendations(user_id)` that takes a user_id as input and computes the cosine similarity matrix, filtering for the given user, and returns the top N recommendations.\n\nUse this variable for your solution:\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef get_recommendations(user_id, N=3):\n    user_ratings = df.pivot_table(index='user_id', columns='item_id', values='rating').fillna(0)\n    cosine_sim = cosine_similarity(user_ratings)\n    sim_df = pd.DataFrame(cosine_sim, index=user_ratings.index, columns=user_ratings.index)\n    \n    similar_users = sim_df[user_id].sort_values(ascending=False).index[1:]\n    similar_users_ratings = user_ratings.loc[similar_users]\n    \n    recommended_items = similar_users_ratings.mean(axis=0).sort_values(ascending=False)\n    recommended_items = recommended_items[~recommended_items.index.isin(user_ratings.loc[user_id][user_ratings.loc[user_id] > 0].index)]\n    \n    top_recommendations = recommended_items.head(N)\n    \n    plt.bar(top_recommendations.index, top_recommendations.values)\n    plt.xlabel('Item ID')\n    plt.ylabel('Predicted Rating')\n    plt.title('Top Recommendations for User {}'.format(user_id))\n    plt.show()\n    \n    return top_recommendations.index.tolist()\n\nresult = get_recommendations(1)\n```"
  },
  {
    "input": "Problem:\nYou are analyzing sales data from an online store, and you have a dataset that contains the following features: order ID, customer ID, order date, and order total amount. The dataset is stored in a Pandas DataFrame with the columns: `order_id`, `customer_id`, `order_date`, and `order_amount`. Your task is to calculate the monthly sales totals and visualize them in a line plot using Matplotlib. The `order_date` is in 'YYYY-MM-DD' format.\n\nYour sales data looks like this:\n```\n   order_id customer_id  order_date order_amount\n0  1001         1      2023-01-15        250.00\n1  1002         2      2023-01-17        150.00\n2  1003         1      2023-01-20        200.00\n3  1004         3      2023-02-05        300.00\n4  1005         4      2023-02-10        400.00\n5  1006         2      2023-03-01        100.00\n```\n\nYou want to group the data by month, sum the order amounts for each month, and then plot the results. \n\nHere is your starting code:\n\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'order_id': [1001, 1002, 1003, 1004, 1005, 1006],\n    'customer_id': [1, 2, 1, 3, 4, 2],\n    'order_date': ['2023-01-15', '2023-01-17', '2023-01-20', '2023-02-05', '2023-02-10', '2023-03-01'],\n    'order_amount': [250.00, 150.00, 200.00, 300.00, 400.00, 100.00]\n}\n\ndf = pd.DataFrame(data)\n\n# Convert 'order_date' to datetime\ndf['order_date'] = pd.to_datetime(df['order_date'])\n\n# Group by month and sum order amounts\nmonthly_sales = df.groupby(df['order_date'].dt.to_period(\"M\"))['order_amount'].sum()\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nplt.plot(monthly_sales.index.astype(str), monthly_sales.values, marker='o')\nplt.title('Monthly Sales Totals')\nplt.xlabel('Month')\nplt.ylabel('Sales Amount')\nplt.xticks(rotation=45)\nplt.grid()\nplt.tight_layout()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = monthly_sales</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Create a sample dataframe with some random data\nnp.random.seed(0)\ndf = pd.DataFrame({\n    'feature1': np.random.rand(100) * 100,\n    'feature2': np.random.rand(100) * 50,\n    'target': np.random.rand(100) * 200\n})\n\n# Split the data into training and testing sets\nX = df[['feature1', 'feature2']]\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Now I want to calculate the predicted values on the test set and the performance metric, which is \n# Root Mean Squared Error (RMSE). The variable \"rmse\" needs to be filled with the calculated RMSE.\ny_pred = model.predict(X_test)\nrmse = ... # put solution in this variable\n```",
    "output": "\n```python\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n# Standardize the data\nstandardized_data = (df - df.mean()) / df.std()\n\n# Apply PCA and capture the principal components\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(standardized_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'], alpha=0.5)\n\n# I want to add labels to the scatter plot for the three different species in the dataset.\n# I know that the target is stored in the iris dataset as well but I want to create a legend for it in the plot.\n\n# Replace with the actual solution to extract the target labels\ntarget_labels = ...  # put solution in this variable\n```",
    "output": "\n```python\ntarget_labels = data.target\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load iris dataset\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a random forest classifier\nclf = RandomForestClassifier(n_estimators=100)\n\n# Fit the classifier to the training data\nclf.fit(X_train, y_train)\n\n# Calculate the accuracy on the test data\naccuracy = clf.score(X_test, y_test)\n\n# Plotting the feature importances\nfeature_importances = clf.feature_importances_\n# Create a bar plot of feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(X.columns, feature_importances)\nplt.title(\"Feature Importances\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Importance\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Specify a variable to hold the accuracy result\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = accuracy\n```"
  },
  {
    "input": "Problem:\nYou are working on a machine learning project where you need to preprocess a dataset. The dataset contains features with missing values represented as NaN. You want to fill these missing values with the mean of each column. After filling the missing values, you want to standardize the features (scale them to have a mean of 0 and a standard deviation of 1) using the StandardScaler from Scikit-learn. Finally, you'll need to visualize the distribution of one of the processed features using Matplotlib.\n\nHere's a typical workflow to achieve this:\n1. Load the dataset using Pandas.\n2. Replace the NaN values in the dataset with the mean of their respective columns.\n3. Standardize the features.\n\nWrite the code to perform these steps. You will define the necessary imports and create a function that takes a Pandas DataFrame as input and returns the standardized DataFrame. The last line of your code should plot the distribution of one of the standardized features.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\ndef preprocess_and_visualize(df):\n    df.fillna(df.mean(), inplace=True)\n    scaler = StandardScaler()\n    standardized_df = scaler.fit_transform(df)\n    standardized_df = pd.DataFrame(standardized_df, columns=df.columns)\n    \n    # Plot the distribution of a specified feature, for instance, the first feature\n    plt.hist(standardized_df.iloc[:, 0], bins=30)\n    plt.title('Distribution of Feature 1')\n    plt.xlabel('Standardized Value')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return standardized_df\n\n# You can load the DataFrame from your dataset here \n# df = pd.read_csv('your_dataset.csv')\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = preprocess_and_visualize(df)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset that contains information about various products sold in different stores, and I want to create a predictive model for sales. The features I have are price, advertising spend, and category, and I want to use Scikit-learn to train a model. I need to preprocess the data first. Specifically, I want to apply one-hot encoding to the category feature and then split the data into features (X) and target (y). The dataset is represented as a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'price': [10.99, 13.49, 9.99, 12.99, 14.99],\n    'ad_spend': [200, 300, 150, 400, 500],\n    'category': ['A', 'B', 'A', 'C', 'B'],\n    'sales': [100, 150, 80, 200, 250]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to extract the features and target variable as follows:\n- Features (X): This should include the 'price', 'ad_spend', and the one-hot encoded 'category'.\n- Target (y): The 'sales' column.\n\nHow can I achieve this by filling in the blank below?\n\nA:\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False)\nX_cat = encoder.fit_transform(df[['category']])\nX = ... # combine price, ad_spend, and X_cat here\ny = df['sales']\n```",
    "output": "\n```python\nX = pd.concat([df[['price', 'ad_spend']].reset_index(drop=True), pd.DataFrame(X_cat)], axis=1)\n```"
  },
  {
    "input": "Problem:\nI have a dataset with the following structure representing various features of car models:\n\n```python\nimport pandas as pd\n\ndata = {\n    'model': ['A', 'B', 'C', 'A', 'B', 'C', 'A'],\n    'year': [2018, 2019, 2020, 2020, 2021, 2021, 2019],\n    'price': [20000, 22000, 25000, 21000, 23000, 24000, 19000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to compute the average price of each model per year, and then visualize this average price in a bar chart using Matplotlib. How should I fill in the code to achieve the average price calculation and plotting?\n\n```python\naverage_price = df.groupby(['model', 'year']).mean().reset_index()  # This line is provided.\n```\n\nNow I am looking for the code to create the bar chart and show it:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Create a bar chart to visualize the average price\nplt.bar(x=..., height=...)  # Fill in the x and height parameters\nplt.xlabel('Model-Year')\nplt.ylabel('Average Price')\nplt.title('Average Price of Car Models per Year')\nplt.xticks(rotation=45)\nplt.show()\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\naverage_price['model_year'] = average_price['model'] + '-' + average_price['year'].astype(str)\nplt.bar(x=average_price['model_year'], height=average_price['price'])\n```"
  },
  {
    "input": "Problem:\nYou are working with a Pandas DataFrame that contains historical stock prices for multiple companies. You need to calculate the rolling mean of the closing prices for a specific number of days (let's say 5 days) for each company and visualize the results using Matplotlib. Here is how the DataFrame is structured:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2023-01-01', periods=10)\ndata = {\n    'Date': dates,\n    'Company_A_Close': np.random.randint(100, 200, size=10),\n    'Company_B_Close': np.random.randint(50, 150, size=10),\n}\n\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nYou want to fill in the blank code below to compute the rolling mean and assign it to a new DataFrame called `rolling_means`, which will then be plotted. \n\n```python\nrolling_means = df.____(window=5)\nplt.figure(figsize=(10, 5))\nplt.plot(rolling_means)\nplt.title('5-Day Rolling Mean of Closing Prices')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.legend(df.columns)\nplt.show()\n```\nComplete the code by filling in the blank with the correct method to compute the rolling mean. ",
    "output": "\n```python\nrolling_means = df.rolling(mean=5).mean()\n```"
  }
]