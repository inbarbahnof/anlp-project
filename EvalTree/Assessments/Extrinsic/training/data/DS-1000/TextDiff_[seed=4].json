[
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations.\n\nHere\u2019s a partial implementation:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\n```\n\nWhat function should I use to complete the `transform` to resize the images to 128x128 pixels before applying other augmentations?\n\nA:\n\n<code>\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.Resize((128, 128)).\n",
    "output": "\n<code>\ntransforms.Resize((128, 128)),\n</code>"
  },
  {
    "input": "Problem:\nI have the following DataFrame containing data about students and their scores:\n\n```\n   student_id   score Mathematics Science \n0           1  89.0       95.0     NaN    \n1           2   NaN       85.0     90.0   \n2           3  77.0       NaN       NaN   \n3           4  90.0       92.0     88.0   \n4           5   NaN       70.0     78.0   \n```\n\nI want to impute the missing values in the 'score' column using the mean of the corresponding subject scores (Mathematics and Science) for each student. If any subject score is available for a student, use the mean from the available scores to fill in the missing 'score'. The expected DataFrame after imputation should maintain the original structure and values with filled `NaN` entries.\n\nWhat is the code to achieve this using `pandas`?\n\n```python\nimport pandas as pd\n\ndata = {\n    'student_id': [1, 2, 3, 4, 5],\n    'score': [89.0, None, 77.0, 90.0, None],\n    'Mathematics': [95.0, 85.0, None, 92.0, 70.0],\n    'Science': [None, 90.0, None, 88.0, 78.0]\n}\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['score'] = df[['Mathematics', 'Science']].mean(axis=1).where(df['score'].isna(), df['score'])\nresult = df\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that calculates the Mean Squared Error (MSE) but only for a specific subset of targets. For example, given an array of predictions and an array of true values, I only want to compute the MSE for the indices specified in a list. \n\nHere\u2019s how the data looks:\n```python\npredictions = tf.constant([0.5, 0.7, 0.9, 0.2, 0.1])\ntrue_values = tf.constant([1.0, 0.0, 1.0, 0.0, 0.0])\nindices = [0, 2, 3]\n```\n\nI need to fill in the blank for the custom loss function that computes the MSE only for the specified indices. \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_loss(predictions, true_values, indices):\n    selected_preds = tf.gather(predictions, indices)\n    selected_true = tf.gather(true_values, indices)\n    return tf.reduce_mean(tf.square(selected_preds - selected_true))\n\npredictions = tf.constant([0.5, 0.7, 0.9, 0.2, 0.1])\ntrue_values = tf.constant([1.0, 0.0, 1.0, 0.0, 0.0])\nindices = [0, 2, 3]\nloss_value = ... # put solution in this variable\nBEGIN SOLUTION\n<code>loss_value = custom_mse_loss(predictions, true_values, indices)</code>",
    "output": "\n<code>loss_value = custom_mse_loss(predictions, true_values, indices)</code>"
  },
  {
    "input": "### Problem:\nI have two DataFrames that represent sales data for products in two different regions. The DataFrames are structured as follows:\n\n**df_sales**\n```\n   product_id  region_a_sales\n0           1             100\n1           2             150\n2           3              80\n3           4             200\n```\n\n**df_product_info**\n```\n   product_id   product_name    region_b_sales\n0           1     Product A              120\n1           2     Product B              180\n2           3     Product C               NaN\n3           4     Product D              210\n4           5     Product E               90\n```\n\nI need to merge these two DataFrames on the `product_id` column, while preserving all products from `df_product_info` even if they do not have corresponding sales data in `df_sales`. After merging, I want to create a new column `total_sales` that sums the sales from both regions. If any sales data is missing (NaN), it should be treated as zero in the summation. The expected structure should look like this:\n\n```\n   product_id   product_name  region_a_sales  region_b_sales  total_sales\n0           1     Product A              100            120           220\n1           2     Product B              150            180           330\n2           3     Product C               80              NaN           80    \n3           4     Product D              200            210           410\n4           5     Product E              NaN              90            90   \n```\n\nHere's the code I have so far for the merge:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({'product_id': [1, 2, 3, 4],\n                         'region_a_sales': [100, 150, 80, 200]})\n\ndf_product_info = pd.DataFrame({'product_id': [1, 2, 3, 4, 5],\n                                 'product_name': ['Product A', 'Product B', 'Product C', 'Product D', 'Product E'],\n                                 'region_b_sales': [120, 180, None, 210, 90]})\n```\n\nWhat should I add to obtain the final DataFrame mentioned above? Fill in the following line to achieve your goal:\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df_product_info, df_sales, on='product_id', how='left').fillna(0)\nresult['total_sales'] = result['region_a_sales'] + result['region_b_sales']\n```"
  },
  {
    "input": "Problem:\n\nSuppose you have two pandas DataFrames: `employees` and `departments`. The `employees` DataFrame contains employee information, and the `departments` DataFrame contains department details. Your goal is to perform a merge operation where you include employee details alongside their respective department information, ensuring to include all employees even those who might not belong to any department.\n\nHere are the DataFrames:\n\n```python\nimport pandas as pd\n\nemployees = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4],\n    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'DepartmentID': [100, 101, None, 100]\n})\n\ndepartments = pd.DataFrame({\n    'DepartmentID': [100, 101, 102],\n    'DepartmentName': ['HR', 'Finance', 'IT']\n})\n```\n\nYou want to merge these two DataFrames such that the resulting DataFrame contains the following columns: `EmployeeID`, `Name`, `DepartmentID`, and `DepartmentName`. If an employee belongs to a department, the department's name should appear; if not, it should show as `NaN`.\n\nHow should you fill in the blank to achieve this via a left merge?\n\n```python\nresult = pd.merge(____, _____, how='left', on='DepartmentID')\n```\n",
    "output": "\n```python\nresult = pd.merge(employees, departments, how='left', on='DepartmentID')\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to implement a custom loss function that computes the mean squared error (MSE) between predicted and true values, but with a twist: I want to give more weight to the errors of a specific class (e.g., class index 2) during the calculation. \nThe predictions and true values are both represented as 2D tensors. Given a list of true labels (e.g., [0, 2, 1, 2, 0]) and a constant weight (e.g., 2.0) for the specific class, how can I achieve this?\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = [0, 2, 1, 2, 0]\npredictions = tf.constant([[0.1, 0.5, 0.4], [0.2, 0.1, 0.7], [0.3, 0.3, 0.4], [0.4, 0.2, 0.4], [0.1, 0.6, 0.3]])\nweight_class_index = 2\nclass_weight = 2.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(true_labels, predictions)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    weights = tf.where(tf.equal(tf.argmax(y_true, axis=1), weight_class_index), class_weight, 1.0)\n    weighted_mse = mse * weights\n    return tf.reduce_mean(weighted_mse)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to build a custom mean squared error loss function based on the predictions and true labels of a regression problem, where I want to penalize predictions that are above a certain threshold more heavily. For instance, if the threshold is set to 0.5, predictions above this should have their squared differences multiplied by 2. I have arrays of predictions and true values as follows:\npredictions = [0.1, 0.6, 0.4, 0.9]\ntrue_values = [0.0, 1.0, 0.5, 1.0]\nHow can I implement this custom loss function, such that it returns the computed loss? \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(predictions, true_values, threshold=0.5):\n    # return the loss calculation in this function\n    ### BEGIN SOLUTION\n```",
    "output": "\n<code>\n    squared_differences = tf.square(predictions - true_values)\n    penalty = tf.where(predictions > threshold, 2.0 * squared_differences, squared_differences)\n    return tf.reduce_mean(penalty)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to construct a custom loss function that calculates the Mean Squared Error (MSE) between the predicted and actual values for a regression task. However, I want to introduce a scaling factor based on the mean value of the actual labels. This scaling factor should amplify the loss if the mean of the actual labels is greater than a predefined threshold (e.g., 0.5). How can I implement this in a function that takes the actual and predicted values as input?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss_function(y_true, y_pred):\n    threshold = 0.5\n    mean_actual = tf.reduce_mean(y_true)\n    scaling_factor = 1.0 if mean_actual <= threshold else 2.0\n    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n    return scaling_factor * mse\n### BEGIN SOLUTION",
    "output": "\n<code>\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have two dataframes representing sales data and inventory data:\n\nsales_df:                          inventory_df:\n+---------+-------+---------+    +---------+---------+\n| SKU     | Date  | Quantity|    | SKU     | Stock   |\n+---------+-------+---------+    +---------+---------+\n| 1001    | 2023-01-01 | 5   |    | 1001    | 10      |\n| 1002    | 2023-01-01 | 3   |    | 1002    | 0       |\n| 1001    | 2023-01-02 | 2   |    | 1003    | 25      |\n| 1003    | 2023-01-02 | 1   |    | 1001    | 20      |\n+---------+-------+---------+    +---------+---------+\n\nYou want to create a new dataframe that combines sales and inventory data, showing the total quantity sold for each SKU along with its current stock level. The resulting dataframe should look like this:\n\nresult_df:\n+---------+-----------------+---------+\n| SKU     | Total_Sold      | Stock   |\n+---------+-----------------+---------+\n| 1001    | 7               | 20      |\n| 1002    | 3               | 0       |\n| 1003    | 1               | 25      |\n+---------+-----------------+---------+\n\nPlease provide the code that achieves this merge and aggregation, filling in the blank below.\n\nA:\n<code>\nimport pandas as pd\n\nsales_df = pd.DataFrame({'SKU': [1001, 1002, 1001, 1003],\n                          'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n                          'Quantity': [5, 3, 2, 1]})\ninventory_df = pd.DataFrame({'SKU': [1001, 1002, 1003],\n                              'Stock': [10, 0, 25]})\nresult_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nresult_df = sales_df.groupby('SKU', as_index=False).agg(Total_Sold=('Quantity', 'sum')).merge(inventory_df, on='SKU', how='left')\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a sequence of time-series data for multiple features, and I want to compute the moving average using PyTorch. The tensor `data` has a shape of `(batch_size, num_features, sequence_length)`, and I want to apply a window size of `k` for the moving average calculation. \n\nHowever, the challenge is to create a new tensor that represents the moving average for each feature across the sequence, which will result in a tensor of shape `(batch_size, num_features, sequence_length - k + 1)`.\n\nGiven the following tensor:\n\n```\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\n```\n\nAnd a moving average window size of `k = 2`, how can I calculate the moving averages efficiently with PyTorch?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nk = 2\nmoving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\nk = 2\nmoving_avg = data.unfold(2, k, 1).mean(dim=3)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe resembling the following:\n\n```python\ndata = {\n    'product_id': [1, 1, 2, 2, 3],\n    'sales': [100, 150, None, 200, None],\n    'month': ['2020-01', '2020-02', '2020-01', '2020-02', '2020-01']\n}\ndf = pd.DataFrame(data)\n```\n\nI need to fill the missing sales values in the `sales` column using the sales values from the same product in other months while ensuring that any existing sales values remain unchanged. For products with no previous sales data in the dataframe, insert a default value of 0. The resulting dataframe should maintain the month-wise sales continuity.\n\nThe expected result should look like this:\n\n```python\n   product_id  sales     month\n0           1  100.0  2020-01\n1           1  150.0  2020-02\n2           2    0.0  2020-01\n3           2  200.0  2020-02\n4           3    0.0  2020-01\n```\n\nHow can I achieve this using pandas? \n\nUse the following starter code:\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 2, 2, 3],\n    'sales': [100, 150, None, 200, None],\n    'month': ['2020-01', '2020-02', '2020-01', '2020-02', '2020-01']\n}\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df.groupby('product_id')['sales'].transform(lambda x: x.fillna(method='ffill').fillna(0))\ndf['sales'] = df['sales'].fillna(result)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to create a custom loss function that penalizes predictions based on a dynamic threshold. Specifically, I need to implement a loss function that computes the mean squared error (MSE) but only for predictions greater than a given threshold (e.g., 0.5). Inputs are two tensors: `y_true` (true labels) and `y_pred` (predicted values). If a predicted value is less than or equal to the threshold, it should not contribute to the loss. \n\nYou should define the function `custom_loss` and ensure it returns the dynamic MSE based on the defined threshold.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred, threshold=0.5):\n    # Compute the solution in this function\n    # result = custom_loss(y_true, y_pred, threshold)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mask = tf.greater(y_pred, threshold)\n    mse = tf.square(y_true - y_pred)\n    masked_mse = tf.where(mask, mse, tf.zeros_like(mse))\n    return tf.reduce_mean(masked_mse)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W) where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is where I need help.\n```\n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\nresult = images\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor containing the pixel values of an image in the shape of (3, 256, 256), representing RGB channels. I want to normalize each channel independently so that the pixel values fall within the range of [0, 1]. Given the tensor `img_tensor`, how can I accomplish this in one line of code?\n\nA:\n\n<code>\nimport torch\nimg_tensor = load_data()\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = (img_tensor - img_tensor.min(dim=(1, 2), keepdim=True).values) / (img_tensor.max(dim=(1, 2), keepdim=True).values - img_tensor.min(dim=(1, 2), keepdim=True).values)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a 1D tensor representing a batch of scores from a model, and you want to achieve a specific transformation. The transformation involves expanding this 1D tensor into a 2D tensor where each score is repeated to form a row corresponding to the scores. The goal is to create a 2D tensor where each score has its own column and the rows are filled with the index values of the scores.\n\nFor example, if your 1D tensor is:\n```\nscores = torch.tensor([0.5, 0.1, 0.4])\n```\nThe desired output should be:\n```\ntensor([[0, 1, 2],\n        [0.5, 0.1, 0.4]])\n```\n\nComplete the following code to achieve this transformation:\n\n<code>\nimport torch\nscores = load_data()\n</code>\ntransformed_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nscores = load_data()\ntransformed_tensor = torch.tensor([torch.arange(len(scores)), scores])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like this:\n\n```python\nimport pandas as pd\n\nx = pd.DataFrame({\n    'product': ['A', 'A', 'B', 'B', 'C'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-02', '2023-01-05', '2023-01-01'],\n    'sales': [100, 150, None, None, 300]\n})\n```\n\nI want to ensure that the 'date' column contains all dates from the minimum to the maximum for each product, and fill missing sales with the average sales for that product. The expected output should maintain the order defined by 'date' with each product having its sales uniformly averaged during the missing periods.\n\nThe resulting DataFrame should look like this:\n\n```\n    date product  sales\n0 2023-01-01      A  100.0\n1 2023-01-02      A  100.0\n2 2023-01-03      A  150.0\n3 2023-01-04      A  100.0\n4 2023-01-05      A  100.0\n5 2023-01-01      B    0.0\n6 2023-01-02      B    0.0\n7 2023-01-03      B    0.0\n8 2023-01-04      B    0.0\n9 2023-01-05      B  150.0\n10 2023-01-01     C  300.0\n11 2023-01-02     C  300.0\n```\n\nI have tried using forward fill but it doesn't give the desired results. What code can I use to achieve this?\n\n```python\nx['date'] = pd.to_datetime(x['date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (x.set_index('date')\n          .groupby('product')\n          .resample('D')\n          .mean()\n          .fillna(0)\n          .reset_index()\n          .sort_values(by=['product', 'date']))\n```"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing daily sales data for a retail store. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [np.nan, 200, np.nan, 300, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to fill in the missing sales data using forward fill for the non-leading NaN values and use a rolling average of the previous three days to fill the leading NaN values. After performing imputation, the DataFrame should look like this:\n\n```plaintext\n        date  sales\n0  2023-01-01   200\n1  2023-01-02   200\n2  2023-01-03   200\n3  2023-01-04   300\n4  2023-01-05   300\n```\n\nWhat one line of code can you use to achieve this filling strategy efficiently on the `sales` column of the DataFrame? \n\n```python\ndf['sales'] = ...\n```",
    "output": "\n```python\ndf['sales'] = df['sales'].fillna(method='ffill').combine_first(df['sales'].rolling(window=3, min_periods=1).mean())\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to apply this function to each image in the dataset based on the provided probability.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flip the image vertically (along height)\n```\n\nYou need to fill in the following code to apply the augmentation:\n\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>\n```\n\nresult = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>flip_image(images[i])</code>",
    "output": "\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>flip_image(images[i])</code>\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I am working on a regression problem and need to implement a custom loss function that calculates the Mean Absolute Percentage Error (MAPE) between predicted and actual values. Given two tensors, `y_true` for actual values and `y_pred` for predicted values, I want to create a function that computes this loss. The function should return the calculated MAPE value.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef mape_loss(y_true, y_pred):\n    # return the MAPE loss\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    diff = tf.abs((y_true - y_pred) / y_true)\n    return tf.reduce_mean(diff) * 100\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing monthly sales data for various products, but some months are missing sales records. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['A', 'A', 'A', 'B', 'B', 'C', 'C'],\n    'month': ['2023-01', '2023-03', '2023-04', '2023-01', '2023-02', '2023-01', '2023-03'],\n    'sales': [100, None, 150, 200, None, None, 300]\n})\n```\n\nI want to fill in the missing sales values for each product by using the values from the previous month, making sure to forward-fill the values. Additionally, if a month has no sales data at all, it should be filled with 0. The expected output should retain all product-month combinations while filling in the missing values appropriately.\n\nPlease fill in the blank with the relevant code to achieve this.\n\nresult = ... # put solution in this variable",
    "output": "\n```python\n<code>\ndf['month'] = pd.to_datetime(df['month'])\ndf = df.set_index(['product', 'month']).unstack(fill_value=0)\ndf = df.fillna(method='ffill').stack().reset_index()\ndf.columns = ['product', 'month', 'sales']\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ________________  # I need to fill in this blank with the proper color jitter transformation\n])\n```\n\nWhat should I put in the blank to apply random brightness, contrast, saturation, and hue adjustments?",
    "output": "\n```python\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to create a custom loss function that implements the Mean Absolute Error (MAE) metric for a regression problem, where the actual values are compared against predictions. However, I want to introduce a weighting factor that emphasizes errors in the positive predictions more heavily. The targets are in a 1-D tensor format (e.g., [3.0, 1.5, 4.0]) and the predictions are also in a similar tensor format (e.g., [2.5, 1.0, 5.0]). The weight for positive predictions is set to 2.0.\n\nI would like to define a function that returns this custom loss. \n\nA:\n<code>\nimport tensorflow as tf\n\nactual = tf.constant([3.0, 1.5, 4.0])\npredictions = tf.constant([2.5, 1.0, 5.0])\nweight = 2.0\n\ndef custom_mae_loss(y_true, y_pred, weight):\n    # return the solution in this function\n    # result = custom_mae_loss(y_true, y_pred, weight)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    absolute_errors = tf.abs(y_true - y_pred)\n    weighted_errors = tf.where(y_pred > 0, absolute_errors * weight, absolute_errors)\n    return tf.reduce_mean(weighted_errors)\n### END SOLUTION\n</code>"
  },
  {
    "input": "### Problem:\nYou have a dataset detailing sales transactions over several months. The dataset looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\n```\n\nIn the `Sale_Date`, some transactions have missing dates denoted by '0'. Your task is to replace the '0' values in the `Sale_Date` with the average date from the existing sales dates for each product, replacing the '0' values with the average date of their respective `Product_ID`. The average date should be in the format 'YYYY-MM-DD'.\n\nHow would you achieve this in pandas? \n\nPlease fill in the code below to perform the imputation:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\nsales_data['Sale_Date'] = pd.to_datetime(sales_data['Sale_Date'].replace('0', pd.NaT)) \n# Your solution to fill in the blanks\nresult = ... # put your solution in this variable\n```\n",
    "output": "\n```python\nresult = sales_data.groupby('Product_ID')['Sale_Date'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like the following:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'employee': ['john', 'john', 'mary', 'mary'], 'date': ['2023-04-01', '2023-04-03', '2023-04-02', '2023-04-04'], 'sales': [200, 300, 400, None]})\n```\n\nWhat I would like to achieve is to compute the daily sales report by creating a complete date range from the minimum to the maximum date for each employee. During this expansion, I want to fill in missing sales values with the average sales for that employee. The desired output should look like this:\n\n```\n        date employee  sales\n0 2023-04-01     john  200.0\n1 2023-04-02     john  200.0\n2 2023-04-03     john  300.0\n3 2023-04-04     john  200.0\n4 2023-04-01     mary  400.0\n5 2023-04-02     mary  400.0\n6 2023-04-03     mary  400.0\n7 2023-04-04     mary  400.0\n```\n\nI've tried using `pd.date_range()` and `groupby()`, but I can't figure out how to combine this effectively. Any suggestions would be appreciated.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('employee').apply(lambda x: x.set_index('date').reindex(pd.date_range(x['date'].min(), x['date'].max())).fillna(x['sales'].mean())).reset_index().rename(columns={'level_1': 'date'})\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\naugmented_images = images.clone()\n```\n\nI can't seem to figure out how to apply the flip operation to `augmented_images` based on the `flip_condition`. How can I fill in the blank in the following line to perform the horizontal flip?\n\n```python\naugmented_images[flip_condition] = ______\n```\n\nA:\n\n<code>\ntorch.flip(images[flip_condition], dims=[3])\n</code>",
    "output": "\n<code>\ntorch.flip(images[flip_condition], dims=[3])\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\n<rotation_transformation_here>\n</code>\nresult = ...  # put solution in this variable",
    "output": "\n<code>\ntransforms.RandomRotation(degrees=30)\n</code>"
  },
  {
    "input": "Problem:\nI have a sales dataframe that contains missing values for the 'quantity' column, and I would like to impute these missing values based on the mean quantity of each product type in the 'product_type' column. Here is what my dataframe looks like:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 102, 103, 104, 105],\n    'product_type': ['A', 'A', 'B', 'A', 'B', 'B', 'A', 'B'],\n    'quantity': [10, None, 15, 5, None, None, 7, 3]\n})\n```\n\nAfter applying the imputation based on the mean quantity of each product type, the resulting dataframe should have the missing values filled appropriately.\n\nHere\u2019s what the data looks like after processing to fill in the missing quantities:\n\n```python\n   product_id product_type  quantity\n0         101            A      10.0\n1         102            A      7.5\n2         103            B      15.0\n3         101            A      5.0\n4         102            B      11.0\n5         103            B      15.0\n6         104            A      7.0\n7         105            B      3.0\n```\n\nCould you provide the code to accomplish this task? Please fill in the necessary part of the code below:\n\n```python\n# Fill in the missing quantity values based on the mean quantity of each product type\nsales_data['quantity'] = sales_data.groupby('product_type')['quantity'].transform(lambda x: x.fillna(x.mean()))\nresult = sales_data\n```",
    "output": "\n```python\nsales_data['quantity'] = sales_data.groupby('product_type')['quantity'].transform(lambda x: x.fillna(x.mean()))\nresult = sales_data\n```"
  },
  {
    "input": "Problem:\n\nI have a 3D tensor representing different channels of data as follows:\n\ntensor([[[0.1, 0.2], \n          [0.3, 0.4]], \n        \n         [[0.5, 0.6], \n          [0.7, 0.8]], \n        \n         [[0.9, 1.0], \n          [1.1, 1.2]]])\n        \nI want to apply a mask tensor to zero out the values in the original tensor based on a 2D mask that selects specific elements. The mask tensor is a 2D tensor:\n\ntensor([[1, 0], \n        [0, 1], \n        [1, 0]])\n\nHow do I create a new tensor that retains values from the original tensor where the mask is 1 and zeros out where the mask is 0?\n\nA:\n\n<code>\nimport torch\noriginal_tensor, mask = load_data()\n</code>\nmasked_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmasked_tensor = original_tensor * mask.unsqueeze(1)\n</code>"
  },
  {
    "input": "### Problem\nI have the following DataFrame representing daily temperature data for different cities, but some entries are missing:\n\n```python\ndata = {\n    'city': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'temperature': [30, 70, None, None, 65, 60]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to fill in the missing temperature values by using forward fill within each city group. Additionally, any missing values that are still present after forward filling should be imputed with the average temperature of each city.\n\nWhat I need is to obtain the following final DataFrame:\n\n```\n         city        date  temperature\n0   New York  2023-01-01         30.0\n1  Los Angeles  2023-01-01         70.0\n2   New York  2023-01-02         30.0\n3     Chicago  2023-01-01         65.0\n4  Los Angeles  2023-01-02         65.0\n5     Chicago  2023-01-02         60.0\n```\n\nSo far, I have tried the following code but it's not working as expected:\n\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill().fillna(df.groupby('city')['temperature'].mean())\n```\n\nHow should I adjust my code to achieve the desired DataFrame? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-02'],\n    'temperature': [30, 70, None, None, 65, 60]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n",
    "output": "\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill()\ndf['temperature'] = df.groupby('city')['temperature'].fillna(df.groupby('city')['temperature'].transform('mean'))\nresult = df\n```"
  },
  {
    "input": "## Problem\nI'm using tensorflow 2.10.0. \nI want to create a custom loss function for a regression problem where I'm interested in penalizing predictions that deviate significantly from the actual values. Specifically, I want to implement a loss that squares the difference between the actual value and the predicted value only if the absolute difference exceeds a certain threshold (e.g., 1.0). If the absolute difference is less than or equal to the threshold, the loss should be zero. \n\nI have two tensors: `y_true` for the true values and `y_pred` for the predicted values. How can I construct the tensor for the custom loss as described?\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([1.0, 2.0, 3.0, 4.0])\ny_pred = tf.constant([1.5, 3.5, 2.5, 4.5])\ndef custom_loss(y_true, y_pred):\n    threshold = 1.0\n    # Calculate the custom loss here\n    loss = ... # fill in the blank\n    return loss\n</code>",
    "output": "\n<code>\n    loss = tf.where(tf.abs(y_true - y_pred) > threshold, \n                    tf.square(y_true - y_pred), \n                    tf.zeros_like(y_true))\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains temperature readings with missing values over time. The DataFrame is structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'timestamp': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', \n                  '2023-01-01 03:00', '2023-01-01 04:00', '2023-01-01 05:00'],\n    'temperature': [22.5, NaN, 23.0, NaN, 22.8, 22.9]\n})\n```\n\nYou need to fill in the missing temperature values by using forward fill for the previous readings and then backward fill for any remaining missing values. The desired final output should retain the original DataFrame structure but with all temperature values filled in. \n\nWhat is the single line of Python code that accomplishes this data imputation using pandas? \n\nPlease fill this response with your solution.\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.fillna(method='ffill').fillna(method='bfill')\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes representing sales data for different regions over some time. The first dataframe (`df_sales`) contains monthly sales figures for various products in different regions. The second dataframe (`df_products`) has information about the product category for each product. \n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'region': ['North', 'South', 'East', 'West'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02'],\n    'sales': [200, 150, 300, 250]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'category': ['A', 'B', 'A', 'B']\n})\n```\n\nYou need to merge these two dataframes such that you get a single dataframe showing product sales alongside their respective categories. Ensure that all sales records are retained even if there is no corresponding product category. The resulting dataframe should be sorted by region and month, as well as by product_id in ascending order.\n\nThe expected merged dataframe should look something like this:\n\n```\n   product_id region     month  sales category\n0         101  North  2023-01    200        A\n1         102  South  2023-01    150        B\n2         103   East  2023-02    300        A\n3         104   West  2023-02    250        B\n```\n\nYour task is to write the code that merges these dataframes appropriately using pandas. \n\nFill in the blank for the merging operation below:\n```python\nresult = df_sales.____(df_products, on='product_id', how='left')\n```",
    "output": "\n```python\nresult = df_sales.merge(df_products, on='product_id', how='left').sort_values(by=['region', 'month', 'product_id'])\n```"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor `data` with the shape of (2, 5, 4) representing batches of features, where each batch contains 5 samples with 4 feature values each. Your goal is to perform a dynamic manipulation to calculate the mean across the first dimension (batch dimension) for each feature across all samples.\n\nThe resulting tensor should have a shape of (5, 4), containing the mean feature values for each of the 5 samples.\n\nHere is the setup you have:\n\n```python\nimport torch\ndata = load_data()  # should be a tensor of shape (2, 5, 4)\n```\n\nHow can you compute the means across the batches to achieve the desired shape in a single line of code?\n\nA:\n\n```python\nmeans = ...  # put solution in this variable\n```",
    "output": "\n```python\nmeans = data.mean(dim=0)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[2])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()  # Use clone to avoid modifying the original tensor\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels, 32x32 pixels\n```\n\nNow, I want to apply the `flip_image` function to each image in the `images` tensor based on the flip probability. I tried using a for loop, but it seems inefficient for larger datasets. \n\nHow can I vectorize this operation using PyTorch?\n\nA:\n\n<code>\nimport torch\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n    \nimages = torch.randn(10, 3, 32, 32)\nflip_probability = 0.5\nflipped_images = ...  # put solution in this variable\n</code>",
    "output": "\n<code>\nflipped_images = images * (torch.rand(images.size(0), 1, 1, 1) < flip_probability).float() + flip_image(images) * (torch.rand(images.size(0), 1, 1, 1) >= flip_probability).float()\n</code>"
  },
  {
    "input": "Problem:\nYou have two Pandas DataFrames that contain sales data from different regions. The first DataFrame `df_sales` contains sales made, identified by a unique `SalesID` and the amount for each sale:\n\n```python\ndf_sales = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Amount': [250, 150, 300, 400]\n})\n```\n\nThe second DataFrame `df_region` contains additional information for each sale, such as the `SalesID` and the region where the sale was made:\n\n```python\ndf_region = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Region': ['North', 'South', 'East', 'West'],\n    'Discount': [0.1, 0.2, 0.15, 0.05]\n})\n```\n\nYou want to merge these two DataFrames into one such that it contains the `SalesID`, `Amount`, and `Region`, but only include the `Discount` for sales made in the 'South' region. The resulting DataFrame should look like this (where 'South' has the discount value and others do not):\n\n```\n   SalesID  Amount Region  Discount\n0      101     250  North       NaN\n1      102     150  South       0.2\n2      103     300   East       NaN\n3      104     400   West       NaN\n```\n\nYou are unsure how to achieve this merge with conditional inclusion of the column. Fill in the solution:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Amount': [250, 150, 300, 400]\n})\n\ndf_region = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Region': ['North', 'South', 'East', 'West'],\n    'Discount': [0.1, 0.2, 0.15, 0.05]\n})\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_region[['SalesID', 'Region', 'Discount']], on='SalesID', how='left')\nresult['Discount'] = result.apply(lambda x: x['Discount'] if x['Region'] == 'South' else None, axis=1)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data for a store represented as follows:\n\n```python\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\n\nThe DataFrame has missing values for the `Date` and `Sales` columns. I want to fill in the missing `Sales` values for the same `ProductID` by using the mean sales value of products with the same `ProductID`, while keeping the original `Date` as is. For the missing `Date`, I would like to fill it with the string \"Unknown Date\".\n\nHere is my current DataFrame before processing:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02    NaN\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04    NaN\n6          5        NaN    NaN\n```\n\nWhat I want to achieve is to apply the necessary imputation method to get the following resulting DataFrame:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02  200.0\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04  300.0\n6          5  Unknown Date    NaN\n```\n\nI would like the code that fills in the missing values in `Sales` with the mean sales for the respective `ProductID` and replaces the missing `Date` with \"Unknown Date\".\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n",
    "output": "\n```python\ndf['Date'].fillna('Unknown Date', inplace=True)\nmean_sales = df.groupby('ProductID')['Sales'].transform('mean')\ndf['Sales'].fillna(mean_sales, inplace=True)\nresult = df\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am implementing a custom loss function for a binary classification problem. I would like to create a modified version of the Mean Squared Error (MSE) that punishes false negatives more heavily than false positives. \nThe loss function should take in the predicted values (a tensor of shape [batch_size, 1]) and the true values (a tensor of shape [batch_size, 1]), using a weight of 2.0 for false negatives. \n\nHow can I implement this custom loss function using TensorFlow?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the loss here\n    ### BEGIN SOLUTION\n```",
    "output": "\n<code>\n    false_negatives = tf.reduce_sum(tf.square(y_true - y_pred) * (1 - y_pred) * 2.0)\n    false_positives = tf.reduce_sum(tf.square(y_true - y_pred) * y_pred)\n    return false_negatives + false_positives\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame representing temperature records for multiple cities over several days. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'city': ['New York', 'New York', 'Los Angeles', 'Los Angeles', 'Chicago', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'temperature': [30, np.nan, 75, np.nan, 20, 25]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to replace the missing temperature values for each city with the mean temperature of that city across the available records. I want this done in a way that minimizes the use of loops for efficiency, especially since the DataFrame may become large. The expected output for the DataFrame, after performing the operation, should be:\n\n```\n          city        date  temperature\n0     New York  2023-01-01          30.0\n1     New York  2023-01-02          30.0\n2  Los Angeles  2023-01-01          75.0\n3  Los Angeles  2023-01-02          75.0\n4      Chicago  2023-01-01          20.0\n5      Chicago  2023-01-02          25.0\n```\n\nPlease provide the line of code to achieve this data imputation. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('city')['temperature'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI need to create a custom loss function to handle a regression problem where I want to minimize the mean squared error only for predictions that exceed a certain threshold, while ignoring those below it. I have a threshold value of 0.5. How can I implement this custom loss function using TensorFlow so that it computes the loss only for those predicted values greater than the threshold?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Implement the custom loss function here\n    pass\n</code>\nloss = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n    mask = tf.cast(y_pred > 0.5, tf.float32)\n    squared_difference = tf.square(y_true - y_pred)\n    loss = tf.reduce_sum(mask * squared_difference) / tf.reduce_sum(mask + tf.keras.backend.epsilon())\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains sales data like this:\n\ndf:\n   id     product   sales   date\n0  1     A         100     2021-01-01\n1  2     B         NaN     2021-01-02\n2  3     C         250     2021-01-03\n3  4     B         NaN     2021-01-04\n4  5     A         NaN     2021-01-05\n5  6     C         300     2021-01-06\n\nWhat you need to do is:\n1. Use forward fill to fill NaN values in the `sales` column based on the same `product` identifier.\n2. After filling in the missing sales data, you need to convert the `date` column to the following format: \"DD-MMM-YYYY\".\n\nThe expected DataFrame after processing should look like this:\n\n   id     product   sales   date\n0  1     A         100     01-Jan-2021\n1  2     B         NaN     02-Jan-2021\n2  3     C         250     03-Jan-2021\n3  4     B         NaN     04-Jan-2021\n4  5     A         100     05-Jan-2021\n5  6     C         300     06-Jan-2021\n\nSo far you\u2019ve created the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'id': [1, 2, 3, 4, 5, 6],\n                   'product': ['A', 'B', 'C', 'B', 'A', 'C'],\n                   'sales': [100, None, 250, None, None, 300],\n                   'date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06']})\n```\n\nWhat would the Python code be to achieve these transformations in the DataFrame? \n\nresult = ... # put your solution here\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['sales'] = df.groupby('product')['sales'].ffill()\ndf['date'] = pd.to_datetime(df['date']).dt.strftime('%d-%b-%Y')\nresult = df\n```"
  },
  {
    "input": "Problem:\nSuppose I have a dataset represented as a DataFrame containing information about the daily sales of various products, with some missing values indicating days when sales were not recorded. The DataFrame is structured like this:\n\n```python\ndf = pd.DataFrame({\n    'product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-01', '2023-01-03', '2023-01-01', \n             '2023-01-02', '2023-01-03', '2023-01-05'],\n    'sales': [100, 150, None, 200, None, None, 50, None, None]\n})\n```\n\nI would like to fill in the missing sales values for each product using the method of forward filling and then backfill on remaining NaNs within the date range of each product. The expected output should fill missing sales values first with the last known value and then with the next known value, resulting in a complete sales record for each product over the provided dates.\n\nThe DataFrame after applying this filling technique should look like this:\n\n```plaintext\n  product        date  sales\n0       A  2023-01-01  100.0\n1       A  2023-01-02  150.0\n2       A  2023-01-03  150.0\n3       A  2023-01-04  150.0\n4       B  2023-01-01  200.0\n5       B  2023-01-02  200.0\n6       B  2023-01-03  200.0\n7       C  2023-01-01   50.0\n8       C  2023-01-02   50.0\n9       C  2023-01-03   50.0\n10      C  2023-01-04   50.0\n11      C  2023-01-05   50.0\n```\n\nHow can I achieve this result using pandas? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-01', '2023-01-03', '2023-01-01', \n             '2023-01-02', '2023-01-03', '2023-01-05'],\n    'sales': [100, 150, None, 200, None, None, 50, None, None]\n}\ndf['date'] = pd.to_datetime(df['date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.sort_values(by=['product', 'date'])\ndf['sales'] = df.groupby('product')['sales'].ffill().bfill()\nresult = df\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a sequence of input features in a PyTorch tensor that represent time series data. Each feature is a vector of size 10, and my dataset contains 100 samples, resulting in a tensor of shape (100, 10). I want to compute the element-wise mean of the features across all samples and return a single tensor of shape (10,), which represents the average feature values over all samples.\n\nHere is the tensor containing my data:\n\n```python\ninput_tensor = load_data()  # Load the (100, 10) tensor\n```\n\nHow can I compute the mean of the features effectively using PyTorch?\n\nA:\n\n```python\nmean_tensor = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nmean_tensor = input_tensor.mean(dim=0)  # Compute the mean across the samples\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a tensor with shape (5, 3), where each row represents a different sample with three features. I want to scale each feature within its respective column to have zero mean and unit variance, which is common in data preprocessing.\n\nGiven the following tensor:\n\n```\ndata = torch.tensor([[2.0, 3.0, 5.0],\n                     [4.0, 5.0, 6.0],\n                     [6.0, 7.0, 8.0],\n                     [8.0, 9.0, 7.0],\n                     [10.0, 11.0, 9.0]])\n```\n\nI want to compute the scaled tensor after normalizing each feature.\n\nTo achieve this, I plan on calculating the mean and standard deviation for each column, and then using these values to scale the data based on the formula:\n\n```\nscaled_data = (data - mean) / std\n```\n\nWhat code should I write to fill in the blank and complete this normalization process?\n\nA:\n\n```python\nimport torch\ndata = torch.tensor([[2.0, 3.0, 5.0],\n                     [4.0, 5.0, 6.0],\n                     [6.0, 7.0, 8.0],\n                     [8.0, 9.0, 7.0],\n                     [10.0, 11.0, 9.0]])\nmean = data.mean(dim=0)\nstd = data.std(dim=0)\nscaled_data = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nscaled_data = (data - mean) / std\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes that contain customer transaction data. The first dataframe represents customer information and looks like this:\n\n```python\nimport pandas as pd\n\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3],\n    'customer_name': ['Alice', 'Bob', 'Charlie'],\n    'region': ['North', 'South', 'East']\n})\n```\n\nThe second dataframe contains transaction records and looks like this:\n\n```python\ntransactions = pd.DataFrame({\n    'transaction_id': [101, 102, 103, 104],\n    'customer_id': [1, 2, 1, 4],\n    'amount': [200, 150, 300, 400]\n})\n```\n\nYou need to perform a merge to combine these two dataframes to create a new dataframe that includes all customers and their corresponding transaction amounts. If a customer has no transactions, their amount should be `0`. The resulting dataframe should have the following structure:\n\n```\ncustomer_id  customer_name  region  amount\n1            Alice          North  500\n2            Bob            South  150\n3            Charlie        East   0\n```\n\nHow can you achieve this?\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = customers.merge(transactions.groupby('customer_id', as_index=False).sum(), on='customer_id', how='left').fillna(0)\n```"
  },
  {
    "input": "Problem:\nI have two dataframes that record sales information. The first dataframe contains the product IDs and their respective sales in quantity per day, while the second dataframe contains product IDs and their corresponding prices. \n\nHere are the dataframes:\n\ndf_sales:\n| product_id | sales_quantity | sales_date  |\n|------------|----------------|--------------|\n| A          | 5              | 2023-01-01   |\n| B          | 3              | 2023-01-01   |\n| A          | 2              | 2023-01-02   |\n| B          | 1              | 2023-01-02   |\n| C          | 4              | 2023-01-01   |\n\ndf_prices:\n| product_id | price |\n|------------|-------|\n| A          | 10    |\n| B          | 15    |\n| C          | 20    |\n\nI want to create a new dataframe that summarizes the total sales value for each product per day, calculated by multiplying the sales quantity by the product price. The resulting dataframe should include these columns: `sales_date`, `product_id`, `total_sales_value`.\n\nHow can I achieve this in a single merging operation?\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': ['A', 'B', 'A', 'B', 'C'],\n    'sales_quantity': [5, 3, 2, 1, 4],\n    'sales_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01']\n})\n\ndf_prices = pd.DataFrame({\n    'product_id': ['A', 'B', 'C'],\n    'price': [10, 15, 20]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_prices, on='product_id').assign(total_sales_value=lambda x: x.sales_quantity * x.price)[['sales_date', 'product_id', 'total_sales_value']]\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 102, 104, 104],\n    'sales': [200, None, 340, None, 300, 400, None],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-01', \n                            '2023-01-02', '2023-01-02', '2023-01-02', '2023-01-03'])\n})\n```\n\nYou would like to forward-fill the missing sales data for each product based on the date, ensuring that every product has sales data for each unique date available in the DataFrame. Therefore, you'll need to produce an output where the sales for each product are filled in consecutively from the last known value.\n\nCurrently, you have this DataFrame:\n\n```python\n   product_id  sales       date\n0         101  200.0 2023-01-01\n1         102    NaN 2023-01-01\n2         103  340.0 2023-01-01\n3         101    NaN 2023-01-02\n4         102  300.0 2023-01-02\n5         104  400.0 2023-01-02\n6         104    NaN 2023-01-03\n```\n\nwhat you need to do is to fill in the missing values in the 'sales' column for each 'product_id' based on the 'date' column.\n\nYour goal is to obtain a compressed DataFrame with no NaN values in 'sales' caused by forward-fill, while maintaining the same format. \n\nPlease provide the correct line of code to achieve this result. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('product_id').apply(lambda group: group.set_index('date').resample('D').ffill()).reset_index()\n```"
  },
  {
    "input": "### Problem:\nContext\nI have two dataframes that contain information about products and their sales.\n\nDataFrame `products` looks like this:\n```\n   ProductID ProductName  Category\n0          1      Apple       Fruits\n1          2      Banana      Fruits\n2          3      Carrot      Vegetables\n3          4      Broccoli    Vegetables\n```\n\nDataFrame `sales` looks like this:\n```\n   SaleID ProductID Quantity SaleDate\n0      101          1       50  2023-01-01\n1      102          2       30  2023-01-02\n2      103          3       20  2023-01-01\n3      104          4      100  2023-01-03\n4      105          5       60  2023-01-04\n```\n\nI want to merge these two dataframes based on `ProductID`. However, if a product in the `sales` dataframe does not exist in the `products` dataframe (like ProductID 5), I would like to drop that entire row in the final dataframe.\n\nThe desired output should look like this:\n```\n   SaleID ProductID Quantity SaleDate ProductName  Category\n0      101          1       50  2023-01-01       Apple      Fruits\n1      102          2       30  2023-01-02      Banana      Fruits\n2      103          3       20  2023-01-01      Carrot  Vegetables\n3      104          4      100  2023-01-03   Broccoli  Vegetables\n```\n\nSo far, I've merged the dataframes like this:\n```python\ndf = pd.merge(sales, products, on='ProductID', how='inner')\n```\n\nWhat change should I make to correctly reflect the required output, ensuring that rows in `sales` with non-existent `ProductID`s in `products` are dropped?\n\nA:\n<code>\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'ProductID': [1, 2, 3, 4],\n    'ProductName': ['Apple', 'Banana', 'Carrot', 'Broccoli'],\n    'Category': ['Fruits', 'Fruits', 'Vegetables', 'Vegetables']\n})\n\nsales = pd.DataFrame({\n    'SaleID': [101, 102, 103, 104, 105],\n    'ProductID': [1, 2, 3, 4, 5],\n    'Quantity': [50, 30, 20, 100, 60],\n    'SaleDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-04']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(sales, products, on='ProductID', how='inner')\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes, where the first dataframe contains product sales data for different stores, and the second dataframe contains product prices. The structures of the dataframes are as follows:\n\ndf_sales:\n```\n+---------+--------+-------+\n| Product | Store  | Sales |\n+---------+--------+-------+\n|   A     | Store1 |  30   |\n|   B     | Store2 |  25   |\n|   A     | Store2 |  15   |\n|   C     | Store1 |  10   |\n+---------+--------+-------+\n```\n\ndf_prices:\n```\n+---------+--------+\n| Product | Price  |\n+---------+--------+\n|   A     |  5.00  |\n|   B     |  3.00  |\n|   C     |  7.50  |\n+---------+--------+\n```\n\nYou need to create a new dataframe that joins these two dataframes based on the \"Product\" column, showing the total revenue for each store from the products sold. The new dataframe should look like this:\n\nresult:\n```\n+--------+--------+------------+\n| Store  | Product| Total_Revenue|\n+--------+--------+------------+\n| Store1 | A      |  150.00    |\n| Store1 | C      |  75.00     |\n| Store2 | A      |  75.00     |\n| Store2 | B      |  75.00     |\n+--------+--------+------------+\n```\n\nTo achieve this, fill in the blank below with the appropriate pandas code.\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Product': ['A', 'B', 'A', 'C'],\n    'Store': ['Store1', 'Store2', 'Store2', 'Store1'],\n    'Sales': [30, 25, 15, 10]\n})\n\ndf_prices = pd.DataFrame({\n    'Product': ['A', 'B', 'C'],\n    'Price': [5.00, 3.00, 7.50]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df_sales.merge(df_prices, on='Product') \\\n                  .assign(Total_Revenue=lambda x: x['Sales'] * x['Price']) \\\n                  .groupby(['Store', 'Product'], as_index=False) \\\n                  .agg({'Total_Revenue': 'sum'}) \\\n                  .reset_index() \n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W) where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is not working as intended.\n```\n\nI expected the images to be flipped, but it seems like I need a more efficient approach to handle this. \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\n# Given tensor of images\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n\n# [Your implementation here]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\n</code>",
    "output": "\n<code>\nimages = torch.where(torch.rand(images.size(0), 1, 1, 1) < 0.5, flip_image(images), images)\n</code>"
  },
  {
    "input": "### Problem:\nYou have a dataset of customer transactions over time structured in a dataframe as follows:\n\n```python\ndf = pd.DataFrame({\n    'customer_id': ['C1', 'C1', 'C2', 'C2', 'C3'],\n    'transaction_date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'amount': [100, 200, None, 150, 300]\n})\n```\n\nDue to missing data in the 'amount' column for some transactions, you would like to fill these missing values. You decide to use the following techniques:\n\n1. For a customer\u2019s missing amounts, fill them with the average of their previous transactions within a 2-day window (i.e., consider transactions from that customer within two days before the missing transaction date).\n2. If there are no prior transactions within that window, fill with the average amount of all transactions for that customer.\n\nComplete the code below to achieve this:\n\n```python\nimport pandas as pd\n\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\n# Set the index for easier date operations\ndf = df.set_index('transaction_date')\n\n# Create a function to impute missing values based on the criteria above\ndef impute_amounts(df):\n    # Your code to fill in the missing amounts\n    ...\n\n# Apply the imputation function\nresult = impute_amounts(df)\n```\n\nFill in the function to effectively impute the missing values according to the described strategy.",
    "output": "\n```python\ndef impute_amounts(df):\n    for customer in df['customer_id'].unique():\n        customer_data = df[df['customer_id'] == customer]\n        for index, row in customer_data.iterrows():\n            if pd.isna(row['amount']):\n                # Get the date of the missing transaction\n                missing_date = index\n                # Get previous transactions within a 2-day window\n                window_start = missing_date - pd.Timedelta(days=2)\n                previous_transactions = customer_data[(customer_data.index < missing_date) & \n                                                      (customer_data.index >= window_start)]\n                \n                if not previous_transactions.empty:\n                    # Fill with the average of previous transactions in the window\n                    df.at[index, 'amount'] = previous_transactions['amount'].mean()\n                else:\n                    # Fill with the average amount of all transactions for that customer\n                    df.at[index, 'amount'] = customer_data['amount'].mean()\n    return df\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information about daily sales over a few weeks for different products, but there are some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n                           'date': ['2023-10-01', '2023-10-02', '2023-10-01', '2023-10-03',\n                                    '2023-10-01', '2023-10-02', '2023-10-02', None],\n                           'units_sold': [20, None, None, 15, 5, None, None, 10]})\n```\n\nI want to fill in the missing values of `date` and `units_sold` with the appropriate entries based on previous entries for the same `product_id`. Specifically, I want to forward fill the `date` and use the mean of previously available `units_sold` for the respective `product_id` to fill in the missing values.\n\nThe expected DataFrame should look like this:\n\n```plaintext\n   product_id        date  units_sold\n0           1  2023-10-01         20.0\n1           1  2023-10-02         20.0\n2           2  2023-10-01         7.5\n3           2  2023-10-03         15.0\n4           3  2023-10-01         5.0\n5           3  2023-10-02         5.0\n6           4  2023-10-02        10.0\n7           4  2023-10-02        10.0\n```\n\nCurrently, I am trying to fill the missing entries but not succeeding in the way I want. Can you help me with a concise inline code that will accomplish this task?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group.fillna({'date': group['date'].ffill(), 'units_sold': group['units_sold'].fillna(group['units_sold'].mean())})).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I need to implement a custom loss function that penalizes predictions based on the deviation from the target values, but with an emphasis on the mispredictions of a particular class (let's say class index 1). I want to create a function that calculates the custom loss where the loss for class index 1 is doubled compared to other classes. The function should take true labels and predicted labels as inputs, and return the computed custom loss.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Custom loss function to penalize class index 1 predictions more\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    class_weights = tf.where(tf.equal(y_true, 1), 2.0, 1.0)\n    loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n    weighted_loss = loss * class_weights\n    return tf.reduce_mean(weighted_loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I am training a neural network and I need to create a custom loss function to penalize predictions based on the distance from the true labels, specifically using Mean Absolute Error (MAE). For my problem, when the prediction is exactly equal to the true label, the loss should be 0. However, if the prediction is off, I want to use a weighted penalty that increases in intensity based on how far the prediction is from the true label, with weights defined as follows: \n\n- If the absolute difference is less than or equal to 1, the weight is 1.\n- If the absolute difference is greater than 1 but less than or equal to 2, the weight is 2.\n- If the absolute difference is greater than 2, the weight is 3.\n\nGiven the true labels and predicted labels, how can I implement this custom loss function? \n\nHere's the initial setup:\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the absolute difference\n    abs_diff = tf.abs(y_true - y_pred)\n    # Initialize the loss variable \n    loss = ... # put solution in this variable\n    return loss\n```\nFill in the blank for the variable `loss` to implement the specified custom loss logic.",
    "output": "\n```python\n    loss = tf.where(abs_diff <= 1, abs_diff * 1, \n            tf.where(abs_diff <= 2, abs_diff * 2, \n            abs_diff * 3))\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am developing a custom loss function to use in a neural network that is meant to identify anomalies in a dataset. My input data consists of a batch of predicted values and the actual values, both in the shape of (batch_size, num_features). I want to implement a custom loss that computes the Mean Squared Error (MSE) specifically for only one feature index across the batch. \nCurrently, I have the following tensors:\n```python\npredictions = tf.constant([[0.5, 0.8], [0.3, 0.2], [0.9, 0.1]])\nactuals = tf.constant([[1.0, 0.0], [0.0, 0.0], [1.0, 0.0]])\nfeature_index = 0\n```\nHow can I compute the loss only for the specified feature index and return a single value?\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.5, 0.8], [0.3, 0.2], [0.9, 0.1]])\nactuals = tf.constant([[1.0, 0.0], [0.0, 0.0], [1.0, 0.0]])\nfeature_index = 0\n\ndef custom_loss(predictions, actuals, feature_index):\n    # return the loss value for the specified feature index\n    # result = custom_loss(predictions, actuals, feature_index)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(predictions[:, feature_index] - actuals[:, feature_index]))\n    return mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have two Pandas DataFrames as follows:\n\nDataFrame A:\n| id | name   | salary |\n|----|--------|--------|\n| 1  | John   | 50000  |\n| 2  | Jane   | 60000  |\n| 3  | Mike   | 45000  |\n\nDataFrame B:\n| id | department | location      |\n|----|------------|---------------|\n| 1  | HR         | New York      |\n| 2  | Engineering| San Francisco  |\n| 4  | Marketing  | Los Angeles   |\n\nYou need to merge these two DataFrames on the 'id' column, such that the resulting DataFrame includes all records from DataFrame A and only the matching records from DataFrame B. If there is no matching record in DataFrame B, the result should include NaN for the columns from DataFrame B. However, you want to drop the 'location' column from the final merged DataFrame. \n\nThe expected structure should look like this:\n\n| id | name   | salary | department  |\n|----|--------|--------|-------------|\n| 1  | John   | 50000  | HR          |\n| 2  | Jane   | 60000  | Engineering  |\n| 3  | Mike   | 45000  | NaN         |\n\nHow can you achieve this using Pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf_a = pd.DataFrame({'id': [1, 2, 3],\n                     'name': ['John', 'Jane', 'Mike'],\n                     'salary': [50000, 60000, 45000]})\n\ndf_b = pd.DataFrame({'id': [1, 2, 4],\n                     'department': ['HR', 'Engineering', 'Marketing'],\n                     'location': ['New York', 'San Francisco', 'Los Angeles']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(df_a, df_b[['id', 'department']], on='id', how='left')"
  },
  {
    "input": "Problem:\n\nI have a collection of images represented as a 4D tensor for a deep learning task. The tensor has a shape of [batch_size, channels, height, width]. I would like to apply a dynamic scaling operation on this tensor such that each image within the batch is scaled by a corresponding factor provided in a 1D tensor. The scaling factors have a shape of [batch_size].\n\nHere's what I have so far:\n\n```python\nimport torch\n\nbatch_size = 4\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\nscaling_factors = torch.tensor([0.5, 1.0, 1.5, 2.0])  # Scaling factors for each image\n\n# Now, I want to scale each image in the batch without using a for loop.\n```\n\nWhat would be the appropriate way to scale the images dynamically based on the scaling factors?\n\nA:\n\n<code>\nscaled_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaled_images = images * scaling_factors.view(batch_size, 1, 1, 1)\n</code>"
  },
  {
    "input": "Problem:\nI have two pandas dataframes, `sales_data` and `product_data`. The `sales_data` dataframe contains sales transactions with a product ID and the quantity sold, while the `product_data` dataframe contains product details including the product ID and product name. The goal is to merge these two dataframes to create a single dataframe that includes the product name next to the sales data based on the matching product ID. If a product in `sales_data` does not exist in `product_data`, the corresponding product name should be `NaN`.\n\nHere are the two dataframes:\n\n`sales_data`:\n```\n   product_id  quantity\n0           1        10\n1           2         5\n2           3        20\n3           4         7\n```\n\n`product_data`:\n```\n   product_id    product_name\n0           1       Apples\n1           2       Bananas\n2           3       Cherries\n```\n\nThe resulting dataframe should look like this:\n```\n   product_id  quantity   product_name\n0           1        10          Apples\n1           2         5         Bananas\n2           3        20        Cherries\n3           4         7             NaN\n```\n\nYour task is to fill in the blank to accomplish this merging operation:\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 3, 4],\n    'quantity': [10, 5, 20, 7]\n})\n\nproduct_data = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Apples', 'Bananas', 'Cherries']\n})\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nresult = pd.merge(sales_data, product_data, on='product_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\nI have the following dataset containing temperatures recorded over several days, with some missing values:\n```python\ndates = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\"]\ntemperatures = [30, None, 32, None, 34]\n```\nI want to fill in the missing temperatures using the method of linear interpolation. Additionally, I need to ensure that the dates are formatted as \"DD-Month-YYYY\". \n\nThe expected output should look like this:\n```\n         date  temperature\n0  01-January-2023         30.0\n1  02-January-2023         31.0\n2  03-January-2023         32.0\n3  04-January-2023         33.0\n4  05-January-2023         34.0\n```\n\nWhat code can I use to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ndates = [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\"]\ntemperatures = [30, None, 32, None, 34]\ndf = pd.DataFrame({'date': dates, 'temperature': temperatures})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['temperature'] = df['temperature'].interpolate()\ndf['date'] = pd.to_datetime(df['date']).dt.strftime('%d-%B-%Y')\nresult = df\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels, 32x32 pixels\n```\n\nNow, I want to apply the `flip_image` function to each image in the `images` tensor based on the flip probability. I need to fill in the blank for the following line of code:\n\n```python\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```\n\nWhat would be the correct approach to perform this operation? \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor\naugmented_images = ...  # put solution in this variable\n</code>",
    "output": "\n<code>\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>"
  },
  {
    "input": "Problem:\n\nI need to normalize a batch of images represented as a PyTorch tensor. The images are stored in a tensor with shape `[batch_size, channels, height, width]`, and I would like to perform a per-channel normalization using the mean and standard deviation for each channel. Here is a snippet of my code that loads the images:\n\n```python\nimport torch\n\nimages = load_data()  # Assuming images is a tensor of shape [batch_size, channels, height, width]\n```\n\nHow can I apply this normalization? The expected output should also be a tensor of the same shape `[batch_size, channels, height, width]`.\n\nA:\n\n```python\nnormalized_images = ...  # put solution in this variable\n```",
    "output": "\n```python\nmean = images.mean(dim=[0, 2, 3], keepdim=True)\nstd = images.std(dim=[0, 2, 3], keepdim=True)\nnormalized_images = (images - mean) / std\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[3])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes containing customer transaction data from different quarters. The first dataframe, `df_q1`, contains customer IDs and their corresponding purchase amounts in the first quarter, while the second dataframe, `df_q2`, contains the same information for the second quarter. \n\ndf_q1:\n```\n   customer_id  purchase_amount\n0           1              250\n1           2              150\n2           3              300\n3           4              400\n```\n\ndf_q2:\n```\n   customer_id  purchase_amount\n0           3              200\n1           4              350\n2           5              150\n3           1              300\n```\n\nI want to merge these two dataframes on `customer_id` using an outer join, keeping all customers and summing their `purchase_amounts`. If a customer appears in both quarters, their amounts should be added together. If a customer is only present in one quarter, the other amount should default to 0. \n\nThe expected resultant dataframe should look like this:\n```\n   customer_id  total_purchase\n0           1              550\n1           2              150\n2           3              500\n3           4              750\n4           5              150\n```\n\nBelow is the setup for the dataframes:\n```\nimport pandas as pd\n\ndf_q1 = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'purchase_amount': [250, 150, 300, 400]\n})\n\ndf_q2 = pd.DataFrame({\n    'customer_id': [3, 4, 5, 1],\n    'purchase_amount': [200, 350, 150, 300]\n})\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(df_q1, df_q2, on='customer_id', how='outer', suffixes=('_q1', '_q2')).fillna(0)\nresult['total_purchase'] = result['purchase_amount_q1'] + result['purchase_amount_q2']\nresult = result[['customer_id', 'total_purchase']]\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to create a custom loss function for a regression task which penalizes predictions that are more than a threshold away from the true values. Specifically, if the absolute difference between the predicted and actual values exceeds a certain threshold, I want to apply a quadratic penalty. If the difference is within the threshold, I want a linear penalty. For this, I have a threshold of 0.5. How can I implement this as a loss function? \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 0.5\n    loss = ... # Fill in the solution here\n    return loss\n</code>",
    "output": "\n<code>\n    diff = tf.abs(y_true - y_pred)\n    quadratic_penalty = tf.square(diff - threshold)\n    linear_penalty = diff - threshold\n    loss = tf.where(diff > threshold, quadratic_penalty, linear_penalty)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset representing daily sales records for a retail store, where some records may have missing values for the 'sales' column. The dataframe looks like this:\n\n```python\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [150, None, 200, None, 250],\n    'store_id': [1, 1, 1, 1, 1]\n})\n```\n\nYou want to fill in the missing 'sales' values using advanced imputation techniques based on the previous and next day's sales figures. Specifically, you want to use forward fill followed by backward fill to ensure no missing values remain before any aggregations. \n\nWhat code would you use to fill the missing values in the 'sales' column of the dataframe?\n\nYour result should be assigned to the variable result:\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df['sales'].fillna(method='ffill').fillna(method='bfill')\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for a retail store, structured as follows:\n\n```python\nimport pandas as pd\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 2, 3],\n    'date': ['2023-01-01', '2023-01-01', '2023-02-01', None, '2023-02-01'],\n    'sales': [100, 150, None, 200, None]\n})\n```\n\nSome dates and sales data are missing, and I would like to perform advanced imputation. I want to fill the missing dates within the range present in the 'date' column while sequentially filling the missing sales values by forward filling them based on previous entries. \n\nThe desired output should look like this:\n\n```\n   product_id        date  sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  150.0\n2          1  2023-02-01  100.0\n3          2  2023-02-01  200.0\n4          3  2023-02-01  200.0\n```\n\nYour task is to fill in the missing values in the 'date' and 'sales' columns as described above. \n\nA:\n<code>\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 2, 3],\n    'date': ['2023-01-01', '2023-01-01', '2023-02-01', None, '2023-02-01'],\n    'sales': [100, 150, None, 200, None]\n})\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsales_data = sales_data.set_index('date').groupby('product_id').resample('D').first().reset_index()\nsales_data['sales'] = sales_data['sales'].fillna(method='ffill')\nsales_data['sales'] = sales_data['sales'].fillna(method='bfill')\nsales_data = sales_data.dropna(subset=['sales'])\nresult = sales_data\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to create a new tensor `augmented_images` that contains the augmented images.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    # This function will flip the input image tensor vertically\n    return image.flip(1)\n```\n\nI have loaded my image tensor as follows:\n\n```python\nimport torch\n\nimages = torch.randn(10, 3, 32, 32)  # for example, a batch of 10 images\n```\n\nNow I need to fill in the blank to generate the `augmented_images` tensor using a list comprehension that applies `flip_image` to each image with the specified flipping probability.\n\nHere\u2019s where I need your help:\n\n```python\naugmented_images = torch.stack([flip_image(image) if torch.rand(1).item() < 0.5 else image for image in images])\n```\n\nPlease fill in the blank for the code above to generate the augmented images correctly.",
    "output": "\n```python\naugmented_images = torch.stack([flip_image(image) if torch.rand(1).item() < 0.5 else image for image in images])\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation step.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.to_tensor(transform(image))\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I need to create a custom loss function to measure how well my model is performing in a regression task where targets are not absolute values but rather normalized scores between 0 and 1. I want to compute the mean squared error (MSE) but want to add a penalty if the prediction is greater than 1, scaling the difference by a factor of 2. The predictions are a tensor of shape (n,), and the true values are a tensor of the same shape. How can I implement the custom loss function where `predictions` and `true_values` are both tensors?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(predictions, true_values):\n    # Calculate the mean squared error\n    mse = ...\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(predictions - true_values))\n    penalty = tf.reduce_mean(tf.where(predictions > 1, 2 * tf.square(predictions - true_values), 0))\n    return mse + penalty\n</code>"
  },
  {
    "input": "Problem:\n\nI have a batch of images represented as a 4D tensor with dimensions (batch_size, channels, height, width). I want to apply a random horizontal flip to each image in the batch. I need to generate a mask tensor of the same height and width as the images that randomly assigns a value of 1 for pixels that will be flipped and 0 for pixels that will not be flipped. This mask will later be used to apply the flip. How can I create this mask using PyTorch?\n\nA:\n\n<code>\nimport numpy as np\nimport torch\nimages = load_data()\ndef generate_flip_mask(images):\n    # return the solution in this function\n    # mask = generate_flip_mask(images)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    batch_size, channels, height, width = images.shape\n    flip_mask = torch.randint(0, 2, (batch_size, 1, height, width), dtype=torch.float32)\n    return flip_mask\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand((8, 3, 32, 32))  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[3])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily average temperature and humidity levels recorded over a month in two separate DataFrames:\n\ntemperature_df:\n+------------+-------------+\n| Date       | AvgTemp     |\n+------------+-------------+\n| 2022-01-01 | 25          |\n| 2022-01-03 | 30          |\n| 2022-01-04 | 28          |\n| 2022-01-05 | NaN         |\n| 2022-01-07 | 32          |\n+------------+-------------+\n\nhumidity_df:\n+------------+--------------+\n| Date       | AvgHumidity   |\n+------------+--------------+\n| 2022-01-01 | 60           |\n| 2022-01-02 | 65           |\n| 2022-01-03 | NaN          |\n| 2022-01-05 | 70           |\n| 2022-01-06 | NaN          |\n| 2022-01-07 | 55           |\n+------------+--------------+\n\nYou want to merge these two datasets into a single DataFrame, ensuring that for each missing value in AvgTemp, you utilize the value from the nearest available date within the same column. Similarly, for AvgHumidity, if there\u2019s a NaN, fill it using the same technique, allowing for forward filling.\n\nAfter merging, the final DataFrame should look something like this:\n\n+------------+-------------+--------------+\n| Date       | AvgTemp     | AvgHumidity   |\n+------------+-------------+--------------+\n| 2022-01-01 | 25          | 60           |\n| 2022-01-02 | 25          | 65           |\n| 2022-01-03 | 30          | 65           |\n| 2022-01-04 | 28          | 65           |\n| 2022-01-05 | 28          | 70           |\n| 2022-01-06 | 28          | 70           |\n| 2022-01-07 | 32          | 55           |\n+------------+-------------+--------------+\n\nPlease provide the code to perform the merging and filling of missing values. \n\n```python\nimport pandas as pd\n\ntemperature_df = pd.DataFrame({\n    'Date': ['2022-01-01', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-07'],\n    'AvgTemp': [25, 30, 28, None, 32]\n})\n\nhumidity_df = pd.DataFrame({\n    'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-05', '2022-01-06', '2022-01-07'],\n    'AvgHumidity': [60, 65, None, 70, None, 55]\n})\n\n\ntemperature_df['Date'] = pd.to_datetime(temperature_df['Date'])\nhumidity_df['Date'] = pd.to_datetime(humidity_df['Date'])\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmerged_df = pd.merge_asof(temperature_df.sort_values('Date'), humidity_df.sort_values('Date'), on='Date', direction='backward')\nmerged_df['AvgTemp'] = merged_df['AvgTemp'].fillna(method='ffill')\nmerged_df['AvgHumidity'] = merged_df['AvgHumidity'].fillna(method='ffill')\nresult = merged_df\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing monthly sales data for different products in a grocery store. The data is represented in the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['apple', 'banana', 'apple', 'banana', 'orange', 'orange'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02', '2023-01', '2023-02'],\n    'sales': [150, None, 200, 250, None, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nIn this DataFrame, some sales figures are missing (`None`). I want to fill in these missing values. To fill the missing sales data, I would like to use the sales figures from the previous month for the same product if available. If there are no previous month sales figures, default the missing sales to 0.\n\nThe desired output after filling in the missing values should look like this:\n\n```\n   product    month  sales\n0    apple  2023-01  150.0\n1   banana  2023-01    0.0\n2    apple  2023-02  200.0\n3   banana  2023-02  250.0\n4   orange  2023-01    0.0\n5   orange  2023-02  300.0\n```\n\nWhat code should I use to achieve this? \n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.groupby('product').apply(lambda x: x['sales'].fillna(method='ffill').fillna(0)).reset_index(level=0, drop=True)\ndf['sales'] = result\n```"
  },
  {
    "input": "Problem:\n\nI have a 4D tensor that represents batches of images with shape (batch_size, channels, height, width), and I want to normalize the pixel values of each image in the batch independently. The tensor is defined as:\n\nimages = torch.rand((16, 3, 64, 64))\n\nI will also have a tensor representing the mean and standard deviation for each channel:\n\nmean = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\nstd = torch.tensor([0.2, 0.2, 0.2]).view(1, 3, 1, 1)\n\nTo normalize the images, I want to subtract the mean and divide by the standard deviation for each channel across all images.  What code fills in the blank to achieve this normalization?\n\nA:\n\n<code>\nimport torch\nimages = torch.rand((16, 3, 64, 64))\nmean = torch.tensor([0.5, 0.5, 0.5]).view(1, 3, 1, 1)\nstd = torch.tensor([0.2, 0.2, 0.2]).view(1, 3, 1, 1)\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_images = (images - mean) / std\n</code>"
  },
  {
    "input": "### Problem\nYou have two DataFrames representing sales data from two different regions. The first DataFrame contains individual sales transactions, while the second DataFrame contains summary statistics for each product:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 104, 102],\n    'region': ['North', 'North', 'South', 'South', 'North', 'South'],\n    'sales_amount': [250, 150, 200, 100, 300, 400]\n})\n\nsummary_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'total_sales': [350, 150, 200, 300],\n    'average_sales': [175, 150, 200, 300]\n})\n```\n\nYou need to merge these two DataFrames on the 'product_id' column, but only keep the records where the 'sales_amount' in the first DataFrame is greater than the 'average_sales' value in the second DataFrame. The result should include all columns from the first DataFrame and the 'total_sales' column from the second DataFrame.\n\nWhat code can you use to achieve this?\n\nA:\n```python\nresult = sales_data.merge(summary_data, on='product_id')[...]\n```",
    "output": "\n```python\nresult = sales_data.merge(summary_data, on='product_id')\nresult = result[result['sales_amount'] > result['average_sales']]\nresult = result[['product_id', 'region', 'sales_amount', 'total_sales']]\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that contains information about daily sales for different products in a store. The dataset looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-02'],\n    'Sales': [10, None, 20, None, 15, None]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nSome sales data for products are missing (represented as `None`). You want to fill in these missing values. The logic is to fill the missing sales values for each product with the sales value from the previous day. If there is no previous value available, fill it with zero.\n\nYour output dataframe should look like this:\n\n```\n  Product       Date  Sales\n0       A 2023-01-01   10.0\n1       B 2023-01-01    0.0\n2       C 2023-01-01   20.0\n3       A 2023-01-02   10.0\n4       B 2023-01-02   15.0\n5       C 2023-01-02   20.0\n```\n\nImplement the code to achieve this without using any explicit loops.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Sales'] = df.groupby('Product')['Sales'].fillna(method='ffill').fillna(0)\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to create a custom loss function to calculate the Mean Squared Error (MSE) specifically for a regression task where the model is predicting values that may not fall within a defined range (e.g., 0 to 1). For this, I want to create a function that returns the loss value adjusted based on whether the predictions exceed a threshold value (let's say 1.0). If a prediction exceeds this threshold, I want to penalize it by multiplying the squared error for that prediction by a factor of 2. \n\nI have a true values tensor and a predicted values tensor as follows:\n\ntrue_values = tf.constant([0.5, 1.2, 0.8, 1.5])\npredicted_values = tf.constant([0.7, 1.8, 0.9, 1.3])\n\nI need to implement this custom loss function and store the resultant loss in a variable named `custom_loss`. \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_loss(y_true, y_pred):\n    # Fill in the custom loss function here\n    pass\n\ntrue_values = tf.constant([0.5, 1.2, 0.8, 1.5])\npredicted_values = tf.constant([0.7, 1.8, 0.9, 1.3])\ncustom_loss = ... # call the custom_mse_loss function here\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef custom_mse_loss(y_true, y_pred):\n    mse = tf.square(y_true - y_pred)\n    penalty = tf.where(y_pred > 1.0, mse * 2, mse)\n    return tf.reduce_mean(penalty)\n\ncustom_loss = custom_mse_loss(true_values, predicted_values)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset of shape (batch_size, features) where each feature is represented as a 1D tensor and I want to transform these feature tensors into a thicker tensor by applying a linear transformation and an activation function. \n\nThe linear transformation is defined by weights and biases where weights are of shape (input_features, output_features) and biases are of shape (output_features). After applying the linear transformation, I want to apply the ReLU activation function.\n\nHere\u2019s the linear transformation function definition:\n\n```python\ndef linear_transform(features, weights, biases):\n    # apply the linear transformation\n    return torch.matmul(features, weights) + biases\n```\n\nI need to fill in the process to create the final transformed tensor that includes the ReLU activation. If the input tensor is:\n\n```python\nfeatures = torch.Tensor([[1, 2], [3, 4]])\nweights = torch.Tensor([[0.5, -0.5], [2, 0]])\nbiases = torch.Tensor([1, -1])\n```\n\nMy task is to transform the tensor using the linear transformation followed by the ReLU activation, then return the result.\n\nHow can I achieve this in PyTorch?\n\nA:\n\n```python\nimport torch\nfeatures, weights, biases = load_data()\ndef transform(features, weights, biases):\n    linear_output = linear_transform(features, weights, biases)\n    # Here is where you will apply the ReLU activation function\n    result = ...  # put solution in this variable\n    return result\n```",
    "output": "\n```python\n    result = torch.relu(linear_output)\n```"
  },
  {
    "input": "Problem:\n\nI am working on a deep learning project where I need to dynamically adjust the size of a tensor based on the batch size during training. In my code, I create a tensor that starts with a particular shape but need to resize it to accommodate a varying number of samples per batch.\n\nI have the following initialization for my tensor:\n\n```python\nimport torch\n\nbatch_size = 4\ninitial_tensor = torch.randn(batch_size, 3, 64, 64)  # A tensor for 4 images of size 3x64x64\n```\n\nNow, during the training process, the batch size may change, either due to the last batch being smaller or other reasons. For example, if the `new_batch_size` is 2, I want to resize `initial_tensor` to match this new batch size while keeping the other dimensions unchanged. \n\nTo change the tensor size dynamically, I need to reshape it to the new batch size like so:\n\n```python\nnew_batch_size = 2\n```\n\nWhat would the correct code be to reshape `initial_tensor` to the new size while maintaining the original dimensions?\n\n```python\nresized_tensor = initial_tensor.__________\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresized_tensor = initial_tensor.view(new_batch_size, 3, 64, 64)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I'm trying to create a custom loss function for my regression model to penalize predictions based on how far they deviate from the true values, but I want to apply a higher penalty for larger errors. Specifically, I'm interested in implementing a loss function where the penalty is the square of the error for absolute errors greater than a certain threshold (e.g. 1.0) and a linear penalty for errors below this threshold. The true values and predictions are both tensors of shape (n,). How can I implement this custom loss function?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss_function(y_true, y_pred):\n    error = y_true - y_pred\n    # Define the threshold\n    threshold = 1.0\n    # Apply the custom loss logic\n    # result = ... \n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    squared_error = tf.square(error)\n    linear_error = tf.abs(error)\n    loss = tf.where(tf.abs(error) > threshold, squared_error, linear_error)\n    return tf.reduce_mean(loss)\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes representing sales data from two different regions:\n\nSales Region 1:\n```\n   Product  Sales\n0       A     100\n1       B     150\n2       C     200\n```\n\nSales Region 2:\n```\n   Product  Sales\n0       A     120\n1       B     None\n2       D     250\n```\n\nI want to combine these two dataframes into one dataframe that includes total sales for each product. If a product appears in both dataframes, sum their sales. If a product appears in only one of the dataframes, include its sales as is. The output should look like this:\n\n```\n   Product  Total_Sales\n0       A          220\n1       B          150\n2       C          200\n3       D          250\n```\n\nHow can I achieve this in Python using pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf1 = pd.DataFrame({'Product': ['A', 'B', 'C'], 'Sales': [100, 150, 200]})\ndf2 = pd.DataFrame({'Product': ['A', 'B', None, 'D'], 'Sales': [120, None, None, 250]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.concat([df1, df2]).groupby('Product', as_index=False).sum().fillna(0).rename(columns={'Sales': 'Total_Sales'})</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI am building a custom loss function based on the mean absolute error (MAE) that incorporates a penalty for predictions that deviate significantly from the actual values. My goal is to multiply the MAE by a penalty factor that ramps up as the error increases. The penalty function is defined as `penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)`, where `threshold` is a fixed value. I want to implement this custom loss function. \n\nGiven `y_true` and `y_pred` as two tensors: \n```python\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nHow can I define the custom loss function that applies the penalty, where `threshold` is set to 1.0?\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\nthreshold = 1.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)\n    return mae * penalty\n### END SOLUTION\n</code>"
  },
  {
    "input": "### Problem\nI have a DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'product_id': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'sales': [100, np.nan, 200, np.nan, np.nan, 300],\n    'profit': [50, 40, np.nan, 80, 30, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nThe sales data for some products is missing (NaN values), and I would like to perform advanced imputation to fill in these missing values. Specifically, I want to fill the missing sales values with the mean sales of each product, and for the profit column, I want to fill the missing values with the median profit of the respective product.\n\nAdditionally, I want to add a new column named `total_trade`, which represents the total trade calculated as `sales + profit`. \n\nAfter all these operations, the expected DataFrame should have all NaN values filled as described.\n\nWhat code can I use to achieve this transformation?\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['sales'] = df.groupby('product_id')['sales'].transform(lambda x: x.fillna(x.mean()))\ndf['profit'] = df.groupby('product_id')['profit'].transform(lambda x: x.fillna(x.median()))\ndf['total_trade'] = df['sales'] + df['profit']\nresult = df\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am working on a regression problem and I need to implement a custom loss function that penalizes predictions based on the squared percentage error (SPE). The SPE is calculated as:\n  \n\\[ \\text{SPE} = \\left( \\frac{|y - \\hat{y}|}{|y|} \\right)^2 \\]\n\nwhere \\( y \\) is the true value and \\( \\hat{y} \\) is the predicted value. If \\( y \\) is 0, the loss should be set to a constant value of 1 for the sake of stability.\n\nI need to apply this loss function on two tensors representing the true values and predicted values. Below is the setup:\n\n```python\nimport tensorflow as tf\n\ntrue_values = tf.constant([10.0, 0.0, 15.0, 25.0], dtype=tf.float32)\npredicted_values = tf.constant([8.0, 1.0, 15.0, 20.0], dtype=tf.float32)\n```\n\nI want to implement the loss function and compute the resulting tensor. \n\nPlease fill in the following code with the correct implementation of the custom loss function:\n\n```python\ndef custom_spe_loss(y_true, y_pred):\n    # Implement the custom squared percentage error loss function here\n    ### BEGIN SOLUTION\n```\n\nEvaluate the loss function using the provided tensors:\n\n```python\nloss_result = custom_spe_loss(true_values, predicted_values)\n```",
    "output": "\n```python\ndef custom_spe_loss(y_true, y_pred):\n    spe = tf.where(tf.equal(y_true, 0.0), 1.0, tf.square(tf.abs(y_true - y_pred) / tf.abs(y_true)))\n    return tf.reduce_mean(spe)\n\nloss_result = custom_spe_loss(true_values, predicted_values)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, `sales` and `returns`, structured as follows:\n\n`sales`:\n```\n   order_id  customer_id  amount\n0         1           101     100\n1         2           102     200\n2         3           101     150\n3         4           103     300\n```\n\n`returns`:\n```\n   return_id  customer_id  amount\n0          A           101      50\n1          B           102      100\n2          C           104      200\n```\n\nI want to merge these DataFrames such that each `customer_id` from `sales` retains its related `amount` value, while matching `customer_id` in `returns` reduces the `amount` from `sales` by the corresponding amount from `returns`. If a `customer_id` in `returns` does not exist in `sales`, it should not affect the final DataFrame. The expected result should include all original rows from `sales`, and an additional column `final_amount` reflecting the adjustments from the `returns` DataFrame.\n\nThe result should look like this:\n```\n   order_id  customer_id  amount  final_amount\n0         1           101     100            50\n1         2           102     200           100\n2         3           101     150            100\n3         4           103     300            300\n```\n\nI tried using a left merge, but I'm unsure how to implement the logic to calculate the `final_amount`.\n\nA:\n<code>\nimport pandas as pd\n\nsales = pd.DataFrame({'order_id': [1, 2, 3, 4],\n                      'customer_id': [101, 102, 101, 103],\n                      'amount': [100, 200, 150, 300]})\n\nreturns = pd.DataFrame({'return_id': ['A', 'B', 'C'],\n                        'customer_id': [101, 102, 104],\n                        'amount': [50, 100, 200]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = sales.merge(returns.groupby('customer_id', as_index=False).sum(), on='customer_id', how='left', suffixes=('', '_return'))\nresult['final_amount'] = result['amount'] - result['amount_return'].fillna(0)\nresult = result[['order_id', 'customer_id', 'amount', 'final_amount']]\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor representing image data with shape (num_images, num_channels, height, width) corresponding to a batch of images. I want to apply a mask that will filter out specific image channels based on a given boolean mask tensor of shape (num_channels,). How can I do this using PyTorch to obtain a tensor that only includes the images with the selected channels, while retaining the other dimensions?\n\nHere is the setup I have:\n\n```python\nimport torch\n\nnum_images = 4\nnum_channels = 3\nheight = 32\nwidth = 32\n\nimages = torch.randn(num_images, num_channels, height, width)  # Random image data\nmask = torch.tensor([1, 0, 1], dtype=torch.bool)  # Boolean mask to select channels\n```\n\nI'd like to apply the mask to the `images` tensor. What code should I add below to carry out this operation?\n\nA:\n\n<code>\nresult = ...  # put your solution in this variable\n</code>",
    "output": "\n<code>\nresult = images[:, mask, :, :]\n</code>"
  },
  {
    "input": "Problem:\nYou are given a DataFrame that tracks daily sales across multiple stores, with some gaps in the data. The DataFrame looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Store': ['Store A', 'Store A', 'Store B', 'Store B', 'Store C'],\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'Sales': [200, None, 150, 300, None]\n})\n```\n\nYour goal is to fill in the missing sales figures using forward filling for each store while ensuring that if a store has no sales recorded for a day, it should still show up in the DataFrame with 0 sales for that date. The expected output format should include all unique dates for each store, even if no sales were recorded, with sales data filled accordingly.\n\nWrite the following code to achieve this goal:\n\n```python\nimport pandas as pd\n\nsales_data['Date'] = pd.to_datetime(sales_data['Date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (sales_data.set_index(['Store', 'Date'])\n          .resample('D')\n          .sum()\n          .fillna(0)\n          .groupby(level=0)\n          .ffill()\n          .reset_index())\n```"
  },
  {
    "input": "Problem:\n\nYou have a sequence of time series data stored in a 3D tensor with the shape (batch_size, sequence_length, features). You need to extract a sliding window of size `window_size` from this tensor, where each window overlaps with the previous one by `step_size`. Your output should be a 4D tensor containing all the sliding windows, preserving the batch dimension.\n\nFor instance, if you have a tensor of shape (2, 5, 3) and you want to create windows of size 3 with a step size of 1, your output should be a tensor of shape (2, 3, 3, 3), where the second dimension corresponds to the number of windows extracted.\n\nHere's the current setup:\n\n```python\nimport torch\ndata = load_data()  # shape is (batch_size, sequence_length, features)\nwindow_size = 3\nstep_size = 1\n```\n\nHow can you generate the sliding windows and obtain the desired shape? \n\nA:\n\n<code>\nwindows = ... # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nwindows = data.unfold(1, window_size, step_size)  # shape will be (batch_size, num_windows, window_size, features)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am implementing a custom loss function for a regression problem that penalizes predictions further away from the target by applying a quadratic penalty. If the prediction (y_pred) and target (y_true) are given as tensors, I would like to create a loss function that calculates the sum of squared differences between them. I'm trying to design the function to return a scalar tensor value representing the loss. Given that y_true is a tensor of shape (n,) and y_pred is a tensor of the same shape, how can I define the custom loss function correctly?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the loss here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    loss = tf.reduce_sum(tf.square(y_true - y_pred))\n    return loss\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI want to implement a custom loss function that calculates the mean squared error (MSE) but with a twist: if the target value is 0, the loss should be multiplied by 2. I have a batch of predictions and target values as follows:\n\npredictions = [0.1, 0.4, 0.0, 0.8]\ntargets = [0.0, 0.5, 0.0, 1.0]\n\nHow can I create a function that takes predictions and targets and returns the computed weighted MSE? \n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.1, 0.4, 0.0, 0.8])\ntargets = tf.constant([0.0, 0.5, 0.0, 1.0])\n\ndef weighted_mse(predictions, targets):\n    # return the solution in this function\n    # result = weighted_mse(predictions, targets)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mse = tf.square(predictions - targets)\n    weights = tf.where(targets == 0.0, 2.0, 1.0)\n    weighted_mse = tf.reduce_mean(mse * weights)\n    return weighted_mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a batch of images, and I want to apply a transformation to each image dynamically based on its mean value. Specifically, I'm looking to normalize each image by subtracting its mean and dividing by its standard deviation. The input tensor `images` has a shape of `(N, C, H, W)` where `N` is the batch size, `C` is the number of channels, and `H` and `W` are the height and width of the images. \n\nCould you fill in the blank to compute the normalized images?\n\nA:\n\n```python\nimport torch\nimages = load_data()\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nnormalized_images = (images - images.mean(dim=(2, 3), keepdim=True)) / images.std(dim=(2, 3), keepdim=True)\n```"
  },
  {
    "input": "Problem:\n\nI'm working with time series data represented as a tensor. Each point in time has multiple features, and I want to compute the moving average for each feature over a specific window size. However, I'm encountering issues when applying the moving average function due to the dimension mismatch.\n\nHere's my code snippet where I'm defining the tensor and trying to reshape it for the moving average calculation:\n\n```python\nimport torch\n\nwindow_size = 3\n# Simulating a 2D time series tensor with shape (time_steps, features)\ndata = torch.randn(10, 4)  # 10 time steps, 4 features\n\n# Reshape for moving average; trying to create sliding window view\ndata_reshaped = data.unfold(0, window_size, 1)  # This is where I'm running into trouble\n```\n\nI need to compute the moving average but keep getting errors regarding the dimensions. How can I fix my approach?\n\nA:\n\n<code>\ndata_moving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndata_moving_avg = data_reshaped.mean(dim=2)  # Compute the mean across the window dimension\n```"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor that represents a grayscale image, and I want to apply a dynamic resizing operation based on the percentage of the original image dimensions. The target size should be calculated as a fraction of the original size. For example, if the original dimensions are (H, W) and the resize percentage is 50%, the new dimensions should be (H * 0.5, W * 0.5).\n\nHere's my starting code, but I'm unsure how to implement the resizing part correctly using PyTorch dynamic tensor operations:\n\nimport torch\n\noriginal_image = torch.randn(1, 1, 100, 200)  # Simulated grayscale image\nresize_percentage = 0.5\n\n# Calculate the new dimensions\nnew_height = int(original_image.size(2) * resize_percentage)\nnew_width = int(original_image.size(3) * resize_percentage)\n\n# How do I resize the tensor to the new dimensions?\nresized_image = ...\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\noriginal_image, resize_percentage = load_data()\n</code>\nresized_image = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresized_image = torch.nn.functional.interpolate(original_image, size=(new_height, new_width), mode='bilinear', align_corners=False)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\naugmented_images = images.clone()\n```\n\nI can't seem to figure out how to apply the flip operation to `augmented_images` based on the `flip_condition`. \n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\nflip_condition = torch.rand(images.size(0)) > 0.5\naugmented_images = images.clone()\n...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>",
    "output": "\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to implement a custom loss function to measure the difference between predicted and actual values, specifically focusing on the mean squared error but with an additional penalty when predictions exceed the actual values.\nMy predictions are provided as a tensor `predictions`, and the actual values are in a tensor `actual`. I would like to compute the custom loss as follows:\n1. Calculate the mean squared error between the predictions and actual values.\n2. If any predictions are greater than the actual values, add a penalty of 0.1 times the sum of the differences.\n\nExample tensors:\n```\npredictions = tf.constant([3.0, 5.0, 2.0])\nactual = tf.constant([2.0, 4.0, 6.0])\n```\nI need the following function that will compute the custom loss:\n```python\nimport tensorflow as tf\n\ndef custom_loss(predictions, actual):\n    # Define the custom loss calculation\n    loss = ...\n    return loss\n```\nFill in the blank with the appropriate code to calculate the custom loss.",
    "output": "\n```python\nimport tensorflow as tf\n\ndef custom_loss(predictions, actual):\n    mse = tf.reduce_mean(tf.square(predictions - actual))\n    penalty = tf.reduce_sum(tf.where(predictions > actual, predictions - actual, 0.0)) * 0.1\n    loss = mse + penalty\n    return loss\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a machine learning model that requires dynamically resizing tensors based on varying input data. You have a tensor `data` with a shape of `[batch_size, features]`, where `data.size() == torch.Size([4, 10])`. The task is to create a new tensor `resized_data` that contains each row of `data` repeated `n` times while keeping the total number of elements constant. The value of `n` will be provided as input which is equal to the length of features minus a specified integer `s`. \n\nFor example, if your input `n` is 5 and `s` is 5, the new shape of the tensor should be `[4, 5]`. If `n` is larger than the remaining features, you should fill the rest with zeros.\n\nHow would you resize the tensor accordingly?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nn = ... # number of times to repeat each element\ns = ... # specified integer to decrease the feature length\n</code>\nresized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nbatch_size, features = data.size()\nnew_features = features - s\nresized_data = torch.zeros(batch_size, new_features)\n\nfor i in range(batch_size):\n    resized_data[i, :min(n, new_features)] = data[i, :min(n, features)]\n</code>\n</code>"
  },
  {
    "input": "Problem:\nYou have two pandas DataFrames: one contains product information and the other contains sales data. The product DataFrame, `df_products`, includes the columns 'ProductID' and 'ProductName', while the sales DataFrame, `df_sales`, includes 'SaleID', 'ProductID', 'Quantity', and 'SaleDate'. You want to combine these two DataFrames to generate a single DataFrame that contains 'SaleID', 'ProductName', 'Quantity', and 'SaleDate'. \n\nHere's the setup:\n\n```python\nimport pandas as pd\n\ndf_products = pd.DataFrame({\n    'ProductID': [1, 2, 3],\n    'ProductName': ['Widget', 'Gadget', 'Sprocket']\n})\n\ndf_sales = pd.DataFrame({\n    'SaleID': [101, 102, 103, 104],\n    'ProductID': [1, 1, 2, 3],\n    'Quantity': [4, 2, 5, 1],\n    'SaleDate': ['2023-10-01', '2023-10-02', '2023-10-03', '2023-10-04']\n})\n\n# Use the following line to merge the two DataFrames to get the desired output\nresult = ... # put solution in this variable\n```\n\nThe expected output should look like this:\n\n```\n   SaleID ProductName  Quantity    SaleDate\n0     101      Widget         4   2023-10-01\n1     102      Widget         2   2023-10-02\n2     103      Gadget         5   2023-10-03\n3     104     Sprocket         1   2023-10-04\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_products, on='ProductID')[['SaleID', 'ProductName', 'Quantity', 'SaleDate']]\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for different products over time, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['A', 'A', 'B', 'B', 'C'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-02', '2023-01-04', '2023-01-01'],\n    'sales': [10, None, None, 5, 20]\n}\ndf = pd.DataFrame(data)\n```\n\nWhat I want to achieve is to forward-fill the missing sales values for each product, and at the same time, fill any remaining NaNs with 0 when there are no prior values to carry forward. The final DataFrame should also be sorted by the 'date' of sales.\n\nThe desired output is as follows:\n\n```\n  product       date  sales\n0       A 2023-01-01   10.0\n1       A 2023-01-03   10.0\n2       B 2023-01-02    0.0\n3       B 2023-01-04    5.0\n4       C 2023-01-01   20.0\n```\n\nWhat is the code to achieve this transformation and create the desired DataFrame? Your answer should replace the line `result = ...` with the appropriate code. \n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.sort_values('date').groupby('product').apply(lambda x: x.fillna(method='ffill').fillna(0)).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI want to create a custom loss function for a regression problem where the target value and the predicted value are compared using the Mean Absolute Error (MAE), but I want to add a penalty if the prediction deviates from a certain threshold. Specifically, if the absolute difference between the predicted and target values exceeds a threshold of 5, I want to multiply the MAE by a factor of 2.\n\nHere's what I've set up so far:\n\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 5.0\n    # compute the Mean Absolute Error\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    # apply the penalty if the error exceeds the threshold\n    result = ...  # fill in this blank with the correct logic\n    return result\n```\n\nHow can I implement this logic in the blank?",
    "output": "\n```python\n    penalty = tf.where(tf.abs(y_true - y_pred) > threshold, 2.0 * mae, mae)\n    result = tf.reduce_mean(penalty)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset that records daily sales of products in different stores as follows:\n\n```python\ndf = pd.DataFrame({\n    'store_id': [1, 1, 2, 2, 3, 3, 3],\n    'product_id': ['A', 'B', 'A', 'B', 'A', 'B', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03'],\n    'sales': [10, 20, 5, None, 15, None, 25]\n})\n```\n\nYour goal is to fill in the missing sales data for each product in each store by using the average sales of the respective product from the same store and date. If there are no sales recorded for that product on that date, it should default to the average sales of that product across all stores. \n\nPlease complete the following code to achieve this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'store_id': [1, 1, 2, 2, 3, 3, 3],\n    'product_id': ['A', 'B', 'A', 'B', 'A', 'B', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03'],\n    'sales': [10, 20, 5, None, 15, None, 25]\n})\n\n# Fill missing sales with the average sales of the same product in the same store and date \n# If that is not available, use the average sales of the product across all stores\ndf['sales'] = ... # put solution in this variable\n```",
    "output": "\n```python\navg_sales_store_date = df.groupby(['store_id', 'product_id', 'date'])['sales'].transform('mean')\navg_sales_product = df.groupby('product_id')['sales'].transform('mean')\ndf['sales'] = df['sales'].fillna(avg_sales_store_date).fillna(avg_sales_product)\n```"
  },
  {
    "input": "Problem:\n\nI have a 4D tensor representing a batch of images, where each image has dimensions: (batch size, channels, height, width). The tensor is of shape (32, 3, 128, 128), and I want to apply a dynamic thresholding operation along the channel dimension. Specifically, I want to set all pixel values to 1 if they are greater than a certain threshold and to 0 otherwise. \n\nHow can I accomplish this operation using PyTorch?\n\nHere is my current setup for the tensor and threshold:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n\nimages_tensor = torch.rand((32, 3, 128, 128))  # Simulate a batch of images\nthreshold = 0.5\n</code>\nthresholded_tensor = ... # put solution in this variable\n### BEGIN SOLUTION",
    "output": "\n<code>\nthresholded_tensor = (images_tensor > threshold).float()\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations, but I'm unsure how to implement the color jitter with the specified parameters.\n\nHere's what I have so far:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    # Fill in the blank with the color jitter transform\n])\n```\n\nI would like to apply color jittering with brightness=0.2, contrast=0.2, saturation=0.2, and hue=0.1.\n\nA:\n\n<code>\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n])\n</code>\nresult = ... # put solution in this variable",
    "output": "\n<code>\nresult = transform\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am developing a custom loss function to improve training on my regression model, which predicts housing prices. I want to implement a loss function that combines Mean Squared Error (MSE) with a penalty for large predictions. The penalty is to be applied only if the predicted price exceeds a threshold of $500,000. If the predicted price exceeds this threshold, an additional loss of 0.1 times the squared difference between the predicted price and the threshold should be added.\n\nHere's a tensor `y_true` for the true prices:\n```\n[450000, 600000, 480000, 700000]\n```\nand a tensor `y_pred` for the predicted prices:\n```\n[430000, 650000, 500000, 750000]\n```\n\nYou need to implement the custom loss function and return the total loss as a scalar tensor. \n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([450000, 600000, 480000, 700000], dtype=tf.float32)\ny_pred = tf.constant([430000, 650000, 500000, 750000], dtype=tf.float32)\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the mean squared error\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n    # Penalty for exceeding the threshold\n    penalty = tf.reduce_mean(tf.where(y_pred > 500000, \n                                      0.1 * tf.square(y_pred - 500000), \n                                      0.0))\n    # Combine both losses\n    total_loss = ...  # put solution in this variable\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    total_loss = mse_loss + penalty\n    return total_loss\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes, one containing customer purchase records and the other containing customer details:\n\nPurchases DataFrame:\n```\n   CustomerID  Amount\n0          1     100\n1          2     200\n2          1     150\n3          3      50\n4          2     300\n```\n\nDetails DataFrame:\n```\n   CustomerID Name    \n0          1   Alice  \n1          2   Bob    \n2          3   Charlie \n3          4   David   \n```\n\nI want to create a new DataFrame that merges both of these, such that for each customer, their total purchase amount is calculated and included in the resulting DataFrame, along with their name. If a customer has no purchases, their details should also be included in a way that their total purchase amount shows as 0. The resulting DataFrame should look like this:\n```\n   CustomerID   Name   TotalAmount\n0          1   Alice          250\n1          2     Bob          500\n2          3 Charlie           50\n3          4   David            0\n```\n\nCan you provide the code that fills in the blank here?\n\nA:\n<code>\nimport pandas as pd\n\npurchases = pd.DataFrame({\"CustomerID\": [1, 2, 1, 3, 2], \"Amount\": [100, 200, 150, 50, 300]})\ndetails = pd.DataFrame({\"CustomerID\": [1, 2, 3, 4], \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = details.merge(purchases.groupby('CustomerID', as_index=False).sum(), on='CustomerID', how='left').fillna(0)\nresult.rename(columns={'Amount': 'TotalAmount'}, inplace=True)\n```"
  },
  {
    "input": "Problem:\nContext\nI have two datasets that represent purchases and customer information. \n\nDataset A (purchases):\n```\nPurchaseID   CustomerID   Amount\n-----------------------------------\n1            101          150\n2            102          200\n3            101          50\n4            103          100\n```\n\nDataset B (customers):\n```\nCustomerID   Name         Age\n---------------------------------\n101          John Doe    30\n102          Jane Smith   25\n103          Alice Johnson 27\n104          Bob Gray     40\n```\n\nI want to merge these datasets to create a final DataFrame that shows PurchaseID, Amount, Name, and Age. However, for any customers in Dataset B who do not have purchases recorded in Dataset A, I want to record `NaN` for the PurchaseID and Amount. \n\nHow can I achieve this with pandas?\n\nA:\n<code>\nimport pandas as pd\n\npurchases = pd.DataFrame({'PurchaseID':[1, 2, 3, 4],\n                           'CustomerID':[101, 102, 101, 103],\n                           'Amount':[150, 200, 50, 100]})\n\ncustomers = pd.DataFrame({'CustomerID':[101, 102, 103, 104],\n                          'Name':['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Gray'],\n                          'Age':[30, 25, 27, 40]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(customers, purchases, on='CustomerID', how='left')[['PurchaseID', 'Amount', 'Name', 'Age']]"
  },
  {
    "input": "Problem:\n\nYou have two dataframes representing sales data for different regions. The first dataframe, `df_sales`, contains information about each sale, including the `product_id`, `region`, and `quantity_sold`. The second dataframe, `df_products`, contains product details including the `product_id`, `product_name`, and `price`.\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2],\n    'region': ['North', 'South', 'North', 'East', 'West'],\n    'quantity_sold': [10, 15, 5, 7, 3]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n    'price': [20.0, 35.0, 50.0]\n})\n```\n\nYou want to merge these two dataframes on `product_id` and calculate the total revenue generated for each product in each region. The desired output should include `product_name`, `region`, and `total_revenue`, with `total_revenue` being calculated as `quantity_sold * price`.\n\nHow can you achieve this?\n\nA:\n\n```python\ndf_result = ... # put solution in this variable\n```",
    "output": "\n```python\ndf_result = df_sales.merge(df_products, on='product_id') \\\n                     .assign(total_revenue=lambda x: x['quantity_sold'] * x['price']) \\\n                     [['product_name', 'region', 'total_revenue']]\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am constructing a custom loss function to address imbalanced classes in a binary classification problem. Specifically, I want to create a loss function that penalizes misclassifications of the minority class more heavily than the majority class. I have a list of true labels and predictions represented as probabilities. \nThe true labels are given as a float list (e.g., [0.0, 1.0, 0.0, 1.0]), and the predicted probabilities are given as another float list (e.g., [0.4, 0.6, 0.3, 0.8]).\nI want to compute the weighted binary cross-entropy loss where the weights for class 0 is 1 and for class 1 is 2. \nThe output should be a single tensor value representing the loss.\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = tf.constant([0.0, 1.0, 0.0, 1.0])\npredicted_probs = tf.constant([0.4, 0.6, 0.3, 0.8])\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # loss = custom_loss(true_labels, predicted_probs)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    weights = tf.constant([1.0, 2.0])  # weights for class 0 and class 1\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = tf.multiply(bce, tf.gather(weights, tf.cast(y_true, tf.int32)))\n    return tf.reduce_mean(weighted_bce)\n### END SOLUTION\n</code>"
  },
  {
    "input": "## Problem:\n\nI have a 3D tensor that represents video data, with dimensions corresponding to (batch_size, num_frames, feature_dim). I want to selectively replace certain features of this tensor with a constant value based on a conditional 2D mask that indicates which frames should be replaced. \n\nThe mask has dimensions (batch_size, num_frames), where each value is either 0 (do not replace) or 1 (replace). \n\nGiven the following code:\n\n```python\nimport torch\n\n# Create a sample 3D tensor (batch_size=5, num_frames=10, feature_dim=20)\nvideo_tensor = torch.rand((5, 10, 20))\n\n# Create a mask tensor of the same batch size and num_frames\nmask = torch.randint(2, (5, 10)).byte()\n```\n\nHow can I replace the features in `video_tensor` with the value -1 wherever the mask is 1?\n\nPlace your solution in the variable `modified_video_tensor`:\n\n```python\nmodified_video_tensor = ...  # put solution in this variable\n```",
    "output": "\n```python\nmodified_video_tensor = video_tensor.clone()  # Clone the original tensor to avoid modifying it\nmodified_video_tensor[mask == 1] = -1  # Replace features where mask is 1\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains monthly sales data for several products over a period of time. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndata = {\n    'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n    'month': ['2023-01', '2023-02', '2023-01', '2023-02', '2023-01', '2023-02', '2023-01', '2023-02'],\n    'sales': [100, None, 150, None, None, 80, None, 95]\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to fill in the missing `sales` values using forward fill for each `product_id` so that if a product had sales in previous months, it carries over to the missing months. The resulting DataFrame should look like this:\n\n```\n   product_id   month  sales\n0           1  2023-01  100.0\n1           1  2023-02  100.0\n2           2  2023-01  150.0\n3           2  2023-02  150.0\n4           3  2023-01   80.0\n5           3  2023-02   80.0\n6           4  2023-01   95.0\n7           4  2023-02   95.0\n```\n\nWhat is the piece of code you would use to achieve this result? \n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('product_id')['sales'].ffill().fillna(method='ffill')\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes, `sales` and `customers`, with the following structure:\n\n```python\nimport pandas as pd\n\nsales = pd.DataFrame({\n    'order_id': [1, 2, 3, 4, 5],\n    'customer_id': [1, 2, 1, 3, 2],\n    'amount': [100, 200, 150, 300, 250]\n})\n\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'customer_name': ['Alice', 'Bob', 'Charlie', 'David']\n})\n```\n\nYou want to merge these two dataframes to create a new dataframe that includes every order along with the corresponding customer's name. However, if a customer has not made any orders, you want to still include the customer in the output with a default amount of zero. The final dataframe should have the structure:\n\n```\n   order_id  customer_id  amount customer_name\n0         1            1     100          Alice\n1         2            2     200            Bob\n2         3            1     150          Alice\n3         4            3     300        Charlie\n4         5            2     250            Bob\n5       NaN            4       0          David\n```\n\nHow can you achieve this merging operation?\n\n```python\nmerged_df = ... # put solution in this variable\n```",
    "output": "\n```python\nmerged_df = pd.merge(customers, sales, on='customer_id', how='left').fillna({'amount': 0})\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor representing image data where each image is flattened into a 1D tensor. The tensor has a shape of (batch_size, num_pixels), where `num_pixels` represents the total pixels in each image. For example:\n\ntensor([[0.2, 0.3, 0.4],\n        [0.1, 0.8, 0.7],\n        [0.4, 0.1, 0.5]])\n\nI want to normalize each image individually so that the values in each row sum up to 1. How can I achieve this using PyTorch without using explicit loops?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = load_data()\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_images = images / images.sum(dim=1, keepdim=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains the daily sales data for a store with missing values. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n```\n\nMy goal is to use advanced imputation techniques to fill the missing sales data based on the mean of the available sales for the last three days in the respective 'date' order (backward filling). After filling the missing values, I want the DataFrame to look like this:\n\n```\n        date  sales\n0 2023-01-01  250.0\n1 2023-01-02  250.0\n2 2023-01-03  300.0\n3 2023-01-04  316.67\n4 2023-01-05  400.0\n```\n\nWhat would be an efficient way to achieve this using pandas? I am currently considering using the rolling window function but need help to refine my approach.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['sales'] = df['sales'].fillna(df['sales'].rolling(window=3, min_periods=1).mean().shift(1))\nresult = df\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that computes the Mean Squared Error (MSE) for a specific class in my multi-class regression dataset. My model predicts an output of shape (batch_size, num_classes), while the true labels are given in a similar shape. For example, if my predicted output is:\n```\npredictions = [[0.5, 0.2, 0.1],\n               [0.4, 0.6, 0.3]]\n```\nand my true labels are:\n```\nlabels = [[0, 1, 0],\n          [1, 0, 0]]\n```\nI need to calculate the MSE for class 1. I am uncertain how to apply the mask properly to only compute the MSE for the specified class index (e.g., class_idx = 1). \n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.5, 0.2, 0.1],\n                            [0.4, 0.6, 0.3]])\nlabels = tf.constant([[0, 1, 0],\n                      [1, 0, 0]])\nclass_idx = 1\n\ndef custom_loss(predictions, labels, class_idx):\n    # return the solution in this function\n    # loss = custom_loss(predictions, labels, class_idx)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mask = tf.equal(tf.argmax(labels, axis=1), class_idx)\n    mse = tf.reduce_mean(tf.square(tf.boolean_mask(predictions[:, class_idx], mask) - \n                                    tf.boolean_mask(labels[:, class_idx], mask)))\n    return mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomRotation(degrees=30),\n            transforms.RandomHorizontalFlip(),\n            # Fill in the blank with the correct rotation implementation\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image()  # This will load an image tensor\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nresult = ...\n</code>",
    "output": "\n<code>\nresult = self.transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, `df1` and `df2`, and they look like this:\n\ndf1\n```\n   ID   Value\n0  A1     10\n1  A2     20\n2  A3     30\n```\n\ndf2\n```\n   ID   Info\n0  A1    XYZ\n1  A2    ABC\n2  A4    DEF\n```\n\nI need to merge these DataFrames on the `ID` column such that:\n- If a row exists in both DataFrames, I want to retain the `Value` from `df1` and the `Info` from `df2`.\n- If a row exists only in `df1`, I want to retain it as is with `NaN` for `Info`.\n- If a row exists only in `df2`, I want to keep it as is with `NaN` for `Value`.\n\nThe resulting DataFrame should have three columns: `ID`, `Value`, and `Info`, with an additional column `ExistsInBoth` indicating whether the `ID` is present in both DataFrames.\n\nHere are my initial DataFrames:\n```python\nimport pandas as pd\n\ndf1 = pd.DataFrame({'ID': ['A1', 'A2', 'A3'], 'Value': [10, 20, 30]})\ndf2 = pd.DataFrame({'ID': ['A1', 'A2', 'A4'], 'Info': ['XYZ', 'ABC', 'DEF']})\n```\n\nWhat single line of code can I use to accomplish this merging and create the new DataFrame while fulfilling the rules mentioned?\n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df1, df2, on='ID', how='outer').assign(ExistsInBoth=lambda x: x['Value'].notna() & x['Info'].notna())\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am implementing a custom loss function to minimize the binary cross-entropy between predicted and actual values. However, I want to apply a weight based on the prediction confidence, meaning that when the predicted probabilities are closer to 0.5, they should contribute more to the loss. Given the predictions (a tensor of shape (n,)) and actual labels (another tensor of shape (n,)), how can I achieve this?\n\nThe weight can be calculated as follows: for each element, the weight should be `abs(predict - 0.5)`, which means that predictions far from 0.5 will contribute less to the final loss. The output should be the total weighted binary cross-entropy loss.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.1, 0.4, 0.6, 0.8])\nlabels = tf.constant([0, 0, 1, 1])\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(labels, predictions)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    weights = tf.abs(y_pred - 0.5)\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = bce * weights\n    return tf.reduce_mean(weighted_bce)\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor representing the weights of a neural network structured as follows:\n\nweights = torch.rand((5, 4))\n\nI need to dynamically scale certain rows by a scaling factor, which is provided in a tensor of shape (3,) that specifies the rows to be scaled. The elements of the scaling tensor are: \n\nscaling_factors = torch.tensor([0.5, 2.0, 3.0])\n\nHow can I multiply the selected rows of the weights tensor by their corresponding scaling factors?\n\nExample of what I'm trying to achieve:\n\nIf I want to scale rows 0, 2, and 4, then the resulting operation should look something like this:\n\nweights[[0, 2, 4], :] *= scaling_factors\n\nPlease implement the correct code snippet below.\n\nA:\n\n<code>\nimport torch\nweights = torch.rand((5, 4))\nscaling_factors = torch.tensor([0.5, 2.0, 3.0])\n</code>\nweights[... ]  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nweights[[0, 2, 4], :] *= scaling_factors\n</code>"
  },
  {
    "input": "Problem:\n\nYou have two DataFrames, `sales_data` and `customer_info`, as shown below:\n\n`sales_data`:\n```\n   sale_id customer_id product     amount\n0       1         101   A1      100.00\n1       2         102   A2      200.00\n2       3         101   A3      150.00\n3       4         103   A1      300.00\n```\n\n`customer_info`:\n```\n   customer_id  name       region\n0          101  John Doe   East\n1          102  Jane Smith West\n2          104  Sam Wilson  North\n```\n\nYou need to merge these two DataFrames on `customer_id`, ensuring that every sale is represented and customer details are filled in where available. Any `customer_id` that exists in `sales_data` but not in `customer_info` should result in NaN values for non-merged columns. Additionally, keep the merged DataFrame sorted by `sale_id` in ascending order.\n\nBased on this, write the code to merge `sales_data` and `customer_info` into a new DataFrame called `merged_data`.\n\n<code>\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'sale_id': [1, 2, 3, 4],\n    'customer_id': [101, 102, 101, 103],\n    'product': ['A1', 'A2', 'A3', 'A1'],\n    'amount': [100.00, 200.00, 150.00, 300.00]\n})\n\ncustomer_info = pd.DataFrame({\n    'customer_id': [101, 102, 104],\n    'name': ['John Doe', 'Jane Smith', 'Sam Wilson'],\n    'region': ['East', 'West', 'North']\n})\n</code>\nmerged_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmerged_data = pd.merge(sales_data, customer_info, on='customer_id', how='left').sort_values(by='sale_id')\n```"
  },
  {
    "input": "Problem:\nI have two separate pandas DataFrames that need to be merged based on a common column, while ensuring that I keep specific columns from each DataFrame. The first DataFrame contains customer details, while the second contains order details. \n\nHere's what they look like:\n\nCustomer DataFrame:\n```\ncustomer_id    name     age\n0           101   Alice      30\n1           102     Bob      22\n2           103   Charlie    35\n```\n\nOrder DataFrame:\n```\norder_id    customer_id   amount\n0        1001           101      250\n1        1002           102      150\n2        1003           103      450\n3        1004           101      300\n```\n\nI want to merge them such that I get a DataFrame with `customer_id`, `name`, and `amount`, but I do not want the `age` from the first DataFrame or the `order_id` from the second DataFrame in the final result.\n\nCan you provide the code necessary to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ncustomers = pd.DataFrame({'customer_id': [101, 102, 103],\n                          'name': ['Alice', 'Bob', 'Charlie'],\n                          'age': [30, 22, 35]})\n\norders = pd.DataFrame({'order_id': [1001, 1002, 1003, 1004],\n                       'customer_id': [101, 102, 103, 101],\n                       'amount': [250, 150, 450, 300]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = pd.merge(customers[['customer_id', 'name']], orders[['customer_id', 'amount']], on='customer_id')\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\n            transforms.RandomRotation(degrees=30),  # Properly defined rotation transformation\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____\n])\n\n# Sample image tensor\nimage = torch.randn(3, 256, 256)  # Example image tensor of shape (C, H, W)\n\ntransformed_image = data_transforms(image)\n```\n\nA:\n\n<code>\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____\n])\n\n# Sample image tensor\nimage = torch.randn(3, 256, 256)  # Example image tensor of shape (C, H, W)\n\ntransformed_image = data_transforms(image)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n</code>",
    "output": "\n<code>\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a PyTorch project where I need to concatenate two tensors along a specified dimension, but I want to avoid errors that arise from mismatched sizes. I have two tensors, `A` and `B`, that I intend to concatenate along the first dimension (0). The tensors are structured like this:\n\n```\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])  # Note: B has a different first dimension size.\n```\n\nBefore concatenating, I want to ensure that `B` has the same number of columns as `A` by possibly reshaping or adjusting it without losing its original data. \n\nHow can I properly concatenate `A` and `B` after making sure their dimensions align? \n\nA:\n\n<code>\nimport torch\nA = load_data()\nB = load_data()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])\n\nif A.size(1) != B.size(1):\n    B = B.expand(-1, A.size(1))\n\nresult = torch.cat((A, B), dim=0)\n</code>"
  }
]