[
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation step.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.to_tensor(transform(image))\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a sequence of time series data represented in a 3D PyTorch tensor of shape (batch_size, time_steps, features). I need to create a function that applies a rolling window operation over the time steps and returns a new tensor that contains rolling averages of the last `n` time steps for each feature. For example, with a 3D tensor of shape (2, 5, 3) and a rolling window size of 2, the shape of the resulting tensor should be (2, 4, 3). Please complete the code below to implement this functionality.\n\nA:\n\n<code>\nimport torch\n\ndef rolling_average(tensor, window_size):\n    batch_size, time_steps, features = tensor.shape\n    # Create an output tensor for the rolling averages\n    output = torch.empty(batch_size, time_steps - window_size + 1, features)\n    for i in range(time_steps - window_size + 1):\n        output[:, i, :] = tensor[:, i:i + window_size, :].mean(dim=1) # Calculate rolling average\n\n    return output\n\ndata = torch.randn(2, 5, 3)  # Example tensor\nwindow_size = 2\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = rolling_average(data, window_size)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function that penalizes differences in predictions based on the mean squared error but with an additional twist. If the absolute difference between the predicted and actual value exceeds a specific threshold (for example, 1.0), an extra penalty of 2.0 should be applied. Here\u2019s my setup:\n\nI have two tensors: `predictions` and `targets` of shape (n,). Now I want to compute the custom loss based on the conditions mentioned.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.5, 1.5, 2.0, 3.5, 4.0])\ntargets = tf.constant([1.0, 1.0, 2.0, 3.0, 5.0])\n\ndef custom_loss(predictions, targets):\n    # return the solution in this function\n    # loss = custom_loss(predictions, targets)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    threshold = 1.0\n    extra_penalty = tf.where(tf.abs(predictions - targets) > threshold, 2.0, 0.0)\n    total_loss = mse + tf.reduce_mean(extra_penalty)\n    return total_loss\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame structured as follows:\n\n```python\ndf = pd.DataFrame({'item_id': [101, 102, 103, 101, 102],\n                   'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-03'],\n                   'sales': [5, None, 7, None, 2]})\n```\n\nI need to generate a new DataFrame that expands the dates to include all dates between the minimum and maximum dates present in the original DataFrame, and fill in the missing 'sales' values with the average sales of each item_id. The final 'date' column should be formatted as 'DD-MMM-YYYY'.\n\nThe desired output should look like this:\n\n```\n        date  item_id  sales\n0  01-Jan-2023      101    5.0\n1  02-Jan-2023      101    5.0\n2  03-Jan-2023      101    5.0\n3  01-Jan-2023      102    0.0\n4  02-Jan-2023      102    0.0\n5  03-Jan-2023      102    2.0\n6  01-Jan-2023      103    7.0\n7  02-Jan-2023      103    7.0\n8  03-Jan-2023      103    7.0\n```\n\nI've attempted to use `pd.date_range()`, but I'm not sure how to effectively fill the missing values based on averages. Can you help me with this? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'item_id': [101, 102, 103, 101, 102],\n                   'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-03'],\n                   'sales': [5, None, 7, None, 2]})\n\n# Convert date column to datetime\ndf['date'] = pd.to_datetime(df['date'])\n\n# Create a date range from min to max date\ndate_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\n\n# Create a new DataFrame with all combinations of dates and item_ids\nitem_ids = df['item_id'].unique()\nexpanded_df = pd.MultiIndex.from_product([date_range, item_ids], names=['date', 'item_id']).to_frame(index=False)\n\n# Merge with original DataFrame to bring in sales data\nmerged_df = pd.merge(expanded_df, df, on=['date', 'item_id'], how='left')\n\n# Fill missing sales with average sales per item_id\naverage_sales = df.groupby('item_id')['sales'].mean().reset_index()\nmerged_df = pd.merge(merged_df, average_sales, on='item_id', suffixes=('', '_avg'))\nmerged_df['sales'].fillna(merged_df['sales_avg'], inplace=True)\nmerged_df.drop(columns='sales_avg', inplace=True)\n\n# Format the date\nmerged_df['date'] = merged_df['date'].dt.strftime('%d-%b-%Y')\n\nresult = merged_df\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am implementing a custom loss function for a regression problem that penalizes predictions further away from the target by applying a quadratic penalty. If the prediction (y_pred) and target (y_true) are given as tensors, I would like to create a loss function that calculates the sum of squared differences between them. I'm trying to design the function to return a scalar tensor value representing the loss. Given that y_true is a tensor of shape (n,) and y_pred is a tensor of the same shape, how can I define the custom loss function correctly?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the loss here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    loss = tf.reduce_sum(tf.square(y_true - y_pred))\n    return loss\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have two pandas DataFrames that contain information about employees and their respective departments:\n\nEmployees DataFrame:\n```python\nimport pandas as pd\nemployees = pd.DataFrame({\n    'EmployeeID': [101, 102, 103, 104, 105],\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'DepartmentID': [1, 2, 2, 1, 3]\n})\n```\n\nDepartments DataFrame:\n```python\ndepartments = pd.DataFrame({\n    'DepartmentID': [1, 2, 3],\n    'DepartmentName': ['HR', 'IT', 'Finance'],\n    'Location': ['Building A', 'Building B', 'Building C']\n})\n```\n\nYou want to merge these two DataFrames based on the `DepartmentID` column, but since you only want the `EmployeeID`, `Name`, and `DepartmentName` in the resulting DataFrame, how can you accomplish this while avoiding the `Location` column in the final output? \n\nPlease provide the code to achieve this:\n```python\nmerged_df = ...\n```",
    "output": "\n```python\nmerged_df = pd.merge(employees, departments[['DepartmentID', 'DepartmentName']], on='DepartmentID')[['EmployeeID', 'Name', 'DepartmentName']]\n```"
  },
  {
    "input": "## Problem\nYou are working with sales data across different regions and want to analyze the performance of products. You have two DataFrames: one contains sales data with product IDs and their sales figures, while the other contains product information including their categories.\n\nHere's the sample data:\n\n```python\nimport pandas as pd\n\nsales_data = {\n    'Product_ID': ['P1', 'P2', 'P1', 'P3', 'P2', 'P4'],\n    'Region': ['North', 'South', 'West', 'East', 'North', 'West'],\n    'Sales_Figures': [200, 150, 300, 400, 250, 100]\n}\n\nproduct_info = {\n    'Product_ID': ['P1', 'P2', 'P3', 'P4'],\n    'Category': ['Electronics', 'Furniture', 'Electronics', 'Toys']\n}\n\ndf_sales = pd.DataFrame(sales_data)\ndf_products = pd.DataFrame(product_info)\n```\n\nYour task is to merge these two DataFrames to get a single DataFrame that includes `Product_ID`, `Region`, `Sales_Figures`, and `Category`. However, you want to retain only the rows from the sales DataFrame that have corresponding product information in the product DataFrame.\n\nHow do you fill in the missing code in the following statement to achieve this?\n\n```python\nmerged_df = pd.merge(df_sales, df_products, on='Product_ID', how='___')\n```\n\nYour final DataFrame should look like this:\n\n```\n  Product_ID Region  Sales_Figures      Category\n0         P1  North             200    Electronics\n1         P1   West             300    Electronics\n2         P2  South             150      Furniture\n3         P2  North             250      Furniture\n4         P3   East             400    Electronics\n5         P4   West             100           Toys\n```\n\nFill in the blank in the code snippet with the appropriate merge type.",
    "output": "\n```python\nmerged_df = pd.merge(df_sales, df_products, on='Product_ID', how='inner')\n```"
  },
  {
    "input": "Problem:\nI have two pandas dataframes, `sales_data` and `product_data`. The `sales_data` dataframe contains sales transactions with a product ID and the quantity sold, while the `product_data` dataframe contains product details including the product ID and product name. The goal is to merge these two dataframes to create a single dataframe that includes the product name next to the sales data based on the matching product ID. If a product in `sales_data` does not exist in `product_data`, the corresponding product name should be `NaN`.\n\nHere are the two dataframes:\n\n`sales_data`:\n```\n   product_id  quantity\n0           1        10\n1           2         5\n2           3        20\n3           4         7\n```\n\n`product_data`:\n```\n   product_id    product_name\n0           1       Apples\n1           2       Bananas\n2           3       Cherries\n```\n\nThe resulting dataframe should look like this:\n```\n   product_id  quantity   product_name\n0           1        10          Apples\n1           2         5         Bananas\n2           3        20        Cherries\n3           4         7             NaN\n```\n\nYour task is to fill in the blank to accomplish this merging operation:\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 3, 4],\n    'quantity': [10, 5, 20, 7]\n})\n\nproduct_data = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Apples', 'Bananas', 'Cherries']\n})\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nresult = pd.merge(sales_data, product_data, on='product_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, invoices and payments, structured as follows:\n\ninvoices\n```\n   invoice_id  amount       date     customer\n0           1     300 2023-01-15      Customer A\n1           2     500 2023-01-16      Customer B\n2           3     200 2023-01-17      Customer A\n3           4     700 2023-01-18      Customer C\n```\n\npayments\n```\n   invoice_id  payment_date  payment_amount\n0           1     2023-01-20             300\n1           2     2023-01-17             300\n2           3     2023-01-19             200\n3           5     2023-01-21             150\n```\n\nI need to create a DataFrame that merges the invoices and payments on the `invoice_id` and fills in the `payment_amount` from the payments DataFrame where it matches. If there is no matching record in payments, the original invoice information should be retained. The merged DataFrame should also include a status column that indicates whether the invoice has been fully paid, partially paid, or is unpaid.\n\nThe expected output should look like this:\n\n```\n   invoice_id  amount       date     customer  payment_amount  status\n0           1     300 2023-01-15      Customer A           300.0  Fully Paid\n1           2     500 2023-01-16      Customer B             NaN  Unpaid\n2           3     200 2023-01-17      Customer A           200.0  Fully Paid\n3           4     700 2023-01-18      Customer C             NaN  Unpaid\n```\n\nIf an invoice has a payment amount that equals the invoice amount, the status should be \"Fully Paid\". If there is a payment amount present but less than the invoice amount, the status should be \"Partially Paid\". If there is no payment for that invoice, the status should be \"Unpaid\".\n\nA:\n```python\nimport pandas as pd\n\ninvoices = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 4],\n    'amount': [300, 500, 200, 700],\n    'date': ['2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18'],\n    'customer': ['Customer A', 'Customer B', 'Customer A', 'Customer C']\n})\n\npayments = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 5],\n    'payment_date': ['2023-01-20', '2023-01-17', '2023-01-19', '2023-01-21'],\n    'payment_amount': [300, 300, 200, 150]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = invoices.merge(payments, on='invoice_id', how='left')\nresult['status'] = result.apply(lambda x: 'Fully Paid' if x['payment_amount'] == x['amount'] else \n                                  ('Partially Paid' if pd.notna(x['payment_amount']) and x['payment_amount'] < x['amount'] else 'Unpaid'), axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images horizontally with a probability of 0.5. I have already defined a function `horizontal_flip` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am not sure how to apply this function to each image in the tensor. I tried using a loop over `images`, but I want a more efficient solution. \n\nHere's the code where I need your help:\n\n```python\ndef horizontal_flip(image):\n    return torch.flip(image, dims=[2])  # Flips the image horizontally\n\naugmented_images = torch.empty_like(images)  # Initialize an empty tensor of the same shape\nfor i in range(images.shape[0]):\n    # Apply random horizontal flip with probability 0.5\n    if torch.rand(1).item() < 0.5:\n        augmented_images[i] = horizontal_flip(images[i])\n    else:\n        augmented_images[i] = images[i]\n```\n\nI would like to achieve the same functionality using a more concise approach. Fill in the blank in the following code snippet to apply the `horizontal_flip` function directly within a tensor operation.\n\n```python\naugmented_images = torch.stack([horizontal_flip(img) if torch.rand(1).item() < 0.5 else img for img in images])\n``` \n\nCan you fill in the blank after `else img`? \n\nA:\n\n<code>\naugmented_images = torch.stack([horizontal_flip(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\naugmented_images = torch.stack([horizontal_flip(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to define a custom loss function for a regression model that penalizes predictions more heavily when they are far from the true values. The function should compute the squared error loss and apply an additional factor that increases the penalty based on the distance from the true value. Specifically, if the difference between the predicted value `y_pred` and true value `y_true` exceeds a threshold (e.g., 1.0), the penalty factor should be 2; otherwise, it should be 1. Here's a snippet of my code where I want to implement this logic:\n\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the absolute difference\n    difference = tf.abs(y_true - y_pred)\n    penalty_factor = tf.where(difference > 1.0, 2.0, 1.0)\n    loss = tf.square(difference) * penalty_factor\n    return tf.reduce_mean(loss)\n\n# Example usage with dummy data\ny_true = tf.constant([2.0, 3.0, 5.0])\ny_pred = tf.constant([2.5, 2.0, 7.0])\nloss_value = custom_loss(y_true, y_pred)\n```\n\nIn this snippet, the last line computes the loss, but I need to define the `loss` variable properly with the logic shown. Fill in the blank with the logic to calculate the loss based on the difference and penalty factor. \n\nA:\n<code>\nloss = ...  # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\nloss = tf.square(difference) * penalty_factor\n</code>"
  },
  {
    "input": "Problem:\nYou have two dataframes as follows:\n\ndf1:\n```\n   product_id   name      price\n0          1  apple        1.0\n1          2  banana       0.5\n2          3  cherry       2.0\n```\n\ndf2:\n```\n   product_id   quantity   store\n0          1       100    store_a\n1          2        50    store_b\n2          3       200    store_a\n3          4        20    store_c\n```\n\nYou need to merge the two dataframes on the `product_id` column. However, for products that do not exist in `df1` (like `product_id` 4), you should still include the row from `df2` but set the `name` and `price` columns to NaN. Finally, the resulting dataframe should be sorted based on `product_id`. \n\nYour solution should look like this:\n```\n   product_id   name      price   quantity   store\n0          1  apple        1.0       100    store_a\n1          2  banana       0.5        50    store_b\n2          3  cherry       2.0       200    store_a\n3          4   NaN         NaN        20    store_c\n```\n\nGiven the dataframes defined as follows:\n<code>\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    \"product_id\": [1, 2, 3],\n    \"name\": [\"apple\", \"banana\", \"cherry\"],\n    \"price\": [1.0, 0.5, 2.0]\n})\n\ndf2 = pd.DataFrame({\n    \"product_id\": [1, 2, 3, 4],\n    \"quantity\": [100, 50, 200, 20],\n    \"store\": [\"store_a\", \"store_b\", \"store_a\", \"store_c\"]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(df2, df1, on='product_id', how='left').sort_values(by='product_id')<code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am developing a custom loss function to evaluate the performance of a neural network that predicts continuous values. I want to implement a custom loss that calculates the Mean Absolute Error (MAE) only for predictions that exceed a certain threshold. For the loss function, if the absolute error is less than the threshold, the contribution should be zero. How can I implement this as a custom loss function?\n\nHere is a sample implementation of your function:\n\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        # return the solution in this function\n        pass\n    return loss\n```\n\nIn the `loss` function, you will receive the ground truth values `y_true` and the predicted values `y_pred`. Complete the implementation based on the above requirements.",
    "output": "\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        absolute_error = tf.abs(y_true - y_pred)\n        mask = tf.cast(absolute_error > threshold, tf.float32)\n        return tf.reduce_mean(mask * absolute_error)\n    return loss\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes representing sales data and product details:\n\ndf_sales:\n+----------+-------+------------+\n| OrderID  | Amount| ProductID  |\n+----------+-------+------------+\n|    1     |  150  |     A      |\n|    2     |  200  |     B      |\n|    3     |  250  |     C      |\n|    4     |  300  |     A      |\n+----------+-------+------------+\n\ndf_products:\n+-----------+------------+---------+\n| ProductID | ProductName|  Price  |\n+-----------+------------+---------+\n|     A     |  Widget A  |   75    |\n|     B     |  Widget B  |   100   |\n|     C     |  Widget C  |   150   |\n+-----------+------------+---------+\n\nYou want to create a new dataframe that includes the sales data along with the product names and total cost (calculated as Amount divided by Price). The resulting dataframe should have the following structure:\n\n+----------+-------+------------+------------+----------+\n| OrderID  | Amount| ProductID  | ProductName| TotalCost|\n+----------+-------+------------+------------+----------+\n|    1     |  150  |     A      |  Widget A  |   2.0    |\n|    2     |  200  |     B      |  Widget B  |   2.0    |\n|    3     |  250  |     C      |  Widget C  |   1.67   |\n|    4     |  300  |     A      |  Widget A  |   4.0    |\n+----------+-------+------------+------------+----------+\n\nTo achieve this, use a merge operation on the two dataframes based on 'ProductID' and compute the 'TotalCost' by dividing 'Amount' by 'Price'. Make sure to handle all necessary imports and prepare the dataframes before performing the operation.\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({'OrderID': [1, 2, 3, 4],\n                         'Amount': [150, 200, 250, 300],\n                         'ProductID': ['A', 'B', 'C', 'A']})\n\ndf_products = pd.DataFrame({'ProductID': ['A', 'B', 'C'],\n                            'ProductName': ['Widget A', 'Widget B', 'Widget C'],\n                            'Price': [75, 100, 150]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_products, on='ProductID')\nresult['TotalCost'] = (result['Amount'] / result['Price']).round(2)\nresult = result[['OrderID', 'Amount', 'ProductID', 'ProductName', 'TotalCost']]\n</code>"
  },
  {
    "input": "Problem:\nYou have two pandas DataFrames that contain user data and their purchase details. The first DataFrame, `user_info`, contains the following columns:\n\n```plaintext\n   user_id  name   age\n0        1  John    25\n1        2  Alice   30\n2        3  Bob     22\n```\n\nThe second DataFrame, `purchase_data`, includes:\n\n```plaintext\n   user_id  purchase_id  amount\n0        1           101     250\n1        2           102     300\n2        1           103     150\n3        3           104     200\n4        4           105     400\n```\n\nYou need to join these two DataFrames on the `user_id` column, such that all information from both DataFrames is included, and missing values should be filled with `NaN`. After merging, you want to sort the resulting DataFrame first by `user_id` and then by `purchase_id`. The `amount` column should be formatted to include two decimal places.\n\nYour merged DataFrame is currently being generated with:\n\n```python\nresult = pd.merge(user_info, purchase_data, on='user_id', how='outer')\n```\n\nFill in the code below to achieve the desired DataFrame:\n\n```python\nimport pandas as pd\n\nuser_info = pd.DataFrame({'user_id': [1, 2, 3],\n                          'name': ['John', 'Alice', 'Bob'],\n                          'age': [25, 30, 22]})\n\npurchase_data = pd.DataFrame({'user_id': [1, 2, 1, 3, 4],\n                               'purchase_id': [101, 102, 103, 104, 105],\n                               'amount': [250, 300, 150, 200, 400]})\n\nresult = ... # fill in this part with the appropriate code to achieve the desired DataFrame\n```\n\nExpected Output:\n```plaintext\n   user_id   name   age  purchase_id  amount\n0        1   John  25.0          101  250.00\n1        1   John  25.0          103  150.00\n2        2  Alice  30.0          102  300.00\n3        3    Bob  22.0          104  200.00\n4        4    NaN   NaN          105  400.00\n```",
    "output": "\n```python\nresult = pd.merge(user_info, purchase_data, on='user_id', how='outer').sort_values(by=['user_id', 'purchase_id'])\nresult['amount'] = result['amount'].map('{:.2f}'.format)\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I want to implement a custom loss function that penalizes predictions based on their distance from the target values. Specifically, I want to create a Mean Absolute Error loss that adds an additional penalty of 0.5 for any predictions that exceed the target values. Given two tensors `y_true` and `y_pred`, how can I define this custom loss function to return a scalar loss value?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Compute the base Mean Absolute Error\n    base_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n    # Calculate penalty for predictions exceeding the target\n    penalty = tf.reduce_sum(tf.maximum(y_pred - y_true, 0))\n    # Combine base loss and penalty\n    total_loss = ...\n    return total_loss\n</code>",
    "output": "\n<code>\n    total_loss = base_loss + 0.5 * penalty\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes representing sales transactions and customer information. The first dataframe (sales) contains customer IDs, purchase amounts, and the date of purchase. The second dataframe (customers) lists customer IDs and their corresponding names. I want to merge these two dataframes such that for each transaction, I can see not only the customer ID and purchase amount but also the customer's name. If a transaction does not have a matching customer in the customers dataframe, the name should appear as NaN.\n\nHere\u2019s the data:\n\nsales dataframe:\n```\n   customer_id  amount      date\n0            1     100 2023-01-01\n1            2     150 2023-01-02\n2            3     200 2023-01-03\n3            4     250 2023-01-04\n```\n\ncustomers dataframe:\n```\n   customer_id     name\n0            1   John Doe\n1            2   Jane Smith\n2            5   Alice Brown\n```\n\nThe resulting merged dataframe should have the following structure:\n```\n   customer_id  amount      date         name\n0            1     100 2023-01-01     John Doe\n1            2     150 2023-01-02   Jane Smith\n2            3     200 2023-01-03         NaN\n3            4     250 2023-01-04         NaN\n```\n\nHow can I achieve this with Python code using pandas? You can use the `merge` function from pandas.\n\nA:\n<code>\nimport pandas as pd\n\nsales = pd.DataFrame({'customer_id': [1, 2, 3, 4],\n                      'amount': [100, 150, 200, 250],\n                      'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04']})\n\ncustomers = pd.DataFrame({'customer_id': [1, 2, 5],\n                          'name': ['John Doe', 'Jane Smith', 'Alice Brown']})\n</code>\nmerged_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmerged_df = pd.merge(sales, customers, on='customer_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that tracks daily sales for multiple stores:\n\n```python\nsales_data = pd.DataFrame({\n    'store_id': ['S1', 'S1', 'S2', 'S2', 'S3', 'S3'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'sales': [200, 300, None, 150, None, 100]\n})\n```\n\nThe dates in the DataFrame are not continuous, and some stores have missing sales data for certain dates. I want to generate a complete dataset that includes all dates between the minimum and maximum dates, for each store, while filling in missing sales with the previous day\u2019s sales (if available) or zero otherwise. The desired output should look similar to this:\n\n```\n   store_id        date  sales\n0       S1  2023-01-01  200.0\n1       S1  2023-01-02    0.0\n2       S1  2023-01-03  300.0\n3       S2  2023-01-01    0.0\n4       S2  2023-01-02  150.0\n5       S2  2023-01-03    0.0\n6       S3  2023-01-01    0.0\n7       S3  2023-01-02    0.0\n8       S3  2023-01-03  100.0\n```\n\nWhat is the best way to achieve this using pandas? \n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'store_id': ['S1', 'S1', 'S2', 'S2', 'S3', 'S3'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'sales': [200, 300, None, 150, None, 100]\n})\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndate_range = pd.date_range(start=sales_data['date'].min(), end=sales_data['date'].max())\nall_stores = sales_data['store_id'].unique()\ncomplete_data = pd.MultiIndex.from_product([all_stores, date_range], names=['store_id', 'date']).to_frame(index=False)\ncomplete_data = complete_data.merge(sales_data, on=['store_id', 'date'], how='left').fillna(0)\ncomplete_data['sales'] = complete_data['sales'].ffill().fillna(0)\nresult = complete_data\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\naugmented_images = images.clone()\n```\n\nI can't seem to figure out how to apply the flip operation to `augmented_images` based on the `flip_condition`. \n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\nflip_condition = torch.rand(images.size(0)) > 0.5\naugmented_images = images.clone()\n...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>",
    "output": "\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that calculates the Mean Squared Error (MSE) but only for a specific subset of targets. For example, given an array of predictions and an array of true values, I only want to compute the MSE for the indices specified in a list. \n\nHere\u2019s how the data looks:\n```python\npredictions = tf.constant([0.5, 0.7, 0.9, 0.2, 0.1])\ntrue_values = tf.constant([1.0, 0.0, 1.0, 0.0, 0.0])\nindices = [0, 2, 3]\n```\n\nI need to fill in the blank for the custom loss function that computes the MSE only for the specified indices. \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_loss(predictions, true_values, indices):\n    selected_preds = tf.gather(predictions, indices)\n    selected_true = tf.gather(true_values, indices)\n    return tf.reduce_mean(tf.square(selected_preds - selected_true))\n\npredictions = tf.constant([0.5, 0.7, 0.9, 0.2, 0.1])\ntrue_values = tf.constant([1.0, 0.0, 1.0, 0.0, 0.0])\nindices = [0, 2, 3]\nloss_value = ... # put solution in this variable\nBEGIN SOLUTION\n<code>loss_value = custom_mse_loss(predictions, true_values, indices)</code>",
    "output": "\n<code>loss_value = custom_mse_loss(predictions, true_values, indices)</code>"
  },
  {
    "input": "Problem:\nYou have a dataset representing daily sales records for a retail store, where some records may have missing values for the 'sales' column. The dataframe looks like this:\n\n```python\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [150, None, 200, None, 250],\n    'store_id': [1, 1, 1, 1, 1]\n})\n```\n\nYou want to fill in the missing 'sales' values using advanced imputation techniques based on the previous and next day's sales figures. Specifically, you want to use forward fill followed by backward fill to ensure no missing values remain before any aggregations. \n\nWhat code would you use to fill the missing values in the 'sales' column of the dataframe?\n\nYour result should be assigned to the variable result:\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df['sales'].fillna(method='ffill').fillna(method='bfill')\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI am building a custom loss function based on the mean absolute error (MAE) that incorporates a penalty for predictions that deviate significantly from the actual values. My goal is to multiply the MAE by a penalty factor that ramps up as the error increases. The penalty function is defined as `penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)`, where `threshold` is a fixed value. I want to implement this custom loss function. \n\nGiven `y_true` and `y_pred` as two tensors: \n```python\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nHow can I define the custom loss function that applies the penalty, where `threshold` is set to 1.0?\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\nthreshold = 1.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)\n    return mae * penalty\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am trying to implement a custom loss function to penalize incorrect predictions in a predictive model that should be more sensitive to false negatives. The goal is to create a modified binary cross-entropy loss where false negatives incur a larger penalty than false positives. How can I calculate this custom loss based on the true labels and predicted probabilities?\n\nThe function should take in two tensors: `y_true` (a tensor of shape `(n_samples,)` containing binary labels) and `y_pred` (a tensor of shape `(n_samples,)` containing predicted probabilities). The custom loss should be computed as follows:\n\n\\[ \\text{custom\\_loss} = - \\frac{1}{n} \\sum_{i=1}^{n} (w_1 \\cdot y_{true}[i] \\cdot \\log(y_{pred}[i]) + w_2 \\cdot (1 - y_{true}[i]) \\cdot \\log(1 - y_{pred}[i])) \\]\n\nWhere \\( w_1 \\) is the weight for false negatives (e.g., 2.0) and \\( w_2 \\) is the weight for false positives (e.g., 1.0).\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    w1 = 2.0  # weight for false negatives\n    w2 = 1.0  # weight for false positives\n    n = tf.cast(tf.shape(y_true)[0], tf.float32)\n</code>\nloss = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    loss = -tf.reduce_mean(w1 * y_true * tf.math.log(y_pred + tf.keras.backend.epsilon()) +\n                           w2 * (1 - y_true) * tf.math.log(1 - y_pred + tf.keras.backend.epsilon()))\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to create a custom loss function that implements the Mean Absolute Error (MAE) metric for a regression problem, where the actual values are compared against predictions. However, I want to introduce a weighting factor that emphasizes errors in the positive predictions more heavily. The targets are in a 1-D tensor format (e.g., [3.0, 1.5, 4.0]) and the predictions are also in a similar tensor format (e.g., [2.5, 1.0, 5.0]). The weight for positive predictions is set to 2.0.\n\nI would like to define a function that returns this custom loss. \n\nA:\n<code>\nimport tensorflow as tf\n\nactual = tf.constant([3.0, 1.5, 4.0])\npredictions = tf.constant([2.5, 1.0, 5.0])\nweight = 2.0\n\ndef custom_mae_loss(y_true, y_pred, weight):\n    # return the solution in this function\n    # result = custom_mae_loss(y_true, y_pred, weight)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    absolute_errors = tf.abs(y_true - y_pred)\n    weighted_errors = tf.where(y_pred > 0, absolute_errors * weight, absolute_errors)\n    return tf.reduce_mean(weighted_errors)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor representing image data with shape (num_images, num_channels, height, width) corresponding to a batch of images. I want to apply a mask that will filter out specific image channels based on a given boolean mask tensor of shape (num_channels,). How can I do this using PyTorch to obtain a tensor that only includes the images with the selected channels, while retaining the other dimensions?\n\nHere is the setup I have:\n\n```python\nimport torch\n\nnum_images = 4\nnum_channels = 3\nheight = 32\nwidth = 32\n\nimages = torch.randn(num_images, num_channels, height, width)  # Random image data\nmask = torch.tensor([1, 0, 1], dtype=torch.bool)  # Boolean mask to select channels\n```\n\nI'd like to apply the mask to the `images` tensor. What code should I add below to carry out this operation?\n\nA:\n\n<code>\nresult = ...  # put your solution in this variable\n</code>",
    "output": "\n<code>\nresult = images[:, mask, :, :]\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am developing a custom loss function to improve training on my regression model, which predicts housing prices. I want to implement a loss function that combines Mean Squared Error (MSE) with a penalty for large predictions. The penalty is to be applied only if the predicted price exceeds a threshold of $500,000. If the predicted price exceeds this threshold, an additional loss of 0.1 times the squared difference between the predicted price and the threshold should be added.\n\nHere's a tensor `y_true` for the true prices:\n```\n[450000, 600000, 480000, 700000]\n```\nand a tensor `y_pred` for the predicted prices:\n```\n[430000, 650000, 500000, 750000]\n```\n\nYou need to implement the custom loss function and return the total loss as a scalar tensor. \n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([450000, 600000, 480000, 700000], dtype=tf.float32)\ny_pred = tf.constant([430000, 650000, 500000, 750000], dtype=tf.float32)\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the mean squared error\n    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n    # Penalty for exceeding the threshold\n    penalty = tf.reduce_mean(tf.where(y_pred > 500000, \n                                      0.1 * tf.square(y_pred - 500000), \n                                      0.0))\n    # Combine both losses\n    total_loss = ...  # put solution in this variable\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    total_loss = mse_loss + penalty\n    return total_loss\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, `sales` and `returns`, structured as follows:\n\n`sales`:\n```\n   order_id  customer_id  amount\n0         1           101     100\n1         2           102     200\n2         3           101     150\n3         4           103     300\n```\n\n`returns`:\n```\n   return_id  customer_id  amount\n0          A           101      50\n1          B           102      100\n2          C           104      200\n```\n\nI want to merge these DataFrames such that each `customer_id` from `sales` retains its related `amount` value, while matching `customer_id` in `returns` reduces the `amount` from `sales` by the corresponding amount from `returns`. If a `customer_id` in `returns` does not exist in `sales`, it should not affect the final DataFrame. The expected result should include all original rows from `sales`, and an additional column `final_amount` reflecting the adjustments from the `returns` DataFrame.\n\nThe result should look like this:\n```\n   order_id  customer_id  amount  final_amount\n0         1           101     100            50\n1         2           102     200           100\n2         3           101     150            100\n3         4           103     300            300\n```\n\nI tried using a left merge, but I'm unsure how to implement the logic to calculate the `final_amount`.\n\nA:\n<code>\nimport pandas as pd\n\nsales = pd.DataFrame({'order_id': [1, 2, 3, 4],\n                      'customer_id': [101, 102, 101, 103],\n                      'amount': [100, 200, 150, 300]})\n\nreturns = pd.DataFrame({'return_id': ['A', 'B', 'C'],\n                        'customer_id': [101, 102, 104],\n                        'amount': [50, 100, 200]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = sales.merge(returns.groupby('customer_id', as_index=False).sum(), on='customer_id', how='left', suffixes=('', '_return'))\nresult['final_amount'] = result['amount'] - result['amount_return'].fillna(0)\nresult = result[['order_id', 'customer_id', 'amount', 'final_amount']]\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes that record sales information. The first dataframe contains the product IDs and their respective sales in quantity per day, while the second dataframe contains product IDs and their corresponding prices. \n\nHere are the dataframes:\n\ndf_sales:\n| product_id | sales_quantity | sales_date  |\n|------------|----------------|--------------|\n| A          | 5              | 2023-01-01   |\n| B          | 3              | 2023-01-01   |\n| A          | 2              | 2023-01-02   |\n| B          | 1              | 2023-01-02   |\n| C          | 4              | 2023-01-01   |\n\ndf_prices:\n| product_id | price |\n|------------|-------|\n| A          | 10    |\n| B          | 15    |\n| C          | 20    |\n\nI want to create a new dataframe that summarizes the total sales value for each product per day, calculated by multiplying the sales quantity by the product price. The resulting dataframe should include these columns: `sales_date`, `product_id`, `total_sales_value`.\n\nHow can I achieve this in a single merging operation?\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': ['A', 'B', 'A', 'B', 'C'],\n    'sales_quantity': [5, 3, 2, 1, 4],\n    'sales_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01']\n})\n\ndf_prices = pd.DataFrame({\n    'product_id': ['A', 'B', 'C'],\n    'price': [10, 15, 20]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_prices, on='product_id').assign(total_sales_value=lambda x: x.sales_quantity * x.price)[['sales_date', 'product_id', 'total_sales_value']]\n</code>"
  },
  {
    "input": "Problem:\n\nI have a set of image data represented as a 4D PyTorch tensor. Each image is of size (channels, height, width), and I wish to apply a resizing operation to all images in the batch to a target size of (new_height, new_width). The new dimensions vary based on the size of the original images, and I would like to apply bilinear interpolation for this resizing.\n\nGiven a tensor `images` of shape `(batch_size, channels, height, width)`, how can I resize the images to a new height of 64 and a new width of 64?\n\nFor example, if `images` is of shape `(4, 3, 128, 128)`, the goal is to transform it to shape `(4, 3, 64, 64)`.\n\nA:\n\n<code>\nimport torch\nimages = load_data()\n</code>\nresized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresized_images = torch.nn.functional.interpolate(images, size=(64, 64), mode='bilinear', align_corners=False)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a sequence of time series data stored in a 3D tensor with the shape (batch_size, sequence_length, features). You need to extract a sliding window of size `window_size` from this tensor, where each window overlaps with the previous one by `step_size`. Your output should be a 4D tensor containing all the sliding windows, preserving the batch dimension.\n\nFor instance, if you have a tensor of shape (2, 5, 3) and you want to create windows of size 3 with a step size of 1, your output should be a tensor of shape (2, 3, 3, 3), where the second dimension corresponds to the number of windows extracted.\n\nHere's the current setup:\n\n```python\nimport torch\ndata = load_data()  # shape is (batch_size, sequence_length, features)\nwindow_size = 3\nstep_size = 1\n```\n\nHow can you generate the sliding windows and obtain the desired shape? \n\nA:\n\n<code>\nwindows = ... # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nwindows = data.unfold(1, window_size, step_size)  # shape will be (batch_size, num_windows, window_size, features)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W) where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is where I need help.\n```\n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\nresult = images\n</code>"
  },
  {
    "input": "Problem:\nContext  \nI have two datasets that track product sales from different sources. The first dataset comprises product information, and the second dataset includes sales details.\n\nProblem  \nThe first Pandas DataFrame looks like this:\n\n| ProductID | ProductName   | Price |\n|-----------|---------------|-------|\n| 101       | Widget A      | 25.0  |\n| 102       | Widget B      | 30.0  |\n| 103       | Widget C      | 22.5  |\n\nThe second DataFrame is structured as follows:\n\n| ProductID | SalesDate | Quantity |\n|-----------|-----------|----------|\n| 101       | 2023-01-01| 100      |\n| 101       | 2023-01-02| 120      |\n| 102       | 2023-01-01| 80       |\n| 103       | 2023-01-03| 150      |\n| 103       | 2023-01-02| 90       |\n\nI want to merge these two DataFrames into one that shows each product's name, price, total quantity sold, and the latest sales date, excluding any product IDs not present in both datasets. The desired final DataFrame should look like this:\n\n| ProductID | ProductName | Price | TotalQuantity | LatestSalesDate |\n|-----------|-------------|-------|---------------|------------------|\n| 101       | Widget A    | 25.0  | 220           | 2023-01-02       |\n| 102       | Widget B    | 30.0  | 80            | 2023-01-01       |\n| 103       | Widget C    | 22.5  | 240           | 2023-01-03       |\n\nUsing SQL, I might have written something like:\n```sql\nSELECT p.ProductID, p.ProductName, p.Price, SUM(s.Quantity) AS TotalQuantity, MAX(s.SalesDate) AS LatestSalesDate\nFROM Products AS p \nJOIN Sales AS s ON p.ProductID = s.ProductID \nGROUP BY p.ProductID, p.ProductName, p.Price;\n```\n\nI want to achieve this result in Pandas. Here is what I have tried:\n\n```python\nimport pandas as pd\n\ndf_products = pd.DataFrame({'ProductID': [101, 102, 103], \n                            'ProductName': ['Widget A', 'Widget B', 'Widget C'], \n                            'Price': [25.0, 30.0, 22.5]})\n\ndf_sales = pd.DataFrame({'ProductID': [101, 101, 102, 103, 103], \n                         'SalesDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'], \n                         'Quantity': [100, 120, 80, 150, 90]})\n\n# How can I merge these DataFrames to achieve the final result?\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\nresult = df_products.merge(df_sales.groupby('ProductID').agg(TotalQuantity=('Quantity', 'sum'), LatestSalesDate=('SalesDate', 'max')).reset_index(), on='ProductID')\n```"
  },
  {
    "input": "Problem:\n\nYou are working with images represented as 4D tensors in PyTorch, with shape (batch_size, channels, height, width). For an image preprocessing step, you want to dynamically resize each image to a fixed size of (height, width) = (128, 128) while maintaining the aspect ratio by padding the shorter dimension with zeros. \n\nAssuming your input tensor `images` has the shape (4, 3, 300, 400), you need to create a new tensor `resized_images` that contains all the images resized to the shape (4, 3, 128, 128) with appropriate padding.\n\nFill in the code to perform this operation.\n\nA:\n\n<code>\nimport torch\nimages = load_data()  # shape: (4, 3, 300, 400)\nresized_images = ...  # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nimport torch\nimport torch.nn.functional as F\n\nimages = load_data()  # shape: (4, 3, 300, 400)\nbatch_size, channels, height, width = images.shape\ntarget_size = (128, 128)\n\n# Calculate the aspect ratio\naspect_ratio = height / width\nif aspect_ratio > 1:  # Height is greater\n    new_height = target_size[0]\n    new_width = int(target_size[0] / aspect_ratio)\nelse:  # Width is greater or equal\n    new_width = target_size[1]\n    new_height = int(target_size[1] * aspect_ratio)\n\n# Resize images\nresized_images = F.interpolate(images, size=(new_height, new_width), mode='bilinear', align_corners=False)\n\n# Pad images to target size\npad_height = target_size[0] - new_height\npad_width = target_size[1] - new_width\nresized_images = F.pad(resized_images, (0, pad_width, 0, pad_height), mode='constant', value=0)\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor representing image pixel values with a shape of (batch_size, channels, height, width), where each value is in the range of [0, 255]. I want to normalize each channel of the tensor independently to the range [0, 1]. \n\nThe tensor `images` is of shape (32, 3, 256, 256), where 32 represents the batch size, 3 is the number of channels (e.g., RGB), and 256x256 are the height and width dimensions of the images.\n\nHow can I normalize each channel by subtracting its minimum value and dividing by the range (max - min) for that channel?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.randint(0, 256, (32, 3, 256, 256), dtype=torch.float32)\nnormalized_images = ... # put solution in this variable\n### BEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmin_vals = images.min(dim=(0, 2, 3), keepdim=True)[0]\nmax_vals = images.max(dim=(0, 2, 3), keepdim=True)[0]\nnormalized_images = (images - min_vals) / (max_vals - min_vals)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W) where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is not working as intended.\n```\n\nI expected the images to be flipped, but it seems like I need a more efficient approach to handle this. \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\n# Given tensor of images\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n\n# [Your implementation here]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\n</code>",
    "output": "\n<code>\nimages = torch.where(torch.rand(images.size(0), 1, 1, 1) < 0.5, flip_image(images), images)\n</code>"
  },
  {
    "input": "## Problem:\nYou have a DataFrame containing the daily temperature readings for multiple cities over a month. The DataFrame looks like this:\n\n```\n   City       Date  Temperature\n0  CityA 2023-10-01          20\n1  CityA 2023-10-02          NaN\n2  CityA 2023-10-03          22\n3  CityB 2023-10-01          18\n4  CityB 2023-10-02          NaN\n5  CityB 2023-10-03          NaN\n6  CityB 2023-10-04          19\n```\n\nYou noticed that some of the temperature readings are missing (NaN). You want to fill these NaN values using the forward fill method combined with the backward fill method to ensure that each city's temperature reading reflects the nearest known values. \n\nFurthermore, you would like to compute the mean temperature for each city after filling the missing values.\n\nGiven this setup, what code will fill the missing temperature values as described and store the resulting DataFrame in the variable `filled_df`?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'City': ['CityA', 'CityA', 'CityA', 'CityB', 'CityB', 'CityB', 'CityB'],\n    'Date': pd.to_datetime(['2023-10-01', '2023-10-02', '2023-10-03', \n                             '2023-10-01', '2023-10-02', '2023-10-03', \n                             '2023-10-04']),\n    'Temperature': [20, np.nan, 22, 18, np.nan, np.nan, 19]\n}\n\ndf = pd.DataFrame(data)\n</code>\nfilled_df = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfilled_df = df.groupby('City')['Temperature'].ffill().bfill().reset_index()\nfilled_df['Mean_Temperature'] = filled_df.groupby('City')['Temperature'].transform('mean')\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to create a new tensor `augmented_images` that contains the augmented images.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    # This function will flip the input image tensor vertically\n    return image.flip(1)\n```\n\nI have loaded my image tensor as follows:\n\n```python\nimport torch\n\nimages = torch.randn(10, 3, 32, 32)  # for example, a batch of 10 images\n```\n\nNow I need to fill in the blank to generate the `augmented_images` tensor using a list comprehension that applies `flip_image` to each image with the specified flipping probability.\n\nHere\u2019s where I need your help:\n\n```python\naugmented_images = torch.stack([flip_image(image) if torch.rand(1).item() < 0.5 else image for image in images])\n```\n\nPlease fill in the blank for the code above to generate the augmented images correctly.",
    "output": "\n```python\naugmented_images = torch.stack([flip_image(image) if torch.rand(1).item() < 0.5 else image for image in images])\n```"
  },
  {
    "input": "Problem:\nYou are working on a data analysis project where you have two datasets that need to be merged based on a common column. The first dataset (`sales_data`) contains information about sales, including the date and product ID, while the second dataset (`product_info`) contains details about the products, including product ID and category.\n\nHere is the `sales_data` DataFrame:\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'product_id': [101, 102, 101, 103],\n    'amount': [250, 300, 150, 400]\n})\n\nproduct_info = pd.DataFrame({\n    'product_id': [101, 102, 103],\n    'category': ['Electronics', 'Toys', 'Books']\n})\n```\n\nYou want to create a new DataFrame (`merged_data`) that includes all columns from `sales_data` and only the `category` column from `product_info`. The result should keep all records from `sales_data` even if a corresponding product ID does not exist in `product_info`.\n\nHow can you accomplish this in pandas?\n\nPlease complete the following line to merge the two DataFrames:\n```python\nmerged_data = ...\n```",
    "output": "\n```python\nmerged_data = pd.merge(sales_data, product_info[['product_id', 'category']], on='product_id', how='left')\n```"
  },
  {
    "input": "Problem:\nI have a dataframe resembling the following:\n\n```python\ndata = {\n    'product_id': [1, 1, 2, 2, 3],\n    'sales': [100, 150, None, 200, None],\n    'month': ['2020-01', '2020-02', '2020-01', '2020-02', '2020-01']\n}\ndf = pd.DataFrame(data)\n```\n\nI need to fill the missing sales values in the `sales` column using the sales values from the same product in other months while ensuring that any existing sales values remain unchanged. For products with no previous sales data in the dataframe, insert a default value of 0. The resulting dataframe should maintain the month-wise sales continuity.\n\nThe expected result should look like this:\n\n```python\n   product_id  sales     month\n0           1  100.0  2020-01\n1           1  150.0  2020-02\n2           2    0.0  2020-01\n3           2  200.0  2020-02\n4           3    0.0  2020-01\n```\n\nHow can I achieve this using pandas? \n\nUse the following starter code:\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 2, 2, 3],\n    'sales': [100, 150, None, 200, None],\n    'month': ['2020-01', '2020-02', '2020-01', '2020-02', '2020-01']\n}\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df.groupby('product_id')['sales'].transform(lambda x: x.fillna(method='ffill').fillna(0))\ndf['sales'] = df['sales'].fillna(result)\n```"
  },
  {
    "input": "Problem:\n\nI am working on a neural network model using PyTorch, where I need to normalize the output of each layer. Given an n x m tensor representing the output of my layer, I want to compute the z-score normalization for each feature (column) individually. The z-score is defined as (X - mean) / stddev, where X is the input tensor, mean is the mean value of the column, and stddev is the standard deviation of the column.\n\nHere's a sample output tensor:\n\n[[1.0, 2.0, 3.0],\n [4.0, 5.0, 6.0],\n [7.0, 8.0, 9.0]]\n\nI need to return the z-score normalized tensor with the same dimensions. How can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\noutput_tensor = load_data()\ndef z_score_normalization(output_tensor):\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    mean = output_tensor.mean(dim=0)\n    stddev = output_tensor.std(dim=0)\n    normalized_tensor = (output_tensor - mean) / stddev\n    return normalized_tensor\n</code>"
  },
  {
    "input": "## Problem\nYou have two DataFrames representing customer orders and customer details:\n\n**orders_df**\n```\n   order_id  customer_id  amount\n0        1            1    100.0\n1        2            2    150.0\n2        3            1    200.0\n3        4            3    50.0\n```\n\n**customers_df**\n```\n   customer_id   name         country\n0            1  Alice  United States\n1            2    Bob         Canada\n2            3  Carol         Canada\n3            4  David       Australia\n```\n\nYour task is to merge these two DataFrames to create a new DataFrame that includes all orders along with the corresponding customer name and country, but excluding customers who do not have made any orders. The resulting DataFrame should only include the columns: `order_id`, `customer_id`, `name`, `amount`, and `country`.\n\nYou are currently unsure how to appropriately filter the merged results to meet these requirements. Here's the initial setup:\n\n```python\nimport pandas as pd\n\norders_df = pd.DataFrame({\n    'order_id': [1, 2, 3, 4],\n    'customer_id': [1, 2, 1, 3],\n    'amount': [100.0, 150.0, 200.0, 50.0]\n})\n\ncustomers_df = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'name': ['Alice', 'Bob', 'Carol', 'David'],\n    'country': ['United States', 'Canada', 'Canada', 'Australia']\n})\n```\n\nNow, fill in the blank to merge the DataFrames and achieve the desired result.\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = orders_df.merge(customers_df, on='customer_id', how='inner')[['order_id', 'customer_id', 'name', 'amount', 'country']]\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to create a custom loss function for a regression task which penalizes predictions that are more than a threshold away from the true values. Specifically, if the absolute difference between the predicted and actual values exceeds a certain threshold, I want to apply a quadratic penalty. If the difference is within the threshold, I want a linear penalty. For this, I have a threshold of 0.5. How can I implement this as a loss function? \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 0.5\n    loss = ... # Fill in the solution here\n    return loss\n</code>",
    "output": "\n<code>\n    diff = tf.abs(y_true - y_pred)\n    quadratic_penalty = tf.square(diff - threshold)\n    linear_penalty = diff - threshold\n    loss = tf.where(diff > threshold, quadratic_penalty, linear_penalty)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels, 32x32 pixels\n```\n\nNow, I want to apply the `flip_image` function to each image in the `images` tensor based on the flip probability. I need to fill in the blank for the following line of code:\n\n```python\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```\n\nWhat would be the correct approach to perform this operation? \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor\naugmented_images = ...  # put solution in this variable\n</code>",
    "output": "\n<code>\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe containing sales data as follows:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'store': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-01', '2022-01-03', '2022-01-02', '2022-01-04'],\n    'sales': [100, None, 200, 150, None, 300]\n})\n```\n\nI want to fill in the missing sales values in the `sales` column using the sales values from the same store on other dates, specifically by applying forward fill if earlier sales exist, and backward fill if no earlier sales exist for a specific store. \n\nThus, the desired output for the `sales_data` dataframe should look like this:\n\n```\n  store        date  sales\n0    A  2022-01-01  100.0\n1    A  2022-01-02  100.0\n2    B  2022-01-01  200.0\n3    B  2022-01-03  150.0\n4    C  2022-01-02  300.0\n5    C  2022-01-04  300.0\n```\n\nWhat code can I use to achieve this filling technique?\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.groupby('store')['sales'].apply(lambda x: x.ffill().bfill())\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to create a custom loss function to implement a modified Mean Absolute Error (MAE) that scales the error based on the predicted values. The formula for the scaled MAE will be defined as follows: \nMAE = mean(abs(y_true - y_pred) / (y_pred + 1e-6)), where y_true are the true values, and y_pred are the predicted values.\n\nNow, I need to implement this function. How can I fill in the blank to achieve this?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef scaled_mae(y_true, y_pred):\n    # Implement the scaled Mean Absolute Error as described \n    return ...  # fill in the implementation here\n```",
    "output": "\n<code>\nimport tensorflow as tf\n\ndef scaled_mae(y_true, y_pred):\n    return tf.reduce_mean(tf.abs(y_true - y_pred) / (y_pred + 1e-6))\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing monthly sales data for various products as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 1, 3, 2, 3],\n    'month': ['2022-01', '2022-01', '2022-02', '2022-01', '2022-02', '2022-02'],\n    'sales': [120, None, 150, None, 200, 170]\n}\ndf = pd.DataFrame(data)\n```\n\nThe sales column has NaN values that need to be filled. You aim to fill these NaN values using forward-fill based on the product_id and month, followed by filling any remaining NaNs with the overall mean of the sales column. After this, you want to ensure the sales values are rounded to the nearest integer.\n\nWhat is the line of code that can achieve this? \n\nThe expected output should look like this:\n\n```\n   product_id     month  sales\n0          1  2022-01  120.0\n1          2  2022-01  110.0\n2          1  2022-02  150.0\n3          3  2022-01  135.0\n4          2  2022-02  200.0\n5          3  2022-02  170.0\n```\n\nFill in the missing line of code:\n\n```python\ndf['sales'] = ...\n```",
    "output": "\n```python\ndf['sales'] = df.groupby('product_id')['sales'].ffill().fillna(df['sales'].mean()).round()\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a neural network that requires the concatenation of two tensors, `tensor1` and `tensor2`, both of size (5, 3). However, they are being produced at different times in your data pipeline, and `tensor2` may come in as a (2, 3) tensor (representing a batch of inputs) due to variable input sequences in your data. You want to ensure that both tensors are compatible in shape for concatenation by padding `tensor2` with zeros if it has fewer than 5 rows.\n\nWrite a code snippet to concatenate `tensor1` and `tensor2` along the first dimension after appropriate padding so the resulting tensor has a shape of (7, 3).\n\nA:\n\n<code>\nimport torch\ntensor1 = load_data()\ntensor2 = load_data()\n</code>\nresult_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nif tensor2.size(0) < 5:\n    padding = (0, 0, 0, 5 - tensor2.size(0))  # (padding_left, padding_right, padding_top, padding_bottom)\n    tensor2 = torch.nn.functional.pad(tensor2, padding)\nresult_tensor = torch.cat((tensor1, tensor2), dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a neural network model that processes image data. You have two tensors, `images` and `labels`, given as:\n\n- `images` of shape (64, 3, 224, 224), representing a batch of 64 RGB images of size 224x224.\n- `labels` of shape (64,), representing the class labels for each of the 64 images.\n\nYour task is to create a new tensor that combines both `images` and `labels` into a single tensor with shape (64, 4, 224, 224). This new tensor should append a channel of zeros to each image for the additional dimension corresponding to the label.\n\nHow can you achieve this without altering the number of images and while preserving the existing tensor structure?\n\nA:\n\n<code>\nimport torch\nimages, labels = load_data()\n</code>\ncombined_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncombined_tensor = torch.cat((images, torch.zeros(images.size(0), 1, images.size(2), images.size(3))), dim=1)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor `data` with the shape of (2, 5, 4) representing batches of features, where each batch contains 5 samples with 4 feature values each. Your goal is to perform a dynamic manipulation to calculate the mean across the first dimension (batch dimension) for each feature across all samples.\n\nThe resulting tensor should have a shape of (5, 4), containing the mean feature values for each of the 5 samples.\n\nHere is the setup you have:\n\n```python\nimport torch\ndata = load_data()  # should be a tensor of shape (2, 5, 4)\n```\n\nHow can you compute the means across the batches to achieve the desired shape in a single line of code?\n\nA:\n\n```python\nmeans = ...  # put solution in this variable\n```",
    "output": "\n```python\nmeans = data.mean(dim=0)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____\n])\n\n# Sample image tensor\nimage = torch.randn(3, 256, 256)  # Example image tensor of shape (C, H, W)\n\ntransformed_image = data_transforms(image)\n```\n\nA:\n\n<code>\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____\n])\n\n# Sample image tensor\nimage = torch.randn(3, 256, 256)  # Example image tensor of shape (C, H, W)\n\ntransformed_image = data_transforms(image)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n</code>",
    "output": "\n<code>\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n</code>"
  },
  {
    "input": "Problem:\nI have the following DataFrame containing data about students and their scores:\n\n```\n   student_id   score Mathematics Science \n0           1  89.0       95.0     NaN    \n1           2   NaN       85.0     90.0   \n2           3  77.0       NaN       NaN   \n3           4  90.0       92.0     88.0   \n4           5   NaN       70.0     78.0   \n```\n\nI want to impute the missing values in the 'score' column using the mean of the corresponding subject scores (Mathematics and Science) for each student. If any subject score is available for a student, use the mean from the available scores to fill in the missing 'score'. The expected DataFrame after imputation should maintain the original structure and values with filled `NaN` entries.\n\nWhat is the code to achieve this using `pandas`?\n\n```python\nimport pandas as pd\n\ndata = {\n    'student_id': [1, 2, 3, 4, 5],\n    'score': [89.0, None, 77.0, 90.0, None],\n    'Mathematics': [95.0, 85.0, None, 92.0, 70.0],\n    'Science': [None, 90.0, None, 88.0, 78.0]\n}\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['score'] = df[['Mathematics', 'Science']].mean(axis=1).where(df['score'].isna(), df['score'])\nresult = df\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing user activity over time:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'user_id': ['U1', 'U1', 'U2', 'U2', 'U3'],\n    'activity_date': ['2021-03-01', '2021-03-02', '2021-03-01', None, '2021-03-05'],\n    'activity_score': [10, None, 15, None, 20]\n})\n```\n\nWhat I would like to achieve is to fill in the missing values in the `activity_date` column with sequential dates starting from the minimum date for each user in a way such that if a user has missing `activity_date`, their most recent previous date is used to fill it in. Additionally, I want to fill the `activity_score` column with the average score of each user for any missing entries.\n\nThe desired output should look like this:\n```\n  user_id activity_date  activity_score\n0     U1    2021-03-01             10\n1     U1    2021-03-02             10\n2     U2    2021-03-01             15\n3     U2    2021-03-02             15\n4     U3    2021-03-05             20\n```\n\nPlease fill in the code below to solve this problem:\n\n```python\n# Your solution starts here\nresult = ...\n```",
    "output": "\n```python\n# Your solution starts here\ndf['activity_date'] = pd.to_datetime(df['activity_date'])\ndf['activity_score'] = df.groupby('user_id')['activity_score'].transform(lambda x: x.fillna(x.mean()))\ndf = df.sort_values(by=['user_id', 'activity_date'])\ndf['activity_date'] = df.groupby('user_id')['activity_date'].ffill()\ndf['activity_date'] = df.groupby('user_id')['activity_date'].apply(lambda x: x.ffill().bfill().sort_values().reset_index(drop=True))\nresult = df.drop_duplicates().reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI have two separate pandas DataFrames that need to be merged based on a common column, while ensuring that I keep specific columns from each DataFrame. The first DataFrame contains customer details, while the second contains order details. \n\nHere's what they look like:\n\nCustomer DataFrame:\n```\ncustomer_id    name     age\n0           101   Alice      30\n1           102     Bob      22\n2           103   Charlie    35\n```\n\nOrder DataFrame:\n```\norder_id    customer_id   amount\n0        1001           101      250\n1        1002           102      150\n2        1003           103      450\n3        1004           101      300\n```\n\nI want to merge them such that I get a DataFrame with `customer_id`, `name`, and `amount`, but I do not want the `age` from the first DataFrame or the `order_id` from the second DataFrame in the final result.\n\nCan you provide the code necessary to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ncustomers = pd.DataFrame({'customer_id': [101, 102, 103],\n                          'name': ['Alice', 'Bob', 'Charlie'],\n                          'age': [30, 22, 35]})\n\norders = pd.DataFrame({'order_id': [1001, 1002, 1003, 1004],\n                       'customer_id': [101, 102, 103, 101],\n                       'amount': [250, 150, 450, 300]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = pd.merge(customers[['customer_id', 'name']], orders[['customer_id', 'amount']], on='customer_id')\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a PyTorch model where I need to perform element-wise multiplication between two tensors that have different shapes. Specifically, I have a tensor A of shape (4, 3) and a tensor B of shape (4, 1). I want to broadcast tensor B to match the shape of tensor A, so that I can perform the multiplication neatly.\n\nGiven the tensors A and B:\n\n<code>\nimport torch\nA = torch.randn(4, 3)\nB = torch.randn(4, 1)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = A * B\n</code>"
  },
  {
    "input": "## Problem\nYou are working with two pandas DataFrames that represent sales data across different regions. The first DataFrame `sales` contains information about sales transactions, while the second DataFrame `regions` provides the corresponding region names.\n\n```python\nimport pandas as pd\n\n# Creating the sales DataFrame\nsales_data = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'region_id': [101, 102, 103, 101, 103],\n    'amount': [250, 150, 200, 300, 100]\n}\nsales = pd.DataFrame(sales_data)\n\n# Creating the regions DataFrame\nregions_data = {\n    'region_id': [101, 102, 103],\n    'region_name': ['North', 'South', 'East']\n}\nregions = pd.DataFrame(regions_data)\n```\n\nYou want to create a new DataFrame that combines both `sales` and `regions`, where each transaction is associated with its region name. The resulting DataFrame should look like this:\n\n```\n   transaction_id  region_id  amount region_name\n0               1        101     250        North\n1               2        102     150        South\n2               3        103     200         East\n3               4        101     300        North\n4               5        103     100         East\n```\n\nIn terms of code, how do you achieve this merging operation?\n\n```python\nmerged_df = ... # put solution in this variable\n```",
    "output": "\n```python\nmerged_df = pd.merge(sales, regions, on='region_id')\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function for my regression model that emphasizes the prediction errors more heavily for large differences. Specifically, I'd like to implement a modified Mean Absolute Error (MAE) where any absolute difference greater than a threshold (let's say 1.0) is penalized more heavily by a factor (let's say 2.0). I have already defined my true values and prediction values as tensors:\n\n```python\ntrue_values = tf.constant([1.0, 2.0, 3.0, 4.0])\npredicted_values = tf.constant([1.5, 1.0, 4.0, 3.0])\n```\n\nNow, I need to define the custom loss function called `custom_mae_loss` which will compute the loss based on the criteria mentioned.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mae_loss(true, predicted, threshold=1.0, penalty=2.0):\n    # return the calculated custom MAE loss\n    ### BEGIN SOLUTION\n```",
    "output": "\n<code>\n    abs_diff = tf.abs(true - predicted)\n    loss = tf.where(abs_diff > threshold, abs_diff * penalty, abs_diff)\n    return tf.reduce_mean(loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nSuppose you have two pandas DataFrames: `employees` and `departments`. The `employees` DataFrame contains employee information, and the `departments` DataFrame contains department details. Your goal is to perform a merge operation where you include employee details alongside their respective department information, ensuring to include all employees even those who might not belong to any department.\n\nHere are the DataFrames:\n\n```python\nimport pandas as pd\n\nemployees = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4],\n    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'DepartmentID': [100, 101, None, 100]\n})\n\ndepartments = pd.DataFrame({\n    'DepartmentID': [100, 101, 102],\n    'DepartmentName': ['HR', 'Finance', 'IT']\n})\n```\n\nYou want to merge these two DataFrames such that the resulting DataFrame contains the following columns: `EmployeeID`, `Name`, `DepartmentID`, and `DepartmentName`. If an employee belongs to a department, the department's name should appear; if not, it should show as `NaN`.\n\nHow should you fill in the blank to achieve this via a left merge?\n\n```python\nresult = pd.merge(____, _____, how='left', on='DepartmentID')\n```\n",
    "output": "\n```python\nresult = pd.merge(employees, departments, how='left', on='DepartmentID')\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations.\n\nHere\u2019s a partial implementation:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\n```\n\nWhat function should I use to complete the `transform` to resize the images to 128x128 pixels before applying other augmentations?\n\nA:\n\n<code>\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.Resize((128, 128)).\n",
    "output": "\n<code>\ntransforms.Resize((128, 128)),\n</code>"
  },
  {
    "input": "Problem:\nYou have two DataFrames, X and Y, which represent sales data for two different regions. The DataFrames are structured as follows:\n\nX\n```\n   Region  Product   Sales\n0   East     A       100\n1   East     B       200\n2   West     A       150\n3   West     C       300\n```\n\nY\n```\n   Region  Product   Sales\n0   East     A       120\n1   West     B       250\n2   West     C       350\n3   East     D       400\n```\n\nYou need to merge both DataFrames such that:\n- The resulting DataFrame includes sales from both regions.\n- If the same Region and Product combination exists in both DataFrames, take the Sales value from DataFrame Y.\n- Also, add a new column 'ExistsInBoth' that indicates whether a specific Region-Product combination exists in both DataFrames (True) or not (False).\n\nThe final DataFrame should retain the row order based on DataFrame X while updating the sales values from Y where applicable.\n\nThe merged DataFrame should look like this:\n```\n   Region  Product   Sales   ExistsInBoth\n0   East     A       120        True\n1   East     B       200        False\n2   West     A       150        False\n3   West     C       350        True\n```\n\nA:\n<code>\nimport pandas as pd\n\nX = pd.DataFrame({\n    'Region': ['East', 'East', 'West', 'West'],\n    'Product': ['A', 'B', 'A', 'C'],\n    'Sales': [100, 200, 150, 300]\n})\n\nY = pd.DataFrame({\n    'Region': ['East', 'West', 'West', 'East'],\n    'Product': ['A', 'B', 'C', 'D'],\n    'Sales': [120, 250, 350, 400]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(X, Y, on=['Region', 'Product'], how='left', suffixes=('', '_Y')).fillna(0)\nresult['Sales'] = result['Sales_Y'].replace(0, result['Sales'])\nresult['ExistsInBoth'] = result['Sales_Y'].ne(0)\nresult = result[['Region', 'Product', 'Sales', 'ExistsInBoth']]\n</code>"
  },
  {
    "input": "Problem:\nI have two dataframes containing sales data from different regions. The first dataframe contains regional sales and is structured like this:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Sales': [200, 150, 300, 250],\n    'Q2_Sales': [250, 200, 350, 300]\n})\n```\n\nThe second dataframe contains regional targets for the quarters, structured as follows:\n\n```python\ndf_targets = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Target': [220, 160, 320, 260],\n    'Q2_Target': [270, 210, 360, 310]\n})\n```\n\nI want to merge these two dataframes on the 'Region' column, resulting in a single dataframe that contains all sales and target data by region. The merged dataframe should look like this:\n\n```\n  Region  Q1_Sales  Q2_Sales  Q1_Target  Q2_Target\n0  North       200       250        220        270\n1  South       150       200        160        210\n2   East       300       350        320        360\n3   West       250       300        260        310\n```\n\nHow can I achieve this? \n\nA:\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Sales': [200, 150, 300, 250],\n    'Q2_Sales': [250, 200, 350, 300]\n})\n\ndf_targets = pd.DataFrame({\n    'Region': ['North', 'South', 'East', 'West'],\n    'Q1_Target': [220, 160, 320, 260],\n    'Q2_Target': [270, 210, 360, 310]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_targets, on='Region')\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to apply this function to each image in the dataset based on the provided probability.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flip the image vertically (along height)\n```\n\nYou need to fill in the following code to apply the augmentation:\n\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>\n```\n\nresult = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>flip_image(images[i])</code>",
    "output": "\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>flip_image(images[i])</code>\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame with missing values like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan, 5],\n    'B': [np.nan, 2, np.nan, 4, np.nan],\n    'C': [1, 2, 3, 4, 5]\n})\n```\n\nI would like to use an efficient method to fill the missing values in column 'A' with the mean of the column, and for column 'B', I want to fill the NaN values using forward fill for the first NaN and backward fill for the remaining NaNs. The expected output should look like this:\n\n```\n     A    B  C\n0  1.0  NaN  1\n1  3.0  2.0  2\n2  3.0  2.0  3\n3  4.0  4.0  4\n4  5.0  4.0  5\n```\n\nWhat would be an efficient way to achieve this?\n\nA:\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.copy()\nresult['A'].fillna(result['A'].mean(), inplace=True)\nresult['B'].fillna(method='ffill', limit=1, inplace=True)\nresult['B'].fillna(method='bfill', inplace=True)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily average temperature and humidity levels recorded over a month in two separate DataFrames:\n\ntemperature_df:\n+------------+-------------+\n| Date       | AvgTemp     |\n+------------+-------------+\n| 2022-01-01 | 25          |\n| 2022-01-03 | 30          |\n| 2022-01-04 | 28          |\n| 2022-01-05 | NaN         |\n| 2022-01-07 | 32          |\n+------------+-------------+\n\nhumidity_df:\n+------------+--------------+\n| Date       | AvgHumidity   |\n+------------+--------------+\n| 2022-01-01 | 60           |\n| 2022-01-02 | 65           |\n| 2022-01-03 | NaN          |\n| 2022-01-05 | 70           |\n| 2022-01-06 | NaN          |\n| 2022-01-07 | 55           |\n+------------+--------------+\n\nYou want to merge these two datasets into a single DataFrame, ensuring that for each missing value in AvgTemp, you utilize the value from the nearest available date within the same column. Similarly, for AvgHumidity, if there\u2019s a NaN, fill it using the same technique, allowing for forward filling.\n\nAfter merging, the final DataFrame should look something like this:\n\n+------------+-------------+--------------+\n| Date       | AvgTemp     | AvgHumidity   |\n+------------+-------------+--------------+\n| 2022-01-01 | 25          | 60           |\n| 2022-01-02 | 25          | 65           |\n| 2022-01-03 | 30          | 65           |\n| 2022-01-04 | 28          | 65           |\n| 2022-01-05 | 28          | 70           |\n| 2022-01-06 | 28          | 70           |\n| 2022-01-07 | 32          | 55           |\n+------------+-------------+--------------+\n\nPlease provide the code to perform the merging and filling of missing values. \n\n```python\nimport pandas as pd\n\ntemperature_df = pd.DataFrame({\n    'Date': ['2022-01-01', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-07'],\n    'AvgTemp': [25, 30, 28, None, 32]\n})\n\nhumidity_df = pd.DataFrame({\n    'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-05', '2022-01-06', '2022-01-07'],\n    'AvgHumidity': [60, 65, None, 70, None, 55]\n})\n\n\ntemperature_df['Date'] = pd.to_datetime(temperature_df['Date'])\nhumidity_df['Date'] = pd.to_datetime(humidity_df['Date'])\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmerged_df = pd.merge_asof(temperature_df.sort_values('Date'), humidity_df.sort_values('Date'), on='Date', direction='backward')\nmerged_df['AvgTemp'] = merged_df['AvgTemp'].fillna(method='ffill')\nmerged_df['AvgHumidity'] = merged_df['AvgHumidity'].fillna(method='ffill')\nresult = merged_df\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I need to implement a custom loss function that penalizes predictions based on the deviation from the target values, but with an emphasis on the mispredictions of a particular class (let's say class index 1). I want to create a function that calculates the custom loss where the loss for class index 1 is doubled compared to other classes. The function should take true labels and predicted labels as inputs, and return the computed custom loss.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Custom loss function to penalize class index 1 predictions more\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    class_weights = tf.where(tf.equal(y_true, 1), 2.0, 1.0)\n    loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n    weighted_loss = loss * class_weights\n    return tf.reduce_mean(weighted_loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a sequence of time-series data for multiple features, and I want to compute the moving average using PyTorch. The tensor `data` has a shape of `(batch_size, num_features, sequence_length)`, and I want to apply a window size of `k` for the moving average calculation. \n\nHowever, the challenge is to create a new tensor that represents the moving average for each feature across the sequence, which will result in a tensor of shape `(batch_size, num_features, sequence_length - k + 1)`.\n\nGiven the following tensor:\n\n```\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\n```\n\nAnd a moving average window size of `k = 2`, how can I calculate the moving averages efficiently with PyTorch?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nk = 2\nmoving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\nk = 2\nmoving_avg = data.unfold(2, k, 1).mean(dim=3)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame with records of sales transactions as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'item_id': [101, 102, 101, 103, 102],\n    'store_id': ['A', 'A', 'B', 'B', 'C'],\n    'sales_date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'],\n    'amount': [100, None, 150, None, 200]\n}\ndf = pd.DataFrame(data)\ndf['sales_date'] = pd.to_datetime(df['sales_date'])\n```\n\nI need to fill in the missing values in the `amount` column. The missing values should be filled in with the mean sales amount of the same `item_id`. I would like the final DataFrame to retain all original rows, including those with the imputed values. Could you help me by providing the code that achieves this?\n\nThe expected output should look similar to this (the exact numeric values may vary based on your computations):\n\n```python\n   item_id store_id sales_date  amount\n0      101       A  2023-01-01   100.0\n1      102       A  2023-01-02   150.0\n2      101       B  2023-01-01   150.0\n3      103       B  2023-01-03   200.0\n4      102       C  2023-01-02   200.0\n```\n\nPlease provide the solution in the `result` variable.",
    "output": "\n```python\nmean_amounts = df.groupby('item_id')['amount'].transform('mean')\ndf['amount'] = df['amount'].fillna(mean_amounts)\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor representing some image data in the form of mini-batches. I need to perform a series of operations on it, specifically, I want to normalize this tensor by subtracting the mean and dividing by the standard deviation for each channel. \n\nHere is my current code:\n\n```python\nimport torch\n\n# Simulated image data with 10 samples and 3 channels (RGB)\nimage_tensor = torch.randn(10, 3, 32, 32) \n```\n\nHow do I compute the normalized tensor using the mean and standard deviation for each channel?\n\nA:\n\n```python\nchannel_means = ... # put solution in this variable\nnormalized_tensor = (image_tensor - channel_means) / channel_stds\n```\nBEGIN SOLUTION\n",
    "output": "\n```python\nchannel_means = image_tensor.mean(dim=(0, 2, 3), keepdim=True)\nchannel_stds = image_tensor.std(dim=(0, 2, 3), keepdim=True)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to develop a custom loss function to address the specific problem of overfitting in my regression model. In this case, I want to punish predictions that are more than a certain threshold (e.g., 0.5) away from the actual values. My input tensors are the predicted values and the actual values. I wish to compute the loss as follows: if the absolute error surpasses the threshold, the loss should multiply that error by two; if it does not exceed the threshold, the loss should be the error itself. \n\nHere's how to set up my function:\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 0.5\n    # Calculate the absolute error\n    error = tf.abs(y_true - y_pred)\n    # Apply the custom logic to compute the loss\n    loss = ...\n    return loss\n</code>",
    "output": "\n<code>\n    loss = tf.where(error > threshold, error * 2, error)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor representing the weights of a neural network structured as follows:\n\nweights = torch.rand((5, 4))\n\nI need to dynamically scale certain rows by a scaling factor, which is provided in a tensor of shape (3,) that specifies the rows to be scaled. The elements of the scaling tensor are: \n\nscaling_factors = torch.tensor([0.5, 2.0, 3.0])\n\nHow can I multiply the selected rows of the weights tensor by their corresponding scaling factors?\n\nExample of what I'm trying to achieve:\n\nIf I want to scale rows 0, 2, and 4, then the resulting operation should look something like this:\n\nweights[[0, 2, 4], :] *= scaling_factors\n\nPlease implement the correct code snippet below.\n\nA:\n\n<code>\nimport torch\nweights = torch.rand((5, 4))\nscaling_factors = torch.tensor([0.5, 2.0, 3.0])\n</code>\nweights[... ]  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nweights[[0, 2, 4], :] *= scaling_factors\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I am training a neural network and I need to create a custom loss function to penalize predictions based on the distance from the true labels, specifically using Mean Absolute Error (MAE). For my problem, when the prediction is exactly equal to the true label, the loss should be 0. However, if the prediction is off, I want to use a weighted penalty that increases in intensity based on how far the prediction is from the true label, with weights defined as follows: \n\n- If the absolute difference is less than or equal to 1, the weight is 1.\n- If the absolute difference is greater than 1 but less than or equal to 2, the weight is 2.\n- If the absolute difference is greater than 2, the weight is 3.\n\nGiven the true labels and predicted labels, how can I implement this custom loss function? \n\nHere's the initial setup:\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the absolute difference\n    abs_diff = tf.abs(y_true - y_pred)\n    # Initialize the loss variable \n    loss = ... # put solution in this variable\n    return loss\n```\nFill in the blank for the variable `loss` to implement the specified custom loss logic.",
    "output": "\n```python\n    loss = tf.where(abs_diff <= 1, abs_diff * 1, \n            tf.where(abs_diff <= 2, abs_diff * 2, \n            abs_diff * 3))\n```"
  },
  {
    "input": "### Problem:\nYou have a dataset detailing sales transactions over several months. The dataset looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\n```\n\nIn the `Sale_Date`, some transactions have missing dates denoted by '0'. Your task is to replace the '0' values in the `Sale_Date` with the average date from the existing sales dates for each product, replacing the '0' values with the average date of their respective `Product_ID`. The average date should be in the format 'YYYY-MM-DD'.\n\nHow would you achieve this in pandas? \n\nPlease fill in the code below to perform the imputation:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\nsales_data['Sale_Date'] = pd.to_datetime(sales_data['Sale_Date'].replace('0', pd.NaT)) \n# Your solution to fill in the blanks\nresult = ... # put your solution in this variable\n```\n",
    "output": "\n```python\nresult = sales_data.groupby('Product_ID')['Sale_Date'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nContext\nI have two datasets that represent purchases and customer information. \n\nDataset A (purchases):\n```\nPurchaseID   CustomerID   Amount\n-----------------------------------\n1            101          150\n2            102          200\n3            101          50\n4            103          100\n```\n\nDataset B (customers):\n```\nCustomerID   Name         Age\n---------------------------------\n101          John Doe    30\n102          Jane Smith   25\n103          Alice Johnson 27\n104          Bob Gray     40\n```\n\nI want to merge these datasets to create a final DataFrame that shows PurchaseID, Amount, Name, and Age. However, for any customers in Dataset B who do not have purchases recorded in Dataset A, I want to record `NaN` for the PurchaseID and Amount. \n\nHow can I achieve this with pandas?\n\nA:\n<code>\nimport pandas as pd\n\npurchases = pd.DataFrame({'PurchaseID':[1, 2, 3, 4],\n                           'CustomerID':[101, 102, 101, 103],\n                           'Amount':[150, 200, 50, 100]})\n\ncustomers = pd.DataFrame({'CustomerID':[101, 102, 103, 104],\n                          'Name':['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Gray'],\n                          'Age':[30, 25, 27, 40]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(customers, purchases, on='CustomerID', how='left')[['PurchaseID', 'Amount', 'Name', 'Age']]"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels, 32x32 pixels\n```\n\nNow, I want to apply the `flip_image` function to each image in the `images` tensor based on the flip probability. I need to fill in the blank for the following line of code:\n\n```python\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```\n\nWhat would be the correct approach to perform this operation? \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor\naugmented_images = ...  # put solution in this variable\n</code>",
    "output": "\n<code>\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\ndef custom_augment(images):\n    # Randomly decide whether to flip the images\n    should_flip = torch.rand(images.size(0)) > 0.5  # Random boolean array for each image\n    # Initialize an output tensor to store augmented images\n    augmented_images = images.clone()\n    \n    # How can I flip the images where should_flip is True?\n    augmented_images[____] = torch.flip(augmented_images[____], dims=[3])  # Flip horizontally\n    return augmented_images\n\naugmented_images = custom_augment(images)\n```\n\nFill in the blanks (`____`) to correctly implement the random horizontal flipping of images within the reusable `custom_augment` function.",
    "output": "\n```python\n    augmented_images[should_flip] = torch.flip(augmented_images[should_flip], dims=[3])  # Flip horizontally\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\ndef flip_images(images):\n    # Randomly decide if we flip the images or not\n    if <condition>:\n        # Flip the images horizontally\n        return torch.flip(images, [3])  # Here, 3 refers to the width dimension\n    return images\n\nflipped_images = flip_images(images)\n```\n\nWhat should replace `<condition>` to randomly decide whether to flip the images horizontally or not?\n\nA:\n\n<code>\n<condition>\n</code>",
    "output": "\n<code>\ntorch.rand(1).item() > 0.5\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a natural language processing task where I need to implement a simple attention mechanism using PyTorch. The attention scores are computed using a similarity measure between a query vector and a set of key vectors, producing a tensor of attention weights. The size of my query vector is (batch_size, query_dim) and the size of my key vectors is (batch_size, num_keys, key_dim).\n\nTo compute attention weights, I plan to calculate the dot product between the query and keys and then apply a softmax to get normalized attention weights. However, I am encountering an issue with the dimensions while trying to perform the dot product.\n\nHere's my current attempt:\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef compute_attention(query, keys):\n    # query: (n, d), keys: (n, k, d)\n    scores = ...  # fill in this part to compute attention scores\n    attention_weights = F.softmax(scores, dim=1)  # normalize the scores\n    return attention_weights\n\nquery = torch.randn(5, 10)  # (batch_size=5, query_dim=10)\nkeys = torch.randn(5, 4, 10)  # (batch_size=5, num_keys=4, key_dim=10)\n```\n\nHow can I fill in the blank in my code to correctly compute the attention scores?\n\nA:\n\n<code>\nscores = torch.matmul(query.unsqueeze(1), keys.transpose(1, 2)).squeeze(1)\n</code>",
    "output": "\n<code>\nscores = torch.bmm(query.unsqueeze(1), keys).squeeze(1)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am building a custom loss function that calculates the mean squared error (MSE) but only for the positive values in the predictions. If the prediction is negative, it should contribute zero to the loss. Given two tensors, `y_true` (the ground truth) and `y_pred` (the predictions), both of shape `(n,)`, how can I implement this custom loss function? Here\u2019s some example code setup:\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -1.0, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # loss = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(tf.maximum(y_pred, 0) - tf.maximum(y_true, 0)))\n    return mse\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations.\n\nHere\u2019s a partial implementation:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\n```\n\nWhat function should I use to complete the `transform` to resize the images to 128x128 pixels before applying other augmentations?\n\nA:\n\n<code>\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    ...\n])\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ntransforms.Resize((128, 128)).\n",
    "output": "\n<code>\ntransforms.Resize((128, 128)),\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a PyTorch tensor representing a batch of images from the MNIST dataset. The tensor has the shape (batch_size, 1, 28, 28), where each image is a grayscale image of size 28x28 pixels. I want to apply a transformation to normalize the pixel values of each image to the range [0, 1].\n\nThe pixel values are currently in the range [0, 255], so I need to divide all the pixel values by 255. However, I also want to ensure that I retain the original tensor shape. \n\nHow can I achieve this normalization using PyTorch, while ensuring that the output tensor maintains the same shape after the operation?\n\nTo illustrate, if my input tensor is:\n\ntensor([[[[255, 0, 127, ..., 30],\n          [50, 255, 255, ..., 10],\n          ...\n          [255, 0, 10, ..., 0]]]])\n\nI want my output tensor to be:\n\ntensor([[[[1.0, 0.0, 0.4980, ..., 0.1176],\n          [0.1961, 1.0, 1.0, ..., 0.0392],\n          ...\n          [1.0, 0.0, 0.0392, ..., 0.0]]]])\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n\ninput_tensor = load_data() # shape should be (batch_size, 1, 28, 28)\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = input_tensor / 255.0\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\ndef custom_augment(images):\n    # Randomly decide if we should flip the image\n    if torch.rand(1).item() < 0.5:\n        # Flip the images horizontally\n        images = ...\n    return images\n\naugmented_images = custom_augment(images)\n```\n\nA:\n\n<code>\nimages = images.flip(dims=[3])\n</code>\n",
    "output": "\n<code>\nimages = images.flip(dims=[3])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like the following:\n\n```python\ndf = pd.DataFrame({\n    'category': ['A', 'A', 'B', 'B', 'C', 'C', 'C'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02', '2023-01-03', None],\n    'value': [10, None, 20, 30, None, 50, 60]\n})\n```\n\nI want to ensure that all dates between the minimum and maximum date for each category are present, and any missing values should be filled in with the mean value for that category. The expected output should contain all the missing dates and the corresponding values calculated.\n\nYour task is to fill in the code below to achieve this:\n\n```python\nimport pandas as pd\n\ndf['date'] = pd.to_datetime(df['date'])\ncategory_range = df.groupby('category')['date'].agg(['min', 'max']).reset_index()\n# Your solution should begin after this line\nresult = ...\n```",
    "output": "\n```python\nresult = (\n    category_range\n    .apply(lambda row: pd.date_range(start=row['min'], end=row['max']), axis=1)\n    .explode()\n    .reset_index(name='date')\n    .merge(df.groupby('category').mean().reset_index(), on='category', how='left')\n)\nresult = result.groupby(['category', 'date']).first().reset_index()\nresult['value'] = result['value'].fillna(result.groupby('category')['value'].transform('mean'))\n```"
  },
  {
    "input": "Problem:\nYou have two pandas DataFrames, `sales` and `returns`, structured as follows:\n\n`sales`\n```\n   order_id   product  quantity  price\n0    1001      A       3        10\n1    1002      B       2        20\n2    1003      C       1        15\n3    1004      A       5        10\n```\n\n`returns`\n```\n   order_id   product  quantity\n0    1002      B       1\n1    1004      A       3\n2    1005      D       2\n```\n\nYou want to create a new DataFrame that combines both DataFrames based on the `order_id`, but you need to adjust the `quantity` in the `sales` DataFrame by subtracting any returned quantity in the `returns` DataFrame. If an `order_id` exists in the `returns` DataFrame but not in the `sales` DataFrame, those rows should still appear in the final DataFrame with the `sales` quantities being set to zero. The final DataFrame should include all columns from both DataFrames and look like this:\n\n```\n   order_id   product  quantity_sale  price  quantity_return\n0    1001      A       3              10          0\n1    1002      B       1              20          1\n2    1003      C       1              15          0\n3    1004      A       2              10          3\n4    1005      D       0              0           2\n```\n\nHere's the starting point to work with:\n\n```python\nimport pandas as pd\n\nsales = pd.DataFrame({\n    'order_id': [1001, 1002, 1003, 1004],\n    'product': ['A', 'B', 'C', 'A'],\n    'quantity': [3, 2, 1, 5],\n    'price': [10, 20, 15, 10]\n})\n\nreturns = pd.DataFrame({\n    'order_id': [1002, 1004, 1005],\n    'product': ['B', 'A', 'D'],\n    'quantity': [1, 3, 2]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(sales, returns, on='order_id', how='outer', suffixes=('_sale', '_return')).fillna(0)\nresult['quantity_sale'] = result['quantity_sale'] - result['quantity_return']\nresult = result[['order_id', 'product_sale', 'quantity_sale', 'price', 'quantity_return']]\nresult['product_sale'] = result['product_sale'].fillna(result['product_return'])\nresult['quantity_return'] = result['quantity_return'].astype(int)\nresult['quantity_sale'] = result['quantity_sale'].astype(int)\n```"
  },
  {
    "input": "Problem:\nYou are given a DataFrame that tracks daily sales across multiple stores, with some gaps in the data. The DataFrame looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Store': ['Store A', 'Store A', 'Store B', 'Store B', 'Store C'],\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'Sales': [200, None, 150, 300, None]\n})\n```\n\nYour goal is to fill in the missing sales figures using forward filling for each store while ensuring that if a store has no sales recorded for a day, it should still show up in the DataFrame with 0 sales for that date. The expected output format should include all unique dates for each store, even if no sales were recorded, with sales data filled accordingly.\n\nWrite the following code to achieve this goal:\n\n```python\nimport pandas as pd\n\nsales_data['Date'] = pd.to_datetime(sales_data['Date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (sales_data.set_index(['Store', 'Date'])\n          .resample('D')\n          .sum()\n          .fillna(0)\n          .groupby(level=0)\n          .ffill()\n          .reset_index())\n```"
  },
  {
    "input": "Problem:\n\nYou have a 1D tensor representing a batch of scores from a model, and you want to achieve a specific transformation. The transformation involves expanding this 1D tensor into a 2D tensor where each score is repeated to form a row corresponding to the scores. The goal is to create a 2D tensor where each score has its own column and the rows are filled with the index values of the scores.\n\nFor example, if your 1D tensor is:\n```\nscores = torch.tensor([0.5, 0.1, 0.4])\n```\nThe desired output should be:\n```\ntensor([[0, 1, 2],\n        [0.5, 0.1, 0.4]])\n```\n\nComplete the following code to achieve this transformation:\n\n<code>\nimport torch\nscores = load_data()\n</code>\ntransformed_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nscores = load_data()\ntransformed_tensor = torch.tensor([torch.arange(len(scores)), scores])\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a PyTorch project where I need to concatenate two tensors along a specified dimension, but I want to avoid errors that arise from mismatched sizes. I have two tensors, `A` and `B`, that I intend to concatenate along the first dimension (0). The tensors are structured like this:\n\n```\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])  # Note: B has a different first dimension size.\n```\n\nBefore concatenating, I want to ensure that `B` has the same number of columns as `A` by possibly reshaping or adjusting it without losing its original data. \n\nHow can I properly concatenate `A` and `B` after making sure their dimensions align? \n\nA:\n\n<code>\nimport torch\nA = load_data()\nB = load_data()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\nA = torch.tensor([[1, 2], [3, 4]])\nB = torch.tensor([[5, 6]])\n\nif A.size(1) != B.size(1):\n    B = B.expand(-1, A.size(1))\n\nresult = torch.cat((A, B), dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a PyTorch tensor representing the features of several samples for a machine learning model. The tensor has the shape (500, 20) where 500 is the number of samples and 20 is the number of features. You need to apply a non-linear activation function (specifically the ReLU function) on this tensor to introduce non-linearity for a neural network. The ReLU function should set all negative values to zero while keeping the positive values unchanged.\n\nGiven the tensor `features`, apply the ReLU function to it.\n\nA:\n\n<code>\nimport torch\nfeatures = load_data()\n</code>\nactivated_features = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nactivated_features = torch.relu(features)\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains sales data for a retail store:\n\n```python\nsales_data = pd.DataFrame({\n    'product_id': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'sale_date': ['2023-01-01', '2023-01-03', '2023-01-02', '2023-01-05', None, '2023-01-07'],\n    'units_sold': [10, 15, 5, None, 20, None]\n})\n```\n\nYour goal is to fill in the missing values in the `sale_date` column with the next sequential sale date for each `product_id` and replace missing `units_sold` values with the average number of units sold for that `product_id`.\n\nThe expected output should resemble this format, where the missing values are appropriately filled:\n\n```\n  product_id   sale_date  units_sold\n0          A  2023-01-01        10.0\n1          A  2023-01-03        15.0\n2          B  2023-01-02         5.0\n3          B  2023-01-05         5.0\n4          C  2023-01-07        20.0\n5          C  2023-01-07        20.0\n```\n\nWrite a single line of Python code that accomplishes this using pandas. Store your result in a variable named `result`.",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda x: x.fillna(method='bfill').fillna(x['units_sold'].mean())).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am developing a custom loss function for a regression problem where I want to penalize large errors more than small errors. Specifically, I want to implement a modified mean squared error (MMSE) loss function where the squared errors are weighted by a factor that increases as the absolute error grows. Given a list of predicted values and a list of true values, how can I compute the MMSE loss?\n\nGiven the true values and predicted values:\n```python\ntrue_values = [3.0, -0.5, 2.0, 7.0]\npredicted_values = [2.5, 0.0, 2.0, 8.0]\n```\nHow can I fill in the blank below to calculate the MMSE loss? \nThe MMSE loss function can be defined as:\n```python\ndef mmse_loss(y_true, y_pred):\n    errors = y_true - y_pred\n    squared_errors = tf.square(errors)\n    weight = tf.maximum(tf.abs(errors), 1.0)  # increasing weight for larger errors\n    weighted_squared_errors = squared_errors * weight\n    return tf.reduce_mean(weighted_squared_errors)\n```\n\nA:\n```python\nimport tensorflow as tf\n\ntrue_values = tf.constant([3.0, -0.5, 2.0, 7.0])\npredicted_values = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nmmse = ... # put solution in this variable",
    "output": "\n```python\nmmse = mmse_loss(true_values, predicted_values)\n```"
  },
  {
    "input": "### Problem:\nYou are working with a 3D tensor that represents a batch of grayscale images with the shape (batch_size, channels, height, width). Let's say you have a tensor `images` with the shape (8, 1, 28, 28). You want to perform dynamic padding on this tensor so that each image becomes square by adding padding to the height or width as necessary. The target shape for each image should be (28, 28) without altering the original data. Your goal is to compute a padded tensor with the shape (8, 1, 30, 30) by applying padding only to the height to maintain the aspect ratio. Use `torch.nn.functional.pad` for padding, which takes a tensor and a tuple of padding sizes for each dimension.\n\nGiven the tensor variable `images`:\n\n```python\nimport torch\nimages = torch.randn(8, 1, 28, 28)\n```\n\nFill in the blank to perform the appropriate padding.\n\nA:\n```python\npadded_images = torch.nn.functional.pad(images, (1, 1, 1, 1)) # put solution in this variable\n```",
    "output": "\n```python\npadded_images = torch.nn.functional.pad(images, (1, 1, 1, 1)) # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou have the following dataframe which records temperature readings over time:\n\ndf:\n|   id |   city |   date       |   temperature |\n|------|--------|--------------|---------------|\n|    1 |   NY   |  2020-01-01  |           32  |\n|    2 |   NY   |  2020-01-02  |          NaN  |\n|    3 |   NY   |  2020-01-03  |           30  |\n|    4 |   LA   |  2020-01-01  |           70  |\n|    5 |   LA   |  2020-01-02  |          NaN  |\n|    6 |   LA   |  2020-01-03  |           68  |\n\nYou want to perform a forward filling of the missing temperature data so that every city has a complete set of temperature readings for each date, while also ensuring that if a city does not have a reading for a particular date, the last known temperature is carried forward. The expected output should look something like this:\n\n|   id |   city |   date       |   temperature |\n|------|--------|--------------|---------------|\n|    1 |   NY   |  2020-01-01  |           32  |\n|    2 |   NY   |  2020-01-02  |           32  |\n|    3 |   NY   |  2020-01-03  |           30  |\n|    4 |   LA   |  2020-01-01  |           70  |\n|    5 |   LA   |  2020-01-02  |           70  |\n|    6 |   LA   |  2020-01-03  |           68  |\n\nYou can start with the following code to create the initial dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'id': [1, 2, 3, 4, 5, 6],\n    'city': ['NY', 'NY', 'NY', 'LA', 'LA', 'LA'],\n    'date': pd.to_datetime(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-02', '2020-01-03']),\n    'temperature': [32, None, 30, 70, None, 68]\n})\n```\n\nFill in the blank below with the appropriate method call for forward filling the temperature data:\n\n```python\ndf['temperature'] = ...\n```",
    "output": "\n```python\ndf['temperature'] = df.groupby('city')['temperature'].ffill()\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am working on a regression problem and I need to implement a custom loss function that penalizes predictions based on the squared percentage error (SPE). The SPE is calculated as:\n  \n\\[ \\text{SPE} = \\left( \\frac{|y - \\hat{y}|}{|y|} \\right)^2 \\]\n\nwhere \\( y \\) is the true value and \\( \\hat{y} \\) is the predicted value. If \\( y \\) is 0, the loss should be set to a constant value of 1 for the sake of stability.\n\nI need to apply this loss function on two tensors representing the true values and predicted values. Below is the setup:\n\n```python\nimport tensorflow as tf\n\ntrue_values = tf.constant([10.0, 0.0, 15.0, 25.0], dtype=tf.float32)\npredicted_values = tf.constant([8.0, 1.0, 15.0, 20.0], dtype=tf.float32)\n```\n\nI want to implement the loss function and compute the resulting tensor. \n\nPlease fill in the following code with the correct implementation of the custom loss function:\n\n```python\ndef custom_spe_loss(y_true, y_pred):\n    # Implement the custom squared percentage error loss function here\n    ### BEGIN SOLUTION\n```\n\nEvaluate the loss function using the provided tensors:\n\n```python\nloss_result = custom_spe_loss(true_values, predicted_values)\n```",
    "output": "\n```python\ndef custom_spe_loss(y_true, y_pred):\n    spe = tf.where(tf.equal(y_true, 0.0), 1.0, tf.square(tf.abs(y_true - y_pred) / tf.abs(y_true)))\n    return tf.reduce_mean(spe)\n\nloss_result = custom_spe_loss(true_values, predicted_values)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI need to create a custom loss function to handle a regression problem where I want to minimize the mean squared error only for predictions that exceed a certain threshold, while ignoring those below it. I have a threshold value of 0.5. How can I implement this custom loss function using TensorFlow so that it computes the loss only for those predicted values greater than the threshold?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Implement the custom loss function here\n    pass\n</code>\nloss = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n    mask = tf.cast(y_pred > 0.5, tf.float32)\n    squared_difference = tf.square(y_true - y_pred)\n    loss = tf.reduce_sum(mask * squared_difference) / tf.reduce_sum(mask + tf.keras.backend.epsilon())\n</code>"
  },
  {
    "input": "Problem:\nYou are working with two pandas dataframes representing sales data for different products. The first dataframe, `df_sales`, contains information about sales transactions and includes the columns `TransactionID`, `ProductID`, and `Amount`. The second dataframe, `df_products`, includes `ProductID`, `ProductName`, and `Category`. \n\nHere are the details of the dataframes:\n\ndf_sales:\n```\n+----------------+------------+--------+\n| TransactionID  | ProductID  | Amount |\n+----------------+------------+--------+\n|        1       |     A      |  250   |\n|        2       |     B      |  400   |\n|        3       |     A      |  150   |\n|        4       |     C      |  300   |\n|        5       |     B      |  200   |\n+----------------+------------+--------+\n```\n\ndf_products:\n```\n+------------+--------------+-----------+\n| ProductID  | ProductName  | Category  |\n+------------+--------------+-----------+\n|     A      | Product A    | Category 1|\n|     B      | Product B    | Category 1|\n|     C      | Product C    | Category 2|\n|     D      | Product D    | Category 2|\n+------------+--------------+-----------+\n```\n\nYour task is to merge these two dataframes so that for each transaction in `df_sales`, you can display the `TransactionID`, `ProductName`, and `Amount`. If a transaction references a `ProductID` that does not exist in `df_products`, the `ProductName` should display `None`. \n\nTo achieve this, fill in the following Python code snippet where `result` will store the merged data:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'ProductID': ['A', 'B', 'A', 'C', 'B'],\n    'Amount': [250, 400, 150, 300, 200]\n})\n\ndf_products = pd.DataFrame({\n    'ProductID': ['A', 'B', 'C', 'D'],\n    'ProductName': ['Product A', 'Product B', 'Product C', 'Product D'],\n    'Category': ['Category 1', 'Category 1', 'Category 2', 'Category 2']\n})\n\nresult = ... # put solution in this variable\n```\n",
    "output": "\n```python\nresult = pd.merge(df_sales, df_products[['ProductID', 'ProductName']], on='ProductID', how='left')[['TransactionID', 'ProductName', 'Amount']]\n```"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, channels, height, width). I want to dynamically apply a random horizontal flip to each image in the batch with a probability of 0.5. The images are represented as a PyTorch tensor. Here is a part of my code:\n\nimport torch\n\ndef random_horizontal_flip(images):\n    # images: (n, c, h, w) where n is the batch size, c is the number of channels, h is height, and w is width\n    # Apply horizontal flip with probability 0.5\n    batch_size, channels, height, width = images.size()\n    flip_mask = torch.rand(batch_size) < 0.5  # Create a random mask for flipping\n\n    # Here I want to use the flip_mask to conditionally flip the images\n    flipped_images = images.clone()  # Create a copy of images for manipulation\n    return flipped_images\n\nimages = load_data()  # assumes this returns a tensor of shape (batch_size, channels, height, width)\nflipped_images = random_horizontal_flip(images)\nI want to fill in the blank below to achieve the desired flip functionality:\n\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [2])  # [2] indicates flipping along height\n</code>",
    "output": "\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [3])  # [3] indicates flipping along width\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that looks like this:\n\n```python\nimport pandas as pd\nx = pd.DataFrame({\n    'department': ['HR', 'Sales', 'HR', 'Sales', 'IT', 'IT', 'HR'],\n    'employee_id': [1, 2, 3, 4, 5, 6, 7],\n    'salary': [60000, None, None, 52000, 70000, None, 58000]\n})\n```\n\nI want to fill in the missing salary values for employees in each department using advanced imputation techniques. Specifically, I want to fill in missing salaries with the median salary of their respective departments.\n\nThe expected output after the imputation should look like this:\n\n```\n  department  employee_id   salary\n0         HR            1  60000.0\n1       Sales            2  52000.0\n2         HR            3  58000.0\n3       Sales            4  52000.0\n4         IT            5  70000.0\n5         IT            6  70000.0\n6         HR            7  58000.0\n```\n\nWhat I would like you to do is to provide the code that performs this replacement of missing salary values appropriately. \n\nA:\n```python\nimport pandas as pd\n\nx = pd.DataFrame({\n    'department': ['HR', 'Sales', 'HR', 'Sales', 'IT', 'IT', 'HR'],\n    'employee_id': [1, 2, 3, 4, 5, 6, 7],\n    'salary': [60000, None, None, 52000, 70000, None, 58000]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nresult = x.groupby('department')['salary'].transform(lambda s: s.fillna(s.median()))\n</code>"
  },
  {
    "input": "### Problem:\nContext\nI have two dataframes that contain information about products and their sales.\n\nDataFrame `products` looks like this:\n```\n   ProductID ProductName  Category\n0          1      Apple       Fruits\n1          2      Banana      Fruits\n2          3      Carrot      Vegetables\n3          4      Broccoli    Vegetables\n```\n\nDataFrame `sales` looks like this:\n```\n   SaleID ProductID Quantity SaleDate\n0      101          1       50  2023-01-01\n1      102          2       30  2023-01-02\n2      103          3       20  2023-01-01\n3      104          4      100  2023-01-03\n4      105          5       60  2023-01-04\n```\n\nI want to merge these two dataframes based on `ProductID`. However, if a product in the `sales` dataframe does not exist in the `products` dataframe (like ProductID 5), I would like to drop that entire row in the final dataframe.\n\nThe desired output should look like this:\n```\n   SaleID ProductID Quantity SaleDate ProductName  Category\n0      101          1       50  2023-01-01       Apple      Fruits\n1      102          2       30  2023-01-02      Banana      Fruits\n2      103          3       20  2023-01-01      Carrot  Vegetables\n3      104          4      100  2023-01-03   Broccoli  Vegetables\n```\n\nSo far, I've merged the dataframes like this:\n```python\ndf = pd.merge(sales, products, on='ProductID', how='inner')\n```\n\nWhat change should I make to correctly reflect the required output, ensuring that rows in `sales` with non-existent `ProductID`s in `products` are dropped?\n\nA:\n<code>\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'ProductID': [1, 2, 3, 4],\n    'ProductName': ['Apple', 'Banana', 'Carrot', 'Broccoli'],\n    'Category': ['Fruits', 'Fruits', 'Vegetables', 'Vegetables']\n})\n\nsales = pd.DataFrame({\n    'SaleID': [101, 102, 103, 104, 105],\n    'ProductID': [1, 2, 3, 4, 5],\n    'Quantity': [50, 30, 20, 100, 60],\n    'SaleDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-04']\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = pd.merge(sales, products, on='ProductID', how='inner')\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing daily sales data for multiple stores, which includes some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'store_id': [1, 1, 1, 2, 2, 2, 3, 3],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03'],\n    'sales': [100, 200, None, 150, None, 250, None, 300]\n})\n```\n\nYour goal is to fill the missing sales values by using a forward fill method and also ensure that each store has an entry for every day from `2023-01-01` to `2023-01-04`. The final DataFrame should retain the sales values after forward filling. Post forward filling, if any store still lacks entries for specific dates, they should be filled with zeros.\n\nThe expected structure of the DataFrame should look like this:\n\n```\n   store_id        date  sales\n0        1  2023-01-01  100.0\n1        1  2023-01-02  200.0\n2        1  2023-01-03  200.0\n3        1  2023-01-04  200.0\n4        2  2023-01-01  150.0\n5        2  2023-01-02  150.0\n6        2  2023-01-03  250.0\n7        2  2023-01-04    0.0\n8        3  2023-01-01    0.0\n9        3  2023-01-02    0.0\n10       3  2023-01-03  300.0\n11       3  2023-01-04    0.0\n```\n\nYour task is to create a single line of code to achieve this transformation, ensuring all missing 'sales' values are handled appropriately.\n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = df.set_index(['store_id', 'date']).reindex(pd.MultiIndex.from_product([df['store_id'].unique(), pd.date_range('2023-01-01', '2023-01-04')]), fill_value=0).fillna(method='ffill').reset_index()\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that implements the mean absolute error (MAE) for a regression problem. Given two tensors: true_values and predictions, each being a 1D tensor of shape (n,), I aim to compute the mean absolute error by defining a custom loss function. The result should be a scalar tensor. Here are the example tensors:\n```python\ntrue_values = tf.constant([3.0, -0.5, 2.0, 7.0])\npredictions = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nHow can I calculate the MAE inside a function?\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_values = tf.constant([3.0, -0.5, 2.0, 7.0])\npredictions = tf.constant([2.5, 0.0, 2.0, 8.0])\ndef custom_mae(true, pred):\n    # return the solution in this function\n    # loss = custom_mae(true, pred)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    loss = tf.reduce_mean(tf.abs(true - pred))\n    return loss\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____(0.2, 0.2, 0.2, 0.2)  # I need to fill in this part for color jitter\n])\n```\n\nWhat goes in the blank to complete the transformations for color jittering with the specified parameters for brightness, contrast, saturation, and hue? \n\nA:\n\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(____)  # Fill in with the correct method\n])\n</code>",
    "output": "\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)  # Fill in with the correct method\n])\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame that looks like this:\n\n```python\ndata = {'store_id': [1, 1, 2, 3, 3],\n        'sales': [200, None, 450, None, 300],\n        'month': ['2022-01', '2022-01', '2022-01', '2022-02', '2022-02']}\ndf = pd.DataFrame(data)\n```\n\nThe `sales` column contains some missing values. You need to fill in these missing values using the following conditions:\n\n1. Fill `None` sales with the average sales for the corresponding `store_id`.\n2. Leave the filled values in `sales` with the original data type.\n3. The output `month` column should be formatted to `MMM-YYYY` (e.g., `Jan-2022`).\n\nYour task is to provide one piece of Python code that performs the above transformations on the DataFrame and returns the final DataFrame in the expected format. \n\nThe final DataFrame should look like this:\n```plaintext\n   store_id  sales     month\n0         1  200.0  Jan-2022\n1         1  200.0  Jan-2022\n2         2  450.0  Jan-2022\n3         3  300.0  Feb-2022\n4         3  300.0  Feb-2022\n```\n\nA:\n```python\nimport pandas as pd\n\ndata = {'store_id': [1, 1, 2, 3, 3],\n        'sales': [200, None, 450, None, 300],\n        'month': ['2022-01', '2022-01', '2022-01', '2022-02', '2022-02']}\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['sales'] = df.groupby('store_id')['sales'].transform(lambda x: x.fillna(x.mean()))\ndf['month'] = pd.to_datetime(df['month']).dt.strftime('%b-%Y')\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor that represents a grayscale image, and I want to apply a dynamic resizing operation based on the percentage of the original image dimensions. The target size should be calculated as a fraction of the original size. For example, if the original dimensions are (H, W) and the resize percentage is 50%, the new dimensions should be (H * 0.5, W * 0.5).\n\nHere's my starting code, but I'm unsure how to implement the resizing part correctly using PyTorch dynamic tensor operations:\n\nimport torch\n\noriginal_image = torch.randn(1, 1, 100, 200)  # Simulated grayscale image\nresize_percentage = 0.5\n\n# Calculate the new dimensions\nnew_height = int(original_image.size(2) * resize_percentage)\nnew_width = int(original_image.size(3) * resize_percentage)\n\n# How do I resize the tensor to the new dimensions?\nresized_image = ...\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\noriginal_image, resize_percentage = load_data()\n</code>\nresized_image = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresized_image = torch.nn.functional.interpolate(original_image, size=(new_height, new_width), mode='bilinear', align_corners=False)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor that contains RGB values of a batch of images represented as a 4D tensor of shape (batch_size, channels, height, width). I want to apply a mask to select only certain channels (for example, the red and blue channels) from this tensor. However, I faced an issue when trying to slice the tensor with a mask that is a Boolean tensor.\n\nHere is the relevant code snippet where I'm running into trouble:\n\n```python\nimport torch\n\nbatch_images = torch.rand((4, 3, 64, 64))  # Randomly generated batch of images\nchannel_mask = torch.ByteTensor([1, 0, 1])  # This mask is supposed to keep channels 0 and 2 (Red and Blue)\n```\n\nHowever, when I try to use this mask to slice the tensor:\n\n```python\nselected_channels = batch_images[:, channel_mask, :, :] # This raises an error.\n```\n\nI need to correct this error to properly select the desired channels. Can you help me with the correct slicing technique?\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nbatch_images, channel_mask = load_data()\n```\nselected_channels = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_channels = batch_images[:, channel_mask.bool(), :, :]\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 102, 104, 104],\n    'sales': [200, None, 340, None, 300, 400, None],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-01', \n                            '2023-01-02', '2023-01-02', '2023-01-02', '2023-01-03'])\n})\n```\n\nYou would like to forward-fill the missing sales data for each product based on the date, ensuring that every product has sales data for each unique date available in the DataFrame. Therefore, you'll need to produce an output where the sales for each product are filled in consecutively from the last known value.\n\nCurrently, you have this DataFrame:\n\n```python\n   product_id  sales       date\n0         101  200.0 2023-01-01\n1         102    NaN 2023-01-01\n2         103  340.0 2023-01-01\n3         101    NaN 2023-01-02\n4         102  300.0 2023-01-02\n5         104  400.0 2023-01-02\n6         104    NaN 2023-01-03\n```\n\nwhat you need to do is to fill in the missing values in the 'sales' column for each 'product_id' based on the 'date' column.\n\nYour goal is to obtain a compressed DataFrame with no NaN values in 'sales' caused by forward-fill, while maintaining the same format. \n\nPlease provide the correct line of code to achieve this result. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('product_id').apply(lambda group: group.set_index('date').resample('D').ffill()).reset_index()\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am not sure how to apply this function to each image in the tensor while handling the probability condition. I tried using a for loop but wasn't able to do it efficiently.\n\nA:\n\n<code>\nimport torch\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images\n\ndef flip_image(image):\n    return torch.flip(image, dims=[1])  # Flip the image vertically\n\n# Implement the augmentation logic here\nresult = ...\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = torch.where(torch.rand(images.size(0), 1, 1, 1) < 0.5, flip_image(images), images)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 3D tensor representing features extracted from images, where the shape of the tensor is (batch_size, channels, height, width). In my context, I need to apply a transformation that reshapes each channel of the tensor into a 2D matrix by flattening the height and width dimensions, allowing me to apply a linear transformation afterward.\n\nGiven the input tensor named `image_features`, which has the shape (16, 3, 32, 32), how can I reshape it to obtain a tensor of shape (16, 3, 1024) for further processing with a linear layer?\n\nHere is the code snippet that includes your input tensor:\n\n<code>\nimport torch\nimage_features = torch.randn(16, 3, 32, 32)\n</code>\ntransformed_features = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntransformed_features = image_features.view(image_features.size(0), image_features.size(1), -1)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor containing scores of different models across several metrics:\n\ntensor([[0.1, 0.4, 0.6],\n        [0.3, 0.2, 0.8],\n        [0.5, 0.7, 0.1]])\n\nI want to normalize each row of this tensor to its maximum value and return a new tensor containing these normalized scores.\n\nI attempted to do this by calculating the maximum of each row and then dividing each element by its respective maximum value, but I'm confused about how to apply this operation efficiently across the rows.\n\nA:\n\n<code>\nimport torch\nscores = load_data()\n</code>\nnormalized_scores = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_values = scores.max(dim=1, keepdim=True)[0]\nnormalized_scores = scores / max_values\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains temperature data for a city with some missing values. The structure of the DataFrame is as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n    'temperature': [20, None, 25, None, 30, None]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat I would like to do is interpolate the missing temperature values based on the adjacent available values. If the first or last value is missing, please fill it with the average of the remaining values in the column. The expected output should maintain the same structure and format.\n\nYour task is to write one line of code that performs this interpolation and filling.\n\nA:\n```python\ndf['temperature'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['temperature'] = df['temperature'].interpolate().fillna(df['temperature'].mean())\n```"
  },
  {
    "input": "Problem:\n\nYou have a PyTorch tensor representing a 2D point cloud with shape (N, 2), where N is the number of points. Each point is defined by its (x, y) coordinates. Your task is to compute the distance of each point from the origin (0, 0) and store these distances in a new tensor. You should use broadcasting for this operation.\n\nGiven a tensor `points`, how can you efficiently calculate the Euclidean distance for all points?\n\nA:\n\n<code>\nimport torch\npoints = torch.randn(100, 2)  # Randomly generated tensor with shape (100, 2)\n</code>\ndistances = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndistances = torch.sqrt(points[:, 0]**2 + points[:, 1]**2)\n</code>"
  },
  {
    "input": "## Problem:\n\nI have a 2D tensor representing the features of a dataset, where each row corresponds to a different example and each column corresponds to a different feature. I want to normalize this tensor by subtracting the mean of each column from the respective column values and then dividing by the standard deviation of each column.\n\nI have tried to utilize PyTorch's operations, but I'm unsure of how to compute the mean and standard deviation and apply them to each column. Given the following tensor:\n\ndata: shape (5, 4), for instance, represented as:\n\n```\n[[1.0, 2.0, 3.0, 4.0],\n [5.0, 6.0, 7.0, 8.0],\n [9.0, 10.0, 11.0, 12.0],\n [13.0, 14.0, 15.0, 16.0],\n [17.0, 18.0, 19.0, 20.0]]\n```\n\nI want to compute the normalized tensor using the following code snippet to fill in the blank:\n\n<code>\nimport torch\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean = data.mean(dim=0)\nstd = data.std(dim=0)\nnormalized_data = (data - mean) / std\n</code>"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing sales data for a retail store as follows:\n\n```\ndf:\n   ProductID   Sales   Date\n0        101      50  2023-01-01\n1        102      20  2023-01-01\n2        103      NaN  2023-01-01\n3        101      30  2023-01-02\n4        102      NaN  2023-01-02\n5        103      15  2023-01-02\n```\n\nYour goal is to fill in the missing sales figures in the `Sales` column using forward-fill for the same `ProductID` by day. Specifically, if a product's sales are missing on a specific day, you want to fill it with the sales figure from the previous available day for that product. The expected DataFrame should be as follows:\n\n```\n   ProductID   Sales       Date\n0        101    50.0  2023-01-01\n1        102    20.0  2023-01-01\n2        103    15.0  2023-01-01\n3        101    30.0  2023-01-02\n4        102    20.0  2023-01-02\n5        103    15.0  2023-01-02\n```\n\nYou have imported the necessary libraries and created the DataFrame. Your task is to complete the following line of code to achieve this:\n\n```python\ndf['Sales'] = df.groupby('ProductID')['Sales'].___\n```\n",
    "output": "\n```python\ndf['Sales'] = df.groupby('ProductID')['Sales'].ffill()\n```"
  },
  {
    "input": "Problem:\n\nI am implementing a sequence-to-sequence model using PyTorch for a text translation task. After processing the input sequences, I need to convert the output logits into predictions by applying a softmax function along the specified dimension. My current output tensor has the shape `[batch_size, seq_length, vocab_size]`. How can I apply the softmax function to obtain the predicted token probabilities for each token in the sequence?\n\nHere is my code so far:\n\n```python\nimport torch\n\n# Suppose output is the tensor with your model's logits\noutput = load_data()  # shape: [batch_size, seq_length, vocab_size]\n```\n\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\npredictions = torch.softmax(output, dim=-1)  # Apply softmax along the vocab_size dimension\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "## Problem\nI have two DataFrames, `products` and `sales`, defined as follows:\n```python\nproducts\n   product_id product_name  price\n0           1      apples   1.00\n1           2      oranges  1.50\n2           3      bananas  1.20\n\nsales\n   product_id quantity sales_date\n0           1      10  2023-01-01\n1           2      20  2023-01-01\n2           3      15  2023-01-02\n3           1      5   2023-01-02\n4           2      10  2023-01-03\n```\n\nI want to create a new DataFrame that summarizes total sales quantity for each product, including the product name and price. The resulting DataFrame should look like this:\n```\n   product_id product_name  price  total_quantity\n0           1      apples   1.00              15\n1           2      oranges  1.50              30\n2           3      bananas  1.20              15\n```\n\nYou can create the desired DataFrame by merging the two DataFrames and aggregating the total quantity sold for each product. I attempted to do this using `pd.merge()` and `groupby()`, but it did not yield the expected results. \n\nHere is the code to start with:\n```python\nimport pandas as pd\n\nproducts = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['apples', 'oranges', 'bananas'],\n    'price': [1.00, 1.50, 1.20]\n})\n\nsales = pd.DataFrame({\n    'product_id': [1, 2, 3, 1, 2],\n    'quantity': [10, 20, 15, 5, 10],\n    'sales_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03']\n})\n```\nThe result should be assigned to the variable `result` like this:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = products.merge(sales.groupby('product_id', as_index=False)['quantity'].sum(), on='product_id') \\\n                 .rename(columns={'quantity': 'total_quantity'})\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information on employees as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [1, 2, 3, 4, 5],\n    'department': ['HR', 'IT', 'IT', 'HR', None],\n    'salary': [50000, 60000, None, 55000, 58000],\n    'hire_date': ['2018-01-10', '2019-02-20', '2020-03-15', None, '2021-05-30']\n})\n\n```\n\nI would like to fill in the missing values in the `department` column with the mode of the existing values and fill the missing values in the `salary` column with the median salary of employees in the same department. The dates should be kept as they are for the existing values in the `hire_date` column. The expected DataFrame after processing should look like this:\n\n```\n   employee_id department   salary   hire_date\n0            1        HR  50000.0  2018-01-10\n1            2        IT  60000.0  2019-02-20\n2            3        IT  55000.0  2020-03-15\n3            4        HR  55000.0        NaN\n4            5        HR  58000.0  2021-05-30\n```\n\nSo far I have processed the DataFrame to remove any missing values but need help to fill the missing ones appropriately. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmode_department = df['department'].mode()[0]\ndf['department'].fillna(mode_department, inplace=True)\n\nmedian_salary = df.groupby('department')['salary'].transform('median')\ndf['salary'].fillna(median_salary, inplace=True)\n\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\nI am working with two dataframes related to sales data and product information. The sales data contains transactions with associated product IDs, and the product information provides details about those products. Here are the two dataframes:\n\ndf_sales:\n```\n   transaction_id  product_id  quantity\n0               1          101         3\n1               2          102         5\n2               3          101         2\n3               4          103         1\n```\n\ndf_products:\n```\n   product_id    product_name   price\n0         101    Widget A      15.00\n1         102    Widget B      20.00\n2         103    Widget C      25.00\n3         104    Widget D      30.00\n```\n\nI want to create a new dataframe that combines sales data with product names and calculates the total revenue per transaction by multiplying the quantity sold by the product price. The resulting dataframe should include columns for `transaction_id`, `product_name`, `quantity`, and `total_revenue`. \n\nThe data from df_sales and df_products should be merged using `product_id` as the key, and total revenue should be calculated as `quantity * price`.\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4],\n    'product_id': [101, 102, 101, 103],\n    'quantity': [3, 5, 2, 1]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'product_name': ['Widget A', 'Widget B', 'Widget C', 'Widget D'],\n    'price': [15.00, 20.00, 25.00, 30.00]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_products, on='product_id') \\\n                  .assign(total_revenue=lambda x: x['quantity'] * x['price']) \\\n                  [['transaction_id', 'product_name', 'quantity', 'total_revenue']]\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that calculates the Mean Squared Error (MSE) based on predictions and targets, but I want to add a penalty for predictions that fall below a specific threshold (e.g., 0.5). If the prediction is less than 0.5, I want to add a fixed penalty of 0.1 to the MSE. Given the predictions and targets as tensors, how can I implement this custom loss function?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_with_penalty(predictions, targets):\n    threshold = 0.5\n    penalty = 0.1\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    penalty_magnitude = tf.reduce_sum(tf.cast(predictions < threshold, tf.float32)) * penalty\n    total_loss = mse + penalty_magnitude\n    return total_loss\n</code>",
    "output": "\n<code>\nimport tensorflow as tf\n\ndef custom_mse_with_penalty(predictions, targets):\n    threshold = 0.5\n    penalty = 0.1\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    penalty_magnitude = tf.reduce_sum(tf.cast(predictions < threshold, tf.float32)) * penalty\n    total_loss = mse + penalty_magnitude\n    return total_loss\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information about daily sales over a few weeks for different products, but there are some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n                           'date': ['2023-10-01', '2023-10-02', '2023-10-01', '2023-10-03',\n                                    '2023-10-01', '2023-10-02', '2023-10-02', None],\n                           'units_sold': [20, None, None, 15, 5, None, None, 10]})\n```\n\nI want to fill in the missing values of `date` and `units_sold` with the appropriate entries based on previous entries for the same `product_id`. Specifically, I want to forward fill the `date` and use the mean of previously available `units_sold` for the respective `product_id` to fill in the missing values.\n\nThe expected DataFrame should look like this:\n\n```plaintext\n   product_id        date  units_sold\n0           1  2023-10-01         20.0\n1           1  2023-10-02         20.0\n2           2  2023-10-01         7.5\n3           2  2023-10-03         15.0\n4           3  2023-10-01         5.0\n5           3  2023-10-02         5.0\n6           4  2023-10-02        10.0\n7           4  2023-10-02        10.0\n```\n\nCurrently, I am trying to fill the missing entries but not succeeding in the way I want. Can you help me with a concise inline code that will accomplish this task?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group.fillna({'date': group['date'].ffill(), 'units_sold': group['units_sold'].fillna(group['units_sold'].mean())})).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\n\nI have a 3D tensor representing different channels of data as follows:\n\ntensor([[[0.1, 0.2], \n          [0.3, 0.4]], \n        \n         [[0.5, 0.6], \n          [0.7, 0.8]], \n        \n         [[0.9, 1.0], \n          [1.1, 1.2]]])\n        \nI want to apply a mask tensor to zero out the values in the original tensor based on a 2D mask that selects specific elements. The mask tensor is a 2D tensor:\n\ntensor([[1, 0], \n        [0, 1], \n        [1, 0]])\n\nHow do I create a new tensor that retains values from the original tensor where the mask is 1 and zeros out where the mask is 0?\n\nA:\n\n<code>\nimport torch\noriginal_tensor, mask = load_data()\n</code>\nmasked_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmasked_tensor = original_tensor * mask.unsqueeze(1)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data for a store represented as follows:\n\n```python\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\n\nThe DataFrame has missing values for the `Date` and `Sales` columns. I want to fill in the missing `Sales` values for the same `ProductID` by using the mean sales value of products with the same `ProductID`, while keeping the original `Date` as is. For the missing `Date`, I would like to fill it with the string \"Unknown Date\".\n\nHere is my current DataFrame before processing:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02    NaN\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04    NaN\n6          5        NaN    NaN\n```\n\nWhat I want to achieve is to apply the necessary imputation method to get the following resulting DataFrame:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02  200.0\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04  300.0\n6          5  Unknown Date    NaN\n```\n\nI would like the code that fills in the missing values in `Sales` with the mean sales for the respective `ProductID` and replaces the missing `Date` with \"Unknown Date\".\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n",
    "output": "\n```python\ndf['Date'].fillna('Unknown Date', inplace=True)\nmean_sales = df.groupby('ProductID')['Sales'].transform('mean')\ndf['Sales'].fillna(mean_sales, inplace=True)\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI have a 2D tensor representing the daily sales figures for items in a store, where each row corresponds to a different item and each column corresponds to a different day. I need to find the daily sales totals for all items combined. Given a tensor named `sales_data`, how can I efficiently compute the sum of sales for each day and return a 1D tensor holding these totals?\n\nA:\n\n<code>\nimport torch\nsales_data = load_data()\n</code>\ndaily_totals = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndaily_totals = sales_data.sum(dim=0)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ________________  # I need to fill in this blank with the proper color jitter transformation\n])\n```\n\nWhat should I put in the blank to apply random brightness, contrast, saturation, and hue adjustments?",
    "output": "\n```python\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n```"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor representing the features of a batch of images, where the shape is (batch_size, channels, height, width). You want to perform an element-wise multiplication of this tensor with a 1D tensor containing scaling factors for each channel. The 1D tensor has a shape that matches the number of channels.\n\nGiven the 3D tensor `images` of shape (4, 3, 64, 64) and a scaling factor tensor `scaling_factors` of shape (3,), how would you apply the scaling factors to each corresponding channel in the `images` tensor?\n\nA:\n\n<code>\nimport torch\nimages = torch.rand((4, 3, 64, 64))\nscaling_factors = torch.rand(3)\n</code>\nscaled_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nscaled_images = images * scaling_factors.view(1, -1, 1, 1)</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is where I need help.\n```\n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\nresult = images\n</code>"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor containing the pixel values of an image in the shape of (3, 256, 256), representing RGB channels. I want to normalize each channel independently so that the pixel values fall within the range of [0, 1]. Given the tensor `img_tensor`, how can I accomplish this in one line of code?\n\nA:\n\n<code>\nimport torch\nimg_tensor = load_data()\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = (img_tensor - img_tensor.min(dim=(1, 2), keepdim=True).values) / (img_tensor.max(dim=(1, 2), keepdim=True).values - img_tensor.min(dim=(1, 2), keepdim=True).values)\n</code>"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing daily sales data for a retail store. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [np.nan, 200, np.nan, 300, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to fill in the missing sales data using forward fill for the non-leading NaN values and use a rolling average of the previous three days to fill the leading NaN values. After performing imputation, the DataFrame should look like this:\n\n```plaintext\n        date  sales\n0  2023-01-01   200\n1  2023-01-02   200\n2  2023-01-03   200\n3  2023-01-04   300\n4  2023-01-05   300\n```\n\nWhat one line of code can you use to achieve this filling strategy efficiently on the `sales` column of the DataFrame? \n\n```python\ndf['sales'] = ...\n```",
    "output": "\n```python\ndf['sales'] = df['sales'].fillna(method='ffill').combine_first(df['sales'].rolling(window=3, min_periods=1).mean())\n```"
  }
]