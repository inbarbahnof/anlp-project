[
  {
    "input": "Problem:\nI'm building a neural network model in TensorFlow and PyTorch to classify images from the CIFAR-10 dataset. After training the model, I want to visualize the predictions made on a batch of images. The model outputs a tensor `predictions` of shape `[batch_size, 10]` where each row contains the predicted probabilities for each class. To determine the final predicted class for each image, I need to extract the indices of the maximum values along the class dimension. \n\nAssuming I have the following tensor:\n```python\npredictions = tf.constant([[0.1, 0.2, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n                           [0.0, 0.1, 0.1, 0.0, 0.0, 0.3, 0.5, 0.0, 0.0, 0.0],\n                           [0.2, 0.0, 0.0, 0.1, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0]])\n```\n\nI need to create a tensor indicating the index of the class with the highest predicted probability for each image. How can I achieve this using TensorFlow?\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.1, 0.2, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n                           [0.0, 0.1, 0.1, 0.0, 0.0, 0.3, 0.5, 0.0, 0.0, 0.0],\n                           [0.2, 0.0, 0.0, 0.1, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales for different products, structured as follows:\n\n```python\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI want to analyze the sales data by filling in the missing dates for each product and ensuring that the `sales` value for those missing dates is set to zero. The desired output should retain the product column and include continuous dates, even for those with no sales recorded.\n\nHow can I achieve this? \n\nThe expected output should look like this:\n\n```\n        date product  sales\n0 2023-01-01       A    100\n1 2023-01-02       A    150\n2 2023-01-03       A      0\n3 2023-01-04       A      0\n4 2023-01-05       A    130\n5 2023-01-06       A      0\n6 2023-01-01       B      0\n7 2023-01-02       B      0\n8 2023-01-03       B    200\n9 2023-01-04       B      0\n10 2023-01-05       B      0\n11 2023-01-06       B    180\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndate_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\nproducts = df['product'].unique()\ndf_full = pd.MultiIndex.from_product([date_range, products], names=['date', 'product']).to_frame(index=False)\ndf_full = df_full.merge(df, on=['date', 'product'], how='left').fillna(0)\ndf_full['sales'] = df_full['sales'].astype(int)\ndf = df_full.sort_values(by=['date', 'product']).reset_index(drop=True)\n</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing daily temperature records for a city over several years. The DataFrame has a 'Date' column and a 'Temperature' column. I want to compute the rolling average temperature over a 7-day window for each day. For example, for each day's temperature, the average should include that day and the previous six days. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\n\ndate_range = pd.date_range(start='2020-01-01', end='2020-01-10', freq='D')\ntemperatures = [30, 32, 31, 34, 36, 30, 29, 33, 35, 36]\ndf = pd.DataFrame({'Date': date_range, 'Temperature': temperatures})\ndf.set_index('Date', inplace=True)\n```\n\nNow, I need to create a new column '7_day_avg' in the DataFrame that contains the rolling average temperature. How can I achieve this? \n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are developing a neural network in TensorFlow to classify images into one of four categories. After training the model, you need to convert the model predictions, which come as a tensor of shape (n, 4), into integer class labels indicating the most likely category for each prediction.\n\nThe tensor output from your model looks something like this:\n\n[[0.1, 0.2, 0.6, 0.1],\n [0.4, 0.3, 0.2, 0.1],\n [0.25, 0.25, 0.25, 0.25],\n [0.7, 0.1, 0.1, 0.1]]\n\nYour goal is to extract the index of the maximum value from each row of this tensor, which corresponds to the predicted class label (0, 1, 2, or 3) for each input sample.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.1, 0.2, 0.6, 0.1],\n                            [0.4, 0.3, 0.2, 0.1],\n                            [0.25, 0.25, 0.25, 0.25],\n                            [0.7, 0.1, 0.1, 0.1]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame containing a column with product descriptions and I need to clean it up. Here is the DataFrame I started with:\n\n```\n                   description\n0  The red dress @Fashionista #Style2023\n1  New shoes -Available Now! #ShopHere\n2  Summer sale (50% OFF!) --> Dress4Less\n3  Check out our @store for new arrivals! \n```\n\nI want to extract only the alphanumeric words and keep everything as lowercase, resulting in the following cleaned column:\n\n```\n             cleaned_description\n0      the red dress fashionista style2023\n1          new shoes available now shophere\n2            summer sale 50 off dress4less\n3           check out our store for new arrivals \n```\n\nThe current code I have only returns the original descriptions without cleaning them properly. \n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'description': [\n        'The red dress @Fashionista #Style2023',\n        'New shoes -Available Now! #ShopHere',\n        'Summer sale (50% OFF!) --> Dress4Less',\n        'Check out our @store for new arrivals!'\n    ]\n})\n\ndf['cleaned_description'] = ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['cleaned_description'] = df['description'].str.lower().str.replace(r'[^a-z0-9\\s]', '', regex=True)"
  },
  {
    "input": "## Problem:\nI have a time series dataset that records the daily sales of a product. The dataframe `sales_df` has the following columns:\n\n- `date`: a datetime column representing the date of the sales\n- `sales`: an integer column representing the number of units sold on that date\n\nIt looks like this:\n\n```\n        date       sales\n0 2023-01-01      120\n1 2023-01-02      135\n2 2023-01-03      150\n3 2023-01-04      145\n4 2023-01-05      160\n```\n\nI want to create a new column `rolling_average` that calculates the 3-day rolling average of the sales. Thus, for each date, this value should represent the average of the sales for that date and the two previous days. Please help me fill in the blank below to achieve this.\n\nMy code:\n\n```python\nimport pandas as pd\n\nsales_df = pd.DataFrame({\n    'date': pd.date_range(start='2023-01-01', periods=5),\n    'sales': [120, 135, 150, 145, 160]\n})\n\nsales_df['rolling_average'] = ...\n```\n",
    "output": "\n```python\nsales_df['rolling_average'] = sales_df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix represented in Compressed Sparse Row (CSR) format, where each row represents a user-item interaction, and I want to compute the mean of the non-zero elements column-wise. The sparse matrix is stored in the variable `sparse_matrix`.\n\nThe matrix has the following structure:\n\n```\n0 0 5 0\n0 3 0 0\n0 0 0 2\n4 0 0 0\n```\n\nI am unsure how to calculate the mean of each column without converting the sparse matrix to a dense format, as this would be inefficient for large datasets.\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\ndata = np.array([5, 3, 2, 4])\nrow_indices = np.array([0, 1, 3, 0])\ncol_indices = np.array([2, 1, 3, 0])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(4, 4))\n</code>\ncolumn_means = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncolumn_means = sparse_matrix.sum(axis=0) / (sparse_matrix != 0).sum(axis=0)\n</code>"
  },
  {
    "input": "### Problem:\nYou are given a DataFrame that contains daily sales data for a retail store over a month, structured as follows:\n\n```python\n                 sales\ndate\n2023-01-01    100\n2023-01-02    150\n2023-01-03    200\n2023-01-04    250\n2023-01-05    300\n2023-01-06    350\n2023-01-07    400\n2023-01-08    450\n2023-01-09    500\n2023-01-10    550\n```\n\nYou need to create a new column in the DataFrame that represents a 3-day rolling average of sales, where the average is calculated based on the current day and the two preceding days.\n\nPlease provide the line of code that will create this new column called '3_day_avg'.\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data).set_index('date')\n```\n\ndf['3_day_avg'] = ... # put solution in this variable",
    "output": "\n```python\ndf['3_day_avg'] = df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a list of dictionaries representing sales data from a store. Each dictionary contains information about the product sold, quantity sold, and price per unit. You want to implement a function that calculates the total revenue generated for each product and returns a list of dictionaries with the product name and the calculated total revenue.\n\nFor example:\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nYour desired output should be:\n[\n    {'product': 'apple', 'total_revenue': 19.5},\n    {'product': 'banana', 'total_revenue': 3.75},\n    {'product': 'orange', 'total_revenue': 8.0}\n]\n\nDefine your function below:\n<code>\ndef calculate_revenue(sales_data):\n    revenue_dict = {}\n    for sale in sales_data:\n        product = sale['product']\n        total = sale['quantity'] * sale['price_per_unit']\n        # Your code here\n    return [{'product': product, 'total_revenue': revenue} for product, revenue in revenue_dict.items()]\n\nsales_data = [\n    {'product': 'apple', 'quantity': 10, 'price_per_unit': 1.5},\n    {'product': 'banana', 'quantity': 5, 'price_per_unit': 0.75},\n    {'product': 'apple', 'quantity': 3, 'price_per_unit': 1.5},\n    {'product': 'orange', 'quantity': 8, 'price_per_unit': 1.0}\n]\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n        if product in revenue_dict:\n            revenue_dict[product] += total\n        else:\n            revenue_dict[product] = total\n</code>"
  },
  {
    "input": "Problem:\nI have a time series data frame which looks like this:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04'],\n        'Temperature': [30, 32, 31, 29]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nI want to calculate the rolling average temperature for a window of 2 days and store the result in a new column called `Rolling_Avg`. However, the rolling average must be calculated in a way that any NaN values should be replaced with the last valid temperature reading. The final output should look like this:\n\n```\n        Date  Temperature  Rolling_Avg\n0 2021-01-01           30           30\n1 2021-01-02           32           31\n2 2021-01-03           31           31.0\n3 2021-01-04           29           30.0\n```\n\nI tried using the rolling function, but I'm unsure how to handle the NaN values afterwards.\n\nA:\n```python\ndf['Rolling_Avg'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=2).mean().fillna(method='ffill')\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information about users and their activity on a website. There are several unique user IDs, and I want to categorize users based on their number of visits into three groups: \"High\", \"Medium\", and \"Low\". The definitions for these groups are as follows: \n\n- \"High\" for users with more than 20 visits\n- \"Medium\" for users with between 11 and 20 visits\n- \"Low\" for users with 10 or fewer visits\n\nCurrently, I have a DataFrame as shown below:\n\n```\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 2, 3, 4, 5],\n    'visits': [25, 14, 10, 31, 8]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a new column in this DataFrame called \"activity_level\" that will contain the activity level of each user based on the number of visits. I would like to implement a custom function to determine the activity level for reuse in the DataFrame.\n\nHow can I structure the code to achieve this?\n\nA:\n<code>\ndef categorize_activity(visits):\n    # return the activity level based on visits\n    pass\n\nresult = ...\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef categorize_activity(visits):\n    if visits > 20:\n        return \"High\"\n    elif 11 <= visits <= 20:\n        return \"Medium\"\n    else:\n        return \"Low\"\n\ndf['activity_level'] = df['visits'].apply(categorize_activity)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix represented as a dictionary of tuples in a data science context, where the keys are tuples representing the coordinates of non-zero elements and the values are the corresponding non-zero values. I need to convert this sparse matrix into a dense form using NumPy.\n\nFor example, if my sparse matrix is given as follows:\n\nsparse_matrix = {\n    (0, 1): 3,\n    (1, 0): 2,\n    (1, 2): 5,\n    (2, 2): 1\n}\n\nI want to create a dense 3x3 matrix that looks like this:\n\n[[0, 3, 0],\n [2, 0, 5],\n [0, 0, 1]]\n\nHow can I achieve this transformation?\n\nTo implement this, start with the following code:\n\n```python\nimport numpy as np\n\nsparse_matrix = {\n    (0, 1): 3,\n    (1, 0): 2,\n    (1, 2): 5,\n    (2, 2): 1\n}\n```\n\ndense_matrix = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndense_matrix = np.zeros((3, 3))\nfor (i, j), value in sparse_matrix.items():\n    dense_matrix[i, j] = value\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of email addresses, and I need to extract the usernames (the part before the '@') and create a new column for them. Here's the DataFrame I have:\n\n```\n      Email\n0  john.doe@example.com\n1  jane.smith@website.org\n2  test.user123@gmail.com\n3  sample@domain.com\n```\n\nI want to create a new column called 'Username' that contains just the usernames extracted from the 'Email' column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Email': ['john.doe@example.com', 'jane.smith@website.org', 'test.user123@gmail.com', 'sample@domain.com']})\n</code>\ndf['Username'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Username'] = df['Email'].str.split('@').str[0]"
  },
  {
    "input": "Problem:\nI have a daily sales record in a DataFrame as follows:\n\n```\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'Sales': [200, 220, 250, 270, 300, 320, 340, 360, 380, 400]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the 3-day moving average of the sales. The result should be a Series with the same index but showing `NaN` for the first two days as there are not enough data points to compute the average.\n\nHow can I obtain this moving average?\n\nA:\n```python\nmoving_average = df['Sales'].rolling(window=3).mean()\n```",
    "output": "\n<code>\nmoving_average = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch. You have a tensor `outputs` representing the prediction scores from your model, which has the shape `[64, 5]` for 64 samples and 5 classes. You also have a tensor `labels` that contains the true class indices for each sample, with a shape of `[64]`. \n\nYou want to calculate the number of correct predictions by comparing the predicted class indices with the true labels. However, first, you need to convert the `outputs` tensor to a tensor that contains the indices of the maximum scores across the classes for each sample.\n\nHow can you perform this operation in a single line? \n\nA:\n<code>\nimport torch\noutputs, labels = load_data()\n</code>\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>predictions = torch.argmax(outputs, dim=1)</code>"
  },
  {
    "input": "## Problem:\nYou have a 2D tensor representing image data in PyTorch, where each element represents a pixel value. The tensor shape is `(batch_size, height, width)`. You want to normalize the pixel values in the tensor to a range between 0 and 1 using Min-Max normalization. Specifically, the normalization formula you want to apply is:\n\n\\[ \\text{normalized\\_value} = \\frac{\\text{value} - \\text{min}}{\\text{max} - \\text{min}} \\]\n\nHow can you perform this operation on a given tensor `image_tensor` using PyTorch? \n\nA:\n```python\nimport torch\n\nimage_tensor = load_data()  # Assume this gives a tensor of shape (batch_size, height, width)\nmin_val = image_tensor.min()\nmax_val = image_tensor.max()\n# Fill in the blank below to get the normalized image tensor\nnormalized_image = ...  # put solution in this variable\n```",
    "output": "\n```python\nnormalized_image = (image_tensor - min_val) / (max_val - min_val)\n```"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing hourly temperature readings for a city over several days. The DataFrame looks like this:\n\n```\n+---------------------+----------+\n|       Timestamp     | Temperature |\n+---------------------+----------+\n| 2023-01-01 00:00:00 |     30   |\n| 2023-01-01 01:00:00 |     32   |\n| 2023-01-01 02:00:00 |     33   |\n| 2023-01-02 00:00:00 |     31   |\n| 2023-01-02 01:00:00 |     35   |\n| 2023-01-02 02:00:00 |     36   |\n| 2023-01-03 00:00:00 |     34   |\n| 2023-01-03 01:00:00 |     32   |\n| 2023-01-03 02:00:00 |     30   |\n+---------------------+----------+\n```\n\nYou want to calculate the daily average temperature and create a new DataFrame that summarizes this data. The resulting DataFrame should have a 'Date' column and an 'Average Temperature' column. What code can you use to achieve this?\n\n```\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00',\n        '2023-01-03 00:00:00', '2023-01-03 01:00:00', '2023-01-03 02:00:00'\n    ],\n    'Temperature': [30, 32, 33, 31, 35, 36, 34, 32, 30]\n}\n\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\ndf.set_index('Timestamp', inplace=True)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.resample('D').mean().reset_index()\nresult['Date'] = result['Timestamp'].dt.date\nresult = result[['Date', 'Temperature']].rename(columns={'Temperature': 'Average Temperature'})\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales of a product over several months, stored in a DataFrame with two columns: 'Date' and 'Sales'. The 'Date' column contains dates in the format 'YYYY-MM-DD', and the 'Sales' column contains the number of products sold on that date. \n\nI need to calculate a moving average of the sales over a 7-day window, ensuring that if there are any gaps in the dates (missing days), those entries are filled with NaN. The result should include the original date and the corresponding moving average in a new DataFrame.\n\nHere's how the DataFrame looks:\n\n```\n          Date    Sales\n0   2023-01-01      10\n1   2023-01-02      15\n2   2023-01-05      25\n3   2023-01-06      20\n4   2023-01-08      30\n5   2023-01-09      40\n```\n\nWhat I'm struggling with is how to properly apply the moving average while handling the missing dates. \nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-06', '2023-01-08', '2023-01-09'],\n                   'Sales': [10, 15, 25, 20, 30, 40]})\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.set_index('Date').asfreq('D')  # Fill missing dates with NaN\nresult = df.assign(Moving_Average=df['Sales'].rolling(window=7).mean()).reset_index()\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame `df` containing daily sales data for multiple products as follows:\n\n```\n           Date       Product  Sales\n0    2023-01-01        A        100\n1    2023-01-01        B        150\n2    2023-01-01        C        200\n3    2023-01-02        A        120\n4    2023-01-02        B        140\n5    2023-01-02        C        210\n6    2023-01-03        A        115\n7    2023-01-03        B        130\n8    2023-01-03        C        230\n```\n\nI want to calculate the daily percentage change in sales for each product, and keep the first row for each product's percentage change as NaN. The expected output should look like this:\n\n```\n           Date       Product  Sales  Percentage_Change\n0    2023-01-01        A        100                NaN\n1    2023-01-01        B        150                NaN\n2    2023-01-01        C        200                NaN\n3    2023-01-02        A        120                0.20\n4    2023-01-02        B        140              -0.07\n5    2023-01-02        C        210                0.05\n6    2023-01-03        A        115              -0.04\n7    2023-01-03        B        130              -0.07\n8    2023-01-03        C        230                0.09\n```\n\nI have initialized the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01',\n             '2023-01-02', '2023-01-02', '2023-01-02',\n             '2023-01-03', '2023-01-03', '2023-01-03'],\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 120, 140, 210, 115, 130, 230]\n}\n\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the following line to calculate the daily percentage change in sales for each product:\n\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(...) \n```",
    "output": "\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(lambda x: x.pct_change())\n```"
  },
  {
    "input": "Problem:\n\nI am working with a sparse matrix in Scipy and I want to extract the non-zero elements along with their corresponding row and column indices. Given a sparse matrix `A`, I need to create a list of tuples where each tuple contains the row index, column index, and the value of each non-zero element from the matrix. \n\nHere's what I have so far:\n\n```python\nfrom scipy import sparse\nA = sparse.csr_matrix([[0, 0, 3], [4, 0, 0], [0, 5, 6]])\n```\n\nI want to achieve an output that looks like this:\n\n```\n[(0, 2, 3), (1, 0, 4), (2, 1, 5), (2, 2, 6)]\n```\n\nWhat code can I use to accomplish this?\n\nA:\n<code>\nfrom scipy import sparse\n\nA = sparse.csr_matrix([[0, 0, 3], [4, 0, 0], [0, 5, 6]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = [(i, j, A[i, j]) for i, j in zip(*A.nonzero())]"
  },
  {
    "input": "Problem:\nYou are working with sparse matrices using SciPy and need to create a function that generates a compressed sparse row (CSR) matrix from a dense 2D list representation. The dense list may contain both zeros and non-zero elements, and the function should efficiently handle and return the CSR matrix. Given the following dense list:\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n\nHow can you create a CSR matrix from this dense representation?\n\nA:\n<code>\nfrom scipy import sparse\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n</code>\ncsr_matrix_result = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncsr_matrix_result = sparse.csr_matrix(dense_matrix)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor `data` representing grayscale image pixel values with shape `(batch_size, height, width)`. I want to normalize the pixel values of each image in the batch to the range [0, 1]. This can be done by subtracting the minimum value of each image from all its pixel values and dividing by the range (max - min) of the image. \n\nWrite the code that normalizes `data` using PyTorch.\n\nA:\n\n<code>\nimport torch\n\ndata = load_data()  # shape (batch_size, height, width)\n</code>\nnormalized_data = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = (data - data.min(dim=(1, 2), keepdim=True)[0]) / (data.max(dim=(1, 2), keepdim=True)[0] - data.min(dim=(1, 2), keepdim=True)[0])"
  },
  {
    "input": "### Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, height, width, channels) and I want to normalize each image along the height and width dimensions (i.e., per image). Given that my tensor has a shape of (2, 4, 4, 3), how can I perform this normalization using TensorFlow and PyTorch?\n\nHere's an example tensor:\n\n```python\nimport torch\nimport tensorflow as tf\n\n# Example tensor for PyTorch\nt = torch.tensor([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n\n# Equivalent tensor for TensorFlow\nx = tf.constant([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n```\n\nNormalize this tensor to have values between 0 and 1 for each image. Fill in the code to achieve this normalization for both TensorFlow and PyTorch.\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nimport tensorflow as tf\nt, x = load_data()\n```\nnormalized_t = ... # put solution in this variable for PyTorch\nnormalized_x = ... # put solution in this variable for TensorFlow\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\nnormalized_t = (t - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0]) / (t.max(dim=2, keepdim=True)[0].max(dim=3, keepdim=True)[0] - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0])\nnormalized_x = (x - tf.reduce_min(x, axis=[1, 2], keepdims=True)) / (tf.reduce_max(x, axis=[1, 2], keepdims=True) - tf.reduce_min(x, axis=[1, 2], keepdims=True))\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing hourly temperature readings from multiple sensors over several days. The DataFrame is structured as follows:\n\n```\nSensor_ID   Timestamp                Temperature\nA           2023-10-01 00:00:00     20.1\nA           2023-10-01 01:00:00     19.8\nA           2023-10-01 02:00:00     20.2\nB           2023-10-01 00:00:00     21.5\nB           2023-10-01 01:00:00     21.6\nB           2023-10-01 02:00:00     21.2\nA           2023-10-02 00:00:00     18.7\nA           2023-10-02 01:00:00     19.0\nB           2023-10-02 00:00:00     20.0\n```\n\nYou want to resample the data to a daily frequency, calculating the mean temperature for each sensor per day. However, you also need to ensure that the date-time index is properly converted. You started with the following imports and DataFrame creation:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Sensor_ID': ['A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'B'],\n    'Timestamp': ['2023-10-01 00:00:00', '2023-10-01 01:00:00', '2023-10-01 02:00:00',\n                  '2023-10-01 00:00:00', '2023-10-01 01:00:00', '2023-10-01 02:00:00',\n                  '2023-10-02 00:00:00', '2023-10-02 01:00:00', '2023-10-02 00:00:00'],\n    'Temperature': [20.1, 19.8, 20.2, 21.5, 21.6, 21.2, 18.7, 19.0, 20.0]\n}\ndf = pd.DataFrame(data)\n```\n\nFollowing this, you want to fill in the missing section of code to achieve your goal. Your current attempt is:\n```python\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\ndf.set_index('Timestamp', inplace=True)\nresult = df.groupby('Sensor_ID').resample('D').mean()\n```\n\nFill in the blank to produce the result variable correctly:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('Sensor_ID').resample('D').mean().reset_index()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains daily temperature recordings as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n        'Temperature': [30, 32, None, 29, 31]}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the missing temperature value on '2023-01-03' by taking the average of the temperatures before and after it, rounding to the nearest whole number. Then, provide the DataFrame with the filled values in order of their dates.\n\nThe expected output should look like this:\n\n```python\n        Date  Temperature\n0 2023-01-01          30.0\n1 2023-01-02          32.0\n2 2023-01-03          30.0\n3 2023-01-05          29.0\n4 2023-01-06          31.0\n```\n\nYou are currently getting the DataFrame like this:\n```python\ndf['Temperature'].fillna(...) \n```\nFill in the blank to complete the code that accurately replaces the missing temperature value:\n\nresult = ...  # put solution in this variable",
    "output": "\n```python\nresult = df['Temperature'].fillna(round((df['Temperature'].shift(1) + df['Temperature'].shift(-1)) / 2))\n```"
  },
  {
    "input": "Problem:\nI am working with a sparse matrix in the context of a recommendation system. I have a sparse matrix representing user interactions with items, where the rows correspond to users and the columns correspond to items. The matrix is represented in Compressed Sparse Row (CSR) format. I wish to efficiently extract the indices of the non-zero elements from a specific user's interactions.\n\nFor example, if the sparse matrix looks like:\n```\nfrom scipy import sparse\ndata = sparse.csr_matrix([[0, 1, 0], [0, 0, 2], [1, 0, 0]])\n```\nI want to extract the item indices for user 2 (zero-based index), which has interactions.\n\nHow do I achieve that?\n\nA:\n<code>\nfrom scipy import sparse\ninteraction_matrix = sparse.csr_matrix([[0, 1, 0], [0, 0, 2], [1, 0, 0]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = interaction_matrix[1].nonzero()[1]\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset represented as a list of dictionaries where each dictionary corresponds to an individual's records. Each record includes 'age', 'income', and 'expenses'. I want to create a function that calculates the savings for each record by subtracting expenses from income. The function should return a list of savings. Here\u2019s a sample of my dataset:\n\n```python\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n```\n\nI need a way to efficiently calculate the savings and return them as a list.\n\nA:\n<code>\ndata = [\n    {'age': 25, 'income': 5000, 'expenses': 3000},\n    {'age': 40, 'income': 7000, 'expenses': 2000},\n    {'age': 30, 'income': 6000, 'expenses': 2500},\n]\n\ndef calculate_savings(records):\n    # return the savings list here\n    savings = ...\n</code>\nsavings = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    savings = [record['income'] - record['expenses'] for record in records]\n    return savings\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataframe representing sales data, shown below:\n\n```python\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\n\nYou want to create a new column called `total_sales`, which is calculated as `quantity * price`. However, if the total sales for any row is less than 50, you want to set it to 0. Your goal is to implement a custom function to achieve this. \n\nWhat should you write to obtain the modified dataframe with the new column?\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': ['P1', 'P2', 'P1', 'P3', 'P2', 'P1', 'P3'],\n    'quantity': [5, 10, 3, 2, 7, 1, 4],\n    'price': [20, 30, 20, 40, 30, 20, 40]\n})\n```\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n```python\ndef calculate_total_sales(row):\n    total = row['quantity'] * row['price']\n    return total if total >= 50 else 0\n\ndf['total_sales'] = df.apply(calculate_total_sales, axis=1)\n```",
    "output": "\n```python\ndf['total_sales'] = df.apply(lambda row: max(row['quantity'] * row['price'], 0) if row['quantity'] * row['price'] >= 50 else 0, axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI am building a neural network to classify images using both TensorFlow and PyTorch. I need to apply a common preprocessing step to my image tensor that consists of normalizing it by subtracting the mean and dividing by the standard deviation per channel. The images are represented as a tensor in the shape of (batch_size, height, width, channels). \n\nGiven a tensor `images` and the mean and standard deviation tensors `mean` and `std`, how can I perform this normalization for both frameworks?\n\nMCVE\nDesired Output\n\nimport torch\nimport tensorflow as tf\n\n# PyTorch normalization\nimages_pytorch = torch.rand((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean = torch.tensor([0.5, 0.5, 0.5])  # mean for each channel\nstd = torch.tensor([0.2, 0.2, 0.2])   # std for each channel\n\n# TensorFlow normalization\nimages_tensorflow = tf.random.uniform((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean_tf = tf.constant([0.5, 0.5, 0.5])  # mean for each channel\nstd_tf = tf.constant([0.2, 0.2, 0.2])    # std for each channel\n\n# PyTorch normalization\nnormalized_images_pt = ...  # put solution in this variable\n\n# TensorFlow normalization\nnormalized_images_tf = ...  # put solution in this variable\n\nA:\n<code>\nimages_pt, mean, std = load_data()\n</code>\nnormalized_images_pt = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nnormalized_images_pt = (images_pytorch - mean[None, None, None, :]) / std[None, None, None, :]\nnormalized_images_tf = (images_tensorflow - mean_tf) / std_tf\n</code>"
  },
  {
    "input": "Problem:\nI have a list of employee records where each record contains an employee's name and their respective department. I want to create a function that organizes these records into a dictionary, where each key is a department name and the corresponding value is a list of employee names belonging to that department. \n\nThe input is a list structured like this:\n\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\nHow can I implement such a function that populates a dictionary with this information? \n\nPlease define the function to achieve this task and output the result into the variable 'department_dict'. \n\n<code>\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\n### Define the function and populate the department_dict variable\n</code>\ndepartment_dict = ... # put solution in this variable",
    "output": "\n<code>\ndef organize_records(records):\n    department_dict = {}\n    for name, department in records:\n        if department not in department_dict:\n            department_dict[department] = []\n        department_dict[department].append(name)\n    return department_dict\n\ndepartment_dict = organize_records(records)\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame with a column that contains mixed content, including product IDs and quantities in a semi-structured format. The DataFrame looks like this:\n\n```\n   products\n0  ID123: 45\n1  ID456: 29\n2  ID123: 60\n3  ID789: 15\n4  ID456: 22\n```\n\nI want to extract the product IDs and their corresponding quantities into two new columns, 'ProductID' and 'Quantity'. The expected output should look like this:\n\n```\n   products   ProductID  Quantity\n0  ID123: 45     ID123        45\n1  ID456: 29     ID456        29\n2  ID123: 60     ID123        60\n3  ID789: 15     ID789        15\n4  ID456: 22     ID456        22\n```\n\nThe code I have written has not been effective. Here is what I attempted:\n\n```\ndf['ProductID'] = df.products.replace(r'([A-Z]+\\d+): \\d+', r'\\1', regex=True)\ndf['Quantity'] = df.products.replace(r'[A-Z]+\\d+: (\\d+)', r'\\1', regex=True)\n```\n\nBut it doesn't work as expected. Can you provide a suggestion? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'products': ['ID123: 45', 'ID456: 29', 'ID123: 60', 'ID789: 15', 'ID456: 22']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['ProductID'] = df['products'].str.split(': ').str[0]\ndf['Quantity'] = df['products'].str.split(': ').str[1].astype(int)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for different products across several months. I would like to create a custom function that computes the total sales for each product over a specified range of months. The DataFrame looks like this:\n\n```\n   Month  Product_A  Product_B  Product_C\n0      1         200        150        300\n1      2         250        200        350\n2      3         300        250        400\n3      4         350        300        450\n4      5         400        350        500\n```\n\nThe function should take the month range as input (e.g., from month 2 to month 4) and return the total sales for each product in that range. I want to call this function that I will define as `calculate_total_sales(df, start_month, end_month)`. Here\u2019s how you can initialize the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': [1, 2, 3, 4, 5],\n    'Product_A': [200, 250, 300, 350, 400],\n    'Product_B': [150, 200, 250, 300, 350],\n    'Product_C': [300, 350, 400, 450, 500]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, write the function call to compute the total sales from month 2 to month 4:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df, start_month, end_month):\n    filtered_df = df[(df['Month'] >= start_month) & (df['Month'] <= end_month)]\n    total_sales = filtered_df[['Product_A', 'Product_B', 'Product_C']].sum()\n    return total_sales\n\nresult = calculate_total_sales(df, 2, 4)\n```"
  },
  {
    "input": "Problem:\nConsider the following pandas DataFrame which contains a list of emails in a column named 'email_addresses':\n```python\nemail_df = pd.DataFrame({'email_addresses': ['john.doe@example.com', 'jane_smith@domain.org', \n                                              'user123@my-site.info', 'invalid-email@.com', \n                                              'another.email@sub.domain.com']})\n```\nYour task is to extract the username and domain from the 'email_addresses' that follow the standard email format. The final DataFrame should contain three columns: 'username', 'domain', and 'valid_email', where 'valid_email' indicates whether the email was valid (True) or not (False). For invalid emails, 'username' and 'domain' should be set to None. \n\nThe final DataFrame should look like this:\n```\n     username           domain  valid_email\n0      john.doe        example.com        True\n1     jane_smith         domain.org        True\n2       user123        my-site.info        True\n3         None                None       False\n4    another.email      sub.domain.com        True\n```\n\nI've written some code to try and accomplish this, but I'm struggling with the regex pattern needed to identify valid emails and populate the new columns. \n\nA:\n```python\nimport pandas as pd\nimport re\n\nemail_df = pd.DataFrame({'email_addresses': ['john.doe@example.com', 'jane_smith@domain.org', \n                                              'user123@my-site.info', 'invalid-email@.com', \n                                              'another.email@sub.domain.com']})\n```\nemail_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef validate_email(email):\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    match = re.match(pattern, email)\n    if match:\n        username, domain = email.split('@')\n        return username, domain, True\n    return None, None, False\n\nresults = email_df['email_addresses'].apply(validate_email)\nemail_df[['username', 'domain', 'valid_email']] = pd.DataFrame(results.tolist(), index=email_df.index)\nemail_df = email_df[['username', 'domain', 'valid_email']]\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing daily temperature readings as follows:\n\n```\n   Date         Temperature\n0  2022-01-01    30\n1  2022-01-02    28\n2  2022-01-03    32\n3  2022-01-04    35\n4  2022-01-05    29\n5  2022-01-06    31\n```\n\nYou need to calculate the 3-day rolling average temperature. The resulting DataFrame should include a new column for the rolling average, with the first two rows of the new column containing NaN values because there are not enough prior days to compute the average. Furthermore, you want to convert the Date column from a string format to a datetime format before performing the rolling average computation.\n\nThe expected resulting DataFrame should look like this:\n\n```\n   Date         Temperature  Rolling_Avg\n0  2022-01-01    30          NaN\n1  2022-01-02    28          NaN\n2  2022-01-03    32          30.0\n3  2022-01-04    35          31.0\n4  2022-01-05    29          32.0\n5  2022-01-06    31          31.0\n```\n\nHere is the current code snippet that you have, but it is incomplete:\n\n```\nimport pandas as pd\nimport numpy as np\n\ndata = {'Date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06'],\n        'Temperature': [30, 28, 32, 35, 29, 31]}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date']) \ndf['Rolling_Avg'] = df['Temperature']... # put solution in this variable\n```\n\nFill in the blank to calculate the 3-day rolling average for the temperature readings.",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse tensor representation in PyTorch. You have a tensor that represents a 3D grid of values, but much of this tensor is zero, making it sparse. You need to find the maximum values along the last axis for each slice of the tensor. Here's how your tensor looks:\n\n```\nt = torch.tensor([[[0, 0, 1], [0, 0, 0], [0, 2, 0]],\n                   [[3, 0, 0], [0, 0, 0], [0, 4, 0]],\n                   [[0, 0, 0], [5, 0, 6], [0, 0, 0]]])\n```\n\nYou need to return a tensor that contains the maximum values for each 2D slice along the last axis. For the given tensor `t`, the expected result should look like this:\n\n```\ntensor([[1, 0, 2],\n        [3, 0, 4],\n        [0, 5, 6]])\n```\n\nHow can you achieve this in PyTorch? \n\nA:\n<code>\nimport torch\nt = load_data()\n</code>\nmax_values = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_values = t.max(dim=2).values\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a sparse tensor representation of a high-dimensional dataset where many values are zero. I have a sparse tensor of shape (3, 4, 5) that I want to convert into a dense representation, but it only contains a few non-zero elements. How can I correctly convert this sparse tensor back to a dense tensor while preserving only the non-zero values and their respective indices?\n\nHere is the setup for my sparse tensor:\n\n```python\nimport torch\n\n# Assume this is the sparse tensor with the same shape\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 1, 2], [0, 2, 3]]),\n    values=torch.tensor([3.0, 4.0, 5.0]),\n    size=(3, 4, 5)\n)\n```\n\nI would like to produce a dense tensor and store it in the variable `dense_tensor` as follows:\n\nA:\n\n```python\ndense_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\ndense_tensor = sparse_tensor.to_dense()\n```"
  },
  {
    "input": "Problem:\nI have a 3D sparse tensor stored in a sparse format (using `scipy.sparse`), where each non-zero entry represents a measurement from a sensor deployed in various locations over time. The tensor has the shape (num_sensors, num_locations, num_time_steps). However, I need to calculate the mean value for each sensor over all time steps, but without converting the entire tensor to a dense format due to memory constraints. \n\nHow can I efficiently compute the mean values for each sensor across all time steps, resulting in a 2D array of shape (num_sensors, num_locations) while retaining the sparse nature of the data?\n\nA:\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Create a 3D sparse tensor example\nnum_sensors = 4\nnum_locations = 3\nnum_time_steps = 5\ndata = np.random.rand(10)  # Random non-zero entries\nindices = np.random.randint(0, num_sensors, size=(10, 1)).flatten(), \\\n          np.random.randint(0, num_locations, size=(10, 1)).flatten(), \\\n          np.random.randint(0, num_time_steps, size=(10, 1)).flatten()\nsparse_tensor = sparse.COO(coords=indices, data=data, shape=(num_sensors, num_locations, num_time_steps))\n\n# Define the function to calculate mean over time steps\ndef compute_mean_over_time(sparse_tensor):\n    # return the solution in this function\n    # mean_values = compute_mean_over_time(sparse_tensor)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    mean_values = sparse_tensor.sum(axis=2).A / sparse_tensor.count(axis=2).A\n    return mean_values\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor in PyTorch and need to efficiently manipulate it. Specifically, I want to sum a scalar value to all non-zero elements in a 3D sparse tensor. The tensor is initialized as follows:\n\n```python\nimport torch\nsparse_tensor = torch.sparse_coo_tensor(indices=torch.tensor([[0, 1, 1, 2], [0, 2, 3, 1]]), \n                                        values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n                                        size=(3, 4))\n```\n\nNow, I want to add a scalar value of 5 to all non-zero elements in `sparse_tensor`. \n\nWhat should I use to accomplish this?\n\nA:\n<code>\nscalar = 5\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = sparse_tensor + scalar * sparse_tensor.to_dense().clamp(min=0)"
  },
  {
    "input": "Problem:\n\nIn a time series forecasting project using TensorFlow, you have a dataset containing daily temperatures over a year, represented as a 365 x 1 tensor. You are tasked with building a simple LSTM model to predict the next day's temperature based on the previous five days' temperatures. After preparing your dataset, you pass the data through the LSTM layers and obtain output predictions stored in a tensor of shape [num_samples, 1]. \n\nNow, you want to compute the root mean square error (RMSE) of your predictions compared to the actual temperatures which are stored in a tensor of the same shape. The formula for RMSE is:\n\n\\[ \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2} \\]\n\nWhere \\( y_i \\) are the actual values and \\( \\hat{y_i} \\) are the predicted values. \n\nYou have already defined your predictions and actual values like this:\n\n```python\nimport tensorflow as tf\n\npredictions = tf.constant([...], shape=(365, 1))\nactuals = tf.constant([...], shape=(365, 1))\n```\n\nWhat code can be used to compute the RMSE and store the result in a variable named `rmse`?\n\nA:\n```python\nrmse = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nrmse = tf.sqrt(tf.reduce_mean(tf.square(actuals - predictions)))\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains product descriptions in one of its columns. The descriptions sometimes include the brand name followed by the product name, and sometimes just the product name. Here is how the DataFrame looks:\n\n   description\n0  Nike Air Max 270\n1  Adidas Ultraboost\n2  Reebok Classic\n3  Puma RS-X\n\nI want to extract the brand name and the product name into two separate columns named \"brand\" and \"product\". The resulting DataFrame should look like this:\n\n   brand      product\n0  Nike      Air Max 270\n1  Adidas    Ultraboost\n2  Reebok    Classic\n3  Puma      RS-X\n\nHow can I achieve this? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'description': ['Nike Air Max 270', 'Adidas Ultraboost', 'Reebok Classic', 'Puma RS-X']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['description'].str.extract(r'(?P<brand>^\\w+)\\s+(?P<product>.+)')"
  },
  {
    "input": "Problem:\nI have a dataset that contains information about user activities on a website, structured as follows:\n\n```\nuser_id  activity          timestamp\n1        login             2023-01-01 10:00:00\n1        view_product      2023-01-01 10:05:00\n1        logout            2023-01-01 10:15:00\n2        login             2023-01-01 10:10:00\n2        view_product      2023-01-01 10:20:00\n2        logout            2023-01-01 10:30:00\n1        view_product      2023-01-02 11:00:00\n```\n\nI want to extract the first and last activity for each user across multiple days ensuring that the activities are logged in a proper order by using the 'timestamp'. The expected output should include the `user_id`, the `first_activity` corresponding to the earliest `timestamp`, and the `last_activity` corresponding to the latest `timestamp` for each user.\n\nA function is provided to load the data into a DataFrame, and you should create a custom function that will process this data to give the desired output.\n\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 1, 2, 2, 2, 1],\n    'activity': ['login', 'view_product', 'logout', 'login', 'view_product', 'logout', 'view_product'],\n    'timestamp': pd.to_datetime(['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:15:00', \n                                  '2023-01-01 10:10:00', '2023-01-01 10:20:00', '2023-01-01 10:30:00', \n                                  '2023-01-02 11:00:00'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('user_id').agg(\n    first_activity=('activity', 'first'),\n    last_activity=('activity', 'last')\n).reset_index()\n```"
  },
  {
    "input": "Problem:\nI have a list of dictionaries where each dictionary represents a product with its name, price, and quantity sold. I need to calculate the total revenue generated from each product and return this information in a new list of dictionaries, where each dictionary contains the product name and its total revenue. The input looks like this:\n\nproducts = [\n    {'name': 'Widget A', 'price': 20, 'quantity': 100},\n    {'name': 'Widget B', 'price': 15, 'quantity': 200},\n    {'name': 'Widget C', 'price': 30, 'quantity': 150}\n]\n\nThe expected output for total revenue calculations should be:\n\n[\n    {'name': 'Widget A', 'total_revenue': 2000},\n    {'name': 'Widget B', 'total_revenue': 3000},\n    {'name': 'Widget C', 'total_revenue': 4500}\n]\n\nYou need to implement a custom function to calculate the total revenue for each product from the input list.\n\nA:\n<code>\nproducts = [\n    {'name': 'Widget A', 'price': 20, 'quantity': 100},\n    {'name': 'Widget B', 'price': 15, 'quantity': 200},\n    {'name': 'Widget C', 'price': 30, 'quantity': 150}\n]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = [\n    {'name': product['name'], 'total_revenue': product['price'] * product['quantity']}\n    for product in products\n]\n</code>"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a neural network model using TensorFlow and PyTorch to classify images from the CIFAR-10 dataset. You have preprocessed the dataset and created a 4D tensor `images_tensor` of shape (num_samples, 32, 32, 3), and the corresponding labels in a 1D tensor `labels_tensor`. Your neural network model should expect input of this shape. \n\nAfter defining your model architecture using TensorFlow, you want to obtain the model's predictions, which will yield a 2D tensor where each row represents the predicted class probabilities for an input image. You need to extract the predicted class index (the class with the highest probability) for each image into a 1D tensor.\n\nHow would you achieve this in TensorFlow?\n\nA:\n\n<code>\nimport tensorflow as tf\n\n# Assuming images_tensor and labels_tensor are already defined\nmodel = ...  # define your model architecture here\npredictions = model(images_tensor)  \npredicted_classes = ...  # put solution in this variable\n### BEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a collection of images represented as a 3D tensor in PyTorch, where the shape of the tensor is (number_of_images, height, width). However, the images have been padded with zeros to make them the same size, which I now want to compress into a sparse representation. The images tensor looks like this:\n\n```\ntensor([\n    [[0, 0, 0], [1, 2, 3], [0, 0, 0]],\n    [[4, 5, 0], [0, 0, 0], [0, 0, 0]],\n    [[0, 0, 0], [6, 7, 8], [0, 0, 0]]\n])\n```\n\nI want to create a sparse tensor from this 3D tensor that retains the non-zero values. How would I generate this sparse tensor using PyTorch?\n\nA:\n<code>\nimport torch\n\nimages = torch.tensor([\n    [[0, 0, 0], [1, 2, 3], [0, 0, 0]],\n    [[4, 5, 0], [0, 0, 0], [0, 0, 0]],\n    [[0, 0, 0], [6, 7, 8], [0, 0, 0]]\n])\n</code>\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsparse_tensor = images.to_sparse()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing features in a tensor format and I want to normalize these features using TensorFlow. The tensor `data` has a shape of (100, 10) representing 100 samples and 10 features. I want to scale these features to a range of [0, 1]. How can I efficiently perform this normalization operation?\n\nA:\n\n<code>\nimport tensorflow as tf\n\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = (data - tf.reduce_min(data, axis=0)) / (tf.reduce_max(data, axis=0) - tf.reduce_min(data, axis=0))</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing daily temperature records for a city over a month, as shown below:\n\n```\n+------------+----------+\n|    Date    |  Temp    |\n+------------+----------+\n| 2023-01-01 |    23    |\n| 2023-01-02 |    25    |\n| 2023-01-03 |    21    |\n| 2023-01-04 |    20    |\n| 2023-01-05 |    22    |\n| ...        |   ...    |\n| 2023-01-30 |    19    |\n| 2023-01-31 |    18    |\n+------------+----------+\n```\n\nYou need to compute a new column called `Rolling Avg` that represents the 7-day rolling average of the temperature. The rolling average should be calculated such that the first six entries in the `Rolling Avg` column will be NaN (since there are not enough previous days to calculate the average).\n\nComplete the following code to calculate and add the `Rolling Avg` column to the DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Create the DataFrame\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=31, freq='D'),\n    'Temp': [23, 25, 21, 20, 22, np.nan, 24, 26, 27, 21, \n             20, 19, 18, 26, 23, 27, 29, 30, 31, 28,\n             24, 22, 25, 26, 20, 19, 18, 17, 16, 15, \n             19, 18, 19]\n}\ndf = pd.DataFrame(data)\n\n# Add rolling average calculation\ndf['Rolling Avg'] = df['Temp'].rolling(window=7).mean()\n\n# Show the updated DataFrame\nprint(df)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse tensor representing an image with dimensions (3, 4, 5) and I want to set all values in the second channel (index 1) to zero without converting the sparse tensor to a dense format. I'm using PyTorch for my operations. Can you show me how to modify the sparse tensor directly while maintaining its sparse nature?\n\nThe initial sparse tensor is created as follows:\n\n```python\nimport torch\n\nindices = torch.tensor([[0, 0, 1, 1], [0, 2, 1, 3], [1, 1, 1, 1]])\nvalues = torch.tensor([1, 2, 3, 4])\nsize = (3, 4, 5)\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n```\n\nI need the code to fill in where indicated:\n\nA:\n\n```python\nsparse_tensor[1, ...] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nsparse_tensor = sparse_tensor.coalesce()  # Ensure the tensor is coalesced\nindices = sparse_tensor.indices()\nvalues = sparse_tensor.values()\n\n# Create a mask for the second channel\nmask = indices[0] == 1\n\n# Set the values in the second channel to zero\nvalues[mask] = 0\n\n# Create a new sparse tensor with the updated values\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size)\nEND SOLUTION\n```"
  },
  {
    "input": "## Problem\nI have a dataset that records the daily temperatures of a city over several years. The data is in a pandas DataFrame with two columns: `Date` and `Temperature`. I want to resample this DataFrame to get the average temperature for each month, and then calculate the rolling average of these monthly averages over a window of 3 months.\n\nThe format of the DataFrame is as follows:\n```\n        Date       Temperature\n0  2018-01-01         5.0\n1  2018-01-02         4.5\n2  2018-01-03         5.5\n3  2018-02-01         6.5\n4  2018-02-02         7.0\n...\n```\nAfter performing the resampling and rolling average calculation, I would like to see the output that only shows the `Date` (as the first day of the month) and the rolling average `Temperature`.\n\nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\n# Sample DataFrame\ndf = pd.DataFrame({\n        'Date': pd.date_range(start='2018-01-01', periods=90, freq='D'),\n        'Temperature': [5.0, 4.5, 5.5, 6.5, 7.0] * 18\n})\n\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmonthly_avg = df.resample('M').mean()\nrolling_avg = monthly_avg.rolling(window=3).mean()\nresult = rolling_avg.reset_index().rename(columns={'Date': 'Date', 'Temperature': 'Rolling_Avg_Temperature'})\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user-item interactions in a recommendation system, where a user has interacted with a limited number of items. Given the following components:\n\n1. A sparse matrix `user_item` of shape (1000, 5000) representing interactions, where rows correspond to users and columns to items.\n2. A list `user_ids` containing the indices of users whose interactions you want to extract.\n\nYou need to create a new sparse matrix `selected_users` that contains only the interactions of the specified users.\n\nThe `user_item` matrix is defined as follows:\n\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]  # example user indices\n```\n\nHow can you fill the variable `selected_users` to contain only the rows of `user_item` corresponding to the users in `user_ids`?\n\nA:\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]\n```\nselected_users = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_users = user_item[user_ids, :]\n```"
  },
  {
    "input": "Problem:\nYou are analyzing daily stock prices recorded in a pandas DataFrame, and you want to compute the percentage change in closing prices from one day to the next. However, if the closing price was zero on a given day, the percentage change should be set to NaN for that day to avoid division by zero. Additionally, you want to drop any rows that contain NaN values after calculating the percentage change.\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n    'Close': [150, 0, 155, 160, 0]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n```\n\nHow can you calculate the percentage change in 'Close' prices and drop NaN values in a single line of code?\n\nA:\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df['Close'].replace(0, pd.NA).pct_change().dropna()\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix representing the features of a set of textual documents, where each row corresponds to a document and each column corresponds to a unique word. The entries of the matrix are counts of how many times each word appears in each document. Additionally, I have a list of word indices that I want to extract from the matrix into a new dense matrix. \n\nGiven the sparse matrix `X` (in the form of a COO format) and a list of word indices `word_indices`, how can I create a dense matrix `D` that retains only the columns indicated by `word_indices`? The shape of `D` should be `(num_documents, len(word_indices))`.\n\nFor instance, if `X` is defined as:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\n```\n\nAnd the `word_indices` is `[0, 2]`, the desired output for `D` should look like this:\n\n```\n[[0 3]\n [2 0]]\n```\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Given sparse matrix X\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\nword_indices = [0, 2]  # List of indices to extract\n\n# Convert X to a dense format and extract necessary columns\nD = ... # put solution in this variable\n### BEGIN SOLUTION\n```",
    "output": "\n<code>\nD = X[:, word_indices].toarray()\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset that contains product reviews in a DataFrame. Each review is a string of text in a column named \"review\". I want to extract the product names mentioned at the beginning of each review, which are always followed by the keyword \"reviewed\". However, the reviews may also contain punctuation or multiple spaces. For example:\n\n| review                       |\n|------------------------------|\n| \"ProductA reviewed this item ...\" |\n| \"ProductB     reviewed it ...\"  |\n| \"An excellent experience with ProductC reviewed\" |\n\nI need to create a new column called \"product_name\" that contains just the product names extracted from the reviews.\n\nHere is how my DataFrame looks:\n\n```python\ndf = pd.DataFrame({\n    'review': [\n        \"ProductA reviewed this item ...\",\n        \"ProductB     reviewed it ...\",\n        \"An excellent experience with ProductC reviewed\"\n    ]\n})\n```\n\nI am struggling to implement this extraction correctly. Can you help me fill in the missing piece of code here?\n\n---\n\ndf['product_name'] = df['review'].str.extract(r'^\\s*(.*?)\\s+reviewed')\n\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df['product_name']\n```"
  },
  {
    "input": "Problem:\n\nI have a large 2D sparse matrix representing a user-item interaction dataset where each row corresponds to a user, and each column corresponds to an item. The interaction is stored in a compressed sparse row (CSR) format using `scipy`. I want to normalize the non-zero values of this matrix so that they sum to 1 for each user. \n\nGiven a `csr_matrix` of shape (N, M), I want to create a new `csr_matrix` where each user's ratings are normalized. Essentially, for every user (row), the promised transformation will be:\n\n`normalized[user, item] = original[user, item] / sum(original[user, :])`\n\nWhat is the efficient way to perform this operation without fully converting the sparse matrix to a dense format?\n\nA:\n<code>\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\n# Simulating user-item interaction data\nN, M = 1000, 5000 \ndata = np.random.rand(50000)\nrow_indices = np.random.randint(0, N, size=50000)\ncol_indices = np.random.randint(0, M, size=50000)\n\n# Creating a sparse matrix in CSR format\noriginal = csr_matrix((data, (row_indices, col_indices)), shape=(N, M))\n</code>\nnormalized = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized = original.multiply(1 / np.array(original.sum(axis=1)).flatten())"
  },
  {
    "input": "Problem:\nI have a time series DataFrame with temperatures recorded every hour over several days. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Timestamp': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', '2023-01-01 03:00',\n                  '2023-01-02 00:00', '2023-01-02 01:00', '2023-01-02 02:00', '2023-01-02 03:00'],\n    'Temperature': [20.1, 19.8, 19.6, 19.7, 18.4, 18.5, 18.3, 18.7]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nI want to resample this temperature data to daily frequency, calculating the average temperature for each day. However, I need to ensure that the resulting DataFrame has the date as the index and the average temperature for each day as a separate column. \n\nThe expected output format should look like this:\n\n```\n            Temperature\nTimestamp\n2023-01-01          ...\n2023-01-02          ...\n```\n\nCan you provide the line of code that fills in the blank in the following placeholder?\n\n```python\ndaily_avg = df.set_index('Timestamp').resample(...).mean()\n```",
    "output": "\n```python\ndaily_avg = df.set_index('Timestamp').resample('D').mean()\n```"
  },
  {
    "input": "```python\nProblem:\nI have a dataframe containing customer feedback in a single string format where customer IDs and messages are combined in the following form: \"ID:1234; Message:Great service; ID:5678; Message:Not satisfied\". I need to extract customer IDs and their corresponding messages into separate columns. \n\nMy dataframe df looks like this:\n\nfeedback\n0  ID:1234; Message:Great service; ID:5678; Message:Not satisfied\n\nI am unsure how to parse this string efficiently using pandas string methods to create a structured dataframe.\n\nThe output I want should look like this:\n\n  customer_id         message\n0        1234      Great service\n1        5678      Not satisfied\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'feedback': ['ID:1234; Message:Great service; ID:5678; Message:Not satisfied']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf = df['feedback'].str.split('; ', expand=True).stack().str.extract(r'ID:(\\d+); Message:(.*)')[0].reset_index(drop=True)\ndf.columns = ['customer_id', 'message']\n</code>\n```"
  },
  {
    "input": "## Problem\nI need to analyze customer transaction data from a CSV file that contains columns: `customer_id`, `transaction_date`, and `amount`. I want to compute the total spending of each customer per month and return a DataFrame that shows `customer_id`, `month`, and `total_spending`. \n\nI started by grouping the DataFrame but I'm struggling to implement a custom function to calculate this total on a month-to-month basis. \n\nHere's an example of how my DataFrame looks:\n\n```\n   customer_id transaction_date  amount\n0           1      2023-01-15     100\n1           1      2023-01-20     50\n2           2      2023-01-25     200\n3           1      2023-02-01     150\n4           2      2023-02-15     300\n```\n\nIn order to do this, I need to define a function that computes the monthly spending and apply it to the DataFrame. \n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 1, 2],\n    'transaction_date': ['2023-01-15', '2023-01-20', '2023-01-25', '2023-02-01', '2023-02-15'],\n    'amount': [100, 50, 200, 150, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')\nresult = df.groupby(['customer_id', 'month'])['amount'].sum().reset_index(name='total_spending')\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have a pandas DataFrame that contains product reviews with metadata. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review_text': [\n        'I love the coffee! It is great, good smell.',\n        'The tea was okay, not the best, I prefer another brand.',\n        'Fantastic chocolate flavor, would definitely buy again!',\n        'I really disliked the texture and the taste.'\n    ],\n    'rating': [5, 3, 4, 1]\n})\n```\n\nYou want to extract keywords (nouns) from the review_text column and create a new column called keywords that concatenates these keywords using a comma as a separator. For this demonstration, you can consider keywords as the words with lengths greater than 3 characters. You can create a simple function to filter and join these keywords.\n\nHere's where you're stuck. You want to apply this custom keyword extraction function to each review and populate the keywords column accordingly.\n\n```python\ndef extract_keywords(text):\n    # Replace this comment with your logic to extract words longer than 3 characters\n    pass\n\ndf['keywords'] = df['review_text'].apply( ... ) # fill in the blank to complete the DataFrame modification\n```\n\nFill in the blank to complete the code that applies your function to the review_text and updates the keywords column in the DataFrame.",
    "output": "\n```python\ndef extract_keywords(text):\n    return ', '.join([word for word in text.split() if len(word) > 3])\n\ndf['keywords'] = df['review_text'].apply(extract_keywords)\n```"
  },
  {
    "input": "## Problem\n\nYou are tasked with training a simple neural network using both TensorFlow and PyTorch to classify images of handwritten digits (from the MNIST dataset). You need to preprocess the images by normalizing the pixel values to the range [0, 1] and then create a model that consists of one hidden layer with 128 neurons and a ReLU activation function. Finally, you will compile and train the model using the Adam optimizer and categorical crossentropy loss.\n\nGiven a TensorFlow and PyTorch setup, you have the following variable declarations:\n\n```python\nimport tensorflow as tf\nimport torch\nfrom torchvision import datasets, transforms\n\n# TensorFlow part\ntrain_images = tf.keras.datasets.mnist.load_data()[0][0]\nnormalized_images_tf = train_images.astype('float32') / 255.0\n\n# PyTorch part\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_images_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\nYou need to define the model architecture and the training process in TensorFlow:\n\n```python\nmodel_tf = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```\n\nYour task is to fill in the training code for the TensorFlow model to fit the normalized_images_tf. Please provide the code snippet that goes in the blank below:\n\n```python\nmodel_tf.fit(_____, epochs=5)\n```",
    "output": "\n```python\nnormalized_labels_tf = tf.keras.datasets.mnist.load_data()[0][1]\nmodel_tf.fit(normalized_images_tf, normalized_labels_tf, epochs=5)\n```"
  },
  {
    "input": "Problem:\nI have a data frame that contains a column named 'full_address' with addresses in the format \"Street, City, State ZIP\". I want to extract the city and the ZIP code into separate columns named 'city' and 'zip_code'.\n\nMy dataframe `df` looks like this:\n\nfull_address\n0 123 Elm St, Springfield, IL 62704\n1 456 Maple Ave, Shelbyville, IN 46176\n2 789 Oak Dr, Capital City, CA 90210\n3 102 Pine Ct, Smallville, KS 67501\n4 111 Birch Blvd, Metropolis, NY 10001\n\nI am unsure how to use string manipulation to achieve this. I can create new columns but need help populating them with the correct extracted values.\n\ncity zip_code full_address\n0 Springfield 62704 123 Elm St, Springfield, IL 62704\n1 Shelbyville 46176 456 Maple Ave, Shelbyville, IN 46176\n2 Capital City 90210 789 Oak Dr, Capital City, CA 90210\n3 Smallville 67501 102 Pine Ct, Smallville, KS 67501\n4 Metropolis 10001 111 Birch Blvd, Metropolis, NY 10001\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'full_address': ['123 Elm St, Springfield, IL 62704', \n                                     '456 Maple Ave, Shelbyville, IN 46176',\n                                     '789 Oak Dr, Capital City, CA 90210',\n                                     '102 Pine Ct, Smallville, KS 67501',\n                                     '111 Birch Blvd, Metropolis, NY 10001']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['city', 'zip_code']] = df['full_address'].str.extract(r',\\s*(.*?),\\s*[A-Z]{2}\\s*(\\d{5})$')\n</code>"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing customer transaction data with columns for 'CustomerID', 'TransactionDate', and 'Amount'. I need to create a function that takes this DataFrame as input and returns a new DataFrame that includes each customer's total spending alongside their first transaction date, all while ensuring reusability for potential future analysis.\n\nThe DataFrame, df, looks like this:\n```\n   CustomerID TransactionDate  Amount\n0         101      2023-01-01   50.00\n1         102      2023-01-02   75.00\n2         101      2023-01-10  150.00\n3         103      2023-01-05  200.00\n4         102      2023-01-15   40.00\n```\n\nThe expected output for a function called `aggregate_transactions(df)` should yield:\n```\n   CustomerID FirstTransaction  TotalAmount\n0         101      2023-01-01        200.00\n1         102      2023-01-02        115.00\n2         103      2023-01-05        200.00\n```\n\nPlease define your function implementation below.\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'CustomerID': [101, 102, 101, 103, 102],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-10', '2023-01-05', '2023-01-15']),\n    'Amount': [50.00, 75.00, 150.00, 200.00, 40.00]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef aggregate_transactions(df):\n    aggregated = df.groupby('CustomerID').agg(\n        FirstTransaction=('TransactionDate', 'min'),\n        TotalAmount=('Amount', 'sum')\n    ).reset_index()\n    return aggregated\n</code>\nresult = aggregate_transactions(df)\n</code>"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.10.0. I have a batch of input tensors with shape (5, 10), and I want to normalize the rows by the maximum value in each row. Specifically, for each row, I want to subtract the maximum value and divide by the maximum value to ensure all values in the row lie between 0 and 1.\n\nGiven my input tensor:\n```\ninput_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n                             [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0],\n                             [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n                             [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0],\n                             [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0]])\n```\nHow can I achieve this normalization with a single line of code?\n\nA:\n<code>\nimport torch\n\ninput_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n                             [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0],\n                             [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n                             [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0],\n                             [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = (input_tensor - input_tensor.max(dim=1, keepdim=True).values) / input_tensor.max(dim=1, keepdim=True).values</code>"
  },
  {
    "input": "Problem:\nI have a data frame containing a single column with mixed strings and I want to extract the numeric part and the alphabetical part into two new columns called 'number' and 'text'. The data frame looks like this:\n\n```\nmixed_data\n0  123abc\n1  45xyz\n2  789pqr\n3  1123\n4  abc456\n```\n\nI want to extract the numbers and text and fill the new columns accordingly. I know I can use `df['new_col'] = df['mixed_data'].str.extract(...)`, but I'm unsure how to properly use regex to achieve this.\n\nfilling the data frame should look like this:\n\n```\nmixed_data   number  text\n0  123abc        123    abc\n1  45xyz         45     xyz\n2  789pqr        789     pqr\n3  1123          1123   NaN\n4  abc456        456     abc\n```\n\nHow can I accomplish this? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'mixed_data': ['123abc', '45xyz', '789pqr', '1123', 'abc456']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['number', 'text']] = df['mixed_data'].str.extract(r'(\\d+)([a-zA-Z]*)')"
  },
  {
    "input": "Problem:\nI have a DataFrame with a column containing strings that contain emails and I want to extract the usernames from each email address. The DataFrame looks like this:\n\n```\n       emails\n0   john.doe@example.com\n1   jane_doe123@test.com\n2   user@domain.org\n3   admin@mywebsite.io\n4   contact@service.net\n```\n\nI want to create a new column named 'usernames' that contains only the username part of each email (the part before the '@').\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'emails': ['john.doe@example.com', 'jane_doe123@test.com', \n                               'user@domain.org', 'admin@mywebsite.io', \n                               'contact@service.net']})\ndf['usernames'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['usernames'] = df['emails'].str.split('@').str[0]\n```"
  },
  {
    "input": "Problem:\nI am working with a dictionary representing sales data for different products over several months:\n\nsales_data = {\n    'Product A': [100, 150, 200],\n    'Product B': [200, 250, 300],\n    'Product C': [50, 75, 100]\n}\n\nI want to create a function that calculates the average sales for each product and returns a new dictionary with the product names and their respective average sales. The function should handle any number of products and sales records.\n\nWhat I have tried is below, but it's incomplete. I need help completing the function to get the desired output.\n\ndef calculate_average_sales(data):\n    averages = {}\n    # Your logic to calculate averages goes here\n    return averages\n\nA:\n<code>\nsales_data = {\n    'Product A': [100, 150, 200],\n    'Product B': [200, 250, 300],\n    'Product C': [50, 75, 100]\n}\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_average_sales(data):\n    averages = {}\n    for product, sales in data.items():\n        averages[product] = sum(sales) / len(sales)\n    return averages\n\nresult = calculate_average_sales(sales_data)\n</code>"
  },
  {
    "input": "### Problem:\nI have a dataset that contains daily sales data for a retail store. The data includes two columns: 'Date' and 'Sales'. Here is a snippet of the dataframe:\n\n```\n        Date      Sales\n0 2023-01-01      200\n1 2023-01-02      250\n2 2023-01-03      300\n3 2023-01-04      350\n4 2023-01-05      400\n```\n\nI want to calculate the moving average of sales over a rolling window of 3 days. I previously tried using the `rolling()` method, but I am unsure how to apply it properly to get the desired output.\n\nI would like the final dataframe to look like this, with an additional 'Moving_Avg' column showing the 3-day moving average of sales:\n\n```\n        Date      Sales  Moving_Avg\n0 2023-01-01      200         NaN\n1 2023-01-02      250         NaN\n2 2023-01-03      300       250.0\n3 2023-01-04      350       300.0\n4 2023-01-05      400       350.0\n```\n\nI have already set up the dataframe but need to fill in the missing part to compute the moving average.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n        'Sales': [200, 250, 300, 350, 400]}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\ndf['Moving_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['Moving_Avg'] = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset where I want to predict house prices based on certain features. I have a PyTorch tensor that represents the features of the houses:\n\ntensor([[1500, 3, 2], \n        [1200, 2, 1], \n        [1800, 4, 3], \n        [2000, 4, 2]])\n\nI also have the corresponding prices in a NumPy array:\n\n[300000, 250000, 400000, 450000]\n\nI would like to create a linear regression model using PyTorch to predict house prices from these features. However, I need to reshape my features tensor to be compatible for model training. Specifically, I need to add a new dimension to the tensor so that its shape changes from (4, 3) to (4, 3, 1).\n\nHere's the starting code:\n\n<code>\nimport torch\nimport numpy as np\n\nfeatures = torch.tensor([[1500, 3, 2], \n                          [1200, 2, 1], \n                          [1800, 4, 3], \n                          [2000, 4, 2]])\nprices = np.array([300000, 250000, 400000, 450000])\n</code>\nreshaped_features = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>reshaped_features = features.unsqueeze(-1)</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing hourly temperature measurements recorded over several days. The DataFrame looks as follows:\n\n```python\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYou need to calculate the daily average temperature and include it in the original DataFrame with a new column named `Daily_Avg`. The output should have the same rows as the original DataFrame, but with the daily average values appropriate for each timestamp's date. \n\nWhat code would you use to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n</code>\ndf['Daily_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Daily_Avg'] = df.groupby(df['Timestamp'].dt.date)['Temperature'].transform('mean')  \n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe that contains user details with names and emails in a single column. The format of the column is \"Name (email@example.com)\". I want to separate the names and emails into two separate columns called 'name' and 'email'. \n\nThe dataframe looks like this:\n\n```\ndetails\n0  John Doe (john.doe@example.com)\n1  Jane Smith (jane.smith@example.com)\n2  Alice Johnson (alice.j@gmail.com)\n3  Bob Brown (bob.brown@mail.com)\n```\n\nHow can I achieve this separation using column operations in pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'details': ['John Doe (john.doe@example.com)', \n                               'Jane Smith (jane.smith@example.com)', \n                               'Alice Johnson (alice.j@gmail.com)', \n                               'Bob Brown (bob.brown@mail.com)']})\n</code>\ndf[['name', 'email']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['details'].str.extract(r'(.+?) \\((.+?)\\)')"
  },
  {
    "input": "Problem:\nI have a sparse tensor representation of some text documents using TensorFlow and I need to perform a transpose operation on it. The tensor is currently in the shape (3, 5, 0) representing 3 documents with 5 unique words, and I need to access the non-zero entries only. However, I'm unsure how to efficiently transpose the necessary axis while preserving the sparse structure.\n\nHere is my sparse tensor creation:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nind = np.array([[0, 1, 2], [0, 2, 1]])\nvals = np.array([1, 2, 3])\nshape = (3, 5)\nsparse_tensor = tf.sparse.SparseTensor(indices=ind, values=vals, dense_shape=shape)\n```\n\nNow, how can I efficiently transpose the tensor while maintaining its sparsity and getting a tensor of shape (5, 3) as output?\n\nA:\n<code>\nsparse_tensor_transposed = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsparse_tensor_transposed = tf.sparse.transpose(sparse_tensor)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame with the following structure:\n\n```\n|   product_id | rating | review_count |\n|--------------|--------|--------------|\n|            1 |      5 |           10 |\n|            2 |      4 |            5 |\n|            3 |      3 |          100 |\n|            4 |      2 |             0 |\n|            5 |      1 |           30 |\n```\n\nI would like to create a new column `quality` that categorizes products based on their `rating` and `review_count`. The criteria are as follows:\n- If the `rating` is 4 or higher and `review_count` is greater than 10, label it as \"High Quality\".\n- If the `rating` is between 3 and 4 (inclusive) and `review_count` is greater than 0, label it as \"Moderate Quality\".\n- Otherwise, label it as \"Low Quality\".\n\nMy current function approach is not very efficient. Here is my code so far:\n\n```python\ndef categorize_quality(row):\n    if row['rating'] >= 4 and row['review_count'] > 10:\n        return 'High Quality'\n    elif 3 <= row['rating'] < 4 and row['review_count'] > 0:\n        return 'Moderate Quality'\n    else:\n        return 'Low Quality'\n\ndf['quality'] = df.apply(categorize_quality, axis=1)\n```\n\nI want to optimize this code to avoid using `apply`. How can I implement a custom function that achieves this more efficiently?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4, 5],\n    'rating': [5, 4, 3, 2, 1],\n    'review_count': [10, 5, 100, 0, 30]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['quality'] = pd.cut(\n    df['rating'].where(df['review_count'] > 10, 0),\n    bins=[-1, 2, 3, 4, 5],\n    labels=['Low Quality', 'Low Quality', 'Moderate Quality', 'High Quality'],\n    right=True\n).fillna('Low Quality')\n```"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple feedforward neural network using both TensorFlow and PyTorch. The input to your model is a tensor of shape (batch_size, 10) representing features. You want to create a model that predicts a single output value for regression tasks. First, you need to define the model in TensorFlow. After that, you will define the same model in PyTorch.\n\nHere\u2019s a template for the TensorFlow model definition. Please fill in the blank to define the model properly:\n\n```python\nimport tensorflow as tf\n\ndef create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(10,)),\n        # Fill in this blank to add a Dense layer with 64 units and ReLU activation\n        ...\n        tf.keras.layers.Dense(1)\n    ])\n    return model\n```\n\nA:\n<code>\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntf.keras.layers.Dense(64, activation='relu')\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a sparse tensor to perform a multi-label classification task, where each row of your data can belong to multiple classes represented as a sparse tensor. Given a sparse tensor `sparse_tensor` with shape (3, 5, 4) that has non-zero elements indicating the presence of classes, how can you efficiently convert the sparse tensor to a dense version that reflects the presence or absence of each class per sample? \n\nHere's a sample of how the sparse tensor is defined in TensorFlow:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.sparse.SparseTensor(\n    indices=[[0, 0, 1], [1, 2, 3], [2, 4, 0]],\n    values=[1, 1, 1],\n    dense_shape=[3, 5, 4]\n)\n```\n\nYou need to fill in the following statement to convert it to a dense tensor:\n\n```python\ndense_tensor = ...  # put solution in this variable\n```\nEnsure that the resulting dense tensor should correctly reflect which classes are present for each data point.",
    "output": "\n```python\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\n```"
  },
  {
    "input": "Problem:\n\nI need to analyze a list of customer purchase records that includes various attributes. Each record is a dictionary with keys: 'customer_id', 'item', 'quantity', and 'price'. I want to create a function that takes this list of records and returns the total revenue generated, which is calculated as the sum of `quantity * price` for each record. \n\nFor example, given the following records:\n\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n\nI would expect your function to return a total revenue of 4.0.\n\nA:\n<code>\nrecords = [\n    {'customer_id': 1, 'item': 'apple', 'quantity': 3, 'price': 0.5},\n    {'customer_id': 2, 'item': 'banana', 'quantity': 1, 'price': 1.0},\n    {'customer_id': 1, 'item': 'orange', 'quantity': 2, 'price': 0.75}\n]\n</code>\ntotal_revenue = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ntotal_revenue = sum(record['quantity'] * record['price'] for record in records)\n</code>"
  },
  {
    "input": "Problem:\n\nI am building a multi-layer perceptron (MLP) classifier using PyTorch. My input data is a tensor of shape (64, 10), representing 64 samples with 10 features each. I have a linear layer followed by a ReLU activation, and then another linear layer which outputs a tensor of shape (64, 3), indicating the class scores for 3 classes. \n\nAfter obtaining the output scores tensor, I want to convert it into probabilities using the softmax function. However, I also wish to ensure that all entries in this resulting probability tensor sum to 1 for each sample. How can I achieve this?\n\nHere\u2019s what I have so far:\n\nimport torch\n\ninput_data = torch.randn(64, 10)\nlinear1 = torch.nn.Linear(10, 5)  # First layer\nrelu = torch.nn.ReLU()\nlinear2 = torch.nn.Linear(5, 3)  # Second layer\nscores = linear2(relu(linear1(input_data)))\n\nWhat should I place here to compute the softmax probabilities?\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = torch.nn.functional.softmax(scores, dim=1)\n</code>"
  },
  {
    "input": "### Problem:\nGiven a sparse tensor representing a 3D RGB image batch of shape (batch_size, height, width, channels), where the tensor has a significant number of zero entries, you want to perform a normalization operation only on the non-zero entries in the channels. The tensor `image_tensor` is a `scipy.sparse.csr_matrix` representation of the images, and you want to apply the normalization as follows:\n\nFor each channel, divide the non-zero pixel values by the maximum pixel value found in that channel across the entire batch, while retaining the original shape of the tensor, including the zeros.\n\nHere's how you can conceptualize it:\n\n```python\nfrom scipy import sparse\nimport numpy as np\n\n# Create a sparse tensor of random values and some zeros\nimage_tensor = sparse.rand(5, 100, 100, 3, density=0.3, format='csr').tocoo()  # shape (5, 100, 100, 3)\n\n# Fill in the blank to normalize non-zero entries in the tensor along the channel dimension.\n```\n\nYou need to fill in the blank to perform this normalization correctly while maintaining the shape of the input sparse tensor. \n\nA:\n<code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n# Convert the sparse tensor to a dense format for processing\ndense_tensor = image_tensor.toarray()\n\n# Normalize non-zero entries in each channel\nmax_values = np.max(dense_tensor, axis=(0, 1), keepdims=True)\nnormalized_tensor = np.where(dense_tensor != 0, dense_tensor / max_values, 0)\n\n# Convert back to sparse format\nnormalized_tensor = sparse.csr_matrix(normalized_tensor)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset of product sales that includes information on product IDs, quantities sold, and prices. You want to calculate the total revenue for each product. Write a custom function `calculate_revenue` that takes three lists: `product_ids`, `quantities`, and `prices`. The function should return a dictionary where the keys are the product IDs and the values are the corresponding total revenue (calculated as quantity sold multiplied by price). \n\nHere's an example of the data you will be working with:\n\n```python\nproduct_ids = ['A101', 'B202', 'C303', 'A101', 'B202']\nquantities = [10, 5, 3, 2, 7]\nprices = [20, 50, 100, 20, 50]\n```\n\nFill in the blank for the line where the output of your function is assigned.\n\n```python\nproduct_ids = ['A101', 'B202', 'C303', 'A101', 'B202']\nquantities = [10, 5, 3, 2, 7]\nprices = [20, 50, 100, 20, 50]\n\ndef calculate_revenue(product_ids, quantities, prices):\n    revenue_dict = {}\n    # Implement your code here\n    \n    return revenue_dict\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = calculate_revenue(product_ids, quantities, prices)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame structured like this:\n\n```\n   Category    Value\n0      A         10\n1      B         15\n2      A         25\n3      C         10\n4      B          5\n5      A         20\n```\n\nI want to create a custom function to compute the cumulative sum of 'Value' for each 'Category' and return a new DataFrame that retains the original structure but adds a new column 'Cumulative_Value' with the cumulative sums. The expected output should look like this:\n\n```\n   Category    Value    Cumulative_Value\n0      A         10                10\n1      B         15                15\n2      A         25                35\n3      C         10                10\n4      B          5                20\n5      A         20                55\n```\n\nHere is my existing setup:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Category': ['A', 'B', 'A', 'C', 'B', 'A'],\n    'Value': [10, 15, 25, 10, 5, 20]\n})\n```\n\nHow can I implement a custom function that does this efficiently?\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef compute_cumulative_sum(df):\n    df['Cumulative_Value'] = df.groupby('Category')['Value'].cumsum()\n    return df\n\nresult = compute_cumulative_sum(df)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with TensorFlow 2.10.0 and PyTorch 1.10.0. You have a dataset of images represented as a tensor in PyTorch, and you want to compute and display statistics about pixel intensity values across the dataset. The pixels are represented in a 4D tensor of shape (batch_size, height, width, channels), where you want to calculate the mean pixel intensity for each channel separately.\n\nGiven a PyTorch tensor named 'image_tensor' with shape (8, 64, 64, 3) representing 8 images of size 64x64 with 3 color channels, you need to calculate the means and convert the result into a TensorFlow tensor.\n\nHow can you compute the mean pixel intensity for each channel and convert it into a TensorFlow tensor? \n\nA:\n<code>\nimport torch\nimport tensorflow as tf\n\nimage_tensor = torch.rand((8, 64, 64, 3))\n</code>\nmean_intensity_tf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmean_intensity = image_tensor.mean(dim=(0, 1, 2))\nmean_intensity_tf = tf.convert_to_tensor(mean_intensity.numpy())</code>"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch and have the following prediction tensor from your model:\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\nEach row in the predictions tensor represents the probabilities of three classes for a batch of four examples. Your goal is to convert these probabilities into predicted class indices, which means identifying the index of the highest probability in each row. \n\nHow would you fill in this code to achieve this?\n\n```python\nimport torch\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\npredicted_classes = ... # fill in with the correct code to get the index of max probability in each row\n```\n",
    "output": "\n```python\npredicted_classes = torch.argmax(predictions, dim=1)\n```"
  },
  {
    "input": "## Problem:\nI have a sparse tensor representing a 3D grid of values that are mostly zeros. The shape of the tensor is (100, 100, 100), and I want to convert this sparse tensor into a dense format only for the non-zero values. I'm using TensorFlow for this task.\n\nThe sparse tensor can be created using the following code:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ncoordinates = np.array([[0, 0, 0], [1, 2, 3], [4, 5, 6], [10, 10, 10]])\nvalues = np.array([1, 2, 3, 4])\nsparse_tensor = tf.SparseTensor(indices=coordinates, values=values, dense_shape=[100, 100, 100])\n```\n\nNow, I want to convert this sparse tensor to a dense tensor that only contains the non-zero values. You can fill in the blank below with the appropriate TensorFlow method to achieve this.\n\nA:\n```python\ndense_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\ndense_tensor = tf.sparse.to_dense(sparse_tensor) # put solution in this variable\n```"
  },
  {
    "input": "Problem:\n\nYou're working on a machine learning project using TensorFlow and PyTorch. You have a dataset loaded as a PyTorch tensor and want to normalize it by subtracting the mean and dividing by the standard deviation. After normalizing, you want to convert this normalized tensor to a TensorFlow tensor for further processing. \n\nAssume that you have the following PyTorch tensor:\n\n```python\nimport torch\ndata_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n```\n\nWhat is the line of code needed to perform the normalization and then convert the result to a TensorFlow tensor?\n\nA:\n\n```python\nimport tensorflow as tf\nimport torch\ndata_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n```\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nnormalized_tensor = tf.convert_to_tensor((data_tensor - data_tensor.mean()) / data_tensor.std())\n```"
  },
  {
    "input": "## Problem\nI have a time series dataset containing daily temperatures in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'temperature': [30, 33, 35, 32, 31, 29, 28, 30, 34, 36]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to analyze this dataset by calculating the rolling average temperature over a 3-day window to smooth out the daily fluctuations. Could you provide the code that would add a new column to the DataFrame called `rolling_avg` that contains these averages?\n\nA:\n```python\ndf['rolling_avg'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing sales data, that looks like this:\n\n```\n   Date       Sales\n0 2023-01-01     200\n1 2023-01-02     120\n2 2023-01-03     150\n3 2023-01-04     170\n4 2023-01-05     180\n```\n\nI want to calculate a 3-day moving average of the sales which will help to smooth out fluctuations. Can you help me implement a function `moving_average` that takes this DataFrame and returns a new DataFrame that includes a column for the moving average?\n\nHere\u2019s the starting code:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Sales': [200, 120, 150, 170, 180]\n}\ndf = pd.DataFrame(data)\n```\n\nThe resulting DataFrame should look like this:\n\n```\n   Date       Sales  Moving_Avg\n0 2023-01-01     200         NaN\n1 2023-01-02     120         NaN\n2 2023-01-03     150   156.666667\n3 2023-01-04     170   146.666667\n4 2023-01-05     180   166.666667\n```\n\nPlease fill in the blank in the following line to implement the required function:\n\n```python\ndef moving_average(df, window=3):\n    df['Moving_Avg'] = ...\n```\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef moving_average(df, window=3):\n    df['Moving_Avg'] = df['Sales'].rolling(window=window).mean()\n```"
  },
  {
    "input": "Problem:\nI have a list of numerical values representing daily sales data over a period of time, and I want to create a custom function to categorize each sales figure into specific revenue brackets. \n\nThe categories should be as follows:\n- \"Low\" for values less than 500\n- \"Medium\" for values between 500 and 1500\n- \"High\" for values greater than 1500\n\nI would like to create a function called `categorize_sales` that takes a list of sales figures as input and returns a new list with the appropriate categorizations for each sales figure.\n\nHere's a sample of my sales data:\nsales_data = [450, 780, 1250, 3000, 600, 150, 1800]\n\nI would like to achieve the following output:\n['Low', 'Medium', 'Medium', 'High', 'Low', 'Low', 'High']\n\nA:\n<code>\nsales_data = [450, 780, 1250, 3000, 600, 150, 1800]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef categorize_sales(sales):\n    categories = []\n    for sale in sales:\n        if sale < 500:\n            categories.append(\"Low\")\n        elif 500 <= sale <= 1500:\n            categories.append(\"Medium\")\n        else:\n            categories.append(\"High\")\n    return categories\n\nresult = categorize_sales(sales_data)\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains daily stock prices for a company over a year. It looks something like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2022-01-01', end='2022-12-31'),\n    'Close': [100 + i * 0.5 for i in range(365)]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to calculate the 30-day rolling mean of the 'Close' prices, and you want to add this as a new column called '30_day_avg' in the same DataFrame. However, you want this new column to have NaN values for the first 29 days where the rolling mean cannot be calculated.\n\nWhat is the code to create the '30_day_avg' column in the DataFrame?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['30_day_avg'] = df['Close'].rolling(window=30).mean()\n```"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame with a column 'product_info' that contains strings representing product details in the format: \"ProductName - Brand - Price\". For example:\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n\nI want to create a new DataFrame that extracts the 'ProductName' and 'Price' into separate columns while removing the 'Brand' from 'product_info'. If 'product_info' does not adhere to the expected format, I want it to remain unchanged.\n\nThe expected output is:\n\n  ProductName       Price\n0      Laptop   1200 USD\n1  Smartphone    999 USD\n2   Smartwatch    300 USD\n3      Laptop   1150 USD\n\nHere is my starting point:\n\n<code>\nimport pandas as pd\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n</code>\nnew_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnew_df = product_data['product_info'].str.extract(r'([^ -]+) - [^-]+ - (.+)')[0].rename('ProductName').to_frame().join(\n    product_data['product_info'].str.extract(r'[^ -]+ - [^-]+ - (.+)')[0].rename('Price')\n)\n</code>"
  },
  {
    "input": "Problem:\nI have been working with a sparse tensor in PyTorch that represents a 3D grid of data, where most of the values are zero. The tensor has a shape of (20, 30, 40), and I need to perform an operation to sum the non-zero elements across the first dimension (axis 0) while retaining the sparse structure. Additionally, I need to normalize the summed tensor by dividing by the number of non-zero elements along the first dimension, effectively creating an average for each (x, y) location in the grid. \n\nHere's how my sparse tensor looks:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 5, 8, 10], [1, 2, 3, 4], [5, 6, 7, 8]]),\n    values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n    size=(20, 30, 40)\n)\n```\n\nHow would I compute the normalized average tensor, ensuring the result remains sparse? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nnon_zero_count = sparse_tensor.coalesce().values().new_zeros(sparse_tensor.size()[1:])\nfor i in range(sparse_tensor.size(0)):\n    non_zero_count += (sparse_tensor[i].coalesce().values() != 0).sum(dim=0)\n\nsummed_tensor = sparse_tensor.sum(dim=0)\nnormalized_tensor = summed_tensor / non_zero_count.unsqueeze(0)\nresult = normalized_tensor.to_sparse()\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix representing user interactions with items, where the entries are ratings (and can include zeros for no interaction). The matrix is of shape (1000, 500) and is in CSR format. I want to create a new matrix where each entry corresponds to the maximum rating for each item across multiple users, ignoring zeros (which represent no interaction). What is the best way to achieve this without converting to a dense format, and how would I go about extracting this information into a new zero-based sparse matrix of shape (1, 500)?\n\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\n\n# Assume 'user_item_matrix' is a sparse matrix of shape (1000, 500)\nuser_item_matrix = sparse.csr_matrix(np.random.randint(0, 6, (1000, 500)))  # Example sparse matrix with ratings from 0 to 5\n</code>\nmax_rating_per_item = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_rating_per_item = sparse.csr_matrix(user_item_matrix.max(axis=0).A.reshape(1, -1))\n</code>"
  },
  {
    "input": "### Problem:\n\nYou are working with PyTorch and TensorFlow for a project where you need to process a batch of images. You have a 4-dimensional tensor of shape `(batch_size, channels, height, width)` representing images and you want to compute the mean across the `channels` dimension, resulting in a 3-dimensional tensor. Given a tensor of images like this:\n\n```python\ntorch_tensor = torch.rand(8, 3, 64, 64)  # A batch of 8 images with 3 channels each\n```\n\nHow can you accomplish this using TensorFlow to get the same result?\n\nA:\n```python\nimport tensorflow as tf\n\ntorch_tensor = ...  # Load the above torch tensor into a TensorFlow variable\n```\nresult = ...  # put solution in this variable",
    "output": "\n```python\nimport tensorflow as tf\n\ntorch_tensor = tf.convert_to_tensor(torch.rand(8, 3, 64, 64).numpy())  # Load the above torch tensor into a TensorFlow variable\nresult = tf.reduce_mean(torch_tensor, axis=1)  # Compute the mean across the channels dimension\n```"
  },
  {
    "input": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({'text': ['Value: 100 units', 'Count is 250 items', 'Total is 50', 'Not a number', 'Amount: 85']})\n\n# There are mixed strings in the 'text' column, and I want to extract only the numeric values (if they exist) in a new column called 'amount'.\n# If no numeric value is found, 'amount' should be NaN.\n\ndf['amount'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['amount'] = df['text'].str.extract('(\\d+)').astype(float)\n```"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing various product reviews, and one of the columns is a string containing product details in the format \"Product_Name (Category) - Review_Score\". The DataFrame looks like this:\n\n```\n       Reviews\n0  Laptop (Electronics) - 5\n1  Coffee Maker (Home) - 4\n2  Phone (Electronics) - 3\n3  Blender (Home) - 5\n4  Camera (Electronics) - 4\n```\n\nI would like to separate the product name, category, and review score into three distinct columns named 'Product', 'Category', and 'Score'. How can I achieve this to transform my DataFrame into the following format?\n\n```\n      Product       Category  Score\n0      Laptop      Electronics     5\n1  Coffee Maker        Home         4\n2      Phone       Electronics     3\n3     Blender         Home         5\n4     Camera       Electronics     4\n```\n\nHere's my initial code, which only creates the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'Reviews': ['Laptop (Electronics) - 5', \n                    'Coffee Maker (Home) - 4', \n                    'Phone (Electronics) - 3', \n                    'Blender (Home) - 5', \n                    'Camera (Electronics) - 4']}\ndf = pd.DataFrame(data)\n```\n\nI need to fill in the blank for the transformation:\n\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>df[['Product', 'Category', 'Score']] = df['Reviews'].str.extract(r'(.+?) \\((.+?)\\) - (\\d+)')</code>"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.12.0. I have a dataset where each sample consists of a feature tensor and a label tensor, and I want to create a neural network model that predicts the label from the features. My model should take an input tensor of shape (batch_size, 10) and output a tensor of shape (batch_size, 2) representing class probabilities. I'm currently attempting to define my model and would like to know how to achieve the following:\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.linear1 = nn.Linear(10, 5)\n        self.linear2 = nn.Linear(5, 2)\n    \n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = self.___ # fill in this line to complete the forward pass\n        return x\n\nmodel = MyModel()\nprint(model)\n```\n\nWhat should I use in place of ___ to ensure that the output represents class probabilities?",
    "output": "\n```python\n        x = torch.softmax(self.linear2(x), dim=1)\n```"
  },
  {
    "input": "Problem:\nI have the following DataFrame with a column containing URLs that include user IDs. Here\u2019s how the DataFrame looks:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nI want to extract the user IDs from the URLs in the 'url' column and create a new column called 'user_id' that contains only these IDs. If there is no user ID in the URL, the new column should contain `NaN`.\n\nHere\u2019s the DataFrame before extraction:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nAfter extraction, the new DataFrame should look like this:\n\n```\n        url                user_id\n0  https://example.com/user/12345/profile   12345\n1  https://example.com/user/67890/dashboard  67890\n2  https://example.com/page/abc/def         NaN\n3  https://example.org/user/54321           54321\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'url': ['https://example.com/user/12345/profile',\n                 'https://example.com/user/67890/dashboard',\n                 'https://example.com/page/abc/def',\n                 'https://example.org/user/54321']}\ndf = pd.DataFrame(data)\n</code>\ndf['user_id'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['user_id'] = df['url'].str.extract(r'user/(\\d+)')\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse tensor in PyTorch that contains embeddings with many zero values and I want to convert it to a dense representation without impacting the sparse data structure. Specifically, I need to replace the sparse tensor's zero entries with a scalar value of your choice while keeping the non-zero entries intact. My sparse tensor is represented as follows:\n\n```python\nimport torch\n\nsparse_tensor = torch.tensor([[0.0, 3.0, 0.0], \n                               [4.0, 0.0, 0.0], \n                               [0.0, 0.0, 5.0]], dtype=torch.float32)\n\nscalar_value = 1.0  # The value to replace zero entries\n```\n\nHow can I efficiently achieve this replacement while maintaining the original non-zero values in a dense format?\n\nA:\n```python\nimport torch\n\nsparse_tensor = torch.tensor([[0.0, 3.0, 0.0], \n                               [4.0, 0.0, 0.0], \n                               [0.0, 0.0, 5.0]], dtype=torch.float32)\n\nscalar_value = 1.0  # The value to replace zero entries\n```\ndense_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndense_tensor = sparse_tensor.clone()\ndense_tensor[dense_tensor == 0] = scalar_value\n```"
  },
  {
    "input": "Problem:\n\nI'm working on a sentiment analysis project using TensorFlow and I have a tensor containing the embeddings of sentences. The shape of my tensor is (50, 300), representing 50 sentences each with 300 features. I want to create a simple feedforward model with TensorFlow that predicts sentiment scores between 0 and 1. I am looking for the appropriate layer to use in TensorFlow to achieve this output shape of (50, 1) after applying a dense layer to my input tensor. \n\nWhat should I use to create this single output layer?\n\nA:\n<code>\nimport tensorflow as tf\n\ninput_tensor = tf.random.uniform((50, 300))\nmodel = tf.keras.Sequential()\n# Add an appropriate layer below to predict sentiment scores\n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe containing various product descriptions, and I want to extract the numerical price values from these descriptions. The prices are written in a consistent format, for example, \"$25.99\" or \"Price: $100\". I want to create a new column in the dataframe that simply contains the price as a float, or NaN if no price is found in the description. \n\nHere is a sample dataframe:\n```\ndescription\n---------------------------\nBuy one get one free: Price: $15.99\nNew product launch! Only for $100.\nLimited time offer: $49.95\nNo price available here\n```\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'description': [\n        'Buy one get one free: Price: $15.99',\n        'New product launch! Only for $100.',\n        'Limited time offer: $49.95',\n        'No price available here'\n    ]\n})\n</code>\nprice_column = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nprice_column = df['description'].str.extract(r'(\\$[0-9]+(?:\\.[0-9]{2})?)')[0].replace({'\\$': ''}, regex=True).astype(float)"
  },
  {
    "input": "Problem:\nYou have a dataset of employees in a company represented as a Pandas dataframe with their details as shown below:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [101, 102, 103, 104, 105],\n    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'salary': [70000, 80000, 60000, 75000, 85000],\n    'department': ['HR', 'Engineering', 'HR', 'Marketing', 'Engineering']\n})\n```\n\nYou need to create a function called `average_salary_by_department` that takes this dataframe as an input and returns a new dataframe showing the average salary for each department. The resulting dataframe should have two columns: `department` and `average_salary`.\n\nFor example, the output should look like this:\n\n```\n    department  average_salary\n0  Engineering         82500.0\n1             HR         65000.0\n2      Marketing         75000.0\n```\n\nPlease fill in the code below to complete your solution.\n\n```python\nresult = ...\ndef average_salary_by_department(df):\n    ...\n```",
    "output": "\n```python\nresult = df.groupby('department')['salary'].mean().reset_index(name='average_salary')\ndef average_salary_by_department(df):\n    return result\n```"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains user activity logs for an online platform, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'UserId': [101, 102, 103, 101, 102, 104, 105, 101, 103, 102],\n    'Activity': ['login', 'signup', 'login', 'logout', 'login', 'signup', 'logout', 'login', 'logout', 'login'],\n    'Timestamp': pd.to_datetime(['2023-01-01 10:00', '2023-01-02 11:00', '2023-01-02 12:00', \n                                  '2023-01-01 14:00', '2023-01-02 14:00', '2023-01-03 09:00', \n                                  '2023-01-03 10:00', '2023-01-04 15:00', '2023-01-04 16:00', \n                                  '2023-01-04 17:00'])\n})\n\n```\n\nI would like to create a custom function that processes this dataframe to add a new column called `'SessionDuration'`. This column will calculate the duration of sessions (in minutes) for each user based on their login and logout activities. A session is defined as the time between the first login and the corresponding logout for each user.\n\nThe expected output, after applying this custom function, will include the original dataframe with an additional column for `'SessionDuration'` that reflects the session duration in minutes for users who logged out.\n\nThanks!\n\n```python\n# Define the function here\ndef calculate_session_duration(df):\n    # Your code goes here to compute session durations\n    ...\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndef calculate_session_duration(df):\n    df['SessionDuration'] = None\n    for user in df['UserId'].unique():\n        user_logs = df[df['UserId'] == user]\n        logins = user_logs[user_logs['Activity'] == 'login']\n        logouts = user_logs[user_logs['Activity'] == 'logout']\n        \n        for index, login in logins.iterrows():\n            corresponding_logout = logouts[logouts['Timestamp'] > login['Timestamp']]\n            if not corresponding_logout.empty:\n                duration = (corresponding_logout.iloc[0]['Timestamp'] - login['Timestamp']).total_seconds() / 60\n                df.loc[index, 'SessionDuration'] = duration\n    return df\n\nresult = calculate_session_duration(data)\n```"
  },
  {
    "input": "Problem:\nI'm working with TensorFlow 2.9.0 to develop a simple neural network. I've prepared input data in the form of a tensor representing features of device usage, shaped as (1000, 10). I also have a corresponding labels tensor indicating the device state (0 or 1) for each usage sample, shaped as (1000, 1). My neural network has been defined, but I need to compile it with the Adam optimizer and binary cross-entropy loss.\n\nHere's my setup:\n\n<code>\nimport tensorflow as tf\n\n# Assuming model is defined\nmodel = tf.keras.Sequential([...])  # your model layers here\nlabels = tf.random.uniform((1000, 1), maxval=2, dtype=tf.int32)\nfeatures = tf.random.uniform((1000, 10))\n\n</code>\nmodel.compile(optimizer=..., loss=...) # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel.compile(optimizer='adam', loss='binary_crossentropy')"
  },
  {
    "input": "Problem:\nYou have a dataset represented as a pandas DataFrame that contains the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A'],\n    'Value': [10, 20, 15, 30, 25, 5, 10]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average Value for each Category and then create a new column in the DataFrame that shows how much each Value deviates from its Category's average. This deviation should be positive if the Value is greater than the average and negative if it is less than the average.\n\nYour expected output DataFrame should look like this:\n\n```python\n  Category  Value  Deviation\n0        A     10        -5.0\n1        B     20         0.0\n2        A     15         0.0\n3        C     30         10.0\n4        B     25         5.0\n5        C      5        -5.0\n6        A     10        -5.0\n```\n\nFill in the blank to accomplish this task:\n\n```python\ncategory_avg = df.groupby('Category')['Value'].mean()\ndf['Deviation'] = df['Value'] - _________\n```",
    "output": "\n```python\ncategory_avg[df['Category']].values\n```"
  },
  {
    "input": "Problem:\nYou are working with a pandas dataframe containing several numerical columns representing the daily sales of different products. The dataframe is structured like this:\n\n```\n      product_A  product_B  product_C\ndate\n2023-01-01        20        10         15\n2023-01-02        25        30         20\n2023-01-03        30        20         25\n```\n\nYou need to calculate the percentage change in sales for each product over the specified period. To make your code reusable, define a function named `calculate_percentage_change` that takes a dataframe and a column name as input, and returns a new series containing the percentage change for that column.\n\nTo test your function, you can use this sample dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_A': [20, 25, 30],\n    'product_B': [10, 30, 20],\n    'product_C': [15, 20, 25]\n}, index=pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03']))\n```\n\nFill in the following blank with your function call to get the percentage change of 'product_A'.\n\n```python\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_percentage_change(df, column):\n    return df[column].pct_change() * 100\n\nresult = calculate_percentage_change(df, 'product_A')\n</code>"
  },
  {
    "input": "Problem:\nI have a list of employees with their worked hours over a week and I would like to calculate the total hours worked for each employee, but I need to implement a function that takes in a list of tuples where each tuple consists of an employee's name and their corresponding hours for the week. If an employee's total hours exceed 40, only record 40 hours as the maximum limit. I want the function to return a dictionary with the employee's name as the key and their total hours (capped at 40) as the value.\n\nFor example, given the following list:\n\n```python\nhours_list = [('Alice', 10), ('Bob', 20), ('Alice', 35), ('Bob', 25), ('Charlie', 20), ('Alice', 10)]\n```\n\nThe expected output should be:\n```python\n{'Alice': 40, 'Bob': 40, 'Charlie': 20}\n```\n\nYou need to fill in the blank with the appropriate function that processes this data.\n\nA:\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    # Your code goes here\n    return result\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    for name, hours in hours_list:\n        if name in result:\n            result[name] += hours\n        else:\n            result[name] = hours\n    for name in result:\n        if result[name] > 40:\n            result[name] = 40\n    return result\n</code>\nresult = calculate_hours(hours_list)\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains product descriptions and pricing as follows:\nproduct_df = pd.DataFrame({'description':['12-inch Red Widget at $15.99','Blue Widget 10\" - $12.50','Large Green Widget (15 inches) $25.00','Small Yellow Widget with price: $9.99']})\n\nI want to extract the product size (if mentioned in inches) and the price into two separate columns named 'size' and 'price'. If the size is not mentioned, it should be NaN. The final DataFrame should look like this:\n\ndescription                                           size      price\n0  12-inch Red Widget at $15.99                     12      15.99\n1  Blue Widget 10\" - $12.50                          10      12.50\n2  Large Green Widget (15 inches) $25.00             15      25.00\n3  Small Yellow Widget with price: $9.99             NaN      9.99\n\nI've attempted to use regex to parse the size and price, but I'm struggling to extract these values correctly. Can you help me with a code snippet to construct this DataFrame correctly?\n\nA:\n<code>\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'description':['12-inch Red Widget at $15.99','Blue Widget 10\" - $12.50','Large Green Widget (15 inches) $25.00','Small Yellow Widget with price: $9.99']})\n</code>\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport numpy as np\nimport re\n\nproduct_df['size'] = product_df['description'].str.extract(r'(\\d+)\\s*[-\" inches]')\nproduct_df['price'] = product_df['description'].str.extract(r'\\$([\\d.]+)')\nproduct_df['size'] = product_df['size'].astype(float)\nproduct_df['price'] = product_df['price'].astype(float)\n</code>"
  },
  {
    "input": "## Problem\nYou have a pandas DataFrame containing timestamps and some measurement values taken every hour over a month. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Timestamp': pd.date_range(start='2023-03-01', freq='H', periods=48),\n    'Measurement': [i + (i % 24) for i in range(48)]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to create a new column in this DataFrame that calculates the rolling average of the 'Measurement' values over the last 24 hours, using the `shift` method for proper alignment with the corresponding timestamp.\n\nHow can you achieve this? Fill in the blank in the following line to complete the task:\n\n```python\ndf['Rolling_Avg'] = df['Measurement'].______ \n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Measurement'].rolling(window=24).mean().shift(1)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains details about book sales, including the title, author, and number of copies sold. I want to create a function that calculates the total sales for each author and returns the results as a new DataFrame. Here's a glimpse of my DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Title': ['Book A', 'Book B', 'Book C', 'Book D', 'Book E'],\n    'Author': ['Author 1', 'Author 2', 'Author 1', 'Author 2', 'Author 3'],\n    'Copies Sold': [150, 200, 100, 300, 50]\n})\n```\n\nThe desired output should group the sales by author and sum the total copies sold, resulting in a DataFrame that looks like this:\n\n```\n       Author  Total Sales\n0    Author 1          250\n1    Author 2          500\n2    Author 3           50\n```\n\nHere is my attempt at calculating the total sales:\n\n```python\ndef calculate_total_sales(df):\n    # this function should return a new DataFrame with total sales per author\n    pass\n\nresult = calculate_total_sales(df) # put the solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df):\n    total_sales = df.groupby('Author')['Copies Sold'].sum().reset_index()\n    total_sales.columns = ['Author', 'Total Sales']\n    return total_sales\n\nresult = calculate_total_sales(df) # put the solution in this variable\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame that contains information about sales transactions, structured like this:\n\n```\n   transaction_id    product_id    quantity\n0               1            101          2\n1               2            102          4\n2               3            103          1\n3               4            101          3\n4               5            102          2\n```\n\nI want to create a function that computes the total quantity sold for each product and returns a new DataFrame that lists each unique `product_id` along with its corresponding total quantity sold. \n\nHere\u2019s how the DataFrame should look after the operation:\n\n```\n   product_id    total_quantity\n0          101               5\n1          102               6\n2          103               1\n```\n\nWhat code can I use to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4, 5],\n    'product_id': [101, 102, 103, 101, 102],\n    'quantity': [2, 4, 1, 3, 2]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('product_id', as_index=False)['quantity'].sum().rename(columns={'quantity': 'total_quantity'})\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a 2D tensor where each row corresponds to a training example and each column corresponds to a feature. I want to build a simple feedforward neural network using TensorFlow and then train it on this dataset. The model should consist of one hidden layer with ReLU activation and an output layer with softmax activation. After defining the model, I need to compile it with categorical crossentropy loss and an Adam optimizer. \n\nHere is a simplified version of the code that establishes the tensor and defines the model up to the compilation step:\n\n```python\nimport tensorflow as tf\n\n# Example data: shape (num_examples, num_features)\nX_train = tf.constant([[0.1, 0.2], [0.2, 0.4], [0.3, 0.6]], dtype=tf.float32)\ny_train = tf.constant([[1, 0], [0, 1], [1, 0]], dtype=tf.float32) # One-hot encoded labels\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(2,))) \nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=...)\n```\n\nWhat should I place in the loss parameter to correctly set up the model for categorical classification?\n\nA:\n\n<code>\nmodel.compile(optimizer='adam', loss='...') \n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.compile(optimizer='adam', loss='categorical_crossentropy') \n</code>"
  },
  {
    "input": "## Problem\nI have a set of images in a tensor `images` of shape `(batch_size, height, width, channels)` and a corresponding tensor of labels `labels` of shape `(batch_size,)`. I want to build a simple neural network model using PyTorch that will classify these images into one of the `num_classes` categories. I am using the `nn.CrossEntropyLoss` as my loss function. \n\nAfter defining my model and putting it in training mode, I have the following code to calculate the predictions from the model and the loss. How can I get the predicted class indices from the raw model outputs `outputs`?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\n# Assuming the model and data is already defined\noutputs = model(images)  # outputs has shape (batch_size, num_classes)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(outputs, labels)\n\n# I need to fill in this part to get the predicted class indices\npredicted_classes = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = torch.argmax(outputs, dim=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains a column with mixed strings, and I need to extract only the email addresses from this column into a separate list. The dataframe looks like this:\n\ndata\n0  John Doe john.doe@example.com\n1  Jane Smith janesmith@web.net\n2  No Email Here\n3  Contact us at support@mywebsite.org\n4  Another Guy with email: anotherguy@domain.com\n\nI am currently struggling to filter the valid email addresses using regex and pandas string operations. Can you help me extract these email addresses into a list?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'data': ['John Doe john.doe@example.com',\n                            'Jane Smith janesmith@web.net',\n                            'No Email Here',\n                            'Contact us at support@mywebsite.org',\n                            'Another Guy with email: anotherguy@domain.com']})\n</code>\nemails = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nemails = df['data'].str.extractall(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})')[0].tolist()  \n</code>"
  },
  {
    "input": "### Problem\n\nI'm working on a predictive modeling task using TensorFlow and PyTorch. I have a dataset represented as a 2D tensor containing features and I'm trying to create a neural network model to predict a single continuous target value. \n\nThe input tensor `X` has shape `(100, 10)` representing 100 samples and 10 features. After training the model, I want to use the trained model to predict the outcomes of a new tensor `X_new` with shape `(20, 10)`. \n\nHere's how my code looks:\n\n```python\nimport tensorflow as tf\nimport torch\n\n# Create a simple sequential model in TensorFlow\nmodel_tf = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n\n# Compile the model\nmodel_tf.compile(optimizer='adam', loss='mean_squared_error')\n\n# Assuming training data is available as X_train and y_train\n# Call to fit the model would go here\n\n# Now, I want to predict using a new dataset\nX_new = ...  # This tensor has shape (20, 10)\n\n# Fill in this blank to perform the prediction using the TensorFlow model\npredictions_tf = ...\n```\n\nWhat should I put in the blank to get the predictions from `X_new` using the model? \n\nA:\n<code>\npredictions_tf = model_tf.predict(X_new)\n</code>",
    "output": "\n<code>\npredictions_tf = model_tf.predict(X_new)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a list of dictionaries representing sales data from a store, and I want to summarize the total sales for each product category. The data structure looks like this:\n\n```python\nsales_data = [\n    {'product': 'A', 'category': 'electronics', 'sales': 200},\n    {'product': 'B', 'category': 'groceries', 'sales': 150},\n    {'product': 'C', 'category': 'electronics', 'sales': 300},\n    {'product': 'D', 'category': 'furniture', 'sales': 400},\n    {'product': 'E', 'category': 'groceries', 'sales': 200},\n]\n```\n\nI would like to create a function called `calculate_total_sales` that takes this list and returns a dictionary with the total sales for each category.\n\nHere is how I want to use it:\n\n```python\nresult = calculate_total_sales(sales_data)\n```\n\nThe expected output for `result` should look like this:\n\n```python\n{\n    'electronics': 500,\n    'groceries': 350,\n    'furniture': 400\n}\n```\n\nPlease fill in the function definition below to achieve this:\n\n```python\ndef calculate_total_sales(sales_data):\n    # return the solution in this function\n    ### BEGIN SOLUTION\n```",
    "output": "\n```python\n    total_sales = {}\n    for entry in sales_data:\n        category = entry['category']\n        sales = entry['sales']\n        if category in total_sales:\n            total_sales[category] += sales\n        else:\n            total_sales[category] = sales\n    return total_sales\n```"
  },
  {
    "input": "## Problem:\nSuppose you have a pandas DataFrame that contains a list of emails, and you'd like to extract the domain names from these emails. Your DataFrame looks like this:\n\n```python\nemail_df = pd.DataFrame({'email':['john.doe@example.com', 'jane.smith@domain.org', 'bob.brown@mail.com', 'charlie@example.com']})\n```\n\nYou want to create a new column in the DataFrame that contains just the domain names (the part after '@') in the following format:\n```python\n       email              domain\n0  john.doe@example.com       example.com\n1  jane.smith@domain.org      domain.org\n2  bob.brown@mail.com         mail.com\n3  charlie@example.com        example.com\n```\n\nHowever, you are unsure how to extract the domain names properly and incorporate them into your DataFrame. \n\nA:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email':['john.doe@example.com', 'jane.smith@domain.org', 'bob.brown@mail.com', 'charlie@example.com']})\n```\nemail_df['domain'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nemail_df['domain'] = email_df['email'].str.split('@').str[1]\n```"
  },
  {
    "input": "Problem:\nI have a list of dictionaries containing sales data as follows:\n\nsales_data = [\n    {\"date\": \"2023-01-01\", \"product\": \"A\", \"amount\": 150},\n    {\"date\": \"2023-01-01\", \"product\": \"B\", \"amount\": 200},\n    {\"date\": \"2023-01-02\", \"product\": \"A\", \"amount\": 100},\n    {\"date\": \"2023-01-02\", \"product\": \"C\", \"amount\": 250},\n    {\"date\": \"2023-01-03\", \"product\": \"B\", \"amount\": 300},\n]\n\nI need to create a function that accepts this list and returns a dictionary summarizing the total sales amount for each product across all dates. The desired output dictionary should have products as keys and their total sales amount as values.\n\nFor the sales_data provided, the output should look like this:\n\n{\n    \"A\": 250,\n    \"B\": 500,\n    \"C\": 250\n}\n\nA:\n<code>\nsales_data = [\n    {\"date\": \"2023-01-01\", \"product\": \"A\", \"amount\": 150},\n    {\"date\": \"2023-01-01\", \"product\": \"B\", \"amount\": 200},\n    {\"date\": \"2023-01-02\", \"product\": \"A\", \"amount\": 100},\n    {\"date\": \"2023-01-02\", \"product\": \"C\", \"amount\": 250},\n    {\"date\": \"2023-01-03\", \"product\": \"B\", \"amount\": 300},\n]\n\ndef summarize_sales(data):\n    # return the solution in this function\n    pass\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef summarize_sales(data):\n    summary = {}\n    for entry in data:\n        product = entry[\"product\"]\n        amount = entry[\"amount\"]\n        if product in summary:\n            summary[product] += amount\n        else:\n            summary[product] = amount\n    return summary\n\nresult = summarize_sales(sales_data)\n```"
  },
  {
    "input": "Problem:\nI'm working on training a neural network using PyTorch and I want to implement a custom training loop. I have a dataset of input features and corresponding labels. After defining a model, I would like to compute the loss using mean squared error and update the model parameters. The dataset is structured such that `inputs` is a tensor of shape [batch_size, num_features] and `labels` is a tensor of shape [batch_size]. \n\nHere\u2019s an example of how I\u2019m initiating my model and defining the optimizer:\n\n<code>\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Sample model and dataset\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        return self.fc(x)\n\nmodel = MyModel()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# Input data and labels\ninputs = torch.randn((32, 10))  # Example input\nlabels = torch.randn((32, 1))    # Example true labels\n</code>\n\nTo compute the loss, I would use the following line of code:\n\nloss = ... # fill in the missing part to define the loss function using mean squared error\nBEGIN SOLUTION\n<code>",
    "output": "\nloss_fn = nn.MSELoss()\nloss = loss_fn(model(inputs), labels)  \n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a neural network using TensorFlow that predicts housing prices based on various features. I defined a simple model and trained it on a dataset. I want to preprocess input data using the built-in normalization function from TensorFlow, but I'm unsure how to apply this normalization effectively during model prediction. Specifically, I want to fill in the blank in the code below to correctly normalize the input data before making a prediction.\n\n```python\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Define a simple model\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(5,)),\n    keras.layers.Dense(1)\n])\n\n# Assuming the model has been trained...\n\n# New input data\nnew_data = [[3000, 3, 2, 10, 1]]  # e.g., [square footage, bedrooms, bathrooms, age, garage]\n\n# Normalize the input data\nnormalized_data = ___\n\n# Make a prediction\npredicted_price = model.predict(normalized_data)\nprint(predicted_price)\n```\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nnew_data = [[3000, 3, 2, 10, 1]]\n</code>\nnormalized_data = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_data = tf.keras.utils.normalize(new_data)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a sequence classification task using a recurrent neural network (RNN) in PyTorch. The RNN outputs a tensor of shape (batch_size, seq_length, num_classes) representing the class probabilities at each time step. However, I need the final output to only reflect the class prediction for the last time step of each sequence. How can I slice the RNN output to obtain a tensor of shape (batch_size, num_classes) that corresponds to the predictions for the last time step?\n\nTo illustrate, if my RNN outputs:\n\n[[[0.2, 0.8],\n  [0.5, 0.5],\n  [0.6, 0.4]],\n\n [[0.1, 0.9],\n  [0.7, 0.3],\n  [0.3, 0.7]]]\n\nI need the resulting output to be:\n\n[[0.6, 0.4],\n [0.3, 0.7]]\n\n\nA:\n\n<code>\nimport torch\nrnn_output = load_data()\n</code>\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredictions = rnn_output[:, -1, :]\n</code>"
  },
  {
    "input": "Problem:\nYou are working on a retail sales dataset stored in a pandas DataFrame, which has the following structure:\n\n   ProductID  Quantity  Price\n0         A         2   10.0\n1         B         0   15.0\n2         C         5    5.0\n3         D         0   20.0\n4         E         8   12.0\n\nYou need to calculate the total revenue from each product that has a quantity greater than zero. Create a function `calculate_revenue` that takes a DataFrame and returns a new DataFrame containing only the rows with non-zero quantity and an additional column `TotalRevenue` that calculates the revenue by multiplying `Quantity` by `Price`. The resulting DataFrame should only include `ProductID`, `Quantity`, `Price`, and `TotalRevenue`.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"ProductID\": [\"A\", \"B\", \"C\", \"D\", \"E\"],\n    \"Quantity\": [2, 0, 5, 0, 8],\n    \"Price\": [10.0, 15.0, 5.0, 20.0, 12.0]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_revenue(df):\n    df_non_zero = df[df['Quantity'] > 0].copy()\n    df_non_zero['TotalRevenue'] = df_non_zero['Quantity'] * df_non_zero['Price']\n    return df_non_zero[['ProductID', 'Quantity', 'Price', 'TotalRevenue']]\n\nresult = calculate_revenue(df)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with a 4-dimensional sparse tensor that represents the preferences of users for different items over various contexts and timeframes. The sparse tensor is defined using the `scipy.sparse` library and contains a few non-zero values indicating positive preferences. I want to efficiently extract the non-zero entries along with their indices (in the form of a list of tuples) from the tensor and format them into a list of dictionaries, where each dictionary associates the indices of each non-zero entry with the corresponding value.\n\nHere's how my sparse tensor is defined:\n\n```python\nfrom scipy import sparse\n\n# Creating a sparse tensor (4D) with some non-zero values\nsparse_tensor = sparse.coo_array((3, 2, 4, 5), dtype=int)\n```\n\nThe current state of the sparse tensor is as follows:\n\n- Non-zero entries at indices (0, 1, 2, 3), (2, 0, 1, 4), and (1, 0, 3, 2), with values 10, 20, and 30 respectively.\n\nI want to construct the output in this format:\n\n```python\noutput = [\n    {'indices': (0, 1, 2, 3), 'value': 10},\n    {'indices': (2, 0, 1, 4), 'value': 20},\n    {'indices': (1, 0, 3, 2), 'value': 30},\n]\n```\n\nCan you help me write the code to achieve this transformation?\n\nA:\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Assume sparse_tensor is defined as given above\nsparse_tensor = sparse.coo_array(...)  # Fill this in with the actual sparse tensor values\n\n# Extract the solution\noutput = ...  # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Assume sparse_tensor is defined as given above\nsparse_tensor = sparse.coo_array((3, 2, 4, 5), dtype=int)\nsparse_tensor.data = np.array([10, 20, 30])\nsparse_tensor.row = np.array([0, 2, 1])\nsparse_tensor.col = np.array([1, 0, 0])\nsparse_tensor.shape = (3, 2, 4, 5)\n\n# Extract the solution\noutput = [{'indices': tuple(sparse_tensor.nonzero()[:, i]), 'value': sparse_tensor.data[i]} for i in range(len(sparse_tensor.data))]\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing daily sales data of a retail store, with each row representing sales for a specific date. The DataFrame looks like this:\n\n```\n           Date     Sales\n0    2023-01-01    200\n1    2023-01-02    220\n2    2023-01-03    250\n3    2023-01-04    240\n4    2023-01-05    260\n5    2023-01-06    300\n```\n\nYou want to calculate the 3-day rolling average of sales, ensuring that the resulting DataFrame retains the original dates and fills in the rolling average where applicable. The first two rows should result in `NaN` since there aren't enough preceding values to compute the average.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n    'Sales': [200, 220, 250, 240, 260, 300]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nrolling_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nrolling_avg = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a voice recognition project using PyTorch. I have a training dataset where each input sample is a spectrogram tensor of shape (50, 30), representing frequencies over time, and the corresponding labels are in a tensor of shape (50,) containing class indices. I want to transform these spectrograms to eliminate any silence regions so that the output tensor retains only the relevant frequencies that have non-zero values, while preserving the original shape's aspect ratio. The silence regions are represented by zeros. \n\nHere's how I have my tensors set up:\n\nspectrograms: shape (50, 30)\nlabels: shape (50,)\n\nI want to perform this operation using a masking technique that results in a tensor that retains only the non-zero entries while keeping them structured as a 2D tensor.\n\nFill in the code below to accomplish this task:\n\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = ...\n</code>\n",
    "output": "\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = spectrograms[mask].view(-1, spectrograms.size(1))\n</code>"
  },
  {
    "input": "Problem:\nI have the following dataframe containing customer data:\n\n```\ncustomer_info\n1   John Doe, 29, New York\n2   Jane Smith, 34, San Francisco\n3   Alice Johnson, 22, Boston\n4   Bob Brown, 45, Chicago\n```\n\nI need to split this `customer_info` column into three separate columns: `name`, `age`, and `city`. The final dataframe should look like this:\n\n```\n      name   age           city\n1  John Doe   29       New York\n2  Jane Smith 34  San Francisco\n3  Alice Johnson 22         Boston\n4  Bob Brown   45        Chicago\n```\n\nI tried to achieve this using the `str.split` method but I'm not getting the expected output. Here is the initial code I have:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'customer_info': ['John Doe, 29, New York', 'Jane Smith, 34, San Francisco', \n                                      'Alice Johnson, 22, Boston', 'Bob Brown, 45, Chicago']})\n```\n\nHow can I correctly extract and separate the name, age, and city into different columns? \n\nA:\n<code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['name', 'age', 'city']] = df['customer_info'].str.split(', ', expand=True)\ndf['age'] = df['age'].astype(int)\ndf = df.drop(columns=['customer_info'])\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a historical weather dataset that contains daily temperature records. The dataset is represented as a Pandas DataFrame with a datetime index and a single column called 'temperature' that holds the recorded temperatures in degrees Celsius. You want to calculate the rolling average of the temperature over a given 7-day window.\n\nHere is an example of your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'temperature': [22, 21, 19, 23, 30, 18, 26, 28, 27, 24, 25, 20, 21]\n}\ndates = pd.date_range(start='2023-01-01', periods=len(data['temperature']), freq='D')\ndf = pd.DataFrame(data, index=dates)\n```\n\nTo compute the rolling average for the temperature over a 7-day window, you can use the `rolling()` method. Complete the following line of code to store the result in a new column called 'rolling_avg' in the DataFrame.\n\n```python\ndf['rolling_avg'] = ...\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['rolling_avg'] = df['temperature'].rolling(window=7).mean()"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing a column of email addresses, and you want to extract the usernames (the part before the '@') and the domain names (the part after the '@'). The DataFrame looks like this:\n\n```python\nemail_df = pd.DataFrame({'email': ['user@example.com', 'john.doe@test.org', 'alice@company.net']})\n```\n\nYou want to create two new columns: \"username\" for the part before the '@' and \"domain\" for the part after it. \n\nI've attempted to split the email addresses using the `str.split()` method, but I'm unsure how to apply this to create new columns effectively.\n\nA:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email': ['user@example.com', 'john.doe@test.org', 'alice@company.net']})\n```\nemail_df[['username', 'domain']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nemail_df[['username', 'domain']] = email_df['email'].str.split('@', expand=True)\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains email addresses in a single column. The DataFrame is structured like this:\n\nemail_df = pd.DataFrame({'email': ['alice@example.com', 'bob@domain.com', 'charlie123@service.org', 'david@company.org', 'eve@xyz.com']})\n\nYour goal is to extract the username and domain from each email address and create two new columns: 'username' and 'domain'. The final DataFrame should look like this:\n\n|      username      |         domain        |\n|---------------------|-----------------------|\n|       alice         |      example.com      |\n|         bob         |       domain.com      |\n|     charlie123      |      service.org      |\n|        david        |      company.org      |\n|         eve         |        xyz.com        |\n\nYou'd like to accomplish this using string manipulation methods in pandas. Start by applying code to extract the username and domain appropriately. \n\nHere is your input DataFrame structure:\n```python\nimport pandas as pd\n\nemail_df = pd.DataFrame({'email': ['alice@example.com', 'bob@domain.com', 'charlie123@service.org', 'david@company.org', 'eve@xyz.com']})\n```\n\nYour task is to fill in the blank below to create the columns 'username' and 'domain':\n```python\nemail_df[['username', 'domain']] = ...\n```",
    "output": "\n```python\nemail_df[['username', 'domain']] = email_df['email'].str.split('@', expand=True)\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing product information as follows:\n```python\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nI want to extract the product name and price into two separate columns: `product_name` and `product_price`. The final DataFrame should look like this:\n```\n  product_name  product_price\n0        Apple          1.50\n1       Banana          0.75\n2       Cherry          3.00\n3         Date          2.50\n```\nI've attempted to use string splitting but it hasn't worked as intended. The column entries always include unwanted spaces. Please help me extract these values properly.\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nproduct_df[['product_name', 'product_price']] = product_df['product_info'].str.split(' - \\$', expand=True)\nproduct_df['product_price'] = product_df['product_price'].astype(float)\nproduct_df['product_name'] = product_df['product_name'].str.strip()\nproduct_df = product_df[['product_name', 'product_price']]\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing daily weather data with a timestamp index, including the high and low temperatures for each day:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Temperature_High': [30, 32, 31, 34, 35],\n    'Temperature_Low': [20, 21, 19, 22, 23]\n}\ndates = pd.date_range(start='2023-01-01', periods=len(data['Temperature_High']), freq='D')\ndf = pd.DataFrame(data, index=dates)\n```\n\nNow, you want to calculate the daily temperature range (high minus low) and create a new column named `Temperature_Range` in the DataFrame to hold these values. What code would you use to achieve this?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df['Temperature_High'] - df['Temperature_Low']\ndf['Temperature_Range'] = result\n```"
  },
  {
    "input": "Problem:\nI need to analyze a dataset consisting of sales data for multiple products over a quarter. Each entry includes the product name, sold quantity, and sale date. The dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'B'],\n    'quantity': [10, 20, 15, 5, 10, 30, 5, 25, 10],\n    'date': pd.date_range(start='2023-01-01', periods=9)\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to create a function that aggregates the total sales for each product over the entire period. Additionally, if any products have a total quantity sold of less than a defined threshold, those products should be excluded from the final result. \n\nHere's the initial setup, and I need your help filling in the blank for the function that performs this calculation:\n\n```python\ndef aggregate_sales(df, threshold):\n    # Your aggregation logic here\n    result = ...\n    return result\n```\n\nWhat should go in the blank for the `result` variable in order to achieve the desired output?",
    "output": "\n```python\n    result = df.groupby('product')['quantity'].sum().loc[lambda x: x >= threshold]\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe containing product descriptions and prices:\n  description           price\n0 \"apple pie\"         4.50\n1 \"banana bread\"      5.00\n2 \"cherry tart\"       6.25\n3 \"date square\"       3.75\n\nI need to extract the dessert type (the part before the space) from each description and create a new column that lists all unique dessert types in a single string, separated by commas. The desired output should look like this:\n\n  description           price       dessert_types\n0 \"apple pie\"         4.50         apple, banana, cherry, date\n1 \"banana bread\"      5.00         apple, banana, cherry, date\n2 \"cherry tart\"       6.25         apple, banana, cherry, date\n3 \"date square\"       3.75         apple, banana, cherry, date\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'description': [\"apple pie\", \"banana bread\", \"cherry tart\", \"date square\"],\n    'price': [4.50, 5.00, 6.25, 3.75]\n})\n</code>\ndf['dessert_types'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['dessert_types'] = ', '.join(df['description'].str.split().str[0].unique())\n</code>"
  }
]