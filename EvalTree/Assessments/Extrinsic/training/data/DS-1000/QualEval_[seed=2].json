[
  {
    "input": "Problem:\nYou are analyzing a dataset of product sales and want to compute the total revenue generated by each product. The dataset contains the following columns: `product_id`, `quantity_sold`, and `price_per_unit`. You need to create a custom function that accepts a DataFrame and returns a new DataFrame with an additional column named `total_revenue`, which is calculated as `quantity_sold * price_per_unit` for each product.\n\nHere is a sample DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103],\n    'quantity_sold': [5, 3, 7],\n    'price_per_unit': [20.0, 15.0, 10.0]\n}\ndf = pd.DataFrame(data)\n```\n\nThe resulting DataFrame should look like this:\n```\n   product_id  quantity_sold  price_per_unit  total_revenue\n0         101              5            20.0           100.0\n1         102              3            15.0            45.0\n2         103              7            10.0            70.0\n```\n\nYou need to write the function and fill in the blank to compute the total revenue.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef calculate_total_revenue(df):\n    df['total_revenue'] = df['quantity_sold'] * df['price_per_unit']\n    return df\n\nresult = calculate_total_revenue(df)\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing sales data from different stores over several months. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Store_ID': ['S001', 'S002', 'S001', 'S003', 'S002'],\n    'Month': ['January', 'January', 'February', 'February', 'March'],\n    'Sales': [200, np.nan, 150, 300, 250]\n})\n```\n\nYour task is to write a custom function that calculates the total sales for each store, ensuring that NaN values are ignored in the sum calculation. You should modify the DataFrame to include a new column called 'Total_Sales' that holds the calculated total for each unique Store_ID.\n\nExpected DataFrame after operation:\n```\n  Store_ID     Month  Sales  Total_Sales\n0     S001   January  200.0         350.0\n1     S002   January    NaN         250.0\n2     S001  February  150.0         350.0\n3     S003  February  300.0         300.0\n4     S002     March  250.0         250.0\n```\n\nA:\n```python\ndf['Total_Sales'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Total_Sales'] = df.groupby('Store_ID')['Sales'].transform(lambda x: x.sum(skipna=True))\n```"
  },
  {
    "input": "### Problem\nI have a dataset representing sales data with the following structure:\n\n```\n   Product    Quantity\n0  Widget A      10\n1  Widget B      5\n2  Widget A      3\n3  Widget C      6\n4  Widget B      7\n5  Widget A      4\n```\n\nI want to create a function that calculates the total quantity sold for each product and returns a DataFrame with the product names and their corresponding total quantities. The output should look like this:\n\n```\n   Product   Total Quantity\n0  Widget A             17\n1  Widget B             12\n2  Widget C              6\n```\n\nHere is what I have so far:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B', 'Widget A'],\n    'Quantity': [10, 5, 3, 6, 7, 4]\n}\n\ndf = pd.DataFrame(data)\n\ndef calculate_total_quantity(df):\n    result = ...  # put solution in this variable\n```\n\nFill in the blank to implement the function that produces the desired output.",
    "output": "\n```python\n    result = df.groupby('Product', as_index=False)['Quantity'].sum().rename(columns={'Quantity': 'Total Quantity'})\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains product descriptions in a column called 'description':\n```\n    description\n0   \"Apple - fresh, 1.5kg\"\n1   \"Banana - ripe, 2kg\"\n2   \"Cherry - sweet, 0.5kg\"\n3   \"Date - dried, 4kg\"\n```\nI want to separate the product name, state (fresh/ripe/sweet/dried), and weight into new columns named 'product', 'state', and 'weight' respectively. The resulting DataFrame should look like this:\n```\n   product   state   weight\n0   Apple    fresh   1.5\n1   Banana   ripe    2.0\n2   Cherry   sweet   0.5\n3   Date     dried   4.0\n```\nHere is my initial attempt to extract the information, but it's not working as expected:\n\n```python\ndf[['product', 'state', 'weight']] = df.description.str.extract(r'\\\"([A-Za-z]+)\\s-\\s([a-z]+),\\s([0-9.]+)kg\\\"')\n```\n\nCan you suggest a fix? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'description': ['\"Apple - fresh, 1.5kg\"', '\"Banana - ripe, 2kg\"', \n                                    '\"Cherry - sweet, 0.5kg\"', '\"Date - dried, 4kg\"']})\n</code>\ndf[['product', 'state', 'weight']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf[['product', 'state', 'weight']] = df.description.str.extract(r'\"([A-Za-z]+)\\s-\\s([a-z]+),\\s([0-9.]+)kg\"')\ndf['weight'] = df['weight'].astype(float)\n</code>"
  },
  {
    "input": "Problem:\nI'm working on training a neural network using PyTorch and I want to implement a custom training loop. I have a dataset of input features and corresponding labels. After defining a model, I would like to compute the loss using mean squared error and update the model parameters. The dataset is structured such that `inputs` is a tensor of shape [batch_size, num_features] and `labels` is a tensor of shape [batch_size]. \n\nHere\u2019s an example of how I\u2019m initiating my model and defining the optimizer:\n\n<code>\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Sample model and dataset\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc = nn.Linear(10, 1)\n        \n    def forward(self, x):\n        return self.fc(x)\n\nmodel = MyModel()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# Input data and labels\ninputs = torch.randn((32, 10))  # Example input\nlabels = torch.randn((32, 1))    # Example true labels\n</code>\n\nTo compute the loss, I would use the following line of code:\n\nloss = ... # fill in the missing part to define the loss function using mean squared error\nBEGIN SOLUTION\n<code>",
    "output": "\nloss_fn = nn.MSELoss()\nloss = loss_fn(model(inputs), labels)  \n</code>"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame with a column 'product_info' that contains strings representing product details in the format: \"ProductName - Brand - Price\". For example:\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n\nI want to create a new DataFrame that extracts the 'ProductName' and 'Price' into separate columns while removing the 'Brand' from 'product_info'. If 'product_info' does not adhere to the expected format, I want it to remain unchanged.\n\nThe expected output is:\n\n  ProductName       Price\n0      Laptop   1200 USD\n1  Smartphone    999 USD\n2   Smartwatch    300 USD\n3      Laptop   1150 USD\n\nHere is my starting point:\n\n<code>\nimport pandas as pd\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n</code>\nnew_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnew_df = product_data['product_info'].str.extract(r'([^ -]+) - [^-]+ - (.+)')[0].rename('ProductName').to_frame().join(\n    product_data['product_info'].str.extract(r'[^ -]+ - [^-]+ - (.+)')[0].rename('Price')\n)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataframe containing email addresses and I want to extract the username (the part before the '@') and the domain (the part after the '@') from the email addresses. The email addresses are in a column called 'email'. I also want to create a separate column that contains the length of the username. Here\u2019s a sample of my data:\n\n```\n   email\n0  john.doe@example.com\n1  jane_smith@company.org\n2  user123@domain.net\n3  test.user@web-service.com\n```\n\nI want to achieve the following structure:\n\n```\n   email                     username     domain           username_length\n0  john.doe@example.com     john.doe     example.com     8\n1  jane_smith@company.org   jane_smith   company.org     10\n2  user123@domain.net       user123      domain.net      7\n3  test.user@web-service.com test.user    web-service.com 9\n```\n\nHere\u2019s what I have tried so far:\n\n```python\ndf['username'] = df.email.replace(r'(.+)@.+', r'\\1', regex=True)\ndf['domain'] = df.email.replace(r'.+@(.+)', r'\\1', regex=True)\ndf['username_length'] = df.username.map(len)\n```\n\nBut it seems this approach does not work as expected. Can you provide the correct solution for the variables? \n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'email': ['john.doe@example.com', 'jane_smith@company.org', 'user123@domain.net', 'test.user@web-service.com']\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['username'] = df['email'].str.split('@').str[0]\ndf['domain'] = df['email'].str.split('@').str[1]\ndf['username_length'] = df['username'].str.len()\nresult = df\n```"
  },
  {
    "input": "Problem:\nI have a time series data frame which looks like this:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04'],\n        'Temperature': [30, 32, 31, 29]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nI want to calculate the rolling average temperature for a window of 2 days and store the result in a new column called `Rolling_Avg`. However, the rolling average must be calculated in a way that any NaN values should be replaced with the last valid temperature reading. The final output should look like this:\n\n```\n        Date  Temperature  Rolling_Avg\n0 2021-01-01           30           30\n1 2021-01-02           32           31\n2 2021-01-03           31           31.0\n3 2021-01-04           29           30.0\n```\n\nI tried using the rolling function, but I'm unsure how to handle the NaN values afterwards.\n\nA:\n```python\ndf['Rolling_Avg'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=2).mean().fillna(method='ffill')\n```"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.10.0. I have a batch of input tensors with shape (5, 10), and I want to normalize the rows by the maximum value in each row. Specifically, for each row, I want to subtract the maximum value and divide by the maximum value to ensure all values in the row lie between 0 and 1.\n\nGiven my input tensor:\n```\ninput_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n                             [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0],\n                             [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n                             [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0],\n                             [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0]])\n```\nHow can I achieve this normalization with a single line of code?\n\nA:\n<code>\nimport torch\n\ninput_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n                             [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0],\n                             [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n                             [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0],\n                             [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = (input_tensor - input_tensor.max(dim=1, keepdim=True).values) / input_tensor.max(dim=1, keepdim=True).values</code>"
  },
  {
    "input": "Problem:\nI have a time series DataFrame with temperatures recorded every hour over several days. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Timestamp': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', '2023-01-01 03:00',\n                  '2023-01-02 00:00', '2023-01-02 01:00', '2023-01-02 02:00', '2023-01-02 03:00'],\n    'Temperature': [20.1, 19.8, 19.6, 19.7, 18.4, 18.5, 18.3, 18.7]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nI want to resample this temperature data to daily frequency, calculating the average temperature for each day. However, I need to ensure that the resulting DataFrame has the date as the index and the average temperature for each day as a separate column. \n\nThe expected output format should look like this:\n\n```\n            Temperature\nTimestamp\n2023-01-01          ...\n2023-01-02          ...\n```\n\nCan you provide the line of code that fills in the blank in the following placeholder?\n\n```python\ndaily_avg = df.set_index('Timestamp').resample(...).mean()\n```",
    "output": "\n```python\ndaily_avg = df.set_index('Timestamp').resample('D').mean()\n```"
  },
  {
    "input": "Problem:\nI have a list of dictionaries where each dictionary represents a product with its name, price, and quantity sold. I need to calculate the total revenue generated from each product and return this information in a new list of dictionaries, where each dictionary contains the product name and its total revenue. The input looks like this:\n\nproducts = [\n    {'name': 'Widget A', 'price': 20, 'quantity': 100},\n    {'name': 'Widget B', 'price': 15, 'quantity': 200},\n    {'name': 'Widget C', 'price': 30, 'quantity': 150}\n]\n\nThe expected output for total revenue calculations should be:\n\n[\n    {'name': 'Widget A', 'total_revenue': 2000},\n    {'name': 'Widget B', 'total_revenue': 3000},\n    {'name': 'Widget C', 'total_revenue': 4500}\n]\n\nYou need to implement a custom function to calculate the total revenue for each product from the input list.\n\nA:\n<code>\nproducts = [\n    {'name': 'Widget A', 'price': 20, 'quantity': 100},\n    {'name': 'Widget B', 'price': 15, 'quantity': 200},\n    {'name': 'Widget C', 'price': 30, 'quantity': 150}\n]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = [\n    {'name': product['name'], 'total_revenue': product['price'] * product['quantity']}\n    for product in products\n]\n</code>"
  },
  {
    "input": "### Problem:\nYou are given a DataFrame that contains daily sales data for a retail store over a month, structured as follows:\n\n```python\n                 sales\ndate\n2023-01-01    100\n2023-01-02    150\n2023-01-03    200\n2023-01-04    250\n2023-01-05    300\n2023-01-06    350\n2023-01-07    400\n2023-01-08    450\n2023-01-09    500\n2023-01-10    550\n```\n\nYou need to create a new column in the DataFrame that represents a 3-day rolling average of sales, where the average is calculated based on the current day and the two preceding days.\n\nPlease provide the line of code that will create this new column called '3_day_avg'.\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data).set_index('date')\n```\n\ndf['3_day_avg'] = ... # put solution in this variable",
    "output": "\n```python\ndf['3_day_avg'] = df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nI am building a neural network to classify images using both TensorFlow and PyTorch. I need to apply a common preprocessing step to my image tensor that consists of normalizing it by subtracting the mean and dividing by the standard deviation per channel. The images are represented as a tensor in the shape of (batch_size, height, width, channels). \n\nGiven a tensor `images` and the mean and standard deviation tensors `mean` and `std`, how can I perform this normalization for both frameworks?\n\nMCVE\nDesired Output\n\nimport torch\nimport tensorflow as tf\n\n# PyTorch normalization\nimages_pytorch = torch.rand((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean = torch.tensor([0.5, 0.5, 0.5])  # mean for each channel\nstd = torch.tensor([0.2, 0.2, 0.2])   # std for each channel\n\n# TensorFlow normalization\nimages_tensorflow = tf.random.uniform((32, 64, 64, 3))  # Example of a batch of 32 images 64x64 with 3 channels\nmean_tf = tf.constant([0.5, 0.5, 0.5])  # mean for each channel\nstd_tf = tf.constant([0.2, 0.2, 0.2])    # std for each channel\n\n# PyTorch normalization\nnormalized_images_pt = ...  # put solution in this variable\n\n# TensorFlow normalization\nnormalized_images_tf = ...  # put solution in this variable\n\nA:\n<code>\nimages_pt, mean, std = load_data()\n</code>\nnormalized_images_pt = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nnormalized_images_pt = (images_pytorch - mean[None, None, None, :]) / std[None, None, None, :]\nnormalized_images_tf = (images_tensorflow - mean_tf) / std_tf\n</code>"
  },
  {
    "input": "Problem:\nI am working with high-dimensional images and need to perform an operation on a sparse tensor. Specifically, I want to compute the sum of values along the last axis for a 3D sparse tensor representation of images (channels, height, width) using PyTorch. My sparse tensor is created as follows:\n\n```python\nimport torch\nfrom torch.sparse import FloatTensor\n\nindices = torch.tensor([[0, 0, 1], [0, 2, 1]])\nvalues = torch.tensor([3.0, 4.0, 5.0])\nsparse_tensor = FloatTensor(indices, values, size=(2, 3, 3))\n```\n\nI need to fill in the blank to compute the sum across the last axis, resulting in a 2D tensor where each row corresponds to the sum of each channel for all positions in the height and width dimensions.\n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = sparse_tensor.sum(dim=-1).to_dense()\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\n\nYou have a sparse matrix representation of a large dataset where the rows represent users and the columns represent items. The users only interact with a small fraction of the items, resulting in a sparse matrix. The goal is to create a function that fills this matrix with a specified value (say 1) for all non-zero entries, effectively transforming it into a binary indicator matrix.\n\nGiven a sparse matrix `sparse_matrix` in the Compressed Sparse Row (CSR) format, write a function `to_binary_matrix(sparse_matrix)` that converts all non-zero elements to 1, preserving the sparse structure.\n\nHere is a sample sparse matrix to start with:\n\n```python\nfrom scipy.sparse import csr_matrix\ndata = [3, 4, 5, 7]\nrow_indices = [0, 0, 1, 2]\ncol_indices = [0, 2, 1, 2]\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n```\n\nNow, you need to implement the function and apply it as follows:\n\n```python\nresult = ...\n``` \n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef to_binary_matrix(sparse_matrix):\n    return sparse_matrix.copy().astype(bool).astype(int)\n\nresult = to_binary_matrix(sparse_matrix)\n```"
  },
  {
    "input": "Problem:\nI have a time series data in a pandas DataFrame containing timestamps and corresponding temperatures taken every hour. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'timestamp': ['2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00', \n                  '2023-01-01 03:00:00', '2023-01-01 04:00:00', '2023-01-01 05:00:00'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n})\n```\n\nWhat I want to achieve is to create a new DataFrame that includes the average temperature computed over a 2-hour rolling window, but only for the timestamps that fall exactly on the hour (e.g., '2023-01-01 00:00:00', '2023-01-01 01:00:00', etc.). \n\nThe resulting DataFrame should have the following structure:\n\n```python\n          timestamp  avg_temperature\n0  2023-01-01 00:00:00              ?\n1  2023-01-01 01:00:00              ?\n2  2023-01-01 02:00:00              ?\n3  2023-01-01 03:00:00              ?\n4  2023-01-01 04:00:00              ?\n5  2023-01-01 05:00:00              ?\n```\n\nPlease fill in the blank with the proper code to derive the column `avg_temperature`. \n\n```python\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.set_index('timestamp').rolling('2H').mean().reset_index().rename(columns={'temperature': 'avg_temperature'})\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe:\n  full_name\n1 \"Alice Doe\"\n2 \"Bob Smith\"\n3 \"Charlie Brown\"\n4 \"Alice Wonderland\"\n\nI need to extract the first names and last names into two separate columns named 'first_name' and 'last_name', so that the resulting dataframe looks like this:\n  first_name  last_name\n1      Alice       Doe\n2        Bob     Smith\n3    Charlie     Brown\n4      Alice  Wonderland\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'full_name': ['Alice Doe', 'Bob Smith', 'Charlie Brown', 'Alice Wonderland']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['full_name'].str.split(' ', expand=True).rename(columns={0: 'first_name', 1: 'last_name'})</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing daily temperature records for a city over several years. The DataFrame has a 'Date' column and a 'Temperature' column. I want to compute the rolling average temperature over a 7-day window for each day. For example, for each day's temperature, the average should include that day and the previous six days. The DataFrame is structured as follows:\n\n```python\nimport pandas as pd\n\ndate_range = pd.date_range(start='2020-01-01', end='2020-01-10', freq='D')\ntemperatures = [30, 32, 31, 34, 36, 30, 29, 33, 35, 36]\ndf = pd.DataFrame({'Date': date_range, 'Temperature': temperatures})\ndf.set_index('Date', inplace=True)\n```\n\nNow, I need to create a new column '7_day_avg' in the DataFrame that contains the rolling average temperature. How can I achieve this? \n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor in PyTorch and need to efficiently manipulate it. Specifically, I want to sum a scalar value to all non-zero elements in a 3D sparse tensor. The tensor is initialized as follows:\n\n```python\nimport torch\nsparse_tensor = torch.sparse_coo_tensor(indices=torch.tensor([[0, 1, 1, 2], [0, 2, 3, 1]]), \n                                        values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n                                        size=(3, 4))\n```\n\nNow, I want to add a scalar value of 5 to all non-zero elements in `sparse_tensor`. \n\nWhat should I use to accomplish this?\n\nA:\n<code>\nscalar = 5\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = sparse_tensor + scalar * sparse_tensor.to_dense().clamp(min=0)"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily temperature data for a city over several months, structured like this:\n\n```\n          Date        Temperature\n0   2023-01-01        15.0\n1   2023-01-02        16.5\n2   2023-01-03        15.5\n3   2023-02-01        14.0\n4   2023-02-02        13.5\n5   2023-03-01        16.0\n6   2023-03-02        18.0\n7   2023-03-03        17.5\n```\n\nI want to calculate the rolling average temperature over a window of 7 days and then return the DataFrame with an additional column showing these rolling averages. The resulting DataFrame should look like this:\n\n```\n          Date        Temperature  Rolling_Avg\n0   2023-01-01        15.0            NaN\n1   2023-01-02        16.5            NaN\n2   2023-01-03        15.5            NaN\n3   2023-02-01        14.0            NaN\n4   2023-02-02        13.5            NaN\n5   2023-03-01        16.0          15.2\n6   2023-03-02        18.0          15.8\n7   2023-03-03        17.5          16.5\n```\n\nI've started by creating the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', \n                 '2023-02-01', '2023-02-02', '2023-03-01', \n                 '2023-03-02', '2023-03-03'], \n        'Temperature': [15.0, 16.5, 15.5, 14.0, 13.5, 16.0, 18.0, 17.5]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, I need to compute the rolling average. Can you help me fill in the blank in this code?\n```python\ndf['Rolling_Avg'] = df['Temperature'].___(window=7)\n```\nBEGIN SOLUTION\n<code>rolling</code>",
    "output": "\n<code>rolling</code>"
  },
  {
    "input": "Problem:\nConsider the following pandas DataFrame which contains a list of emails in a column named 'email_addresses':\n```python\nemail_df = pd.DataFrame({'email_addresses': ['john.doe@example.com', 'jane_smith@domain.org', \n                                              'user123@my-site.info', 'invalid-email@.com', \n                                              'another.email@sub.domain.com']})\n```\nYour task is to extract the username and domain from the 'email_addresses' that follow the standard email format. The final DataFrame should contain three columns: 'username', 'domain', and 'valid_email', where 'valid_email' indicates whether the email was valid (True) or not (False). For invalid emails, 'username' and 'domain' should be set to None. \n\nThe final DataFrame should look like this:\n```\n     username           domain  valid_email\n0      john.doe        example.com        True\n1     jane_smith         domain.org        True\n2       user123        my-site.info        True\n3         None                None       False\n4    another.email      sub.domain.com        True\n```\n\nI've written some code to try and accomplish this, but I'm struggling with the regex pattern needed to identify valid emails and populate the new columns. \n\nA:\n```python\nimport pandas as pd\nimport re\n\nemail_df = pd.DataFrame({'email_addresses': ['john.doe@example.com', 'jane_smith@domain.org', \n                                              'user123@my-site.info', 'invalid-email@.com', \n                                              'another.email@sub.domain.com']})\n```\nemail_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef validate_email(email):\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    match = re.match(pattern, email)\n    if match:\n        username, domain = email.split('@')\n        return username, domain, True\n    return None, None, False\n\nresults = email_df['email_addresses'].apply(validate_email)\nemail_df[['username', 'domain', 'valid_email']] = pd.DataFrame(results.tolist(), index=email_df.index)\nemail_df = email_df[['username', 'domain', 'valid_email']]\n```"
  },
  {
    "input": "## Problem:\nI have a time series dataset that records the daily sales of a product. The dataframe `sales_df` has the following columns:\n\n- `date`: a datetime column representing the date of the sales\n- `sales`: an integer column representing the number of units sold on that date\n\nIt looks like this:\n\n```\n        date       sales\n0 2023-01-01      120\n1 2023-01-02      135\n2 2023-01-03      150\n3 2023-01-04      145\n4 2023-01-05      160\n```\n\nI want to create a new column `rolling_average` that calculates the 3-day rolling average of the sales. Thus, for each date, this value should represent the average of the sales for that date and the two previous days. Please help me fill in the blank below to achieve this.\n\nMy code:\n\n```python\nimport pandas as pd\n\nsales_df = pd.DataFrame({\n    'date': pd.date_range(start='2023-01-01', periods=5),\n    'sales': [120, 135, 150, 145, 160]\n})\n\nsales_df['rolling_average'] = ...\n```\n",
    "output": "\n```python\nsales_df['rolling_average'] = sales_df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "## Problem\nI need to analyze customer transaction data from a CSV file that contains columns: `customer_id`, `transaction_date`, and `amount`. I want to compute the total spending of each customer per month and return a DataFrame that shows `customer_id`, `month`, and `total_spending`. \n\nI started by grouping the DataFrame but I'm struggling to implement a custom function to calculate this total on a month-to-month basis. \n\nHere's an example of how my DataFrame looks:\n\n```\n   customer_id transaction_date  amount\n0           1      2023-01-15     100\n1           1      2023-01-20     50\n2           2      2023-01-25     200\n3           1      2023-02-01     150\n4           2      2023-02-15     300\n```\n\nIn order to do this, I need to define a function that computes the monthly spending and apply it to the DataFrame. \n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 1, 2],\n    'transaction_date': ['2023-01-15', '2023-01-20', '2023-01-25', '2023-02-01', '2023-02-15'],\n    'amount': [100, 50, 200, 150, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')\nresult = df.groupby(['customer_id', 'month'])['amount'].sum().reset_index(name='total_spending')\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing product descriptions in the following format:\nproduct_df = pd.DataFrame({'description':['Laptop - Intel i7 - 16GB RAM - 512GB SSD', \n                                           'Smartphone - Snapdragon 888 - 128GB Storage', \n                                           'Tablet - Apple M1 - 8GB RAM', \n                                           'Monitor - 27\" - 144Hz - 1ms Response']})\n\nI want to separate the description into columns 'product_type', 'processor', 'memory', and 'storage' where applicable. The final DataFrame should look like this:\n\n  product_type                processor     memory      storage\n0     Laptop                 Intel i7      16GB RAM    512GB SSD\n1   Smartphone             Snapdragon 888    128GB Storage   NaN\n2       Tablet                    Apple M1        8GB RAM           NaN\n3     Monitor                         NaN         NaN           NaN\n\nI've been trying to accomplish this by utilizing regular expressions to extract the necessary parts of the description, but I'm having difficulty structuring the logic to handle cases where certain components might be missing. Here's what I've come up with so far:\n\ndef extract_product_info(description: str) -> tuple:\n    # Extraction logic would go here\n    pass\n\nAny guidance on how to effectively implement this function and apply it to the DataFrame would be appreciated!\n\nA:\n<code>\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'description':['Laptop - Intel i7 - 16GB RAM - 512GB SSD', \n                                           'Smartphone - Snapdragon 888 - 128GB Storage', \n                                           'Tablet - Apple M1 - 8GB RAM', \n                                           'Monitor - 27\" - 144Hz - 1ms Response']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nimport re\n\ndef extract_product_info(description: str) -> tuple:\n    pattern = r'(?P<product_type>[\\w\\s]+) - (?P<processor>[\\w\\s]+(?:\\d+)?(?:\\s\\w+)?(?:\\s\\w+)?)?(?: - (?P<memory>\\d+\\s\\w+))?(?: - (?P<storage>[\\d\\w\\s]+))?'\n    match = re.match(pattern, description)\n    if match:\n        return match.group('product_type'), match.group('processor'), match.group('memory'), match.group('storage')\n    return None, None, None, None\n\nproduct_df[['product_type', 'processor', 'memory', 'storage']] = product_df['description'].apply(extract_product_info).apply(pd.Series)\ndf = product_df\n```"
  },
  {
    "input": "### Problem\nI am working with a 3D sparse tensor representing multiple batches of data in a machine learning application. The tensor, `X`, has a shape of (batch_size, depth, height, width), where many values are zeroes, and I want to extract a 2D sparse matrix from this tensor. Specifically, I need to obtain a sparse matrix containing non-zero values aggregated across the depth dimension for each (height, width) pair.\n\nGiven the 3D tensor input as a numpy array with some zero values, how can I create a sparse matrix representing the sum of non-zero values across the depth dimension while keeping the original (height, width) structure?\n\nExample input:\n```python\nimport numpy as np\nfrom scipy import sparse\n\nX = np.array([[[1, 0, 0], [0, 0, 2]],  # Batch 1\n               [[0, 3, 0], [0, 0, 0]],  # Batch 2\n               [[0, 0, 0], [1, 0, 0]],  # Batch 3\n               [[4, 0, 0], [0, 5, 6]]]) # Batch 4\n```\n\nYour task is to fill in the blank for the following code snippet to achieve the desired output:\n\nA:\n```python\ntensor = sparse.csr_matrix(X)\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = tensor.sum(axis=0).A\n```"
  },
  {
    "input": "Problem:\nI have a dataframe that contains user details with names and emails in a single column. The format of the column is \"Name (email@example.com)\". I want to separate the names and emails into two separate columns called 'name' and 'email'. \n\nThe dataframe looks like this:\n\n```\ndetails\n0  John Doe (john.doe@example.com)\n1  Jane Smith (jane.smith@example.com)\n2  Alice Johnson (alice.j@gmail.com)\n3  Bob Brown (bob.brown@mail.com)\n```\n\nHow can I achieve this separation using column operations in pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'details': ['John Doe (john.doe@example.com)', \n                               'Jane Smith (jane.smith@example.com)', \n                               'Alice Johnson (alice.j@gmail.com)', \n                               'Bob Brown (bob.brown@mail.com)']})\n</code>\ndf[['name', 'email']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['details'].str.extract(r'(.+?) \\((.+?)\\)')"
  },
  {
    "input": "Problem:\nI have been working with a sparse tensor in PyTorch that represents a 3D grid of data, where most of the values are zero. The tensor has a shape of (20, 30, 40), and I need to perform an operation to sum the non-zero elements across the first dimension (axis 0) while retaining the sparse structure. Additionally, I need to normalize the summed tensor by dividing by the number of non-zero elements along the first dimension, effectively creating an average for each (x, y) location in the grid. \n\nHere's how my sparse tensor looks:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 5, 8, 10], [1, 2, 3, 4], [5, 6, 7, 8]]),\n    values=torch.tensor([1.0, 2.0, 3.0, 4.0]), \n    size=(20, 30, 40)\n)\n```\n\nHow would I compute the normalized average tensor, ensuring the result remains sparse? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nnon_zero_count = sparse_tensor.coalesce().values().new_zeros(sparse_tensor.size()[1:])\nfor i in range(sparse_tensor.size(0)):\n    non_zero_count += (sparse_tensor[i].coalesce().values() != 0).sum(dim=0)\n\nsummed_tensor = sparse_tensor.sum(dim=0)\nnormalized_tensor = summed_tensor / non_zero_count.unsqueeze(0)\nresult = normalized_tensor.to_sparse()\n</code>\n```"
  },
  {
    "input": "Problem:\nI am working with a sparse matrix in Python using SciPy and I need to perform a matrix multiplication with another matrix. I have a sparse matrix named `A` of shape (5, 5) in COO format and a dense matrix `B` of shape (5, 3). I want to compute the resulting matrix `C` from the multiplication of `A` and `B`, while keeping `C` in CSR (Compressed Sparse Row) format, which is more efficient for arithmetic operations. Here is a snippet of my code:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Initialize a sparse matrix A in COO format\ndata = np.array([1, 2, 3])\nrow_indices = np.array([0, 2, 4])\ncol_indices = np.array([0, 2, 4])\nA = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n\n# Create a dense matrix B\nB = np.array([[1, 0, 2],\n              [0, 1, 0],\n              [3, 0, 1],\n              [0, 0, 0],\n              [1, 2, 0]])\n\n# Now, compute the result C\nC = ...\n```\n\nHow can I fill in the blank `C = ...` to get the result of `A` multiplied by `B` while ensuring `C` is in CSR format?",
    "output": "\n```python\nC = A.dot(B).tocsr()\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that contains daily temperature readings for a city over a span of two months. The DataFrame looks like this:\n\n```\n          date  temperature\n0   2023-01-01          30\n1   2023-01-02          32\n2   2023-01-03          31\n3   2023-01-04          29\n4   2023-01-05          33\n..         ...         ...\n57  2023-02-26          28\n58  2023-02-27          30\n59  2023-02-28          31\n```\n\nYou need to calculate the rolling average temperature over a 7-day window and format the result to include the date as `dd-MMM-YYYY`. The rolling average should be appended as a new column in the DataFrame and the output should display the date and the rolling average temperature.\n\nThe provided code initializes the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=59, freq='D'),\n        'temperature': [30, 32, 31, 29, 33, 28, 27, 26, 30, 32, 31, 29, 33, 28, 27, 26, \n                        30, 31, 32, 29, 30, 28, 27, 26, 30, 32, 29, 38, 28, 27, 32, \n                        36, 38, 37, 40, 35, 30, 28, 29, 30, 31, 28, 27, 29, 30, \n                        31, 28, 26, 30, 31, 29, 30, 28, 31, 28, 30, 31]} \n\ndf = pd.DataFrame(data)\n```\n\nWhat code should you use to create a new column `rolling_avg` in the DataFrame, which contains the rolling average temperature, formatted properly?\n\n```python\ndf['rolling_avg'] = ...\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=7).mean().round(2)\ndf['date'] = df['date'].dt.strftime('%d-%b-%Y')\n```"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.12.0. I have a dataset where each sample consists of a feature tensor and a label tensor, and I want to create a neural network model that predicts the label from the features. My model should take an input tensor of shape (batch_size, 10) and output a tensor of shape (batch_size, 2) representing class probabilities. I'm currently attempting to define my model and would like to know how to achieve the following:\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.linear1 = nn.Linear(10, 5)\n        self.linear2 = nn.Linear(5, 2)\n    \n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = self.___ # fill in this line to complete the forward pass\n        return x\n\nmodel = MyModel()\nprint(model)\n```\n\nWhat should I use in place of ___ to ensure that the output represents class probabilities?",
    "output": "\n```python\n        x = torch.softmax(self.linear2(x), dim=1)\n```"
  },
  {
    "input": "Problem:\nYou have collected daily temperature data for a city over the past two weeks, represented in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-10-01', '2023-10-02', '2023-10-03', '2023-10-04', '2023-10-05', \n             '2023-10-06', '2023-10-07', '2023-10-08', '2023-10-09', '2023-10-10', \n             '2023-10-11', '2023-10-12', '2023-10-13', '2023-10-14'],\n    'Temperature': [22, 21, 19, 24, 25, 23, 22, 20, 21, 19, 18, 22, 23, 26]\n}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])  # Converting 'Date' to datetime\n```\n\nYour goal is to compute the rolling average temperature over a 3-day window and add it as a new column called 'Rolling_Avg_Temp' in the DataFrame. Fill any missing values in the 'Rolling_Avg_Temp' column with the overall mean temperature from the 'Temperature' column.\n\nWrite the following line of code to fill in the blank, ensuring it addresses the requirements:\n\n```python\ndf['Rolling_Avg_Temp'] = df['Temperature'].rolling(window=3).mean().fillna(____)\n```\n",
    "output": "\n```python\ndf['Rolling_Avg_Temp'] = df['Temperature'].rolling(window=3).mean().fillna(df['Temperature'].mean())\n```"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple neural network using TensorFlow. You have a dataset consisting of two features and a binary label indicating whether an instance belongs to class 0 or class 1. After preprocessing your data, you obtain two tensors: `X` of shape (1000, 2) representing the features and `y` of shape (1000, 1) representing the labels. \n\nYou want to create a model that has one hidden layer with 10 units and uses the ReLU activation function. Following model instantiation, your goal is to compile the model with binary cross-entropy loss and the Adam optimizer.\n\nHere is your existing code:\n\n```python\nimport tensorflow as tf\n\n# Load your dataset\nX, y = load_data() \n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(10, activation='...'))  # Fill this blank\n```\n\nWhat should you put in place of the `...` to correctly define the activation function for the hidden layer? \n\nA:\n\n<code>\nmodel.add(tf.keras.layers.Dense(10, activation='...')) # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel.add(tf.keras.layers.Dense(10, activation='relu'))  # Fill this blank\n</code>"
  },
  {
    "input": "Problem:\nI'm working on a neural network using PyTorch to classify images. I have a batch of images represented as a tensor with shape `[batch_size, channels, height, width]`. My goal is to apply a 2D convolution operation to this tensor using PyTorch. Specifically, I want to use a kernel of size 3x3 and apply a stride of 1 with no padding. How can I achieve this?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\nbatch_size = 8\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\n\nconv_layer = nn.Conv2d(in_channels=channels, out_channels=16, kernel_size=3, stride=1, padding=0)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = conv_layer(images)  \n</code>"
  },
  {
    "input": "### Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, height, width, channels) and I want to normalize each image along the height and width dimensions (i.e., per image). Given that my tensor has a shape of (2, 4, 4, 3), how can I perform this normalization using TensorFlow and PyTorch?\n\nHere's an example tensor:\n\n```python\nimport torch\nimport tensorflow as tf\n\n# Example tensor for PyTorch\nt = torch.tensor([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n\n# Equivalent tensor for TensorFlow\nx = tf.constant([[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n                    [[1.3, 1.4, 1.5], [1.6, 1.7, 1.8], [1.9, 2.0, 2.1], [2.2, 2.3, 2.4]]],\n                   [[[2.5, 2.6, 2.7], [2.8, 2.9, 3.0], [3.1, 3.2, 3.3], [3.4, 3.5, 3.6]],\n                    [[3.7, 3.8, 3.9], [4.0, 4.1, 4.2], [4.3, 4.4, 4.5], [4.6, 4.7, 4.8]]]])\n```\n\nNormalize this tensor to have values between 0 and 1 for each image. Fill in the code to achieve this normalization for both TensorFlow and PyTorch.\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nimport tensorflow as tf\nt, x = load_data()\n```\nnormalized_t = ... # put solution in this variable for PyTorch\nnormalized_x = ... # put solution in this variable for TensorFlow\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\nnormalized_t = (t - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0]) / (t.max(dim=2, keepdim=True)[0].max(dim=3, keepdim=True)[0] - t.min(dim=2, keepdim=True)[0].min(dim=3, keepdim=True)[0])\nnormalized_x = (x - tf.reduce_min(x, axis=[1, 2], keepdims=True)) / (tf.reduce_max(x, axis=[1, 2], keepdims=True) - tf.reduce_min(x, axis=[1, 2], keepdims=True))\n```"
  },
  {
    "input": "Problem:\nI have a dataframe that contains sales data for different products over several months. The dataframe includes columns for 'Product', 'Month', and 'Sales'. I want to create a function that calculates the total sales for each product across all months and returns a new dataframe with 'Product' and 'Total_Sales' columns. \n\nHere\u2019s a snippet of the dataframe:\n```\nProduct   Month   Sales\nA        January   100\nA        February  150\nB        January   200\nB        February  250\nC        January   300\n```\n\nHow can I achieve this using a custom function? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'Product': ['A', 'A', 'B', 'B', 'C'],\n    'Month': ['January', 'February', 'January', 'February', 'January'],\n    'Sales': [100, 150, 200, 250, 300]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef calculate_total_sales(df):\n    total_sales = df.groupby('Product')['Sales'].sum().reset_index()\n    total_sales.columns = ['Product', 'Total_Sales']\n    return total_sales\n\nresult = calculate_total_sales(df)\n```"
  },
  {
    "input": "Problem:\nI have a time series DataFrame containing daily temperature readings for a city over a year, indexed by date. I want to calculate a rolling average temperature over the last 7 days for each date. After calculating the rolling average, I want to create a new DataFrame that contains only the dates where the rolling average was above a specified threshold. The DataFrame is defined as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(start='2023-01-01', periods=365)\ntemperatures = np.random.normal(loc=20, scale=5, size=len(dates))  # Average temperature around 20\u00b0C\ntemp_df = pd.DataFrame(data=temperatures, index=dates, columns=['Temperature'])\n```\n\nNow, I want to extract the dates where the rolling average is greater than a threshold of 22\u00b0C. To achieve this, I'm looking to complete the following code:\n\n```python\nrolling_avg = temp_df['Temperature'].rolling(window=7).mean()\nfiltered_dates = ... # put solution in this variable\n```\n",
    "output": "\n```python\nfiltered_dates = temp_df[rolling_avg > 22].index\n```"
  },
  {
    "input": "### Problem\nI have a dataset represented as a Pandas DataFrame containing a column with email addresses, and I want to extract the domain part from each email to create a new column called 'domain'. For example, if the email is 'user@example.com', the domain should be 'example.com'. \n\nHere is what my DataFrame looks like:\n\n```\n           email\n0  user1@gmail.com\n1  user2@yahoo.com\n2  user3@hotmail.com\n3  user4@outlook.com\n4  user5@company.org\n```\n\nHow can I achieve this? Here is my current attempt to create the new column:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'email': ['user1@gmail.com', 'user2@yahoo.com', \n                             'user3@hotmail.com', 'user4@outlook.com', \n                             'user5@company.org']})\n```\n\nI want to fill in the blank for this line in my code to extract the domain:\n```python\ndf['domain'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['domain'] = df['email'].str.split('@').str[1]\n```"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple feedforward neural network using both TensorFlow and PyTorch. The input to your model is a tensor of shape (batch_size, 10) representing features. You want to create a model that predicts a single output value for regression tasks. First, you need to define the model in TensorFlow. After that, you will define the same model in PyTorch.\n\nHere\u2019s a template for the TensorFlow model definition. Please fill in the blank to define the model properly:\n\n```python\nimport tensorflow as tf\n\ndef create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(10,)),\n        # Fill in this blank to add a Dense layer with 64 units and ReLU activation\n        ...\n        tf.keras.layers.Dense(1)\n    ])\n    return model\n```\n\nA:\n<code>\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntf.keras.layers.Dense(64, activation='relu')\n</code>"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a neural network model using TensorFlow and PyTorch to classify images from the CIFAR-10 dataset. You have preprocessed the dataset and created a 4D tensor `images_tensor` of shape (num_samples, 32, 32, 3), and the corresponding labels in a 1D tensor `labels_tensor`. Your neural network model should expect input of this shape. \n\nAfter defining your model architecture using TensorFlow, you want to obtain the model's predictions, which will yield a 2D tensor where each row represents the predicted class probabilities for an input image. You need to extract the predicted class index (the class with the highest probability) for each image into a 1D tensor.\n\nHow would you achieve this in TensorFlow?\n\nA:\n\n<code>\nimport tensorflow as tf\n\n# Assuming images_tensor and labels_tensor are already defined\nmodel = ...  # define your model architecture here\npredictions = model(images_tensor)  \npredicted_classes = ...  # put solution in this variable\n### BEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = tf.argmax(predictions, axis=1)\n</code>"
  },
  {
    "input": "## Problem:\nYou have a time series data containing daily stock prices for multiple companies in a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': pd.date_range(start='2020-01-01', periods=10),\n        'CompanyA': [100, 102, 101, 103, 105, 107, 106, 108, 110, 111],\n        'CompanyB': [200, 198, 202, 201, 203, 205, 206, 204, 207, 203],\n        'CompanyC': [300, 303, 301, 299, 298, 300, 302, 303, 305, 306]}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nYour task is to calculate the daily percentage change of each company's stock prices relative to their previous day's closing prices. You want to save this as a new DataFrame. \n\nProvide the code to achieve this, filling in the blank below:\n\n```python\nresult = df.______\n```\n",
    "output": "\n```python\nresult = df.pct_change() * 100\n```"
  },
  {
    "input": "Problem:\nI have a time series data set containing daily temperature readings for a month. The data is represented as a pandas DataFrame with a `Date` column and a `Temperature` column. I want to compute a new column `7_day_avg` that contains the average temperature of the past 7 days for each entry, while handling the first 6 days where there aren't enough previous entries for a full 7-day average (you can set those values to NaN). \n\nHere is an example of my DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'Temperature': np.random.randint(low=-10, high=35, size=30)\n}\ndf = pd.DataFrame(data)\n```\n\nWhat is the code to calculate the `7_day_avg` column in this DataFrame? Fill in the blank below:\n\nA:\n<code>\ndf['7_day_avg'] = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing daily sales data for a retail store. The 'Date' column is the index and the 'Sales' column records the daily sales figures:\n\n```python\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2022-01-01', periods=30, freq='D'),\n    'Sales': [120, 135, 150, 160, 110, 130, 145, 155, 170, 180, 200, 190, 210, 220, 230, 225, 240, 230, 215, 205, 201, 199, 210, 220, 230, 240, 250, 245, 240, 235, 250]\n})\ndf.set_index('Date', inplace=True)\n```\n\nYou want to calculate the rolling average of sales over a 7-day window and store this in a new column named '7-day Avg'. What should you fill in the blank below to achieve this?\n\n```python\ndf['7-day Avg'] = ...\n```",
    "output": "\n```python\ndf['7-day Avg'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing daily weather data with a timestamp index, including the high and low temperatures for each day:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Temperature_High': [30, 32, 31, 34, 35],\n    'Temperature_Low': [20, 21, 19, 22, 23]\n}\ndates = pd.date_range(start='2023-01-01', periods=len(data['Temperature_High']), freq='D')\ndf = pd.DataFrame(data, index=dates)\n```\n\nNow, you want to calculate the daily temperature range (high minus low) and create a new column named `Temperature_Range` in the DataFrame to hold these values. What code would you use to achieve this?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df['Temperature_High'] - df['Temperature_Low']\ndf['Temperature_Range'] = result\n```"
  },
  {
    "input": "Problem:\n\nI'm working with a dataset where I need to preprocess the images into a normalized format for training a neural network using TensorFlow. The images are represented as a 4D tensor with the shape [batch_size, height, width, channels]. I want to normalize the pixel values of these images to be in the range [0, 1]. For this, I need to divide all pixel values by 255. \n\nGiven a tensor representing a batch of images:\n\n```python\nimages = tf.constant([[[[0, 128, 255], [255, 128, 0]], \n                        [[0, 255, 128], [128, 0, 255]]],\n                       \n                       [[[128, 0, 255], [255, 255, 0]], \n                        [[255, 128, 128], [0, 0, 0]]]])\n```\n\nHow can I normalize this tensor so that the pixel values are in the range [0, 1]?\n\nA:\n```python\nimport tensorflow as tf\n\nimages = tf.constant([[[[0, 128, 255], [255, 128, 0]], \n                        [[0, 255, 128], [128, 0, 255]]],\n                       \n                       [[[128, 0, 255], [255, 255, 0]], \n                        [[255, 128, 128], [0, 0, 0]]]])\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nnormalized_images = images / 255.0\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse tensor in PyTorch that represents a 3D grid of size (10, 10, 10), where most of the elements are zeros. You need to extract the non-zero elements from this sparse tensor and their corresponding indices in a sparse format. \n\nHere is how you have initialized the sparse tensor:\n\n<code>\nimport torch\n\n# Create a sparse tensor with random non-zero elements\nindices = torch.tensor([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\nvalues = torch.tensor([5.0, 3.0, 1.0, 4.0, 2.0])\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size=(10, 10, 10))\n</code>\n\nUsing this sparse tensor, fill in the blank for the code that extracts the non-zero values and their indices:\n\nA:\n\n<code>\nnon_zero_values, non_zero_indices = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnon_zero_values = sparse_tensor.values()\nnon_zero_indices = sparse_tensor.indices()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix of shape (5, 5) represented in COO format, filled with random integers. I want to convert this sparse matrix to a dense NumPy array and then extract the diagonal elements as a 1D array. Here's the sparse matrix I created:\n\n```\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\n\nGiven the `sparse_matrix`, please provide the code to obtain the diagonal elements in a 1D NumPy array.\n\nA:\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.random.randint(1, 10, size=8)\nrow_indices = np.random.choice(5, size=8)\ncol_indices = np.random.choice(5, size=8)\nsparse_matrix = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n```\ndiagonal_elements = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndiagonal_elements = sparse_matrix.toarray().diagonal()\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains monthly sales data for a retail store as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': ['2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06'],\n    'Sales': [200, 150, 300, 250, 400, 350]\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to calculate the month-over-month percentage change in sales and add this as a new column called 'Percentage Change'. The first row will be marked as NaN (Not a Number) since there is no previous month to compare it to. \n\nThe desired output should look like this:\n\n```\n     Month  Sales  Percentage Change\n0  2021-01    200                 NaN\n1  2021-02    150                -25.0\n2  2021-03    300                100.0\n3  2021-04    250                -16.67\n4  2021-05    400                60.0\n5  2021-06    350                -12.5\n```\n\nI need help with the following code:\n\n```python\ndf['Percentage Change'] = df['Sales'].pct_change() * 100\n```\n\nPlease fill in the blank to apply this in the context of the given DataFrame. \nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df\ndf['Percentage Change'] = df['Sales'].pct_change() * 100\n```"
  },
  {
    "input": "## Problem:\nYou have a DataFrame containing daily sales data for a retail store over a year. The DataFrame has two columns: 'Date' in the format 'YYYY-MM-DD' and 'Sales' indicating the total sales for that day. You need to compute the rolling 7-day average of sales to understand weekly performance.\n\nHere is a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2022-01-01', periods=12, freq='D'),\n    'Sales': [200, 220, 250, 270, 290, 300, 330, 360, 400, 420, 450, 480]\n}\ndf = pd.DataFrame(data)\n```\n\nYour task is to fill in the blank to create a new column in the DataFrame called '7-day Average' that computes the rolling mean of the 'Sales' column over a 7-day window.\n\nA:\n```python\ndf['7-day Average'] = ...\n```",
    "output": "\n```python\ndf['7-day Average'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame with a column of addresses that look like this:\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n\nI want to extract the city and state from each address and create separate columns for them. If the address does not contain a state, I want the state column to be None.\n\nThe final DataFrame should look like this:\n\naddress                     city          state\n0 123 Main St, Springfield, IL  Springfield            IL\n1 456 Elm St, Gotham City, NY  Gotham City            NY\n2 789 Oak St, Metropolis, CA  Metropolis            CA\n3 101 Maple Ave, Star City, TX  Star City            TX\n\nI've attempted to use string manipulation to achieve this, but I'm unsure how to split and extract the components correctly. Can you help me get this working?\n\nA:\n<code>\nimport pandas as pd\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n</code>\naddress_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\naddress_df[['city', 'state']] = address_df['address'].str.extract(r',\\s*([^,]+),\\s*([A-Z]{2})$')\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have a pandas DataFrame containing product descriptions like the one shown below:\n```python\nproduct_df = pd.DataFrame({'description': ['Red Apples 1kg - Fresh and juicy', \n                                           'Green Grapes 500g - Sweet and tangy', \n                                           'Bananas Great Quality 1.5kg',\n                                           'Oranges 2lbs - Tangy citrus fruits']})\n```\nYou would like to extract the product type (the first word) and the weight (the value followed by \"kg\" or \"g\" or \"lbs\") from the description and create two new columns: 'product_type' and 'weight'.\n\nThe expected resulting DataFrame should look like this:\n```\n    description                                   product_type   weight\n0  Red Apples 1kg - Fresh and juicy                  Red         1kg\n1  Green Grapes 500g - Sweet and tangy               Green       500g\n2  Bananas Great Quality 1.5kg                        Bananas     1.5kg\n3  Oranges 2lbs - Tangy citrus fruits                 Oranges     2lbs\n```\n\nYou have attempted to use the `str.extract` method but are unsure about the correct regex to capture both the product type and weight. Here is where you need help.\n\nProvide the solution code that will generate the required DataFrame with the new columns. Please put your solution in the variable `result`.\n\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'description': ['Red Apples 1kg - Fresh and juicy', \n                                           'Green Grapes 500g - Sweet and tangy', \n                                           'Bananas Great Quality 1.5kg',\n                                           'Oranges 2lbs - Tangy citrus fruits']})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = product_df.assign(\n    product_type=product_df['description'].str.extract(r'(\\w+)'),\n    weight=product_df['description'].str.extract(r'(\\d*\\.?\\d+\\s*(?:kg|g|lbs))')\n)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily sales data of a product as follows:\n\n```\n   date        sales\n0  2023-01-01   100\n1  2023-01-02   150\n2  2023-01-03   200\n3  2023-01-04   250\n4  2023-01-05   300\n```\n\nI want to calculate the rolling average of sales over a 3-day window. The resulting DataFrame should have the same index as the original DataFrame, and the rolling average values should be aligned with the last date of each window.\n\nHow can I achieve this in Python? \n\nHere's the initial DataFrame setup:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=5, freq='D'),\n    'sales': [100, 150, 200, 250, 300]\n}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\n\nI would like the output to look like this:\n\n```\n             sales  rolling_avg\ndate                         \n2023-01-01   100          NaN\n2023-01-02   150          NaN\n2023-01-03   200        150.0\n2023-01-04   250        200.0\n2023-01-05   300        250.0\n```\n\nYour task is to fill in the blank below with the code to calculate the rolling average.\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.assign(rolling_avg=df['sales'].rolling(window=3).mean())\n```"
  },
  {
    "input": "Problem:\n\nI'm working with TensorFlow 2.10.0 and have two tensors: `data` with shape (64, 20, 128) and `weights` with shape (128, 10). I want to perform a batched matrix multiplication that results in a tensor with shape (64, 20, 10). How can I achieve this?\n\nHere is my current code setup:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ndata = tf.constant(np.random.rand(64, 20, 128), dtype=tf.float32)\nweights = tf.constant(np.random.rand(128, 10), dtype=tf.float32)\n```\n\nHow can I complete the operation? \n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = tf.matmul(data, weights)  # Perform batched matrix multiplication\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\nYou are working with a sparse tensor to perform a multi-label classification task, where each row of your data can belong to multiple classes represented as a sparse tensor. Given a sparse tensor `sparse_tensor` with shape (3, 5, 4) that has non-zero elements indicating the presence of classes, how can you efficiently convert the sparse tensor to a dense version that reflects the presence or absence of each class per sample? \n\nHere's a sample of how the sparse tensor is defined in TensorFlow:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.sparse.SparseTensor(\n    indices=[[0, 0, 1], [1, 2, 3], [2, 4, 0]],\n    values=[1, 1, 1],\n    dense_shape=[3, 5, 4]\n)\n```\n\nYou need to fill in the following statement to convert it to a dense tensor:\n\n```python\ndense_tensor = ...  # put solution in this variable\n```\nEnsure that the resulting dense tensor should correctly reflect which classes are present for each data point.",
    "output": "\n```python\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix representing user interactions with items, where the entries are ratings (and can include zeros for no interaction). The matrix is of shape (1000, 500) and is in CSR format. I want to create a new matrix where each entry corresponds to the maximum rating for each item across multiple users, ignoring zeros (which represent no interaction). What is the best way to achieve this without converting to a dense format, and how would I go about extracting this information into a new zero-based sparse matrix of shape (1, 500)?\n\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\n\n# Assume 'user_item_matrix' is a sparse matrix of shape (1000, 500)\nuser_item_matrix = sparse.csr_matrix(np.random.randint(0, 6, (1000, 500)))  # Example sparse matrix with ratings from 0 to 5\n</code>\nmax_rating_per_item = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_rating_per_item = sparse.csr_matrix(user_item_matrix.max(axis=0).A.reshape(1, -1))\n</code>"
  },
  {
    "input": "Problem:\n\nI'm working with a dataset of images in TensorFlow, and I need to preprocess them by normalizing the pixel values to the range [0, 1]. The original pixel values in the images range from 0 to 255. I have a tensor containing the image data, and I want to apply normalization across all the images at once. Given a tensor `images` of shape (batch_size, height, width, channels), how do I normalize it?\n\nA:\n<code>\nimport tensorflow as tf\n\nimages = load_data()\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_images = images / 255.0\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse tensor representation of a 3D grid where many of the elements are zero. This tensor is represented in the COO format using the `scipy.sparse` module. My goal is to efficiently compute the sum of all non-zero elements in this tensor without converting it into a dense format, as it would consume too much memory.\n\nThe tensor has been initialized and populated as follows:\n\n```python\nimport numpy as np\nfrom scipy import sparse\n\n# Randomly generating sparse tensor coordinates and values\ncoords = np.array([[0, 1, 2], [0, 2, 1], [1, 0, 2], [1, 1, 1], [2, 0, 0]])\nvalues = np.array([1, 2, 3, 4, 5])\nsparse_tensor = sparse.coo_matrix((values, (coords[:, 0], coords[:, 1], coords[:, 2])), shape=(3, 3, 3))\n```\n\nHow can I compute the sum of all non-zero values in this sparse tensor using the appropriate method from `scipy`?\n\nA:\n```python\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\nsum_non_zero = sparse_tensor.sum()\n</code>\n```"
  },
  {
    "input": "### Problem:\nYou have a DataFrame that contains a list of customer feedback comments and their ratings. Each comment may have additional notes that you want to extract. The feedback has a specific format where each comment follows the structure: \"Comment: {text} | Note: {note}\". You want to extract the notes and create a new column in your DataFrame for those notes.\n\nGiven the following DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'Feedback': [\n        'Comment: Great service! | Note: Quick delivery',\n        'Comment: Not satisfied | Note: Late arrival',\n        'Comment: Decent experience | Note: Could be better',\n        'Comment: Excellent | Note: Will recommend',\n        'Comment: Poor quality | Note: Did not meet expectations'\n    ]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the blank code below to create a new column `Extracted_Note` that holds only the note part from the `Feedback` column.\n\nA:\n```python\ndf['Extracted_Note'] = df['Feedback'].str.extract(r'\\| Note: (.*)')\n```",
    "output": "\n```python\ndf['Extracted_Note'] = df['Feedback'].str.extract(r'\\| Note: (.+)')\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix representing user interactions in a recommendation system. The matrix is stored as a list of tuples, with each tuple containing the row index, column index, and the value (indicating the interaction score). Your task is to convert this sparse representation into a dense matrix using NumPy. Specifically, given a sparse matrix in the form of `sparse_data = [(0, 1, 5), (1, 0, 3), (2, 2, 2)]`, which indicates that user 0 interacted with item 1 with a score of 5, user 1 with item 0 with a score of 3, and user 2 with item 2 with a score of 2, how can you represent this as a dense matrix of shape (3, 3)?\n\nA:\n\n<code>\nimport numpy as np\nsparse_data = load_data()\ndef solve(sparse_data):\n    # return the solution in this function\n    # dense_matrix = solve(sparse_data)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    dense_matrix = np.zeros((3, 3))\n    for row, col, value in sparse_data:\n        dense_matrix[row, col] = value\n    return dense_matrix\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset that records daily sales of a product over several months. The data is organized in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=60, freq='D'),\n        'sales': np.random.poisson(lam=200, size=60)}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\n\nYou want to calculate a moving average of the sales data over a 7-day window. However, you also want to exclude the moving average for days where the sales count is below 150. Fill in the blank with the correct code to create a new column in the DataFrame that contains the desired moving average, ensuring that it doesn't include values below 150:\n\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean() # fill in this code to apply the condition\n```\n\nWhat code would replace the `# fill in this code to apply the condition` comment? \n\nA:\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean().where(df['sales'] >= 150)\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].where(df['sales'] >= 150).rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nI have a time series dataframe containing daily temperature readings for a city, structured like this:\n\n```\ndate         temperature\n2023-01-01   5.0\n2023-01-02   6.5\n2023-01-03   7.0\n2023-01-04   4.5\n2023-01-05   6.0\n```\n\nI want to calculate the rolling average temperature over a 3-day window. However, I also want the first two rows to be left as `NaN` since there are insufficient previous days to calculate the average for those dates. I tried using the `pandas.DataFrame.rolling()` function, but I'm not sure how to implement this correctly.\n\nHere is my setup:\n\n```python\nimport pandas as pd\n\ndata = {'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n        'temperature': [5.0, 6.5, 7.0, 4.5, 6.0]}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n```\n\nI want to replace the following line to calculate the rolling average:\n\n```python\ndf['rolling_avg'] = ...\n```\n\nPlease put the solution in the `...` variable.",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=3, min_periods=3).mean()\n```"
  },
  {
    "input": "Problem:\nI am working with a sparse tensor in PyTorch, and I need to compute the element-wise sum of two sparse tensors. I have two sparse tensors t1 and t2, and I want to get a new sparse tensor that retains the sparsity while summing the elements.\n\nHere are the sparse tensors I'm starting with:\nt1 = torch.sparse_coo_tensor([[0, 1], [2, 0]], [3, 4], size=(3, 3))\nt2 = torch.sparse_coo_tensor([[1, 2], [2, 1]], [5, 6], size=(3, 3))\n\nWhat is the proper way to perform this element-wise addition while ensuring the result is still a sparse tensor? \n\nA:\n```python\nimport torch\n\nt1 = torch.sparse_coo_tensor([[0, 1], [2, 0]], [3, 4], size=(3, 3))\nt2 = torch.sparse_coo_tensor([[1, 2], [2, 1]], [5, 6], size=(3, 3))\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = t1 + t2\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset containing timestamps and sales transactions in a DataFrame:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   100\n1 2023-01-01 10:05:00   150\n2 2023-01-01 10:10:00   200\n3 2023-01-01 10:15:00   50\n4 2023-01-01 10:20:00   300\n5 2023-01-01 10:40:00   120\n6 2023-01-01 10:50:00   180\n7 2023-01-01 11:00:00   250\n```\n\nWhat I want to achieve is resampling this data to 15-minute intervals and calculating the sum of sales for each interval. If there are any intervals with no sales data, they should still appear in the final output with a sales value of 0.\n\nThe desired output format should look like this:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   450\n1 2023-01-01 10:15:00   0\n2 2023-01-01 10:30:00   0\n3 2023-01-01 10:45:00   180\n4 2023-01-01 11:00:00   250\n```\n\nHere's the starting point of the code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': ['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:10:00', \n                  '2023-01-01 10:15:00', '2023-01-01 10:20:00', '2023-01-01 10:40:00', \n                  '2023-01-01 10:50:00', '2023-01-01 11:00:00'],\n    'Sales': [100, 150, 200, 50, 300, 120, 180, 250]\n})\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYour task is to fill in the blank to complete the code for the resampling and summing of sales:\n\n```python\ndf.set_index('Timestamp', inplace=True)\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = df.resample('15T').sum().fillna(0).reset_index()\ndf['Sales'] = df['Sales'].astype(int)\n```"
  },
  {
    "input": "Problem:\nI have a dataset that contains product reviews in a DataFrame. Each review is a string of text in a column named \"review\". I want to extract the product names mentioned at the beginning of each review, which are always followed by the keyword \"reviewed\". However, the reviews may also contain punctuation or multiple spaces. For example:\n\n| review                       |\n|------------------------------|\n| \"ProductA reviewed this item ...\" |\n| \"ProductB     reviewed it ...\"  |\n| \"An excellent experience with ProductC reviewed\" |\n\nI need to create a new column called \"product_name\" that contains just the product names extracted from the reviews.\n\nHere is how my DataFrame looks:\n\n```python\ndf = pd.DataFrame({\n    'review': [\n        \"ProductA reviewed this item ...\",\n        \"ProductB     reviewed it ...\",\n        \"An excellent experience with ProductC reviewed\"\n    ]\n})\n```\n\nI am struggling to implement this extraction correctly. Can you help me fill in the missing piece of code here?\n\n---\n\ndf['product_name'] = df['review'].str.extract(r'^\\s*(.*?)\\s+reviewed')\n\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df['product_name']\n```"
  },
  {
    "input": "Problem:\nI have a sparse 3D tensor represented as a dictionary of coordinates in the format: `{(i, j, k): value}` where `i`, `j`, and `k` correspond to the indices of the tensor and `value` is the value at that position. I need to convert this dictionary representation into a sparse tensor format using `scipy.sparse`. Given the following tensor representation:\n\n```python\nimport numpy as np\nfrom scipy import sparse\n\nsparse_dict = {\n    (0, 0, 0): 1,\n    (1, 2, 0): 2,\n    (3, 1, 1): 3\n}\n```\n\nHow can I create a compressed sparse row (CSR) representation of this tensor while keeping the 3D structure?\n\nA:\n```python\nimport numpy as np\nfrom scipy import sparse\n\nsparse_dict = {\n    (0, 0, 0): 1,\n    (1, 2, 0): 2,\n    (3, 1, 1): 3\n}\n# shape of the tensor\nshape = (4, 3, 2)\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\n    coords = np.array(list(sparse_dict.keys()))\n    values = np.array(list(sparse_dict.values()))\n    result = sparse.coo_matrix((values, (coords[:, 0], coords[:, 1], coords[:, 2])), shape=shape).tocsr()\nEND SOLUTION\n```"
  },
  {
    "input": "## Problem:\n\nSuppose you are working with a sparse tensor representing user interactions on a website, where each slice of the tensor represents a different month. Your tensor `user_interactions` is in the form of a 3D sparse tensor with dimensions `[num_users, num_pages, num_months]`. There are many users and pages, but most interactions are zero, making it sparse.\n\nYou need to calculate the total number of interactions for each user across all months and return it as a 2D dense array with the shape `[num_users, 1]`.\n\nYou can use the `torch.sparse` functionality to handle the sparse tensor. \n\nHere's a snippet where `user_interactions` is defined as a sparse tensor. How can you compute the total interactions for each user and store the result in a variable named `total_interactions`?\n\n```python\nimport torch\n\n# Create a sparse tensor representing user interactions\nuser_interactions = torch.sparse.FloatTensor(\n    torch.LongTensor([[0, 1, 2], [0, 1, 2]]),  # Indices for non-zero interactions\n    torch.FloatTensor([5, 10, 3]),             # Corresponding interaction values\n    torch.Size([3, 4, 2])                       # Shape: 3 users, 4 pages, 2 months\n)\n\n# Total interactions initialization\ntotal_interactions = ... # put solution in this variable\n```",
    "output": "\n```python\ntotal_interactions = user_interactions.sum(dim=(1, 2)).to_dense().view(-1, 1)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing product descriptions, and I want to extract the brand name and product type from a \"description\" column. The descriptions follow the format \"Brand: [brand name], Type: [product type]\". I would like to create two new columns: \"brand\" and \"type\" filled with the corresponding values.\n\nHere's the DataFrame I have:\n```python\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\n\nWhat is the correct code to parse the \"description\" column and create the new \"brand\" and \"type\" columns?\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({\n    'description': [\n        'Brand: Nike, Type: Shoes',\n        'Brand: Apple, Type: Phone',\n        'Brand: Samsung, Type: Tablet',\n        'Brand: Sony, Type: Headphones'\n    ]\n})\n```\nproduct_df[['brand', 'type']] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nproduct_df[['brand', 'type']] = product_df['description'].str.extract(r'Brand: (.*?), Type: (.*)')\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing student scores across various subjects. I would like to create a function that takes the DataFrame as input and returns a new DataFrame including the average score for each student, but only for those subjects where they have scored above a specified threshold.\n\nFor example, given a DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Student': ['Alice', 'Bob', 'Charlie', 'David'],\n    'Math': [88, 56, 73, 90],\n    'Science': [92, 65, 78, 85],\n    'English': [85, 100, 61, 72]\n})\n```\n\nI would like to call a function `average_scores(df, threshold)` which will filter the scores based on the threshold (let's say 70) and calculate the average for each student, resulting in a DataFrame like this:\n\n```\n   Student  Average Score\n0    Alice             88.33\n1      Bob             82.50\n2  Charlie             78.50\n3    David             85.00\n```\n\nHow can I implement this function to achieve the desired result? \n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Student': ['Alice', 'Bob', 'Charlie', 'David'],\n    'Math': [88, 56, 73, 90],\n    'Science': [92, 65, 78, 85],\n    'English': [85, 100, 61, 72]\n})\n```\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef average_scores(df, threshold):\n    filtered_df = df.loc[:, df.columns != 'Student'].gt(threshold)\n    averages = df.loc[:, df.columns != 'Student'][filtered_df].mean(axis=1)\n    return pd.DataFrame({'Student': df['Student'], 'Average Score': averages})\n\nresult = average_scores(df, 70)\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix represented as a dictionary of tuples in a data science context, where the keys are tuples representing the coordinates of non-zero elements and the values are the corresponding non-zero values. I need to convert this sparse matrix into a dense form using NumPy.\n\nFor example, if my sparse matrix is given as follows:\n\nsparse_matrix = {\n    (0, 1): 3,\n    (1, 0): 2,\n    (1, 2): 5,\n    (2, 2): 1\n}\n\nI want to create a dense 3x3 matrix that looks like this:\n\n[[0, 3, 0],\n [2, 0, 5],\n [0, 0, 1]]\n\nHow can I achieve this transformation?\n\nTo implement this, start with the following code:\n\n```python\nimport numpy as np\n\nsparse_matrix = {\n    (0, 1): 3,\n    (1, 0): 2,\n    (1, 2): 5,\n    (2, 2): 1\n}\n```\n\ndense_matrix = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndense_matrix = np.zeros((3, 3))\nfor (i, j), value in sparse_matrix.items():\n    dense_matrix[i, j] = value\n```"
  },
  {
    "input": "## Problem\n\nYou are tasked with training a simple neural network using both TensorFlow and PyTorch to classify images of handwritten digits (from the MNIST dataset). You need to preprocess the images by normalizing the pixel values to the range [0, 1] and then create a model that consists of one hidden layer with 128 neurons and a ReLU activation function. Finally, you will compile and train the model using the Adam optimizer and categorical crossentropy loss.\n\nGiven a TensorFlow and PyTorch setup, you have the following variable declarations:\n\n```python\nimport tensorflow as tf\nimport torch\nfrom torchvision import datasets, transforms\n\n# TensorFlow part\ntrain_images = tf.keras.datasets.mnist.load_data()[0][0]\nnormalized_images_tf = train_images.astype('float32') / 255.0\n\n# PyTorch part\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_images_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\nYou need to define the model architecture and the training process in TensorFlow:\n\n```python\nmodel_tf = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```\n\nYour task is to fill in the training code for the TensorFlow model to fit the normalized_images_tf. Please provide the code snippet that goes in the blank below:\n\n```python\nmodel_tf.fit(_____, epochs=5)\n```",
    "output": "\n```python\nnormalized_labels_tf = tf.keras.datasets.mnist.load_data()[0][1]\nmodel_tf.fit(normalized_images_tf, normalized_labels_tf, epochs=5)\n```"
  },
  {
    "input": "Problem:\n\nI have a large 2D sparse matrix representing a user-item interaction dataset where each row corresponds to a user, and each column corresponds to an item. The interaction is stored in a compressed sparse row (CSR) format using `scipy`. I want to normalize the non-zero values of this matrix so that they sum to 1 for each user. \n\nGiven a `csr_matrix` of shape (N, M), I want to create a new `csr_matrix` where each user's ratings are normalized. Essentially, for every user (row), the promised transformation will be:\n\n`normalized[user, item] = original[user, item] / sum(original[user, :])`\n\nWhat is the efficient way to perform this operation without fully converting the sparse matrix to a dense format?\n\nA:\n<code>\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\n# Simulating user-item interaction data\nN, M = 1000, 5000 \ndata = np.random.rand(50000)\nrow_indices = np.random.randint(0, N, size=50000)\ncol_indices = np.random.randint(0, M, size=50000)\n\n# Creating a sparse matrix in CSR format\noriginal = csr_matrix((data, (row_indices, col_indices)), shape=(N, M))\n</code>\nnormalized = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized = original.multiply(1 / np.array(original.sum(axis=1)).flatten())"
  },
  {
    "input": "Problem:\nI have a time series dataset in a DataFrame with two columns: \"Timestamp\" and \"Temperature\". The \"Timestamp\" column contains timestamps at minute intervals and the \"Temperature\" column contains temperature readings in Celsius. I need to calculate the rolling average temperature over a 5-minute window and create a new column \"Rolling_Avg\" to store these averages.\n\nHere is the initial DataFrame:\n\n```\n  Timestamp           Temperature\n0 2023-10-01 00:00:00      20.3\n1 2023-10-01 00:01:00      21.0\n2 2023-10-01 00:02:00      20.8\n3 2023-10-01 00:03:00      19.9\n4 2023-10-01 00:04:00      20.1\n5 2023-10-01 00:05:00      20.6\n6 2023-10-01 00:06:00      21.2\n7 2023-10-01 00:07:00      21.1\n8 2023-10-01 00:08:00      20.8\n9 2023-10-01 00:09:00      20.5\n```\n\nYou can achieve this with a rolling average function. Here's how you can fill in the blank for the creation of the \"Rolling_Avg\" column:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': pd.date_range(start='2023-10-01', periods=10, freq='T'),\n    'Temperature': [20.3, 21.0, 20.8, 19.9, 20.1, 20.6, 21.2, 21.1, 20.8, 20.5]\n})\n\ndf['Rolling_Avg'] = ...\n```\n\ndf = ... # put solution in this variable  \nBEGIN SOLUTION\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window='5T').mean()\n</code>",
    "output": "\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window='5T').mean()\n</code>"
  },
  {
    "input": "Problem:\n\nI'm working with a sparse tensor representation of a dataset, where each entry corresponds to a count of some event in a 3D space (e.g., time, user ID, and item ID). The tensor is initialized to zero, and I receive updates in the form of a list of tuples that indicate which indices to increment.\n\nSuppose I have a 3D sparse tensor initialized with size (5, 5, 5) and I receive an update list as follows:\n\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n\nI want to update the tensor so that each specified index in the updates list has its count incremented by 1.\n\nHow can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\nsparse_tensor = torch.zeros((5, 5, 5))\nupdates = [(0, 1, 2), (1, 0, 3), (1, 1, 1), (4, 4, 4)]\n</code>\nsparse_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfor update in updates:\n    sparse_tensor[update] += 1\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains information about various products, including their categories and prices. I want to categorize products into price ranges (e.g., 'cheap', 'moderate', 'expensive') based on their price. The categorization should be defined as follows: prices less than 10 are 'cheap', prices between 10 and 100 are 'moderate', and prices greater than 100 are 'expensive'. I would like to create a new column `price_category` that reflects this categorization.\n\nFor example:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['apple', 'banana', 'carrot', 'dragonfruit', 'eggplant'],\n    'price': [1.5, 25, 5, 120, 45]\n})\n```\n\nThe desired output should look like this:\n```python\n   product  price price_category\n0    apple    1.5          cheap\n1   banana   25.0       moderate\n2   carrot    5.0          cheap\n3 dragonfruit 120.0      expensive\n4 eggplant   45.0       moderate\n```\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['apple', 'banana', 'carrot', 'dragonfruit', 'eggplant'],\n    'price': [1.5, 25, 5, 120, 45]\n})\n```\ndf['price_category'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndf['price_category'] = pd.cut(df['price'], bins=[-float('inf'), 10, 100, float('inf')], labels=['cheap', 'moderate', 'expensive'])\n```"
  },
  {
    "input": "Problem:\n\nYou have a sparse tensor representing a collection of images in a batch of size `10`, each with a height of `32` pixels, width of `32` pixels, and `3` color channels. The tensor uses a coordinate format and has only a few values set. You want to replace all values in this tensor that are below a certain threshold (e.g., `0.5`) with a set value, `1.0`.\n\nGiven your sparse tensor and threshold, how can you fill in the gaps with `1.0` for all elements below this threshold without modifying the existing values above the threshold?\n\nYour starting code looks like this:\n\n```python\nimport torch\n\nsparse_tensor = torch.sparse.FloatTensor(\n    torch.tensor([[0, 0, 1], [1, 2, 3]]), \n    torch.tensor([0.1, 0.8, 0.4, 0.7])\n)\nthreshold = 0.5\n```\n\nYou need to fill the sparse tensor. \n\nPlease complete the following line of code to achieve this:\n\n```python\nfilled_tensor = ... # put solution in this variable\n```",
    "output": "\n```python\nfilled_tensor = sparse_tensor.to_dense().clamp(min=threshold).masked_fill(sparse_tensor.to_dense() < threshold, 1.0)\n```"
  },
  {
    "input": "Problem:\nYou are analyzing daily stock prices recorded in a pandas DataFrame, and you want to compute the percentage change in closing prices from one day to the next. However, if the closing price was zero on a given day, the percentage change should be set to NaN for that day to avoid division by zero. Additionally, you want to drop any rows that contain NaN values after calculating the percentage change.\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n    'Close': [150, 0, 155, 160, 0]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n```\n\nHow can you calculate the percentage change in 'Close' prices and drop NaN values in a single line of code?\n\nA:\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df['Close'].replace(0, pd.NA).pct_change().dropna()\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset with daily sales figures for a retail store, structured like this:\n\n```\n                 Sales\nDate               \n2023-01-01     150\n2023-01-02     200\n2023-01-03     100\n2023-01-04     180\n2023-01-05     220\n```\n\nNow, I want to calculate a rolling 3-day average of the sales data to smooth out the daily fluctuations. I've attempted to use the `.rolling()` method to achieve this, but I'm not sure how to fill in the gap for the rolling average right. \n\nHere is the initial code I have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Sales': [150, 200, 100, 180, 220]\n}\nindex = pd.date_range(start='2023-01-01', periods=len(data['Sales']))\ndf = pd.DataFrame(data, index=index)\n\n# Calculate the rolling average\nrolling_avg = df['Sales'].______ # put solution in this variable\n```\n\nWhat should I put in the blank to calculate the rolling average?",
    "output": "\n```python\nrolling_avg = df['Sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nIn a time series forecasting project using TensorFlow, you have a dataset containing daily temperatures over a year, represented as a 365 x 1 tensor. You are tasked with building a simple LSTM model to predict the next day's temperature based on the previous five days' temperatures. After preparing your dataset, you pass the data through the LSTM layers and obtain output predictions stored in a tensor of shape [num_samples, 1]. \n\nNow, you want to compute the root mean square error (RMSE) of your predictions compared to the actual temperatures which are stored in a tensor of the same shape. The formula for RMSE is:\n\n\\[ \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2} \\]\n\nWhere \\( y_i \\) are the actual values and \\( \\hat{y_i} \\) are the predicted values. \n\nYou have already defined your predictions and actual values like this:\n\n```python\nimport tensorflow as tf\n\npredictions = tf.constant([...], shape=(365, 1))\nactuals = tf.constant([...], shape=(365, 1))\n```\n\nWhat code can be used to compute the RMSE and store the result in a variable named `rmse`?\n\nA:\n```python\nrmse = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nrmse = tf.sqrt(tf.reduce_mean(tf.square(actuals - predictions)))\n```"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix representing the features of a set of textual documents, where each row corresponds to a document and each column corresponds to a unique word. The entries of the matrix are counts of how many times each word appears in each document. Additionally, I have a list of word indices that I want to extract from the matrix into a new dense matrix. \n\nGiven the sparse matrix `X` (in the form of a COO format) and a list of word indices `word_indices`, how can I create a dense matrix `D` that retains only the columns indicated by `word_indices`? The shape of `D` should be `(num_documents, len(word_indices))`.\n\nFor instance, if `X` is defined as:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\n```\n\nAnd the `word_indices` is `[0, 2]`, the desired output for `D` should look like this:\n\n```\n[[0 3]\n [2 0]]\n```\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Given sparse matrix X\ndata = np.array([1, 2, 3])  # the counts\nrow_indices = np.array([0, 1, 1])  # document indices\ncol_indices = np.array([1, 0, 2])  # word indices\n\nX = coo_matrix((data, (row_indices, col_indices)), shape=(2, 3))\nword_indices = [0, 2]  # List of indices to extract\n\n# Convert X to a dense format and extract necessary columns\nD = ... # put solution in this variable\n### BEGIN SOLUTION\n```",
    "output": "\n<code>\nD = X[:, word_indices].toarray()\n### END SOLUTION\n</code>"
  },
  {
    "input": "### Problem:\nI have a time series dataset represented in a Pandas DataFrame where the index is a datetime object. The DataFrame contains daily sales data for a store. I want to calculate a moving average of the sales over a 7-day window, and I also want to retain the original index format.\n\nHere is an example of the DataFrame structure:\n\n```\n             sales\ndate               \n2023-01-01    200\n2023-01-02    210\n2023-01-03    180\n2023-01-04    240\n2023-01-05    220\n2023-01-06    190\n2023-01-07    210\n2023-01-08    250\n2023-01-09    260\n2023-01-10    240\n```\n\nHow can I compute the moving average and save it in a new column named `moving_average` in the same DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'sales': [200, 210, 180, 240, 220, 190, 210, 250, 260, 240]}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\ndf['moving_average'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\n\nYou are training a neural network model using TensorFlow and PyTorch interchangeably. After training a simple model in TensorFlow, you extract the weights and want to load them into a PyTorch model. Suppose the TensorFlow model weights are given as a NumPy array of the shape (128, 64) for a fully connected layer.\n\nHow can you convert this NumPy array into a PyTorch tensor and assign it directly to the weights of a PyTorch model's layer called `fc_layer`?\n\nA:\n```python\nimport torch\nimport numpy as np\ntf_weights = np.random.rand(128, 64)  # Example weights from TensorFlow model\nfc_layer = torch.nn.Linear(128, 64)\n```\nfc_layer.weight.data = ... # put solution in this variable\nBEGIN SOLUTION\n```python",
    "output": "\n```python\nfc_layer.weight.data = torch.from_numpy(tf_weights).float()\n```"
  },
  {
    "input": "Problem:\nI'm working with TensorFlow 2.9.0 to develop a simple neural network. I've prepared input data in the form of a tensor representing features of device usage, shaped as (1000, 10). I also have a corresponding labels tensor indicating the device state (0 or 1) for each usage sample, shaped as (1000, 1). My neural network has been defined, but I need to compile it with the Adam optimizer and binary cross-entropy loss.\n\nHere's my setup:\n\n<code>\nimport tensorflow as tf\n\n# Assuming model is defined\nmodel = tf.keras.Sequential([...])  # your model layers here\nlabels = tf.random.uniform((1000, 1), maxval=2, dtype=tf.int32)\nfeatures = tf.random.uniform((1000, 10))\n\n</code>\nmodel.compile(optimizer=..., loss=...) # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel.compile(optimizer='adam', loss='binary_crossentropy')"
  },
  {
    "input": "Problem:\n\nI have a tensor `data` representing grayscale image pixel values with shape `(batch_size, height, width)`. I want to normalize the pixel values of each image in the batch to the range [0, 1]. This can be done by subtracting the minimum value of each image from all its pixel values and dividing by the range (max - min) of the image. \n\nWrite the code that normalizes `data` using PyTorch.\n\nA:\n\n<code>\nimport torch\n\ndata = load_data()  # shape (batch_size, height, width)\n</code>\nnormalized_data = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = (data - data.min(dim=(1, 2), keepdim=True)[0]) / (data.max(dim=(1, 2), keepdim=True)[0] - data.min(dim=(1, 2), keepdim=True)[0])"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains daily temperature recordings as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n        'Temperature': [30, 32, None, 29, 31]}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the missing temperature value on '2023-01-03' by taking the average of the temperatures before and after it, rounding to the nearest whole number. Then, provide the DataFrame with the filled values in order of their dates.\n\nThe expected output should look like this:\n\n```python\n        Date  Temperature\n0 2023-01-01          30.0\n1 2023-01-02          32.0\n2 2023-01-03          30.0\n3 2023-01-05          29.0\n4 2023-01-06          31.0\n```\n\nYou are currently getting the DataFrame like this:\n```python\ndf['Temperature'].fillna(...) \n```\nFill in the blank to complete the code that accurately replaces the missing temperature value:\n\nresult = ...  # put solution in this variable",
    "output": "\n```python\nresult = df['Temperature'].fillna(round((df['Temperature'].shift(1) + df['Temperature'].shift(-1)) / 2))\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product information with a column of product codes that includes both letters and numbers, and I want to extract only the numeric part from these codes into a new column. Here\u2019s how my DataFrame looks:\n\n      Product_Code\n0     AB12345\n1     CD67890\n2     EF23456\n3     GH89012\n4     IJ34567\n\nI would like to achieve the following output:\n\n      Product_Code  Numeric_Code\n0     AB12345        12345\n1     CD67890        67890\n2     EF23456        23456\n3     GH89012        89012\n4     IJ34567        34567\n\nHow can I do this using the `str.extract` method in pandas to create the new column?\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'Product_Code': ['AB12345', 'CD67890', 'EF23456', 'GH89012', 'IJ34567']})\n</code>\ndf['Numeric_Code'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Numeric_Code'] = df['Product_Code'].str.extract('(\\d+)')"
  },
  {
    "input": "### Problem\nI have a dataset containing daily sales data for products over a year. The data is in a DataFrame with two columns: 'Date' and 'Sales'. I would like to analyze trends by calculating a rolling average of sales over the past 7 days for each day in the DataFrame. \n\nHere's an example of what the DataFrame looks like:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', \n             '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10'],\n    'Sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nI want to create a new column 'Rolling_Avg' that contains the 7-day rolling average of sales. The first 6 entries should be NaN since there aren't 7 days to calculate the average yet.\n\nPlease fill in the blank with the appropriate solution.\n\n```python\ndf['Rolling_Avg'] = ...\n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataframe containing various product descriptions, and I want to extract the numerical price values from these descriptions. The prices are written in a consistent format, for example, \"$25.99\" or \"Price: $100\". I want to create a new column in the dataframe that simply contains the price as a float, or NaN if no price is found in the description. \n\nHere is a sample dataframe:\n```\ndescription\n---------------------------\nBuy one get one free: Price: $15.99\nNew product launch! Only for $100.\nLimited time offer: $49.95\nNo price available here\n```\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'description': [\n        'Buy one get one free: Price: $15.99',\n        'New product launch! Only for $100.',\n        'Limited time offer: $49.95',\n        'No price available here'\n    ]\n})\n</code>\nprice_column = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nprice_column = df['description'].str.extract(r'(\\$[0-9]+(?:\\.[0-9]{2})?)')[0].replace({'\\$': ''}, regex=True).astype(float)"
  },
  {
    "input": "Problem:\nSuppose you have a pandas DataFrame that contains product reviews with metadata. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review_text': [\n        'I love the coffee! It is great, good smell.',\n        'The tea was okay, not the best, I prefer another brand.',\n        'Fantastic chocolate flavor, would definitely buy again!',\n        'I really disliked the texture and the taste.'\n    ],\n    'rating': [5, 3, 4, 1]\n})\n```\n\nYou want to extract keywords (nouns) from the review_text column and create a new column called keywords that concatenates these keywords using a comma as a separator. For this demonstration, you can consider keywords as the words with lengths greater than 3 characters. You can create a simple function to filter and join these keywords.\n\nHere's where you're stuck. You want to apply this custom keyword extraction function to each review and populate the keywords column accordingly.\n\n```python\ndef extract_keywords(text):\n    # Replace this comment with your logic to extract words longer than 3 characters\n    pass\n\ndf['keywords'] = df['review_text'].apply( ... ) # fill in the blank to complete the DataFrame modification\n```\n\nFill in the blank to complete the code that applies your function to the review_text and updates the keywords column in the DataFrame.",
    "output": "\n```python\ndef extract_keywords(text):\n    return ', '.join([word for word in text.split() if len(word) > 3])\n\ndf['keywords'] = df['review_text'].apply(extract_keywords)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of email addresses, and I need to extract the usernames (the part before the '@') and create a new column for them. Here's the DataFrame I have:\n\n```\n      Email\n0  john.doe@example.com\n1  jane.smith@website.org\n2  test.user123@gmail.com\n3  sample@domain.com\n```\n\nI want to create a new column called 'Username' that contains just the usernames extracted from the 'Email' column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Email': ['john.doe@example.com', 'jane.smith@website.org', 'test.user123@gmail.com', 'sample@domain.com']})\n</code>\ndf['Username'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Username'] = df['Email'].str.split('@').str[0]"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset represented as a sparse tensor in PyTorch that contains sales data for multiple products across different stores. The tensor has the shape (10, 5, 3), which implies there are 10 stores, each selling 5 products with 3 types of sales data (e.g., online, in-store, wholesale). \n\nYou need to find the average sales data for each product across all stores and types. However, since the tensor is sparse, you want to utilize the `torch.sparse` functionality to compute the mean without converting it to a dense format.\n\nGiven the sparse tensor `sales_tensor`, how can you compute a new tensor `average_sales` of shape (5, 3), which contains the average sales data for each product across all stores?\n\nA:\n\n```python\nimport torch\n\nsales_tensor = load_data()  # Assume this loads a sparse tensor of shape (10, 5, 3)\n\naverage_sales = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\naverage_sales = torch.sparse.sum(sales_tensor, dim=0).to_dense() / torch.sparse.sum(sales_tensor != 0, dim=0).to_dense()\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing daily sales data of a retail store, with each row representing sales for a specific date. The DataFrame looks like this:\n\n```\n           Date     Sales\n0    2023-01-01    200\n1    2023-01-02    220\n2    2023-01-03    250\n3    2023-01-04    240\n4    2023-01-05    260\n5    2023-01-06    300\n```\n\nYou want to calculate the 3-day rolling average of sales, ensuring that the resulting DataFrame retains the original dates and fills in the rolling average where applicable. The first two rows should result in `NaN` since there aren't enough preceding values to compute the average.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],\n    'Sales': [200, 220, 250, 240, 260, 300]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\nrolling_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nrolling_avg = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse matrix representing user-item interactions in a recommendation system. The sparse matrix is defined using coordinate format (COO), and I need to construct a dense tensor that can be used for further calculations. Given three lists: `row_indices`, `col_indices`, and `data` which represent the non-zero entries of the sparse tensor, how can I create a 2D tensor of shape `(num_users, num_items)`? Here\u2019s how the inputs look:\n\n```python\nrow_indices = [0, 1, 2, 0, 1]\ncol_indices = [0, 1, 2, 2, 0]\ndata = [1, 2, 3, 4, 5]\n```\n\nThe expected output tensor should have zeros in the places without direct user-item interactions. Assuming `num_users` is 3 and `num_items` is 3, the resulting tensor should look like this:\n\n```\n[[1 0 4]\n [5 2 0]\n [0 0 3]]\n```\n\nA:\n<code>\nimport tensorflow as tf\n\nrow_indices = [0, 1, 2, 0, 1]\ncol_indices = [0, 1, 2, 2, 0]\ndata = [1, 2, 3, 4, 5]\nnum_users = 3\nnum_items = 3\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = tf.zeros((num_users, num_items), dtype=tf.int32)\nresult = tf.tensor_scatter_nd_update(result, tf.stack((row_indices, col_indices), axis=1), data)\n</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing various product reviews, and one of the columns is a string containing product details in the format \"Product_Name (Category) - Review_Score\". The DataFrame looks like this:\n\n```\n       Reviews\n0  Laptop (Electronics) - 5\n1  Coffee Maker (Home) - 4\n2  Phone (Electronics) - 3\n3  Blender (Home) - 5\n4  Camera (Electronics) - 4\n```\n\nI would like to separate the product name, category, and review score into three distinct columns named 'Product', 'Category', and 'Score'. How can I achieve this to transform my DataFrame into the following format?\n\n```\n      Product       Category  Score\n0      Laptop      Electronics     5\n1  Coffee Maker        Home         4\n2      Phone       Electronics     3\n3     Blender         Home         5\n4     Camera       Electronics     4\n```\n\nHere's my initial code, which only creates the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'Reviews': ['Laptop (Electronics) - 5', \n                    'Coffee Maker (Home) - 4', \n                    'Phone (Electronics) - 3', \n                    'Blender (Home) - 5', \n                    'Camera (Electronics) - 4']}\ndf = pd.DataFrame(data)\n```\n\nI need to fill in the blank for the transformation:\n\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>df[['Product', 'Category', 'Score']] = df['Reviews'].str.extract(r'(.+?) \\((.+?)\\) - (\\d+)')</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a 2D tensor where each row corresponds to a training example and each column corresponds to a feature. I want to build a simple feedforward neural network using TensorFlow and then train it on this dataset. The model should consist of one hidden layer with ReLU activation and an output layer with softmax activation. After defining the model, I need to compile it with categorical crossentropy loss and an Adam optimizer. \n\nHere is a simplified version of the code that establishes the tensor and defines the model up to the compilation step:\n\n```python\nimport tensorflow as tf\n\n# Example data: shape (num_examples, num_features)\nX_train = tf.constant([[0.1, 0.2], [0.2, 0.4], [0.3, 0.6]], dtype=tf.float32)\ny_train = tf.constant([[1, 0], [0, 1], [1, 0]], dtype=tf.float32) # One-hot encoded labels\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(2,))) \nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=...)\n```\n\nWhat should I place in the loss parameter to correctly set up the model for categorical classification?\n\nA:\n\n<code>\nmodel.compile(optimizer='adam', loss='...') \n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.compile(optimizer='adam', loss='categorical_crossentropy') \n</code>"
  },
  {
    "input": "Problem:\nI am working with a large sparse tensor that represents a multi-dimensional dataset. The tensor is in coordinate format (COO), and I want to convert it to a compressed sparse row (CSR) representation for efficient computation. My current tensor looks like this:\n\n```\nindices = [[0, 0, 1, 2, 2, 2],\n           [0, 2, 2, 0, 1, 2]]\nvalues = [3, 1, 2, 1, 4, 5]\nshape = (3, 3)\n```\n\nI need to convert it into a CSR format, and I want to store the result in a variable called `csr_tensor`. How can I achieve this using Scipy?\n\nA:\n<code>\nfrom scipy import sparse\n\nindices = [[0, 0, 1, 2, 2, 2],\n           [0, 2, 2, 0, 1, 2]]\nvalues = [3, 1, 2, 1, 4, 5]\nshape = (3, 3)\n</code>\ncsr_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncsr_tensor = sparse.coo_matrix((values, (indices[0], indices[1])), shape=shape).tocsr()\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains product descriptions in one of its columns. The descriptions sometimes include the brand name followed by the product name, and sometimes just the product name. Here is how the DataFrame looks:\n\n   description\n0  Nike Air Max 270\n1  Adidas Ultraboost\n2  Reebok Classic\n3  Puma RS-X\n\nI want to extract the brand name and the product name into two separate columns named \"brand\" and \"product\". The resulting DataFrame should look like this:\n\n   brand      product\n0  Nike      Air Max 270\n1  Adidas    Ultraboost\n2  Reebok    Classic\n3  Puma      RS-X\n\nHow can I achieve this? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({'description': ['Nike Air Max 270', 'Adidas Ultraboost', 'Reebok Classic', 'Puma RS-X']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['description'].str.extract(r'(?P<brand>^\\w+)\\s+(?P<product>.+)')"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing customer transaction data with columns for 'CustomerID', 'TransactionDate', and 'Amount'. I need to create a function that takes this DataFrame as input and returns a new DataFrame that includes each customer's total spending alongside their first transaction date, all while ensuring reusability for potential future analysis.\n\nThe DataFrame, df, looks like this:\n```\n   CustomerID TransactionDate  Amount\n0         101      2023-01-01   50.00\n1         102      2023-01-02   75.00\n2         101      2023-01-10  150.00\n3         103      2023-01-05  200.00\n4         102      2023-01-15   40.00\n```\n\nThe expected output for a function called `aggregate_transactions(df)` should yield:\n```\n   CustomerID FirstTransaction  TotalAmount\n0         101      2023-01-01        200.00\n1         102      2023-01-02        115.00\n2         103      2023-01-05        200.00\n```\n\nPlease define your function implementation below.\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'CustomerID': [101, 102, 101, 103, 102],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-10', '2023-01-05', '2023-01-15']),\n    'Amount': [50.00, 75.00, 150.00, 200.00, 40.00]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef aggregate_transactions(df):\n    aggregated = df.groupby('CustomerID').agg(\n        FirstTransaction=('TransactionDate', 'min'),\n        TotalAmount=('Amount', 'sum')\n    ).reset_index()\n    return aggregated\n</code>\nresult = aggregate_transactions(df)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset of images represented as a 4D tensor in PyTorch, where the shape is (batch_size, channels, height, width). I want to apply a normalization process such that each image (in the batch) is normalized independently based on its own mean and standard deviation.\n\nHow can I achieve this in PyTorch without using explicit loops?\n\nGiven a 4D tensor `images`, please provide the one-liner solution that normalizes each image across the channels dimension.\n\nExample input:\n```python\nimages = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]], \n                        [[0.5, 0.6], [0.7, 0.8]]],\n                       [[[0.9, 1.0], [1.1, 1.2]], \n                        [[1.3, 1.4], [1.5, 1.6]]]])\n```\n\nThe output should look like this, where each image is normalized:\n```python\nnormalized_images = ...\n```\n\nA:\n```python\nimport torch\nimages = torch.tensor([[[[0.1, 0.2], [0.3, 0.4]], \n                        [[0.5, 0.6], [0.7, 0.8]]],\n                       [[[0.9, 1.0], [1.1, 1.2]], \n                        [[1.3, 1.4], [1.5, 1.6]]]])\n```\nnormalized_images = ...  # put solution in this variable\nBEGIN SOLUTION\n```python\nnormalized_images = (images - images.mean(dim=(2, 3), keepdim=True)) / images.std(dim=(2, 3), keepdim=True)\n```",
    "output": "\n```python\nnormalized_images = (images - images.mean(dim=(1, 2), keepdim=True)) / images.std(dim=(1, 2), keepdim=True)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing columns with customer feedback where each feedback entry has a customer ID and a review message combined together in a single string. I would like to separate the customer ID and the review message into two different columns named 'Customer ID' and 'Review'. The current DataFrame looks like this:\n\n```\nfeedback\n0  101:Great service, loved the experience!\n1  102:Not satisfied, could be better.\n2  103:Excellent support, very helpful.\n3  104:Horrible experience, would not recommend.\n4  105:Decent food, but the service was slow.\n```\n\nI want to extract the numerical part (customer ID) and everything after the colon (the review message) into their respective new columns. How can I achieve that?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'feedback': ['101:Great service, loved the experience!', \n                                 '102:Not satisfied, could be better.', \n                                 '103:Excellent support, very helpful.', \n                                 '104:Horrible experience, would not recommend.', \n                                 '105:Decent food, but the service was slow.']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['Customer ID', 'Review']] = df['feedback'].str.split(':', expand=True)"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales of a product over several months, stored in a DataFrame with two columns: 'Date' and 'Sales'. The 'Date' column contains dates in the format 'YYYY-MM-DD', and the 'Sales' column contains the number of products sold on that date. \n\nI need to calculate a moving average of the sales over a 7-day window, ensuring that if there are any gaps in the dates (missing days), those entries are filled with NaN. The result should include the original date and the corresponding moving average in a new DataFrame.\n\nHere's how the DataFrame looks:\n\n```\n          Date    Sales\n0   2023-01-01      10\n1   2023-01-02      15\n2   2023-01-05      25\n3   2023-01-06      20\n4   2023-01-08      30\n5   2023-01-09      40\n```\n\nWhat I'm struggling with is how to properly apply the moving average while handling the missing dates. \nCan someone help me with the code to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Date': ['2023-01-01', '2023-01-02', '2023-01-05', '2023-01-06', '2023-01-08', '2023-01-09'],\n                   'Sales': [10, 15, 25, 20, 30, 40]})\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.set_index('Date').asfreq('D')  # Fill missing dates with NaN\nresult = df.assign(Moving_Average=df['Sales'].rolling(window=7).mean()).reset_index()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing user reviews of products, and I want to extract the star ratings embedded within the review strings. The reviews are structured as follows: \"Product A - \u2605\u2605\u2605\u2605\u2606 (4/5)\", \"Product B - \u2605\u2605\u2605\u2605\u2605 (5/5)\", etc. I want to create a new DataFrame column that contains only the numeric star ratings.\n\nHere\u2019s the DataFrame I started with:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review': [\"Product A - \u2605\u2605\u2605\u2605\u2606 (4/5)\", \"Product B - \u2605\u2605\u2605\u2605\u2605 (5/5)\", \"Product C - \u2605\u2605\u2605\u2606\u2606 (3/5)\"]\n})\n```\n\nHow can I extract just the numeric ratings (e.g., 4, 5, 3) into a new column called 'rating'?\n\nA:\n```python\ndf['rating'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['rating'] = df['review'].str.extract(r'(\\d)/5')[0].astype(int)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product information with mixed formatting in the 'product_name' column. Each product name may include extra spaces, inconsistent casing, and some variations in characters like hyphens and underscores. Here\u2019s the DataFrame I have:\n\n```python\nimport pandas as pd\n\ndata = {'product_name': ['  apple-juice ', 'Orange_JUICE', 'banAna', 'Grapes    ', '  Watermelon  ', 'kiwi  ']}\ndf = pd.DataFrame(data)\n```\n\nI want to normalize the 'product_name' column by:\n1. Stripping leading and trailing spaces.\n2. Converting the names to lowercase.\n3. Replacing any hyphens and underscores with spaces.\n\nThe expected output should retain a DataFrame with the normalized product names:\n\n| product_name |\n|--------------|\n| apple juice  |\n| orange juice |\n| banana       |\n| grapes       |\n| watermelon   |\n| kiwi         |\n\nWhat code should I fill in to transform the DataFrame as described above?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df['product_name'].str.strip().str.lower().str.replace('[-_]', ' ', regex=True)\n```"
  },
  {
    "input": "Problem:\nYou are working with a pandas dataframe containing several numerical columns representing the daily sales of different products. The dataframe is structured like this:\n\n```\n      product_A  product_B  product_C\ndate\n2023-01-01        20        10         15\n2023-01-02        25        30         20\n2023-01-03        30        20         25\n```\n\nYou need to calculate the percentage change in sales for each product over the specified period. To make your code reusable, define a function named `calculate_percentage_change` that takes a dataframe and a column name as input, and returns a new series containing the percentage change for that column.\n\nTo test your function, you can use this sample dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_A': [20, 25, 30],\n    'product_B': [10, 30, 20],\n    'product_C': [15, 20, 25]\n}, index=pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03']))\n```\n\nFill in the following blank with your function call to get the percentage change of 'product_A'.\n\n```python\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_percentage_change(df, column):\n    return df[column].pct_change() * 100\n\nresult = calculate_percentage_change(df, 'product_A')\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user interactions in a recommendation system using PyTorch. The sparse matrix is defined by its indices and values, such as:\n\n```python\nindices = torch.tensor([[0, 1, 1], [0, 2, 0]])\nvalues = torch.tensor([5.0, 3.0, 4.0])\n```\n\nThis signifies that user 0 interacted with item 0 with a score of 5.0, user 1 interacted with item 2 with a score of 3.0, and user 1 interacted with item 0 with a score of 4.0. \n\nHow can you construct a dense tensor `interaction_matrix` of shape (2, 3) from the sparse representation while filling the missing interactions with zeros?\n\nA:\n```python\nimport torch\n\nindices = torch.tensor([[0, 1, 1], [0, 2, 0]])\nvalues = torch.tensor([5.0, 3.0, 4.0])\n```\ninteraction_matrix = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ninteraction_matrix = torch.zeros((2, 3))\ninteraction_matrix[indices[0], indices[1]] = values\n```"
  },
  {
    "input": "Problem:\nI have a tensor representing image data, specifically for a batch of images in the format (batch_size, channels, height, width). I want to apply a basic thresholding operation to each image in the batch. The thresholding will set all pixel values below a certain threshold to zero and leave the others unchanged. I want to achieve this efficiently without converting to a numpy array. \n\nGiven a 4D tensor for the images and a specified threshold, how can I perform this operation directly on the tensor?\n\nFor example, if I have:\n\n```python\nimport torch \nimages = torch.rand((5, 3, 256, 256))  # 5 images, 3 channels, 256x256 pixels\nthreshold = 0.5\n```\n\nI want to apply the thresholding operation with:\n\n```python\nresult_tensor = ...\n```\n\nFill in the blank with the appropriate PyTorch operation to achieve this.",
    "output": "\n```python\nresult_tensor = images * (images >= threshold).float()\n```"
  },
  {
    "input": "Problem:\n\nI am working with a model that requires me to standardize the features of my input dataset before training. Given a tensor `data` of shape `(batch_size, num_features)`, I want to compute the standardized values by subtracting the mean and dividing by the standard deviation for each feature across all batches. How can I achieve this in both TensorFlow and PyTorch?\n\nBelow is the tensor data I have:\n\n```python\nimport numpy as np\nimport torch\nimport tensorflow as tf\n\ndata = np.array([[1.0, 2.0, 3.0],\n                 [4.0, 5.0, 6.0],\n                 [7.0, 8.0, 9.0]])\ndata_tensor_tf = tf.convert_to_tensor(data, dtype=tf.float32)\ndata_tensor_torch = torch.tensor(data, dtype=torch.float32)\n```\n\nTo get standardized data in TensorFlow, I would like to compute:\n\n```python\nmean_tf = ... \nstd_tf = ...\nstandardized_data_tf = (data_tensor_tf - mean_tf) / std_tf\n```\n\nIn PyTorch, I want to do the same:\n\n```python\nmean_torch = ... \nstd_torch = ...\nstandardized_data_torch = (data_tensor_torch - mean_torch) / std_torch\n```\n\nFill in the blanks for `mean_tf`, `std_tf`, `mean_torch`, and `std_torch` for both frameworks. \n\nA:\n\n<code>\nmean_tf = ... # put solution in this variable\nstd_tf = ... # put solution in this variable\nmean_torch = ... # put solution in this variable\nstd_torch = ... # put solution in this variable\n</code>",
    "output": "\n<code>\nmean_tf = tf.reduce_mean(data_tensor_tf, axis=0)\nstd_tf = tf.math.reduce_std(data_tensor_tf, axis=0)\nmean_torch = data_tensor_torch.mean(dim=0)\nstd_torch = data_tensor_torch.std(dim=0)\n</code>"
  },
  {
    "input": "Problem:\nYou are analyzing a time series of daily temperatures over a month. You have a DataFrame that records the date and temperature for each day, but there are some missing days. Your goal is to fill in the missing dates and impute the temperature on those dates with the average temperature of their neighboring dates. \n\nHere is the DataFrame you start with:\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05', '2023-01-07', '2023-01-08'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nYou need to expand the DataFrame to include all dates from `2023-01-01` to `2023-01-08`, filling the missing dates with the average temperature of their immediate neighbors.\n\nFill in the following line with the required code to achieve this:\n```python\nfilled_df = ... # insert your solution here\n```",
    "output": "\n```python\nfilled_df = df.set_index('date').reindex(pd.date_range(start='2023-01-01', end='2023-01-08')).interpolate(method='linear').reset_index()\n```"
  },
  {
    "input": "Problem:\nI have the following dataset containing transaction details:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'transaction_id': [1, 2, 1, 3, 2, 4, 5],\n    'amount': [100, 150, 100, 200, 150, 300, 400],\n    'transaction_date': ['2023-01-10', '2023-01-12', '2023-01-10', '2023-01-14', '2023-01-12', '2023-01-15', '2023-01-16']\n})\n```\n\nI want to summarize the total transaction amount for each unique transaction ID while preserving the details of the first occurrence of each transaction, along with the corresponding date. The expected output should retain the first transaction date for those duplicate IDs.\n\nWhat I tried:\n```python\nsummary = data.groupby('transaction_id').sum()  \n```\n\nThis approach does not provide me with the associated `transaction_date` of the first occurrence for each unique transaction ID.\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = data.groupby('transaction_id').agg({'amount': 'sum', 'transaction_date': 'first'}).reset_index()\n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset containing daily sales data for a retail store. The data frame looks like this:\n\n```\n        Date       Sales\n0  2023-01-01   150\n1  2023-01-02   200\n2  2023-01-03   250\n3  2023-01-04   300\n4  2023-01-05   100\n```\n\nYou want to calculate a 3-day moving average of sales and add it as a new column named 'Moving_Avg' in the data frame. You have already populated the `Date` column with datetime objects.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n        'Sales': [150, 200, 250, 300, 100]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\ndf['Moving_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['Moving_Avg'] = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for various products over several months:\n\n| product_id | month      | sales |\n|------------|------------|-------|\n| 1          | 2023-01   | 100   |\n| 1          | 2023-02   | 150   |\n| 1          | 2023-03   | 120   |\n| 2          | 2023-01   | 200   |\n| 2          | 2023-03   | 250   |\n| 3          | 2023-02   | 300   |\n| 3          | 2023-03   | 200   |\n\nI want to create a custom function that takes this DataFrame and generates a new DataFrame that shows the average monthly sales for each product. The resulting DataFrame should look like this:\n\n| product_id | average_sales |\n|------------|---------------|\n| 1          | 123.33        |\n| 2          | 225.00        |\n| 3          | 250.00        |\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 1, 2, 2, 3, 3],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-03', '2023-02', '2023-03'],\n    'sales': [100, 150, 120, 200, 250, 300, 200]\n}\ndf = pd.DataFrame(data)\n\ndef calculate_average_sales(df):\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    average_sales = df.groupby('product_id')['sales'].mean().reset_index()\n    average_sales.columns = ['product_id', 'average_sales']\n    return average_sales\n\nresult = calculate_average_sales(df)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing daily sales for different products, structured as follows:\n\n```python\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI want to analyze the sales data by filling in the missing dates for each product and ensuring that the `sales` value for those missing dates is set to zero. The desired output should retain the product column and include continuous dates, even for those with no sales recorded.\n\nHow can I achieve this? \n\nThe expected output should look like this:\n\n```\n        date product  sales\n0 2023-01-01       A    100\n1 2023-01-02       A    150\n2 2023-01-03       A      0\n3 2023-01-04       A      0\n4 2023-01-05       A    130\n5 2023-01-06       A      0\n6 2023-01-01       B      0\n7 2023-01-02       B      0\n8 2023-01-03       B    200\n9 2023-01-04       B      0\n10 2023-01-05       B      0\n11 2023-01-06       B    180\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05', '2023-01-06'],\n    'product': ['A', 'A', 'B', 'A', 'B'],\n    'sales': [100, 150, 200, 130, 180]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndate_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\nproducts = df['product'].unique()\ndf_full = pd.MultiIndex.from_product([date_range, products], names=['date', 'product']).to_frame(index=False)\ndf_full = df_full.merge(df, on=['date', 'product'], how='left').fillna(0)\ndf_full['sales'] = df_full['sales'].astype(int)\ndf = df_full.sort_values(by=['date', 'product']).reset_index(drop=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a list of employees with their worked hours over a week and I would like to calculate the total hours worked for each employee, but I need to implement a function that takes in a list of tuples where each tuple consists of an employee's name and their corresponding hours for the week. If an employee's total hours exceed 40, only record 40 hours as the maximum limit. I want the function to return a dictionary with the employee's name as the key and their total hours (capped at 40) as the value.\n\nFor example, given the following list:\n\n```python\nhours_list = [('Alice', 10), ('Bob', 20), ('Alice', 35), ('Bob', 25), ('Charlie', 20), ('Alice', 10)]\n```\n\nThe expected output should be:\n```python\n{'Alice': 40, 'Bob': 40, 'Charlie': 20}\n```\n\nYou need to fill in the blank with the appropriate function that processes this data.\n\nA:\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    # Your code goes here\n    return result\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef calculate_hours(hours_list):\n    result = {}\n    for name, hours in hours_list:\n        if name in result:\n            result[name] += hours\n        else:\n            result[name] = hours\n    for name in result:\n        if result[name] > 40:\n            result[name] = 40\n    return result\n</code>\nresult = calculate_hours(hours_list)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for different products across several months. I would like to create a custom function that computes the total sales for each product over a specified range of months. The DataFrame looks like this:\n\n```\n   Month  Product_A  Product_B  Product_C\n0      1         200        150        300\n1      2         250        200        350\n2      3         300        250        400\n3      4         350        300        450\n4      5         400        350        500\n```\n\nThe function should take the month range as input (e.g., from month 2 to month 4) and return the total sales for each product in that range. I want to call this function that I will define as `calculate_total_sales(df, start_month, end_month)`. Here\u2019s how you can initialize the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': [1, 2, 3, 4, 5],\n    'Product_A': [200, 250, 300, 350, 400],\n    'Product_B': [150, 200, 250, 300, 350],\n    'Product_C': [300, 350, 400, 450, 500]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, write the function call to compute the total sales from month 2 to month 4:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df, start_month, end_month):\n    filtered_df = df[(df['Month'] >= start_month) & (df['Month'] <= end_month)]\n    total_sales = filtered_df[['Product_A', 'Product_B', 'Product_C']].sum()\n    return total_sales\n\nresult = calculate_total_sales(df, 2, 4)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of strings where each string includes a person's full name in the format \"Last, First\". I want to split this column into two new columns: one for the first name and one for the last name. However, I noticed that some names also have a middle name or initial included, and I only want the first name to be extracted, regardless of its presence. \n\nHere\u2019s how my DataFrame looks:\n```\n    Names\n0  Smith, John A.\n1  Doe, Jane\n2  Johnson, Emily R.\n```\nI want to achieve a DataFrame that looks like this:\n```\n    First Name    Last Name\n0      John         Smith\n1      Jane         Doe\n2      Emily        Johnson\n```\nI have the following code, but I am struggling to properly extract the first and last names:\n```\ndf[['Last Name', 'First Name']] = df['Names'].str.split(',', expand=True)\n```\nThis splits the Last and First names but includes the middle name with the first name. How can I just get the first name?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Names': ['Smith, John A.', 'Doe, Jane', 'Johnson, Emily R.']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['Names'].str.split(',', expand=True)\nresult.columns = ['Last Name', 'First Name']\nresult['First Name'] = result['First Name'].str.split().str[0]\n</code>"
  },
  {
    "input": "Problem:\nI have a data frame that contains a column named 'full_address' with addresses in the format \"Street, City, State ZIP\". I want to extract the city and the ZIP code into separate columns named 'city' and 'zip_code'.\n\nMy dataframe `df` looks like this:\n\nfull_address\n0 123 Elm St, Springfield, IL 62704\n1 456 Maple Ave, Shelbyville, IN 46176\n2 789 Oak Dr, Capital City, CA 90210\n3 102 Pine Ct, Smallville, KS 67501\n4 111 Birch Blvd, Metropolis, NY 10001\n\nI am unsure how to use string manipulation to achieve this. I can create new columns but need help populating them with the correct extracted values.\n\ncity zip_code full_address\n0 Springfield 62704 123 Elm St, Springfield, IL 62704\n1 Shelbyville 46176 456 Maple Ave, Shelbyville, IN 46176\n2 Capital City 90210 789 Oak Dr, Capital City, CA 90210\n3 Smallville 67501 102 Pine Ct, Smallville, KS 67501\n4 Metropolis 10001 111 Birch Blvd, Metropolis, NY 10001\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'full_address': ['123 Elm St, Springfield, IL 62704', \n                                     '456 Maple Ave, Shelbyville, IN 46176',\n                                     '789 Oak Dr, Capital City, CA 90210',\n                                     '102 Pine Ct, Smallville, KS 67501',\n                                     '111 Birch Blvd, Metropolis, NY 10001']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['city', 'zip_code']] = df['full_address'].str.extract(r',\\s*(.*?),\\s*[A-Z]{2}\\s*(\\d{5})$')\n</code>"
  },
  {
    "input": "Problem:\nI am working with a time series dataset containing sales data for a retail store. The data is represented as a pandas DataFrame with a 'Date' column and a 'Sales' column. I would like to calculate the rolling mean of the sales over a specified window size and store the results in a new column called 'Rolling_Mean'. The rolling mean should not include any missing values. \n\nHere is a sample of the DataFrame before the operation:\n\n```\n        Date     Sales\n0 2023-01-01     100\n1 2023-01-02     150\n2 2023-01-03     200\n3 2023-01-04     250\n4 2023-01-05     300\n```\n\nFor a window size of 2, the result should look like this:\n\n```\n        Date     Sales  Rolling_Mean\n0 2023-01-01     100            NaN\n1 2023-01-02     150          125.0\n2 2023-01-03     200          175.0\n3 2023-01-04     250          225.0\n4 2023-01-05     300          275.0\n```\n\nStart with the following code snippet:\n\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Sales': [100, 150, 200, 250, 300]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\nwindow_size = 2\n</code>\ndf['Rolling_Mean'] = ... # put solution in this variable",
    "output": "\n<code>\ndf['Rolling_Mean'] = df['Sales'].rolling(window=window_size, min_periods=1).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame `df` containing daily sales data for multiple products as follows:\n\n```\n           Date       Product  Sales\n0    2023-01-01        A        100\n1    2023-01-01        B        150\n2    2023-01-01        C        200\n3    2023-01-02        A        120\n4    2023-01-02        B        140\n5    2023-01-02        C        210\n6    2023-01-03        A        115\n7    2023-01-03        B        130\n8    2023-01-03        C        230\n```\n\nI want to calculate the daily percentage change in sales for each product, and keep the first row for each product's percentage change as NaN. The expected output should look like this:\n\n```\n           Date       Product  Sales  Percentage_Change\n0    2023-01-01        A        100                NaN\n1    2023-01-01        B        150                NaN\n2    2023-01-01        C        200                NaN\n3    2023-01-02        A        120                0.20\n4    2023-01-02        B        140              -0.07\n5    2023-01-02        C        210                0.05\n6    2023-01-03        A        115              -0.04\n7    2023-01-03        B        130              -0.07\n8    2023-01-03        C        230                0.09\n```\n\nI have initialized the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01',\n             '2023-01-02', '2023-01-02', '2023-01-02',\n             '2023-01-03', '2023-01-03', '2023-01-03'],\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 120, 140, 210, 115, 130, 230]\n}\n\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the following line to calculate the daily percentage change in sales for each product:\n\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(...) \n```",
    "output": "\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(lambda x: x.pct_change())\n```"
  },
  {
    "input": "Problem:  \nI have a pandas dataframe that contains a column of email addresses. I would like to extract the domain name part from each email address while disregarding the subdomains (if any). The dataframe looks like this:\n\n| Email                      |\n|----------------------------|\n| john.doe@example.com       |\n| jane.smith@mail.co.uk      |\n| info@subdomain.domain.org   |\n| user123@yahoo.com          |\n| no-reply@service.global.com |\n\nI need to create a new column called 'Domain' that contains just the main domain (e.g., `example.com`, `mail.co.uk`, `domain.org`, `yahoo.com`, `global.com`) for each email address. I attempted using `.str.split()` with indexes but I'm having trouble getting just the relevant part.\n\nA:  \n```python\nimport pandas as pd\n\ndata = {'Email': ['john.doe@example.com',\n                  'jane.smith@mail.co.uk',\n                  'info@subdomain.domain.org',\n                  'user123@yahoo.com',\n                  'no-reply@service.global.com']}\ndf = pd.DataFrame(data)\n```  \ndf['Domain'] = ... # put solution in this variable  \nBEGIN SOLUTION  \n```python",
    "output": "\n```python\ndf['Domain'] = df['Email'].str.split('@').str[1].str.split('.').str[-2:].str.join('.')\n```"
  },
  {
    "input": "### Problem\nYou have a dataset with multiple sales records, and you want to calculate the total sales per product while ensuring that the code is reusable for any product. You have a DataFrame `df` that contains sales data structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 300, 250, 400, 150, 300, 350],\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a function `calculate_total_sales(product)` that takes a product name as input and returns the total sales for that product. \n\nYour current implementation to call the function looks like this:\n\n```python\ntotal_sales_A = calculate_total_sales('A')\n```\n\nWhat do you need to fill in for the function `calculate_total_sales` to achieve this? \n\n<!-- The variable to put your solution inside -->\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>",
    "output": "\n```python\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing product information as follows:\n```python\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nI want to extract the product name and price into two separate columns: `product_name` and `product_price`. The final DataFrame should look like this:\n```\n  product_name  product_price\n0        Apple          1.50\n1       Banana          0.75\n2       Cherry          3.00\n3         Date          2.50\n```\nI've attempted to use string splitting but it hasn't worked as intended. The column entries always include unwanted spaces. Please help me extract these values properly.\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nproduct_df[['product_name', 'product_price']] = product_df['product_info'].str.split(' - \\$', expand=True)\nproduct_df['product_price'] = product_df['product_price'].astype(float)\nproduct_df['product_name'] = product_df['product_name'].str.strip()\nproduct_df = product_df[['product_name', 'product_price']]\n</code>"
  },
  {
    "input": "Problem:\n\nI'm working with a sparse matrix in PyTorch, which represents a graph where the edges have weights. The matrix is in Compressed Sparse Row format and looks like this:\n\n```\nimport torch\nfrom torch_sparse import SparseTensor\n\nedge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])\nedge_weight = torch.tensor([1.0, 1.5, 2.0, 0.5])\nsparse_matrix = SparseTensor(row=edge_index[0], col=edge_index[1], value=edge_weight, sparse_sizes=(3, 3))\n```\n\nI want to compute the degree matrix of this graph, which is a diagonal matrix where each diagonal entry is the sum of the weights of the edges connected to each vertex. How can I create this degree matrix in PyTorch as a dense tensor?\n\nA:\n<code>\nimport torch\nfrom torch_sparse import SparseTensor\n\nedge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])\nedge_weight = torch.tensor([1.0, 1.5, 2.0, 0.5])\nsparse_matrix = SparseTensor(row=edge_index[0], col=edge_index[1], value=edge_weight, sparse_sizes=(3, 3))\n\ndef compute_degree_matrix(sparse_matrix):\n    # return the solution in this function\n    # degree_matrix = compute_degree_matrix(sparse_matrix)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    degree = sparse_matrix.sum(dim=1)\n    degree_matrix = torch.diag(degree)\n    return degree_matrix\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix representing customer purchase data, where each row corresponds to a customer and each column corresponds to a product. The matrix contains purchase counts, but many entries are zero (indicating no purchase). I want to normalize this matrix so that each row sums to 1 (i.e., each customer's purchases are represented as a proportion of their total purchases). If a row sums to zero, it should remain unchanged.\n\nHere is my sparse matrix:\n\n```python\nfrom scipy import sparse\npurchase_data = sparse.csr_matrix([[0, 0, 3], [0, 0, 0], [2, 0, 0], [0, 5, 0]])\n```\n\nI would like to achieve the normalization with the following code structure. \n\nnormalized_matrix = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nrow_sums = purchase_data.sum(axis=1).A1\nnormalized_matrix = purchase_data.copy()\nfor i in range(normalized_matrix.shape[0]):\n    if row_sums[i] > 0:\n        normalized_matrix[i] = normalized_matrix[i] / row_sums[i]\n</code>\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe containing customer data:\n\n```\ncustomer_info\n1   John Doe, 29, New York\n2   Jane Smith, 34, San Francisco\n3   Alice Johnson, 22, Boston\n4   Bob Brown, 45, Chicago\n```\n\nI need to split this `customer_info` column into three separate columns: `name`, `age`, and `city`. The final dataframe should look like this:\n\n```\n      name   age           city\n1  John Doe   29       New York\n2  Jane Smith 34  San Francisco\n3  Alice Johnson 22         Boston\n4  Bob Brown   45        Chicago\n```\n\nI tried to achieve this using the `str.split` method but I'm not getting the expected output. Here is the initial code I have:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'customer_info': ['John Doe, 29, New York', 'Jane Smith, 34, San Francisco', \n                                      'Alice Johnson, 22, Boston', 'Bob Brown, 45, Chicago']})\n```\n\nHow can I correctly extract and separate the name, age, and city into different columns? \n\nA:\n<code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['name', 'age', 'city']] = df['customer_info'].str.split(', ', expand=True)\ndf['age'] = df['age'].astype(int)\ndf = df.drop(columns=['customer_info'])\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing daily temperatures recorded in multiple cities. The data is structured as follows:\n\n```python\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'Chicago', 'Chicago'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'Temperature': [30, 75, 28, 73, 25, 22]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to compute the average temperature for each city across all recorded dates, outputting the result as a new data frame with two columns: 'City' and 'Average_Temperature'. \nThe expected result should look like this:\n\n```\n           City  Average_Temperature\n0      Chicago                  23.5\n1  Los Angeles                  74.0\n2     New York                  29.0\n```\n\nHere's a starting point:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'Chicago', 'Chicago'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'Temperature': [30, 75, 28, 73, 25, 22]\n}\ndf = pd.DataFrame(data)\n\n### Your answer should be stored in the variable 'result'\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('City', as_index=False)['Temperature'].mean().rename(columns={'Temperature': 'Average_Temperature'})\n```"
  },
  {
    "input": "Problem:\n\nI am working with a sparse matrix in Scipy and I want to extract the non-zero elements along with their corresponding row and column indices. Given a sparse matrix `A`, I need to create a list of tuples where each tuple contains the row index, column index, and the value of each non-zero element from the matrix. \n\nHere's what I have so far:\n\n```python\nfrom scipy import sparse\nA = sparse.csr_matrix([[0, 0, 3], [4, 0, 0], [0, 5, 6]])\n```\n\nI want to achieve an output that looks like this:\n\n```\n[(0, 2, 3), (1, 0, 4), (2, 1, 5), (2, 2, 6)]\n```\n\nWhat code can I use to accomplish this?\n\nA:\n<code>\nfrom scipy import sparse\n\nA = sparse.csr_matrix([[0, 0, 3], [4, 0, 0], [0, 5, 6]])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = [(i, j, A[i, j]) for i, j in zip(*A.nonzero())]"
  },
  {
    "input": "Problem:\nI have a list of temperatures recorded over a week in Celsius, and I want to convert these temperatures to Fahrenheit using a custom function. The conversion is done using the formula: Fahrenheit = (Celsius * 9/5) + 32. I need to apply this function to the entire list and return the converted list of temperatures. Here is what I have so far:\n\ntemperatures_celsius = [15, 22, 30, 10, 25, 28, 0]\n\ndef convert_to_fahrenheit(celsius):\n    # Conversion logic\n    \nfahrenheit_temperatures = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef convert_to_fahrenheit(celsius):\n    return (celsius * 9/5) + 32\n\nfahrenheit_temperatures = [convert_to_fahrenheit(temp) for temp in temperatures_celsius]\n</code>"
  },
  {
    "input": "Problem:\nI have a sparse matrix represented in coordinate format (COO) and I'm trying to convert it into a dense NumPy array while rearranging the non-zero values in a specific order. The sparse matrix is as follows:\n\n```\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\n```\n\nThis creates a sparse matrix where only the specified (row, col) pairs have non-zero values. I want to convert this sparse matrix into a dense 3x3 NumPy array in a way that the values appear in descending order of their row indices first, and if there are duplicates in the row indices, they should be sorted by their column indices. \n\nHow can I achieve this? \n\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\n# Create the sparse matrix\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\nsparse_matrix = coo_matrix((data, (row, col)), shape=(3, 3))\n</code>\ndense_array = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_array = np.zeros((3, 3))\nsorted_indices = sorted(zip(row, col, data), key=lambda x: (-x[0], x[1]))\nfor r, c, v in sorted_indices:\n    dense_array[r, c] = v\n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix in a Scipy environment, and you would like to efficiently find the non-zero elements and their indices. Let's say you have a sparse matrix `sparse_matrix` created using `scipy.sparse.csr_matrix`. You want to extract the indices of the non-zero elements in a way that they can be represented as a coordinate tensor. How can you achieve this?\n\nHere\u2019s a small snippet for context:\n\n```python\nfrom scipy.sparse import csr_matrix\nimport numpy as np\n\n# Sample sparse matrix\ndata = np.array([1, 2, 3, 4])\nrow_indices = np.array([0, 0, 1, 2])\ncol_indices = np.array([0, 2, 2, 1])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n```\n\nYou need to fill in the blank to extract the indices of the non-zero elements in `sparse_matrix`:\n\nnon_zero_indices = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>non_zero_indices = sparse_matrix.nonzero()</code>"
  },
  {
    "input": "Problem:\nI am working with a pandas DataFrame that contains sales data for a retail store. The DataFrame looks like this:\n\n```\nstore_id    sale_date      sale_amount\n1           2023-01-01     200.00\n1           2023-01-02     150.00\n1           2023-01-03     300.00\n2           2023-01-01     250.00\n2           2023-01-03     350.00\n2           2023-01-05     300.00\n```\n\nI want to calculate the rolling average of the `sale_amount` for each store over a window of 2 days but want to ensure that the rolling average includes only values from same store and looks like this:\n\n```\nstore_id    sale_date      sale_amount  rolling_avg\n1           2023-01-01     200.00       200.00\n1           2023-01-02     150.00       175.00\n1           2023-01-03     300.00       225.00\n2           2023-01-01     250.00       250.00\n2           2023-01-03     350.00       300.00\n2           2023-01-05     300.00       325.00\n```\n\nHow can I achieve this using pandas? \n\nHere is the code to create the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'store_id': [1, 1, 1, 2, 2, 2],\n    'sale_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03', '2023-01-05']),\n    'sale_amount': [200.00, 150.00, 300.00, 250.00, 350.00, 300.00]\n}\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['rolling_avg'] = df.groupby('store_id')['sale_amount'].apply(lambda x: x.rolling(window=2, min_periods=1).mean())\n```"
  }
]