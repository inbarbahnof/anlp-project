[
  {
    "input": "Problem:\nI'm working on a neural network using PyTorch to classify images. I have a batch of images represented as a tensor with shape `[batch_size, channels, height, width]`. My goal is to apply a 2D convolution operation to this tensor using PyTorch. Specifically, I want to use a kernel of size 3x3 and apply a stride of 1 with no padding. How can I achieve this?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\nbatch_size = 8\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\n\nconv_layer = nn.Conv2d(in_channels=channels, out_channels=16, kernel_size=3, stride=1, padding=0)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = conv_layer(images)  \n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame that contains sentences with various punctuation marks. The DataFrame looks like this:\n\n```python\nimport pandas as pd\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n```\n\nYour goal is to create a new column in the DataFrame that contains the number of punctuation marks found in each sentence. The final DataFrame should look like this:\n\n```\n                     sentences      punctuation_count\n0                  Hello, world!                     1\n1         Python is great; isn't it?                  3\n2          Let's code: Python is fun!                  3\n3      Data science; is changing the world.          4\n```\n\nTo accomplish this, I've started with the following approach using a lambda function to count the punctuation:\n\n```python\nimport string\ndf['punctuation_count'] = df['sentences'].apply(lambda x: ...)\n```\n\nPlease fill in the blank where the lambda function processes the `x` variable to return the count of punctuation marks. \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'sentences': [\"Hello, world!\", \"Python is great; isn't it?\", \"Let's code: Python is fun!\", \"Data science; is changing the world.\"]})\n</code>\ndf['punctuation_count'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n```python\ndf['punctuation_count'] = df['sentences'].apply(lambda x: sum(1 for char in x if char in string.punctuation))\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of sales transactions in a DataFrame format with columns including 'Transaction_ID', 'Date', 'Product', 'Quantity', and 'Total_Sale'. Here's a sample of your data:\n\n```\n   Transaction_ID       Date     Product  Quantity  Total_Sale\n0               1 2023-01-01    Apples        5        15.0\n1               2 2023-01-01   Oranges        3        6.0\n2               3 2023-01-02    Apples        2         6.0\n3               4 2023-01-02   Bananas        1         1.0\n4               5 2023-01-03   Oranges        4        12.0\n```\n\nYou would like to create a custom function that takes a DataFrame as input and a product name as a string. The function should output a DataFrame containing only the rows where the specified product was sold, along with a new column that calculates the sales amount (`Total_Sale / Quantity`) for each transaction.\n\nHere\u2019s the DataFrame you created:\n\n```\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Transaction_ID': [1, 2, 3, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'],\n    'Product': ['Apples', 'Oranges', 'Apples', 'Bananas', 'Oranges'],\n    'Quantity': [5, 3, 2, 1, 4],\n    'Total_Sale': [15.0, 6.0, 6.0, 1.0, 12.0]\n})\n```\n\nYou need to define your function as follows:\n```python\ndef filter_sales_by_product(df, product_name):\n    # Your code here\n```\n\ndf_filtered = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef filter_sales_by_product(df, product_name):\n    filtered_df = df[df['Product'] == product_name].copy()\n    filtered_df['Sales_Amount'] = filtered_df['Total_Sale'] / filtered_df['Quantity']\n    return filtered_df\n\ndf_filtered = filter_sales_by_product(df, 'Apples')\n```"
  },
  {
    "input": "Problem:\nI have a 3D sparse tensor stored in a sparse format (using `scipy.sparse`), where each non-zero entry represents a measurement from a sensor deployed in various locations over time. The tensor has the shape (num_sensors, num_locations, num_time_steps). However, I need to calculate the mean value for each sensor over all time steps, but without converting the entire tensor to a dense format due to memory constraints. \n\nHow can I efficiently compute the mean values for each sensor across all time steps, resulting in a 2D array of shape (num_sensors, num_locations) while retaining the sparse nature of the data?\n\nA:\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Create a 3D sparse tensor example\nnum_sensors = 4\nnum_locations = 3\nnum_time_steps = 5\ndata = np.random.rand(10)  # Random non-zero entries\nindices = np.random.randint(0, num_sensors, size=(10, 1)).flatten(), \\\n          np.random.randint(0, num_locations, size=(10, 1)).flatten(), \\\n          np.random.randint(0, num_time_steps, size=(10, 1)).flatten()\nsparse_tensor = sparse.COO(coords=indices, data=data, shape=(num_sensors, num_locations, num_time_steps))\n\n# Define the function to calculate mean over time steps\ndef compute_mean_over_time(sparse_tensor):\n    # return the solution in this function\n    # mean_values = compute_mean_over_time(sparse_tensor)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    mean_values = sparse_tensor.sum(axis=2).A / sparse_tensor.count(axis=2).A\n    return mean_values\n</code>"
  },
  {
    "input": "Problem:\nI'm working with a sparse tensor representation for a multi-dimensional dataset, where our data consists of customer purchases across different categories over several months. The shape of my sparse tensor is [30, 12, 5], which represents 30 customers, 12 months, and 5 product categories. I have a tensor containing the actual number of purchases for each customer in each category with the shape [30, 5]. The challenge is to populate the sparse tensor with the corresponding purchase values for each customer and category from the purchase tensor in a way that only the relevant entries are updated.\n\nThe sparse tensor is initialized as follows:\n\n```python\nimport tensorflow as tf\n\nsparse_tensor = tf.Variable(tf.zeros((30, 12, 5), dtype=tf.float32))\npurchase_tensor = tf.constant([[2, 0, 5, 3, 1],\n                                [0, 3, 0, 1, 0],\n                                [1, 1, 1, 1, 1], \n                                # ... (and so on for 30 customers)\n                               ])\n```\n\nHow do I fill `sparse_tensor` so that each customer's purchases only fill in their respective category across the months? For instance, for the first customer with purchase values `[2, 0, 5, 3, 1]`, we should populate the sparse tensor accordingly for the available months.\n\nThe specific code line to fill in is:\n\n```python\nsparse_tensor[...] = ...\n```",
    "output": "\n```python\nsparse_tensor[...] = tf.reshape(purchase_tensor, (30, 1, 5)) * tf.ones((1, 12, 1), dtype=tf.float32)\n```"
  },
  {
    "input": "Problem:\nI'm working with TensorFlow 2.9.0 to develop a simple neural network. I've prepared input data in the form of a tensor representing features of device usage, shaped as (1000, 10). I also have a corresponding labels tensor indicating the device state (0 or 1) for each usage sample, shaped as (1000, 1). My neural network has been defined, but I need to compile it with the Adam optimizer and binary cross-entropy loss.\n\nHere's my setup:\n\n<code>\nimport tensorflow as tf\n\n# Assuming model is defined\nmodel = tf.keras.Sequential([...])  # your model layers here\nlabels = tf.random.uniform((1000, 1), maxval=2, dtype=tf.int32)\nfeatures = tf.random.uniform((1000, 10))\n\n</code>\nmodel.compile(optimizer=..., loss=...) # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel.compile(optimizer='adam', loss='binary_crossentropy')"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing sales data from different stores over several months. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Store_ID': ['S001', 'S002', 'S001', 'S003', 'S002'],\n    'Month': ['January', 'January', 'February', 'February', 'March'],\n    'Sales': [200, np.nan, 150, 300, 250]\n})\n```\n\nYour task is to write a custom function that calculates the total sales for each store, ensuring that NaN values are ignored in the sum calculation. You should modify the DataFrame to include a new column called 'Total_Sales' that holds the calculated total for each unique Store_ID.\n\nExpected DataFrame after operation:\n```\n  Store_ID     Month  Sales  Total_Sales\n0     S001   January  200.0         350.0\n1     S002   January    NaN         250.0\n2     S001  February  150.0         350.0\n3     S003  February  300.0         300.0\n4     S002     March  250.0         250.0\n```\n\nA:\n```python\ndf['Total_Sales'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Total_Sales'] = df.groupby('Store_ID')['Sales'].transform(lambda x: x.sum(skipna=True))\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing daily temperatures recorded in multiple cities. The data is structured as follows:\n\n```python\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'Chicago', 'Chicago'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'Temperature': [30, 75, 28, 73, 25, 22]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to compute the average temperature for each city across all recorded dates, outputting the result as a new data frame with two columns: 'City' and 'Average_Temperature'. \nThe expected result should look like this:\n\n```\n           City  Average_Temperature\n0      Chicago                  23.5\n1  Los Angeles                  74.0\n2     New York                  29.0\n```\n\nHere's a starting point:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'Chicago', 'Chicago'],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'Temperature': [30, 75, 28, 73, 25, 22]\n}\ndf = pd.DataFrame(data)\n\n### Your answer should be stored in the variable 'result'\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('City', as_index=False)['Temperature'].mean().rename(columns={'Temperature': 'Average_Temperature'})\n```"
  },
  {
    "input": "Problem:\nI have a list of dictionaries containing sales data as follows:\n\nsales_data = [\n    {\"date\": \"2023-01-01\", \"product\": \"A\", \"amount\": 150},\n    {\"date\": \"2023-01-01\", \"product\": \"B\", \"amount\": 200},\n    {\"date\": \"2023-01-02\", \"product\": \"A\", \"amount\": 100},\n    {\"date\": \"2023-01-02\", \"product\": \"C\", \"amount\": 250},\n    {\"date\": \"2023-01-03\", \"product\": \"B\", \"amount\": 300},\n]\n\nI need to create a function that accepts this list and returns a dictionary summarizing the total sales amount for each product across all dates. The desired output dictionary should have products as keys and their total sales amount as values.\n\nFor the sales_data provided, the output should look like this:\n\n{\n    \"A\": 250,\n    \"B\": 500,\n    \"C\": 250\n}\n\nA:\n<code>\nsales_data = [\n    {\"date\": \"2023-01-01\", \"product\": \"A\", \"amount\": 150},\n    {\"date\": \"2023-01-01\", \"product\": \"B\", \"amount\": 200},\n    {\"date\": \"2023-01-02\", \"product\": \"A\", \"amount\": 100},\n    {\"date\": \"2023-01-02\", \"product\": \"C\", \"amount\": 250},\n    {\"date\": \"2023-01-03\", \"product\": \"B\", \"amount\": 300},\n]\n\ndef summarize_sales(data):\n    # return the solution in this function\n    pass\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef summarize_sales(data):\n    summary = {}\n    for entry in data:\n        product = entry[\"product\"]\n        amount = entry[\"amount\"]\n        if product in summary:\n            summary[product] += amount\n        else:\n            summary[product] = amount\n    return summary\n\nresult = summarize_sales(sales_data)\n```"
  },
  {
    "input": "## Problem:\nYou are working with a sparse tensor representation of a multi-dimensional dataset, where you have a tensor representing user reviews across different categories. You have a sparse representation of this tensor in the form of a COO matrix from the `scipy.sparse` module.\n\n```python\nfrom scipy.sparse import coo_matrix\n\ndata = [5, 10, 15, 20]\nrows = [0, 1, 1, 2]\ncols = [0, 1, 2, 0]\nsparse_tensor = coo_matrix((data, (rows, cols)), shape=(3, 3))\n```\n\nYou want to convert this sparse tensor to a dense format but are also interested in replacing any zero values in the resulting dense array with the number -1. How can you achieve that?\n\nA:\n<code>\nfrom scipy.sparse import coo_matrix\nimport numpy as np\n\ndata = [5, 10, 15, 20]\nrows = [0, 1, 1, 2]\ncols = [0, 1, 2]\nsparse_tensor = coo_matrix((data, (rows, cols)), shape=(3, 3))\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = sparse_tensor.toarray()\nresult[result == 0] = -1\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame `df` containing daily sales data for multiple products as follows:\n\n```\n           Date       Product  Sales\n0    2023-01-01        A        100\n1    2023-01-01        B        150\n2    2023-01-01        C        200\n3    2023-01-02        A        120\n4    2023-01-02        B        140\n5    2023-01-02        C        210\n6    2023-01-03        A        115\n7    2023-01-03        B        130\n8    2023-01-03        C        230\n```\n\nI want to calculate the daily percentage change in sales for each product, and keep the first row for each product's percentage change as NaN. The expected output should look like this:\n\n```\n           Date       Product  Sales  Percentage_Change\n0    2023-01-01        A        100                NaN\n1    2023-01-01        B        150                NaN\n2    2023-01-01        C        200                NaN\n3    2023-01-02        A        120                0.20\n4    2023-01-02        B        140              -0.07\n5    2023-01-02        C        210                0.05\n6    2023-01-03        A        115              -0.04\n7    2023-01-03        B        130              -0.07\n8    2023-01-03        C        230                0.09\n```\n\nI have initialized the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-01',\n             '2023-01-02', '2023-01-02', '2023-01-02',\n             '2023-01-03', '2023-01-03', '2023-01-03'],\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 120, 140, 210, 115, 130, 230]\n}\n\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the following line to calculate the daily percentage change in sales for each product:\n\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(...) \n```",
    "output": "\n```python\ndf['Percentage_Change'] = df.groupby('Product')['Sales'].apply(lambda x: x.pct_change())\n```"
  },
  {
    "input": "Problem:\nI have a dataframe with a column containing text containing URLs, and I want to extract just the domain names from those URLs. Here is the initial dataframe:\n\n  urls\n0 https://www.example.com/path/to/page\n1 http://subdomain.example.org\n2 https://www.test.com\n3 ftp://files.test.com/resource\n\nI want to transform this dataframe to only contain the domain names like this:\n\n  domain\n0 example.com\n1 example.org\n2 test.com\n3 files.test.com\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'urls': ['https://www.example.com/path/to/page', 'http://subdomain.example.org', 'https://www.test.com', 'ftp://files.test.com/resource']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['domain'] = df['urls'].str.extract(r'://(?:www\\.)?([^/]+)')[0]\ndf['domain'] = df['domain'].str.replace(r'^[^.]+\\.', '', regex=True)\ndf = df[['domain']]\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame containing sales data, that looks like this:\n\n```\n   Date       Sales\n0 2023-01-01     200\n1 2023-01-02     120\n2 2023-01-03     150\n3 2023-01-04     170\n4 2023-01-05     180\n```\n\nI want to calculate a 3-day moving average of the sales which will help to smooth out fluctuations. Can you help me implement a function `moving_average` that takes this DataFrame and returns a new DataFrame that includes a column for the moving average?\n\nHere\u2019s the starting code:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Sales': [200, 120, 150, 170, 180]\n}\ndf = pd.DataFrame(data)\n```\n\nThe resulting DataFrame should look like this:\n\n```\n   Date       Sales  Moving_Avg\n0 2023-01-01     200         NaN\n1 2023-01-02     120         NaN\n2 2023-01-03     150   156.666667\n3 2023-01-04     170   146.666667\n4 2023-01-05     180   166.666667\n```\n\nPlease fill in the blank in the following line to implement the required function:\n\n```python\ndef moving_average(df, window=3):\n    df['Moving_Avg'] = ...\n```\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef moving_average(df, window=3):\n    df['Moving_Avg'] = df['Sales'].rolling(window=window).mean()\n```"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.10.0.\nI have two tensors, one for features and another for labels, and I want to perform a linear regression using these tensors. The feature tensor has the shape (100, 1), and the label tensor has the shape (100,). \nHow can I define a simple linear regression model and compute the predictions for the features tensor?\n\nA:\n<code>\nimport torch\n\n# Define feature and label tensors\nfeatures = torch.randn(100, 1)\nlabels = torch.randn(100)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch.nn as nn\n\n# Define a simple linear regression model\nmodel = nn.Linear(1, 1)\n\n# Compute predictions\nresult = model(features)\n</code>"
  },
  {
    "input": "Problem:\nI have a time series dataset containing timestamps and sales transactions in a DataFrame:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   100\n1 2023-01-01 10:05:00   150\n2 2023-01-01 10:10:00   200\n3 2023-01-01 10:15:00   50\n4 2023-01-01 10:20:00   300\n5 2023-01-01 10:40:00   120\n6 2023-01-01 10:50:00   180\n7 2023-01-01 11:00:00   250\n```\n\nWhat I want to achieve is resampling this data to 15-minute intervals and calculating the sum of sales for each interval. If there are any intervals with no sales data, they should still appear in the final output with a sales value of 0.\n\nThe desired output format should look like this:\n\n```\n              Timestamp    Sales\n0 2023-01-01 10:00:00   450\n1 2023-01-01 10:15:00   0\n2 2023-01-01 10:30:00   0\n3 2023-01-01 10:45:00   180\n4 2023-01-01 11:00:00   250\n```\n\nHere's the starting point of the code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Timestamp': ['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:10:00', \n                  '2023-01-01 10:15:00', '2023-01-01 10:20:00', '2023-01-01 10:40:00', \n                  '2023-01-01 10:50:00', '2023-01-01 11:00:00'],\n    'Sales': [100, 150, 200, 50, 300, 120, 180, 250]\n})\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYour task is to fill in the blank to complete the code for the resampling and summing of sales:\n\n```python\ndf.set_index('Timestamp', inplace=True)\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = df.resample('15T').sum().fillna(0).reset_index()\ndf['Sales'] = df['Sales'].astype(int)\n```"
  },
  {
    "input": "### Problem\nI have a dataset containing daily sales data for products over a year. The data is in a DataFrame with two columns: 'Date' and 'Sales'. I would like to analyze trends by calculating a rolling average of sales over the past 7 days for each day in the DataFrame. \n\nHere's an example of what the DataFrame looks like:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', \n             '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10'],\n    'Sales': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nI want to create a new column 'Rolling_Avg' that contains the 7-day rolling average of sales. The first 6 entries should be NaN since there aren't 7 days to calculate the average yet.\n\nPlease fill in the blank with the appropriate solution.\n\n```python\ndf['Rolling_Avg'] = ...\n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Sales'].rolling(window=7).mean()\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains product descriptions in a column called 'description':\n```\n    description\n0   \"Apple - fresh, 1.5kg\"\n1   \"Banana - ripe, 2kg\"\n2   \"Cherry - sweet, 0.5kg\"\n3   \"Date - dried, 4kg\"\n```\nI want to separate the product name, state (fresh/ripe/sweet/dried), and weight into new columns named 'product', 'state', and 'weight' respectively. The resulting DataFrame should look like this:\n```\n   product   state   weight\n0   Apple    fresh   1.5\n1   Banana   ripe    2.0\n2   Cherry   sweet   0.5\n3   Date     dried   4.0\n```\nHere is my initial attempt to extract the information, but it's not working as expected:\n\n```python\ndf[['product', 'state', 'weight']] = df.description.str.extract(r'\\\"([A-Za-z]+)\\s-\\s([a-z]+),\\s([0-9.]+)kg\\\"')\n```\n\nCan you suggest a fix? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'description': ['\"Apple - fresh, 1.5kg\"', '\"Banana - ripe, 2kg\"', \n                                    '\"Cherry - sweet, 0.5kg\"', '\"Date - dried, 4kg\"']})\n</code>\ndf[['product', 'state', 'weight']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf[['product', 'state', 'weight']] = df.description.str.extract(r'\"([A-Za-z]+)\\s-\\s([a-z]+),\\s([0-9.]+)kg\"')\ndf['weight'] = df['weight'].astype(float)\n</code>"
  },
  {
    "input": "Problem:\nI have the following DataFrame with a column containing URLs that include user IDs. Here\u2019s how the DataFrame looks:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nI want to extract the user IDs from the URLs in the 'url' column and create a new column called 'user_id' that contains only these IDs. If there is no user ID in the URL, the new column should contain `NaN`.\n\nHere\u2019s the DataFrame before extraction:\n\n```\n        url\n0  https://example.com/user/12345/profile\n1  https://example.com/user/67890/dashboard\n2  https://example.com/page/abc/def\n3  https://example.org/user/54321\n```\n\nAfter extraction, the new DataFrame should look like this:\n\n```\n        url                user_id\n0  https://example.com/user/12345/profile   12345\n1  https://example.com/user/67890/dashboard  67890\n2  https://example.com/page/abc/def         NaN\n3  https://example.org/user/54321           54321\n```\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'url': ['https://example.com/user/12345/profile',\n                 'https://example.com/user/67890/dashboard',\n                 'https://example.com/page/abc/def',\n                 'https://example.org/user/54321']}\ndf = pd.DataFrame(data)\n</code>\ndf['user_id'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['user_id'] = df['url'].str.extract(r'user/(\\d+)')\n</code>"
  },
  {
    "input": "Problem:\n\nYou are tasked with training a simple feedforward neural network using both TensorFlow and PyTorch. The input to your model is a tensor of shape (batch_size, 10) representing features. You want to create a model that predicts a single output value for regression tasks. First, you need to define the model in TensorFlow. After that, you will define the same model in PyTorch.\n\nHere\u2019s a template for the TensorFlow model definition. Please fill in the blank to define the model properly:\n\n```python\nimport tensorflow as tf\n\ndef create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(shape=(10,)),\n        # Fill in this blank to add a Dense layer with 64 units and ReLU activation\n        ...\n        tf.keras.layers.Dense(1)\n    ])\n    return model\n```\n\nA:\n<code>\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ntf.keras.layers.Dense(64, activation='relu')\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing information about student exam scores. The dataset is organized in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\ndata = pd.DataFrame({\n    'StudentId': [1, 2, 3, 4, 5],\n    'Math': [85, 78, 92, 70, 88],\n    'English': [90, 82, 89, 95, 80],\n    'Science': [75, 80, 95, 70, 85]\n})\n```\n\nYou want to create a custom function that computes the average score for each student across the subjects listed in the DataFrame. The function should take a DataFrame and a list of column names as input, and return a new DataFrame with an additional column for the average score. \n\nThe resulting DataFrame should look like this (with an 'Average' column included):\n\n```\n   StudentId  Math  English  Science  Average\n0          1    85       90       75     83.33\n1          2    78       82       80     80.00\n2          3    92       89       95     92.00\n3          4    70       95       70     78.33\n4          5    88       80       85     84.33\n```\n\nPlease fill in the blank with the appropriate function call to achieve this result.\n\n```python\ndef calculate_average(df, columns):\n    <# fill in the code here #>\n    \nlist_of_subjects = ['Math', 'English', 'Science']\nresult_df = calculate_average(data, list_of_subjects)\n```",
    "output": "\n```python\ndef calculate_average(df, columns):\n    df['Average'] = df[columns].mean(axis=1)\n    return df\n    \nlist_of_subjects = ['Math', 'English', 'Science']\nresult_df = calculate_average(data, list_of_subjects)\n```"
  },
  {
    "input": "### Problem:\nI have a dataset containing product reviews, and I need to extract the numerical ratings from a comments column that contains both text and the ratings. The reviews are mixed with non-numeric characters, such as \"Rating: 4/5\", \"This is great, I give it 5!\", or \"Not worth it - scored 2 out of 5\". I want to create a new column that contains just the numerical ratings extracted from these strings, ideally as floats.\n\nHere is my dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review': [\n        'Rating: 4/5 Awesome product!',\n        'This is great, I give it 5!',\n        'Not worth it - scored 2 out of 5',\n        'Excellent experience with 4.5/5',\n        'Completely satisfied with a score of 5'\n    ]\n})\n```\n\nI\u2019ve attempted to use regex to find the ratings, but I am struggling to get it to work correctly. I want to extract the ratings as floats. \n\nYour task is to write the missing code for extracting the ratings into a new column called \"rating\" in the dataframe below:\n\n```python\ndf['rating'] = ...\n```\n\nEnsure that your final ratings are in the range of 0 to 5.",
    "output": "\n```python\ndf['rating'] = df['review'].str.extract(r'(\\d+\\.?\\d*)/?\\s*5?')[0].astype(float)\ndf['rating'] = df['rating'].clip(0, 5)\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch and have the following prediction tensor from your model:\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\nEach row in the predictions tensor represents the probabilities of three classes for a batch of four examples. Your goal is to convert these probabilities into predicted class indices, which means identifying the index of the highest probability in each row. \n\nHow would you fill in this code to achieve this?\n\n```python\nimport torch\n\npredictions = torch.tensor([[0.2, 0.4, 0.4],\n                             [0.1, 0.9, 0.0],\n                             [0.8, 0.1, 0.1],\n                             [0.3, 0.3, 0.4]])\n\npredicted_classes = ... # fill in with the correct code to get the index of max probability in each row\n```\n",
    "output": "\n```python\npredicted_classes = torch.argmax(predictions, dim=1)\n```"
  },
  {
    "input": "Problem:\nI have a dataset of sales records, structured as follows:\n\n   OrderID   CustomerID   Product   Quantity   Price\n0      101         C001     WidgetA        2     10.00\n1      102         C002     WidgetB        1     20.00\n2      103         C001     WidgetA        3     10.00\n3      104         C003     WidgetC        5     15.00\n4      105         C002     WidgetB        2     20.00\n\nI want to create a new column that calculates the total price for each order, which is derived by multiplying the 'Quantity' and 'Price' columns for each row. I'm trying to use a custom function for this task.\n\nWhat I started with:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'OrderID': [101, 102, 103, 104, 105],\n    'CustomerID': ['C001', 'C002', 'C001', 'C003', 'C002'],\n    'Product': ['WidgetA', 'WidgetB', 'WidgetA', 'WidgetC', 'WidgetB'],\n    'Quantity': [2, 1, 3, 5, 2],\n    'Price': [10.00, 20.00, 10.00, 15.00, 20.00]\n})\n```\nNow, I want to calculate the total price and store it in the 'TotalPrice' column:\n\ntotal_price_function = ... # put your function here\ndf['TotalPrice'] = df.apply(total_price_function, axis=1) # put solution in the 'TotalPrice' column\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ntotal_price_function = lambda row: row['Quantity'] * row['Price']\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe containing customer data:\n\n```\ncustomer_info\n1   John Doe, 29, New York\n2   Jane Smith, 34, San Francisco\n3   Alice Johnson, 22, Boston\n4   Bob Brown, 45, Chicago\n```\n\nI need to split this `customer_info` column into three separate columns: `name`, `age`, and `city`. The final dataframe should look like this:\n\n```\n      name   age           city\n1  John Doe   29       New York\n2  Jane Smith 34  San Francisco\n3  Alice Johnson 22         Boston\n4  Bob Brown   45        Chicago\n```\n\nI tried to achieve this using the `str.split` method but I'm not getting the expected output. Here is the initial code I have:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'customer_info': ['John Doe, 29, New York', 'Jane Smith, 34, San Francisco', \n                                      'Alice Johnson, 22, Boston', 'Bob Brown, 45, Chicago']})\n```\n\nHow can I correctly extract and separate the name, age, and city into different columns? \n\nA:\n<code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf[['name', 'age', 'city']] = df['customer_info'].str.split(', ', expand=True)\ndf['age'] = df['age'].astype(int)\ndf = df.drop(columns=['customer_info'])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information about books. Some entries have the title and author combined in a single string like \"Title: The Great Gatsby, Author: F. Scott Fitzgerald\". I want to separate this information into two distinct columns: 'title' and 'author'. \n\nHere is the DataFrame I have:\n\n```python\ndf = pd.DataFrame({\n    'info': [\n        \"Title: To Kill a Mockingbird, Author: Harper Lee\",\n        \"Title: 1984, Author: George Orwell\",\n        \"Title: The Catcher in the Rye, Author: J.D. Salinger\"\n    ]\n})\n```\n\nI need some Python code to achieve this. My expected DataFrame should look like:\n\n```\n               title               author\n0  To Kill a Mockingbird          Harper Lee\n1                 1984           George Orwell\n2   The Catcher in the Rye         J.D. Salinger\n```\n\nCan you help me extract the title and author into separate columns? \n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'info': [\n        \"Title: To Kill a Mockingbird, Author: Harper Lee\",\n        \"Title: 1984, Author: George Orwell\",\n        \"Title: The Catcher in the Rye, Author: J.D. Salinger\"\n    ]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['info'].str.extract(r'Title:\\s*(.*?),\\s*Author:\\s*(.*)')  \nresult.columns = ['title', 'author']  \n</code>"
  },
  {
    "input": "Problem:\nI am working on a neural network in PyTorch, and I have matrices of weights and inputs in the form of tensors. I need to perform a matrix multiplication between a weight tensor of shape (5, 3) and an input tensor of shape (3, 2). After the multiplication, I would like to reshape the resulting tensor into shape (5, 2). How can I achieve this?\n\nA:\n<code>\nimport torch\n\nweights = torch.randn(5, 3)\ninputs = torch.randn(3, 2)\n\n# Perform matrix multiplication and reshape the result\nresult = ... # put solution in this variable\n</code>",
    "output": "\n<code>\nresult = torch.matmul(weights, inputs).reshape(5, 2)\n</code>"
  },
  {
    "input": "Problem:\nI'm using PyTorch 1.12.0. I have a dataset where each sample consists of a feature tensor and a label tensor, and I want to create a neural network model that predicts the label from the features. My model should take an input tensor of shape (batch_size, 10) and output a tensor of shape (batch_size, 2) representing class probabilities. I'm currently attempting to define my model and would like to know how to achieve the following:\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.linear1 = nn.Linear(10, 5)\n        self.linear2 = nn.Linear(5, 2)\n    \n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = self.___ # fill in this line to complete the forward pass\n        return x\n\nmodel = MyModel()\nprint(model)\n```\n\nWhat should I use in place of ___ to ensure that the output represents class probabilities?",
    "output": "\n```python\n        x = torch.softmax(self.linear2(x), dim=1)\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe containing product descriptions and prices:\n  description           price\n0 \"apple pie\"         4.50\n1 \"banana bread\"      5.00\n2 \"cherry tart\"       6.25\n3 \"date square\"       3.75\n\nI need to extract the dessert type (the part before the space) from each description and create a new column that lists all unique dessert types in a single string, separated by commas. The desired output should look like this:\n\n  description           price       dessert_types\n0 \"apple pie\"         4.50         apple, banana, cherry, date\n1 \"banana bread\"      5.00         apple, banana, cherry, date\n2 \"cherry tart\"       6.25         apple, banana, cherry, date\n3 \"date square\"       3.75         apple, banana, cherry, date\n\nA:\n<code>\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    'description': [\"apple pie\", \"banana bread\", \"cherry tart\", \"date square\"],\n    'price': [4.50, 5.00, 6.25, 3.75]\n})\n</code>\ndf['dessert_types'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['dessert_types'] = ', '.join(df['description'].str.split().str[0].unique())\n</code>"
  },
  {
    "input": "Problem:\nYou have a pandas DataFrame containing hourly temperature readings for a city over several days. The DataFrame looks like this:\n\n```\n+---------------------+----------+\n|       Timestamp     | Temperature |\n+---------------------+----------+\n| 2023-01-01 00:00:00 |     30   |\n| 2023-01-01 01:00:00 |     32   |\n| 2023-01-01 02:00:00 |     33   |\n| 2023-01-02 00:00:00 |     31   |\n| 2023-01-02 01:00:00 |     35   |\n| 2023-01-02 02:00:00 |     36   |\n| 2023-01-03 00:00:00 |     34   |\n| 2023-01-03 01:00:00 |     32   |\n| 2023-01-03 02:00:00 |     30   |\n+---------------------+----------+\n```\n\nYou want to calculate the daily average temperature and create a new DataFrame that summarizes this data. The resulting DataFrame should have a 'Date' column and an 'Average Temperature' column. What code can you use to achieve this?\n\n```\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00',\n        '2023-01-03 00:00:00', '2023-01-03 01:00:00', '2023-01-03 02:00:00'\n    ],\n    'Temperature': [30, 32, 33, 31, 35, 36, 34, 32, 30]\n}\n\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\ndf.set_index('Timestamp', inplace=True)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.resample('D').mean().reset_index()\nresult['Date'] = result['Timestamp'].dt.date\nresult = result[['Date', 'Temperature']].rename(columns={'Temperature': 'Average Temperature'})\n```"
  },
  {
    "input": "Problem:\nI have the following dataframe:\n  full_name\n1 \"Alice Doe\"\n2 \"Bob Smith\"\n3 \"Charlie Brown\"\n4 \"Alice Wonderland\"\n\nI need to extract the first names and last names into two separate columns named 'first_name' and 'last_name', so that the resulting dataframe looks like this:\n  first_name  last_name\n1      Alice       Doe\n2        Bob     Smith\n3    Charlie     Brown\n4      Alice  Wonderland\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'full_name': ['Alice Doe', 'Bob Smith', 'Charlie Brown', 'Alice Wonderland']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df['full_name'].str.split(' ', expand=True).rename(columns={0: 'first_name', 1: 'last_name'})</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing sales data with columns for 'product_id', 'units_sold', and 'returns'. I want to calculate the net sales for each product, where net sales are defined as the total units sold minus the total returns for each product. I'm using a DataFrame and want to implement a function to do this computation for better reusability.\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 4, 1],\n    'units_sold': [10, 15, 5, 10, 20, 8, 7],\n    'returns': [1, 2, 0, 1, 0, 2, 1]\n})\n```\n\nWhat I tried:\n```python\nnet_sales = df.groupby('product_id').apply(lambda x: (x['units_sold'] - x['returns']).sum())\n```\n\nHowever, I am getting an output with indexes and want to have a simple DataFrame with 'product_id' and 'net_sales'. I want to encapsulate this logic into a reusable function that can return the desired summary. \n\nA:\n```python\ndef calculate_net_sales(df):\n    # Return the solution in this function\n    ...\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef calculate_net_sales(df):\n    net_sales = df.groupby('product_id').apply(lambda x: (x['units_sold'] - x['returns']).sum()).reset_index(name='net_sales')\n    return net_sales\n\nresult = calculate_net_sales(df)\n```"
  },
  {
    "input": "```python\nProblem:\nI have a dataframe containing customer feedback in a single string format where customer IDs and messages are combined in the following form: \"ID:1234; Message:Great service; ID:5678; Message:Not satisfied\". I need to extract customer IDs and their corresponding messages into separate columns. \n\nMy dataframe df looks like this:\n\nfeedback\n0  ID:1234; Message:Great service; ID:5678; Message:Not satisfied\n\nI am unsure how to parse this string efficiently using pandas string methods to create a structured dataframe.\n\nThe output I want should look like this:\n\n  customer_id         message\n0        1234      Great service\n1        5678      Not satisfied\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'feedback': ['ID:1234; Message:Great service; ID:5678; Message:Not satisfied']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf = df['feedback'].str.split('; ', expand=True).stack().str.extract(r'ID:(\\d+); Message:(.*)')[0].reset_index(drop=True)\ndf.columns = ['customer_id', 'message']\n</code>\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse tensor representation in PyTorch. You have a tensor that represents a 3D grid of values, but much of this tensor is zero, making it sparse. You need to find the maximum values along the last axis for each slice of the tensor. Here's how your tensor looks:\n\n```\nt = torch.tensor([[[0, 0, 1], [0, 0, 0], [0, 2, 0]],\n                   [[3, 0, 0], [0, 0, 0], [0, 4, 0]],\n                   [[0, 0, 0], [5, 0, 6], [0, 0, 0]]])\n```\n\nYou need to return a tensor that contains the maximum values for each 2D slice along the last axis. For the given tensor `t`, the expected result should look like this:\n\n```\ntensor([[1, 0, 2],\n        [3, 0, 4],\n        [0, 5, 6]])\n```\n\nHow can you achieve this in PyTorch? \n\nA:\n<code>\nimport torch\nt = load_data()\n</code>\nmax_values = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_values = t.max(dim=2).values\n</code>"
  },
  {
    "input": "Problem:\nYou are analyzing daily stock prices recorded in a pandas DataFrame, and you want to compute the percentage change in closing prices from one day to the next. However, if the closing price was zero on a given day, the percentage change should be set to NaN for that day to avoid division by zero. Additionally, you want to drop any rows that contain NaN values after calculating the percentage change.\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n    'Close': [150, 0, 155, 160, 0]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n```\n\nHow can you calculate the percentage change in 'Close' prices and drop NaN values in a single line of code?\n\nA:\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df['Close'].replace(0, pd.NA).pct_change().dropna()\n```"
  },
  {
    "input": "Problem:\n\nI'm working with a dataset of images in TensorFlow, and I need to preprocess them by normalizing the pixel values to the range [0, 1]. The original pixel values in the images range from 0 to 255. I have a tensor containing the image data, and I want to apply normalization across all the images at once. Given a tensor `images` of shape (batch_size, height, width, channels), how do I normalize it?\n\nA:\n<code>\nimport tensorflow as tf\n\nimages = load_data()\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_images = images / 255.0\n</code>"
  },
  {
    "input": "### Problem:\nYou are tasked with implementing a simple neural network using TensorFlow 2.10.0 and PyTorch to classify grayscale images. Each model will output a probability distribution across three classes (0, 1, or 2).\n\nAfter training both models, you need to create a tensor that captures the predicted class with the highest probability for the TensorFlow model's output. Given the tensor output from the TensorFlow model as follows:\n\n```\npredictions_tf = [[0.1, 0.6, 0.3],\n                  [0.8, 0.1, 0.1],\n                  [0.4, 0.4, 0.2]]\n```\n\nYour goal is to extract the indices of the maximum probabilities across each row and convert it to a tensor with shape (n, 1) using TensorFlow.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions_tf = tf.constant([[0.1, 0.6, 0.3],\n                               [0.8, 0.1, 0.1],\n                               [0.4, 0.4, 0.2]])\n</code>\npredicted_classes = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\npredicted_classes = tf.argmax(predictions_tf, axis=1, output_type=tf.int32)[:, tf.newaxis]</code>"
  },
  {
    "input": "Problem:\nI am training a neural network using TensorFlow and I want to combine multiple batches of tensor data for further processing. I have a list of tensors where each tensor is of shape (batch_size, features). However, I want to concatenate these tensors along the first dimension (batch dimension) while ensuring that their feature dimensions match. How can I achieve this effectively with TensorFlow?\n\nExample input:\nbatch1 = tf.constant([[1, 2], [3, 4]])\nbatch2 = tf.constant([[5, 6], [7, 8]])\nbatch3 = tf.constant([[9, 10]])\nbatches = [batch1, batch2, batch3]\n\n# Desired output shape would be (6, 2)\n\nA:\n<code>\nimport tensorflow as tf\n\nbatches = [tf.constant([[1, 2], [3, 4]]), tf.constant([[5, 6], [7, 8]]), tf.constant([[9, 10]])]\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = tf.concat(batches, axis=0)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a sparse matrix represented in Compressed Sparse Row (CSR) format, where each row represents a user-item interaction, and I want to compute the mean of the non-zero elements column-wise. The sparse matrix is stored in the variable `sparse_matrix`.\n\nThe matrix has the following structure:\n\n```\n0 0 5 0\n0 3 0 0\n0 0 0 2\n4 0 0 0\n```\n\nI am unsure how to calculate the mean of each column without converting the sparse matrix to a dense format, as this would be inefficient for large datasets.\n\nA:\n\n<code>\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\ndata = np.array([5, 3, 2, 4])\nrow_indices = np.array([0, 1, 3, 0])\ncol_indices = np.array([2, 1, 3, 0])\nsparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(4, 4))\n</code>\ncolumn_means = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncolumn_means = sparse_matrix.sum(axis=0) / (sparse_matrix != 0).sum(axis=0)\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have a pandas DataFrame that contains product reviews with metadata. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review_text': [\n        'I love the coffee! It is great, good smell.',\n        'The tea was okay, not the best, I prefer another brand.',\n        'Fantastic chocolate flavor, would definitely buy again!',\n        'I really disliked the texture and the taste.'\n    ],\n    'rating': [5, 3, 4, 1]\n})\n```\n\nYou want to extract keywords (nouns) from the review_text column and create a new column called keywords that concatenates these keywords using a comma as a separator. For this demonstration, you can consider keywords as the words with lengths greater than 3 characters. You can create a simple function to filter and join these keywords.\n\nHere's where you're stuck. You want to apply this custom keyword extraction function to each review and populate the keywords column accordingly.\n\n```python\ndef extract_keywords(text):\n    # Replace this comment with your logic to extract words longer than 3 characters\n    pass\n\ndf['keywords'] = df['review_text'].apply( ... ) # fill in the blank to complete the DataFrame modification\n```\n\nFill in the blank to complete the code that applies your function to the review_text and updates the keywords column in the DataFrame.",
    "output": "\n```python\ndef extract_keywords(text):\n    return ', '.join([word for word in text.split() if len(word) > 3])\n\ndf['keywords'] = df['review_text'].apply(extract_keywords)\n```"
  },
  {
    "input": "Problem:\nYou have been given a dataset representing sales information for various products. The dataset is presented as a pandas DataFrame, as shown below:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet'],\n    'Sales': [1200, 800, 450, 1300, 900, 500, 1150, 850, 470]\n})\n```\n\nYou need to create a custom function that calculates the average sales per product and appends this average to the original DataFrame as a new column named 'Average_Sales'. The resulting DataFrame should have the format:\n\n```\nProduct    Sales   Average_Sales\nLaptop     1200    average_sales_laptop\nPhone      800     average_sales_phone\nTablet     450     average_sales_tablet\nLaptop     1300    average_sales_laptop\nPhone      900     average_sales_phone\nTablet     500     average_sales_tablet\nLaptop     1150    average_sales_laptop\nPhone      850     average_sales_phone\nTablet     470     average_sales_tablet\n```\n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef calculate_average_sales(df):\n    average_sales = df.groupby('Product')['Sales'].mean().to_dict()\n    df['Average_Sales'] = df['Product'].map(average_sales)\n    return df\n\nresult = calculate_average_sales(data)\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame that contains product descriptions and pricing as follows:\nproduct_df = pd.DataFrame({'description':['12-inch Red Widget at $15.99','Blue Widget 10\" - $12.50','Large Green Widget (15 inches) $25.00','Small Yellow Widget with price: $9.99']})\n\nI want to extract the product size (if mentioned in inches) and the price into two separate columns named 'size' and 'price'. If the size is not mentioned, it should be NaN. The final DataFrame should look like this:\n\ndescription                                           size      price\n0  12-inch Red Widget at $15.99                     12      15.99\n1  Blue Widget 10\" - $12.50                          10      12.50\n2  Large Green Widget (15 inches) $25.00             15      25.00\n3  Small Yellow Widget with price: $9.99             NaN      9.99\n\nI've attempted to use regex to parse the size and price, but I'm struggling to extract these values correctly. Can you help me with a code snippet to construct this DataFrame correctly?\n\nA:\n<code>\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'description':['12-inch Red Widget at $15.99','Blue Widget 10\" - $12.50','Large Green Widget (15 inches) $25.00','Small Yellow Widget with price: $9.99']})\n</code>\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport numpy as np\nimport re\n\nproduct_df['size'] = product_df['description'].str.extract(r'(\\d+)\\s*[-\" inches]')\nproduct_df['price'] = product_df['description'].str.extract(r'\\$([\\d.]+)')\nproduct_df['size'] = product_df['size'].astype(float)\nproduct_df['price'] = product_df['price'].astype(float)\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe containing sales data for different products over multiple months. Here is the initial setup:\n\n```python\nimport pandas as pd\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n    'Month': ['2022-01', '2022-02', '2022-01', '2022-02', '2022-01', '2022-02', '2022-01', '2022-02'],\n    'Sales': [100, 150, 200, 250, 300, 350, 400, 450]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a function called `add_sales_totals` that takes a dataframe as input and adds a new column that contains the total sales for each product across all months. The resulting dataframe should look like this:\n\n```\n  Product    Month  Sales  Total_Sales\n0       A  2022-01    100           250\n1       A  2022-02    150           250\n2       B  2022-01    200           450\n3       B  2022-02    250           450\n4       C  2022-01    300           650\n5       C  2022-02    350           650\n6       D  2022-01    400           850\n7       D  2022-02    450           850\n```\n\nYou can assume the `add_sales_totals` function will be called like this:\n\n```python\nresult_df = add_sales_totals(df)\n```\n\nPlease provide the code to define the `add_sales_totals` function that accomplishes this task. \n```python\ndef add_sales_totals(df):\n    ...\n```",
    "output": "\n```python\ndef add_sales_totals(df):\n    total_sales = df.groupby('Product')['Sales'].transform('sum')\n    df['Total_Sales'] = total_sales\n    return df\n```"
  },
  {
    "input": "Problem:\nI have a dataframe that contains a column with product descriptions that include both the product name and its price in a mixed format like so:\n\n```python\ndata = {'description': ['Laptop - $1200', 'Mouse - $25', 'Keyboard - $75', 'Monitor - $300']}\ndf = pd.DataFrame(data)\n```\n\nI want to extract the product name into a new column called `product_name` and the price (as a numeric value) into another new column called `price`. The final dataframe should look like this:\n\n```\n       description     product_name  price\n0   Laptop - $1200           Laptop  1200.0\n1     Mouse - $25            Mouse    25.0\n2  Keyboard - $75         Keyboard    75.0\n3  Monitor - $300         Monitor     300.0\n```\n\nHowever, my current attempt to extract these values is failing. I want the correct pandas code to achieve this transformation. \n\nPlease provide the solution in the following blank:\n```python\ndf[['product_name', 'price']] = df['description'].str.extract(r'(?P<product_name>.*?) - \\$(?P<price>\\d+)')\n```",
    "output": "\n```python\ndf[['product_name', 'price']] = df['description'].str.extract(r'(?P<product_name>.*?) - \\$(?P<price>\\d+)')\ndf['price'] = df['price'].astype(float)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product information with mixed formatting in the 'product_name' column. Each product name may include extra spaces, inconsistent casing, and some variations in characters like hyphens and underscores. Here\u2019s the DataFrame I have:\n\n```python\nimport pandas as pd\n\ndata = {'product_name': ['  apple-juice ', 'Orange_JUICE', 'banAna', 'Grapes    ', '  Watermelon  ', 'kiwi  ']}\ndf = pd.DataFrame(data)\n```\n\nI want to normalize the 'product_name' column by:\n1. Stripping leading and trailing spaces.\n2. Converting the names to lowercase.\n3. Replacing any hyphens and underscores with spaces.\n\nThe expected output should retain a DataFrame with the normalized product names:\n\n| product_name |\n|--------------|\n| apple juice  |\n| orange juice |\n| banana       |\n| grapes       |\n| watermelon   |\n| kiwi         |\n\nWhat code should I fill in to transform the DataFrame as described above?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df['product_name'].str.strip().str.lower().str.replace('[-_]', ' ', regex=True)\n```"
  },
  {
    "input": "Problem:\nI have a time series data in a pandas DataFrame containing timestamps and corresponding temperatures taken every hour. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'timestamp': ['2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00', \n                  '2023-01-01 03:00:00', '2023-01-01 04:00:00', '2023-01-01 05:00:00'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n})\n```\n\nWhat I want to achieve is to create a new DataFrame that includes the average temperature computed over a 2-hour rolling window, but only for the timestamps that fall exactly on the hour (e.g., '2023-01-01 00:00:00', '2023-01-01 01:00:00', etc.). \n\nThe resulting DataFrame should have the following structure:\n\n```python\n          timestamp  avg_temperature\n0  2023-01-01 00:00:00              ?\n1  2023-01-01 01:00:00              ?\n2  2023-01-01 02:00:00              ?\n3  2023-01-01 03:00:00              ?\n4  2023-01-01 04:00:00              ?\n5  2023-01-01 05:00:00              ?\n```\n\nPlease fill in the blank with the proper code to derive the column `avg_temperature`. \n\n```python\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.set_index('timestamp').rolling('2H').mean().reset_index().rename(columns={'temperature': 'avg_temperature'})\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains hourly temperature readings over a period of several days, structured as follows:\n\n```python\ndata = {\n    'datetime': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', '2023-01-02 00:00', '2023-01-02 01:00', '2023-01-02 02:00'],\n    'temperature': [15.0, 14.5, 14.0, 16.0, 15.5, 15.0]\n}\ndf = pd.DataFrame(data)\ndf['datetime'] = pd.to_datetime(df['datetime'])\n```\n\nI want to resample this data to get the daily average temperature, even if there are missing hourly records, and fill those missing days with NaN. The desired output should retain the index as a DatetimeIndex with daily frequency. Please provide the code to achieve this.\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.set_index('datetime').resample('D').mean()\n```"
  },
  {
    "input": "Problem:\nI have a sparse tensor represented in a list format where the first element is the shape of the tensor, and the second element is a list of tuples (row_index, column_index, value) representing the non-zero entries. I need to convert this into a format that allows easy access to elements and supports efficient computations. Specifically, I want to convert this list representation into a sparse tensor and then access a specific element based on its indices.\n\nHere's the data I have:\n```\ntensor_data = [\n    (3, 4, 2),  # shape of the tensor: 3 rows, 4 columns, 2 non-zero entries\n    [(0, 1, 5), (2, 3, 8)]  # non-zero entries: (row_index, column_index, value)\n]\n```\n\nTo achieve this, I want to use the `scipy.sparse` module to create a sparse matrix from this representation. Additionally, I want to retrieve the value at the entry located at row 2 and column 3 of the sparse tensor.\n\nHow can I fill in the blank below to accomplish this task?\n\nA:\n<code>\nfrom scipy import sparse\n\ntensor_data = [\n    (3, 4, 2),\n    [(0, 1, 5), (2, 3, 8)]\n]\n\nentries = tensor_data[1]\nrows, cols, values = zip(*entries)\n\n# Create the sparse matrix\nsparse_tensor = ...  # put solution in this variable\n\n# Accessing the value at row 2, column 3\nvalue_at_2_3 = sparse_tensor[2, 3]\n</code>\n",
    "output": "\n<code>\nsparse_tensor = sparse.coo_matrix((values, (rows, cols)), shape=tensor_data[0][:2]).toarray()\n</code>"
  },
  {
    "input": "Problem:\nI am working with a sparse matrix in Python using SciPy and I need to perform a matrix multiplication with another matrix. I have a sparse matrix named `A` of shape (5, 5) in COO format and a dense matrix `B` of shape (5, 3). I want to compute the resulting matrix `C` from the multiplication of `A` and `B`, while keeping `C` in CSR (Compressed Sparse Row) format, which is more efficient for arithmetic operations. Here is a snippet of my code:\n\n```python\nimport numpy as np\nfrom scipy.sparse import coo_matrix, csr_matrix\n\n# Initialize a sparse matrix A in COO format\ndata = np.array([1, 2, 3])\nrow_indices = np.array([0, 2, 4])\ncol_indices = np.array([0, 2, 4])\nA = coo_matrix((data, (row_indices, col_indices)), shape=(5, 5))\n\n# Create a dense matrix B\nB = np.array([[1, 0, 2],\n              [0, 1, 0],\n              [3, 0, 1],\n              [0, 0, 0],\n              [1, 2, 0]])\n\n# Now, compute the result C\nC = ...\n```\n\nHow can I fill in the blank `C = ...` to get the result of `A` multiplied by `B` while ensuring `C` is in CSR format?",
    "output": "\n```python\nC = A.dot(B).tocsr()\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of strings where each string includes a person's full name in the format \"Last, First\". I want to split this column into two new columns: one for the first name and one for the last name. However, I noticed that some names also have a middle name or initial included, and I only want the first name to be extracted, regardless of its presence. \n\nHere\u2019s how my DataFrame looks:\n```\n    Names\n0  Smith, John A.\n1  Doe, Jane\n2  Johnson, Emily R.\n```\nI want to achieve a DataFrame that looks like this:\n```\n    First Name    Last Name\n0      John         Smith\n1      Jane         Doe\n2      Emily        Johnson\n```\nI have the following code, but I am struggling to properly extract the first and last names:\n```\ndf[['Last Name', 'First Name']] = df['Names'].str.split(',', expand=True)\n```\nThis splits the Last and First names but includes the middle name with the first name. How can I just get the first name?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Names': ['Smith, John A.', 'Doe, Jane', 'Johnson, Emily R.']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['Names'].str.split(',', expand=True)\nresult.columns = ['Last Name', 'First Name']\nresult['First Name'] = result['First Name'].str.split().str[0]\n</code>"
  },
  {
    "input": "Problem:\nI am working with high-dimensional images and need to perform an operation on a sparse tensor. Specifically, I want to compute the sum of values along the last axis for a 3D sparse tensor representation of images (channels, height, width) using PyTorch. My sparse tensor is created as follows:\n\n```python\nimport torch\nfrom torch.sparse import FloatTensor\n\nindices = torch.tensor([[0, 0, 1], [0, 2, 1]])\nvalues = torch.tensor([3.0, 4.0, 5.0])\nsparse_tensor = FloatTensor(indices, values, size=(2, 3, 3))\n```\n\nI need to fill in the blank to compute the sum across the last axis, resulting in a 2D tensor where each row corresponds to the sum of each channel for all positions in the height and width dimensions.\n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = sparse_tensor.sum(dim=-1).to_dense()\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\n\nI am working with a 4-dimensional sparse tensor that represents the preferences of users for different items over various contexts and timeframes. The sparse tensor is defined using the `scipy.sparse` library and contains a few non-zero values indicating positive preferences. I want to efficiently extract the non-zero entries along with their indices (in the form of a list of tuples) from the tensor and format them into a list of dictionaries, where each dictionary associates the indices of each non-zero entry with the corresponding value.\n\nHere's how my sparse tensor is defined:\n\n```python\nfrom scipy import sparse\n\n# Creating a sparse tensor (4D) with some non-zero values\nsparse_tensor = sparse.coo_array((3, 2, 4, 5), dtype=int)\n```\n\nThe current state of the sparse tensor is as follows:\n\n- Non-zero entries at indices (0, 1, 2, 3), (2, 0, 1, 4), and (1, 0, 3, 2), with values 10, 20, and 30 respectively.\n\nI want to construct the output in this format:\n\n```python\noutput = [\n    {'indices': (0, 1, 2, 3), 'value': 10},\n    {'indices': (2, 0, 1, 4), 'value': 20},\n    {'indices': (1, 0, 3, 2), 'value': 30},\n]\n```\n\nCan you help me write the code to achieve this transformation?\n\nA:\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Assume sparse_tensor is defined as given above\nsparse_tensor = sparse.coo_array(...)  # Fill this in with the actual sparse tensor values\n\n# Extract the solution\noutput = ...  # put solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\nimport numpy as np\nfrom scipy import sparse\n\n# Assume sparse_tensor is defined as given above\nsparse_tensor = sparse.coo_array((3, 2, 4, 5), dtype=int)\nsparse_tensor.data = np.array([10, 20, 30])\nsparse_tensor.row = np.array([0, 2, 1])\nsparse_tensor.col = np.array([1, 0, 0])\nsparse_tensor.shape = (3, 2, 4, 5)\n\n# Extract the solution\noutput = [{'indices': tuple(sparse_tensor.nonzero()[:, i]), 'value': sparse_tensor.data[i]} for i in range(len(sparse_tensor.data))]\n</code>"
  },
  {
    "input": "Problem:\n\nI'm working with TensorFlow 2.10.0 and have two tensors: `data` with shape (64, 20, 128) and `weights` with shape (128, 10). I want to perform a batched matrix multiplication that results in a tensor with shape (64, 20, 10). How can I achieve this?\n\nHere is my current code setup:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ndata = tf.constant(np.random.rand(64, 20, 128), dtype=tf.float32)\nweights = tf.constant(np.random.rand(128, 10), dtype=tf.float32)\n```\n\nHow can I complete the operation? \n\nA:\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = tf.matmul(data, weights)  # Perform batched matrix multiplication\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a multi-class classification problem using PyTorch. You have a tensor `outputs` representing the prediction scores from your model, which has the shape `[64, 5]` for 64 samples and 5 classes. You also have a tensor `labels` that contains the true class indices for each sample, with a shape of `[64]`. \n\nYou want to calculate the number of correct predictions by comparing the predicted class indices with the true labels. However, first, you need to convert the `outputs` tensor to a tensor that contains the indices of the maximum scores across the classes for each sample.\n\nHow can you perform this operation in a single line? \n\nA:\n<code>\nimport torch\noutputs, labels = load_data()\n</code>\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>predictions = torch.argmax(outputs, dim=1)</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains a column with mixed strings, and I need to extract only the email addresses from this column into a separate list. The dataframe looks like this:\n\ndata\n0  John Doe john.doe@example.com\n1  Jane Smith janesmith@web.net\n2  No Email Here\n3  Contact us at support@mywebsite.org\n4  Another Guy with email: anotherguy@domain.com\n\nI am currently struggling to filter the valid email addresses using regex and pandas string operations. Can you help me extract these email addresses into a list?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'data': ['John Doe john.doe@example.com',\n                            'Jane Smith janesmith@web.net',\n                            'No Email Here',\n                            'Contact us at support@mywebsite.org',\n                            'Another Guy with email: anotherguy@domain.com']})\n</code>\nemails = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nemails = df['data'].str.extractall(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})')[0].tolist()  \n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains a column of email addresses, and I need to extract the usernames (the part before the '@') and create a new column for them. Here's the DataFrame I have:\n\n```\n      Email\n0  john.doe@example.com\n1  jane.smith@website.org\n2  test.user123@gmail.com\n3  sample@domain.com\n```\n\nI want to create a new column called 'Username' that contains just the usernames extracted from the 'Email' column.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Email': ['john.doe@example.com', 'jane.smith@website.org', 'test.user123@gmail.com', 'sample@domain.com']})\n</code>\ndf['Username'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Username'] = df['Email'].str.split('@').str[0]"
  },
  {
    "input": "Problem:\nI have a DataFrame with the following structure:\n\n```\n|   product_id | rating | review_count |\n|--------------|--------|--------------|\n|            1 |      5 |           10 |\n|            2 |      4 |            5 |\n|            3 |      3 |          100 |\n|            4 |      2 |             0 |\n|            5 |      1 |           30 |\n```\n\nI would like to create a new column `quality` that categorizes products based on their `rating` and `review_count`. The criteria are as follows:\n- If the `rating` is 4 or higher and `review_count` is greater than 10, label it as \"High Quality\".\n- If the `rating` is between 3 and 4 (inclusive) and `review_count` is greater than 0, label it as \"Moderate Quality\".\n- Otherwise, label it as \"Low Quality\".\n\nMy current function approach is not very efficient. Here is my code so far:\n\n```python\ndef categorize_quality(row):\n    if row['rating'] >= 4 and row['review_count'] > 10:\n        return 'High Quality'\n    elif 3 <= row['rating'] < 4 and row['review_count'] > 0:\n        return 'Moderate Quality'\n    else:\n        return 'Low Quality'\n\ndf['quality'] = df.apply(categorize_quality, axis=1)\n```\n\nI want to optimize this code to avoid using `apply`. How can I implement a custom function that achieves this more efficiently?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 2, 3, 4, 5],\n    'rating': [5, 4, 3, 2, 1],\n    'review_count': [10, 5, 100, 0, 30]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['quality'] = pd.cut(\n    df['rating'].where(df['review_count'] > 10, 0),\n    bins=[-1, 2, 3, 4, 5],\n    labels=['Low Quality', 'Low Quality', 'Moderate Quality', 'High Quality'],\n    right=True\n).fillna('Low Quality')\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset of customer transactions in a DataFrame, where each transaction has a 'price' and a 'quantity' column. You want to create a new column that calculates the total amount spent for each transaction, which is the product of 'price' and 'quantity'. To ensure your code is reusable, you plan to implement a custom function for this calculation.\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'price': [10.5, 20.0, 7.5, 15.0],\n    'quantity': [2, 1, 3, 4]\n})\n```\n\nYou should define a function named `calculate_total` that takes two arguments, `price` and `quantity`, and returns the total spent for that transaction. Then, use this function to apply it to the DataFrame and create a new column called 'total_spent'.\n\n```python\ndf['total_spent'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_total(price, quantity):\n    return price * quantity\n\ndf['total_spent'] = df.apply(lambda row: calculate_total(row['price'], row['quantity']), axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset that contains employee performance metrics across multiple departments, formatted as follows:\n\n| EmployeeID | Department | PerformanceScores          |\n|------------|------------|----------------------------|\n| 1          | HR         | [3, 5, 4]                  |\n| 2          | IT         | [4, 4, 5]                  |\n| 3          | HR         | [2, 3, 4]                  |\n| 4          | Sales      | [5, 3, 2]                  |\n| 5          | IT         | [4, 5, 4]                  |\n| 6          | Sales      | [3, 5, 3]                  |\n\nI want to create a function that computes the average performance score for each employee, but I also want to store the maximum score achieved. Given the current dataframe, this is what I have tried:\n\n```python\ndf['AverageScore'] = df['PerformanceScores'].apply(lambda x: sum(x) / len(x))\n```\n\nHowever, I also want to keep track of the maximum score. Can you help create a function `calculate_performance_metrics` that takes a dataframe as input and returns a new dataframe including two new columns: 'AverageScore' and 'MaxScore'?\n\nYour function should look something like:\n\n```python\ndef calculate_performance_metrics(df):\n    df['AverageScore'] = ...\n    df['MaxScore'] = ...\n    return df\n```\n\nUsing the above dataframe, `df` should be transformed to include the 'AverageScore' and 'MaxScore'. \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4, 5, 6],\n    'Department': ['HR', 'IT', 'HR', 'Sales', 'IT', 'Sales'],\n    'PerformanceScores': [[3, 5, 4], [4, 4, 5], [2, 3, 4], [5, 3, 2], [4, 5, 4], [3, 5, 3]]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndef calculate_performance_metrics(df):\n    df['AverageScore'] = df['PerformanceScores'].apply(lambda x: sum(x) / len(x))\n    df['MaxScore'] = df['PerformanceScores'].apply(lambda x: max(x))\n    return df\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix representing user interactions with items, where the entries are ratings (and can include zeros for no interaction). The matrix is of shape (1000, 500) and is in CSR format. I want to create a new matrix where each entry corresponds to the maximum rating for each item across multiple users, ignoring zeros (which represent no interaction). What is the best way to achieve this without converting to a dense format, and how would I go about extracting this information into a new zero-based sparse matrix of shape (1, 500)?\n\nA:\n<code>\nfrom scipy import sparse\nimport numpy as np\n\n# Assume 'user_item_matrix' is a sparse matrix of shape (1000, 500)\nuser_item_matrix = sparse.csr_matrix(np.random.randint(0, 6, (1000, 500)))  # Example sparse matrix with ratings from 0 to 5\n</code>\nmax_rating_per_item = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmax_rating_per_item = sparse.csr_matrix(user_item_matrix.max(axis=0).A.reshape(1, -1))\n</code>"
  },
  {
    "input": "## Problem:\nI have a time series dataset that records the daily sales of a product. The dataframe `sales_df` has the following columns:\n\n- `date`: a datetime column representing the date of the sales\n- `sales`: an integer column representing the number of units sold on that date\n\nIt looks like this:\n\n```\n        date       sales\n0 2023-01-01      120\n1 2023-01-02      135\n2 2023-01-03      150\n3 2023-01-04      145\n4 2023-01-05      160\n```\n\nI want to create a new column `rolling_average` that calculates the 3-day rolling average of the sales. Thus, for each date, this value should represent the average of the sales for that date and the two previous days. Please help me fill in the blank below to achieve this.\n\nMy code:\n\n```python\nimport pandas as pd\n\nsales_df = pd.DataFrame({\n    'date': pd.date_range(start='2023-01-01', periods=5),\n    'sales': [120, 135, 150, 145, 160]\n})\n\nsales_df['rolling_average'] = ...\n```\n",
    "output": "\n```python\nsales_df['rolling_average'] = sales_df['sales'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nSuppose you have a sparse tensor representing a 3D data structure for image features, stored in a PyTorch SparseTensor. The tensor is of size (5, 5, 5), with a few non-zero entries. You want to create a dense representation of this sparse tensor, but only for a specific slice along the first dimension (batch). You need the slice for the first two batches (i.e., `tensor[0:2, :, :]`).\n\nA:\n<code>\nimport torch\nindices = torch.tensor([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\nvalues = torch.tensor([10.0, 20.0, 30.0])\nsize = (5, 5, 5)\nsparse_tensor = torch.sparse_coo_tensor(indices.t(), values, size)\n</code>\ndense_slice = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_slice = sparse_tensor.to_dense()[0:2, :, :]"
  },
  {
    "input": "Problem:\n\nI have a dataset containing user reviews of products, and I want to extract the star ratings embedded within the review strings. The reviews are structured as follows: \"Product A - \u2605\u2605\u2605\u2605\u2606 (4/5)\", \"Product B - \u2605\u2605\u2605\u2605\u2605 (5/5)\", etc. I want to create a new DataFrame column that contains only the numeric star ratings.\n\nHere\u2019s the DataFrame I started with:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'review': [\"Product A - \u2605\u2605\u2605\u2605\u2606 (4/5)\", \"Product B - \u2605\u2605\u2605\u2605\u2605 (5/5)\", \"Product C - \u2605\u2605\u2605\u2606\u2606 (3/5)\"]\n})\n```\n\nHow can I extract just the numeric ratings (e.g., 4, 5, 3) into a new column called 'rating'?\n\nA:\n```python\ndf['rating'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['rating'] = df['review'].str.extract(r'(\\d)/5')[0].astype(int)\n```"
  },
  {
    "input": "## Problem\nI have a set of images in a tensor `images` of shape `(batch_size, height, width, channels)` and a corresponding tensor of labels `labels` of shape `(batch_size,)`. I want to build a simple neural network model using PyTorch that will classify these images into one of the `num_classes` categories. I am using the `nn.CrossEntropyLoss` as my loss function. \n\nAfter defining my model and putting it in training mode, I have the following code to calculate the predictions from the model and the loss. How can I get the predicted class indices from the raw model outputs `outputs`?\n\nA:\n<code>\nimport torch\nimport torch.nn as nn\n\n# Assuming the model and data is already defined\noutputs = model(images)  # outputs has shape (batch_size, num_classes)\nloss_fn = nn.CrossEntropyLoss()\nloss = loss_fn(outputs, labels)\n\n# I need to fill in this part to get the predicted class indices\npredicted_classes = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\npredicted_classes = torch.argmax(outputs, dim=1)\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a dataset consisting of images that you want to preprocess before feeding them into a neural network for classification. The images are stored in a 4D tensor of shape (batch_size, height, width, channels). You would like to normalize the pixel values to be between 0 and 1 using PyTorch. \n\nGiven a 4D tensor `images`, how can you normalize it?\n\nA:\n\n<code>\nimport torch\n\nbatch_size, height, width, channels = 10, 32, 32, 3\nimages = torch.randn(batch_size, height, width, channels) * 255  # Simulated image data with pixel values from 0 to 255\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nnormalized_images = images / 255.0\n</code>",
    "output": "\n<code>\nnormalized_images = images / 255.0\n</code>"
  },
  {
    "input": "Problem:\nI have a time series DataFrame with temperatures recorded every hour over several days. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Timestamp': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', '2023-01-01 03:00',\n                  '2023-01-02 00:00', '2023-01-02 01:00', '2023-01-02 02:00', '2023-01-02 03:00'],\n    'Temperature': [20.1, 19.8, 19.6, 19.7, 18.4, 18.5, 18.3, 18.7]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nI want to resample this temperature data to daily frequency, calculating the average temperature for each day. However, I need to ensure that the resulting DataFrame has the date as the index and the average temperature for each day as a separate column. \n\nThe expected output format should look like this:\n\n```\n            Temperature\nTimestamp\n2023-01-01          ...\n2023-01-02          ...\n```\n\nCan you provide the line of code that fills in the blank in the following placeholder?\n\n```python\ndaily_avg = df.set_index('Timestamp').resample(...).mean()\n```",
    "output": "\n```python\ndaily_avg = df.set_index('Timestamp').resample('D').mean()\n```"
  },
  {
    "input": "Problem:\n\nI am building a multi-layer perceptron (MLP) classifier using PyTorch. My input data is a tensor of shape (64, 10), representing 64 samples with 10 features each. I have a linear layer followed by a ReLU activation, and then another linear layer which outputs a tensor of shape (64, 3), indicating the class scores for 3 classes. \n\nAfter obtaining the output scores tensor, I want to convert it into probabilities using the softmax function. However, I also wish to ensure that all entries in this resulting probability tensor sum to 1 for each sample. How can I achieve this?\n\nHere\u2019s what I have so far:\n\nimport torch\n\ninput_data = torch.randn(64, 10)\nlinear1 = torch.nn.Linear(10, 5)  # First layer\nrelu = torch.nn.ReLU()\nlinear2 = torch.nn.Linear(5, 3)  # Second layer\nscores = linear2(relu(linear1(input_data)))\n\nWhat should I place here to compute the softmax probabilities?\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = torch.nn.functional.softmax(scores, dim=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a sparse 3D tensor represented as a dictionary of coordinates in the format: `{(i, j, k): value}` where `i`, `j`, and `k` correspond to the indices of the tensor and `value` is the value at that position. I need to convert this dictionary representation into a sparse tensor format using `scipy.sparse`. Given the following tensor representation:\n\n```python\nimport numpy as np\nfrom scipy import sparse\n\nsparse_dict = {\n    (0, 0, 0): 1,\n    (1, 2, 0): 2,\n    (3, 1, 1): 3\n}\n```\n\nHow can I create a compressed sparse row (CSR) representation of this tensor while keeping the 3D structure?\n\nA:\n```python\nimport numpy as np\nfrom scipy import sparse\n\nsparse_dict = {\n    (0, 0, 0): 1,\n    (1, 2, 0): 2,\n    (3, 1, 1): 3\n}\n# shape of the tensor\nshape = (4, 3, 2)\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\n    coords = np.array(list(sparse_dict.keys()))\n    values = np.array(list(sparse_dict.values()))\n    result = sparse.coo_matrix((values, (coords[:, 0], coords[:, 1], coords[:, 2])), shape=shape).tocsr()\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing sales transactions for various products, structured as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'Product': ['A', 'B', 'A', 'C', 'B'],\n    'Quantity': [2, 1, 3, 4, 2],\n    'Price': [10, 20, 10, 30, 20]\n})\n```\n\nYou want to create a function that calculates the total sales for each product based on the Quantity and Price columns. The desired output should be a dictionary with product names as keys and total sales as values.\n\n```python\ntotal_sales = ... # Write your function and assign the output here\n```\n\nMake sure the function is reusable and can handle different DataFrames structured like the provided one.",
    "output": "\n```python\ndef calculate_total_sales(dataframe):\n    sales = {}\n    for index, row in dataframe.iterrows():\n        product = row['Product']\n        total = row['Quantity'] * row['Price']\n        if product in sales:\n            sales[product] += total\n        else:\n            sales[product] = total\n    return sales\n\ntotal_sales = calculate_total_sales(df)\n```"
  },
  {
    "input": "Problem:\nYou have a dataframe containing timestamps in a string format, which includes both the date and time. The format looks like this: \"2023-10-15 14:25:00\" or \"2023/10/15 14:25:00\". You need to split this column into two new columns: one for the date and another for the time.\n\nGiven the following dataframe:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'timestamp': ['2023-10-15 14:25:00', '2023/10/16 15:30:00', '2023-10-17 16:45:00']})\n```\n\nYou want to create a new dataframe that looks like this:\n```\n       date      time\n0  2023-10-15  14:25:00\n1  2023-10-16  15:30:00\n2  2023-10-17  16:45:00\n```\n\nI started with this code but it doesn't work properly:\n```python\ndf['date'], df['time'] = df['timestamp'].str.split(' ', expand=True)\n```\n\nWhat can I do to make it work? \n\nA:\n<code>\ndf = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf[['date', 'time']] = df['timestamp'].str.replace('/', '-').str.split(' ', expand=True)\n</code>"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing user data in a single column called 'info'. The 'info' column consists of strings formatted as \"Name: Age: Email\". For example:\n\n```\ninfo\n0  John Doe: 28: john@example.com\n1  Jane Smith: 35: jane@example.com\n2  Sam Johnson: 22: sam@example.com\n3  Lisa Lee: 30: lisa@example.com\n```\n\nI need to split this 'info' column into three new columns: 'Name', 'Age', and 'Email'. The resulting DataFrame should look like this:\n\n```\n   Name          Age               Email\n0  John Doe      28            john@example.com\n1  Jane Smith    35            jane@example.com\n2  Sam Johnson    22           sam@example.com\n3  Lisa Lee      30            lisa@example.com\n```\n\nHow can I achieve this using pandas string manipulation methods? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'info': ['John Doe: 28: john@example.com', \n                             'Jane Smith: 35: jane@example.com',\n                             'Sam Johnson: 22: sam@example.com',\n                             'Lisa Lee: 30: lisa@example.com']})\n</code>\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf[['Name', 'Age', 'Email']] = df['info'].str.split(': ', expand=True)"
  },
  {
    "input": "Problem:\n\nI have a tensor in PyTorch representing some raw input data:\n\ntensor([[0.1, 0.2, 0.3],\n        [0.4, 0.5, 0.6],\n        [0.7, 0.8, 0.9]])\n\nI would like to normalize this tensor along the second dimension (columns), so that each element is divided by the maximum element of its column. How can I achieve this without using a loop?\n\nA:\n\n<code>\nimport torch\ndata = torch.tensor([[0.1, 0.2, 0.3],\n                     [0.4, 0.5, 0.6],\n                     [0.7, 0.8, 0.9]])\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \n\n",
    "output": "\n<code>\nnormalized_data = data / data.max(dim=0, keepdim=True).values\n</code>"
  },
  {
    "input": "Problem:\nYou are working on a neural network model for image classification using TensorFlow. You have a batch of images represented as a 4D tensor and want to apply a dropout layer to prevent overfitting. The dropout rate is specified and you need to ensure that the dropout is applied correctly. Assuming `images` is your input tensor with shape (batch_size, height, width, channels), fill in the blank to apply the dropout layer with the specified rate.\n\nA:\n<code>\nimport tensorflow as tf\n\nimages = tf.random.normal((32, 64, 64, 3))  # Example shape for a batch of images\ndropout_rate = 0.5\n</code>\noutput = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\noutput = tf.keras.layers.Dropout(rate=dropout_rate)(images)\n</code>",
    "output": "\n<code>\noutput = tf.keras.layers.Dropout(rate=dropout_rate)(images, training=True)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains product sales data with the following columns: 'product_id', 'sales', and 'returns'. The aim is to create a new DataFrame that summarizes this data by calculating the net sales for each product (which is defined as sales minus returns). Additionally, if the net sales are negative, we want to store 'Low' in a new column; if they are zero, store 'None'; and if they are positive, store 'High'.\n\nHere is what the DataFrame looks like:\n\nproduct_id  sales  returns\n1           150    10\n2           200    50\n3           100    200\n4           300    0\n5           50     100\n\nI need a function that computes the net sales and labels them accordingly, producing a new DataFrame with 'product_id', 'net_sales', and 'sales_label'.\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 3, 4, 5],\n    'sales': [150, 200, 100, 300, 50],\n    'returns': [10, 50, 200, 0, 100]\n})\n\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.copy()\nresult['net_sales'] = result['sales'] - result['returns']\nresult['sales_label'] = result['net_sales'].apply(lambda x: 'Low' if x < 0 else ('None' if x == 0 else 'High'))\nresult = result[['product_id', 'net_sales', 'sales_label']]\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing hourly temperature measurements recorded over several days. The DataFrame looks as follows:\n\n```python\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```\n\nYou need to calculate the daily average temperature and include it in the original DataFrame with a new column named `Daily_Avg`. The output should have the same rows as the original DataFrame, but with the daily average values appropriate for each timestamp's date. \n\nWhat code would you use to achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Timestamp': [\n        '2023-01-01 00:00:00', '2023-01-01 01:00:00', '2023-01-01 02:00:00',\n        '2023-01-02 00:00:00', '2023-01-02 01:00:00', '2023-01-02 02:00:00'],\n    'Temperature': [22.1, 21.8, 21.5, 22.3, 22.1, 21.9]\n}\ndf = pd.DataFrame(data)\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n</code>\ndf['Daily_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Daily_Avg'] = df.groupby(df['Timestamp'].dt.date)['Temperature'].transform('mean')  \n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing features in a tensor format and I want to normalize these features using TensorFlow. The tensor `data` has a shape of (100, 10) representing 100 samples and 10 features. I want to scale these features to a range of [0, 1]. How can I efficiently perform this normalization operation?\n\nA:\n\n<code>\nimport tensorflow as tf\n\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = (data - tf.reduce_min(data, axis=0)) / (tf.reduce_max(data, axis=0) - tf.reduce_min(data, axis=0))</code>"
  },
  {
    "input": "## Problem\nGiven a DataFrame that contains product information with a column named `ProductID` and `Description`, you would like to extract the numeric part of the `ProductID` which follows the format 'PROD-###' (where ### is a numeric sequence) and create a new column called `ProductNumber`. Additionally, you want to concatenate this extracted number with the first 5 characters of the `Description` column to form a new column called `ProductKey`.\n\nFor instance, if your DataFrame looks like this:\n\n```\n   ProductID       Description\n0   PROD-001   Widget A - Red\n1   PROD-002   Widget B - Blue\n2   PROD-003   Gadget C - Green\n3   PROD-004   Device D - Yellow\n```\n\nThe resulting DataFrame should look like:\n\n```\n   ProductID       Description  ProductNumber   ProductKey\n0   PROD-001   Widget A - Red           001         001Wi\n1   PROD-002   Widget B - Blue          002         002Wi\n2   PROD-003   Gadget C - Green         003         003Gad\n3   PROD-004   Device D - Yellow        004         004Dev\n```\n\nGiven this DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': ['PROD-001', 'PROD-002', 'PROD-003', 'PROD-004'],\n    'Description': ['Widget A - Red', 'Widget B - Blue', 'Gadget C - Green', 'Device D - Yellow']\n}\n\ndf = pd.DataFrame(data)\n```\n\nComplete the following code to derive the `ProductNumber` and `ProductKey` columns:\n\n```python\ndf['ProductNumber'] = df['ProductID'].str.extract('(\\d+)')\ndf['ProductKey'] = df['ProductNumber'] + df['Description'].str[:5]\n```\nImplement the solution by filling in the blank in the provided code:\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df\n```"
  },
  {
    "input": "### Problem:\nI have a DataFrame containing various product reviews, and one of the columns is a string containing product details in the format \"Product_Name (Category) - Review_Score\". The DataFrame looks like this:\n\n```\n       Reviews\n0  Laptop (Electronics) - 5\n1  Coffee Maker (Home) - 4\n2  Phone (Electronics) - 3\n3  Blender (Home) - 5\n4  Camera (Electronics) - 4\n```\n\nI would like to separate the product name, category, and review score into three distinct columns named 'Product', 'Category', and 'Score'. How can I achieve this to transform my DataFrame into the following format?\n\n```\n      Product       Category  Score\n0      Laptop      Electronics     5\n1  Coffee Maker        Home         4\n2      Phone       Electronics     3\n3     Blender         Home         5\n4     Camera       Electronics     4\n```\n\nHere's my initial code, which only creates the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'Reviews': ['Laptop (Electronics) - 5', \n                    'Coffee Maker (Home) - 4', \n                    'Phone (Electronics) - 3', \n                    'Blender (Home) - 5', \n                    'Camera (Electronics) - 4']}\ndf = pd.DataFrame(data)\n```\n\nI need to fill in the blank for the transformation:\n\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>df[['Product', 'Category', 'Score']] = df['Reviews'].str.extract(r'(.+?) \\((.+?)\\) - (\\d+)')</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains monthly sales data for a retail store as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': ['2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06'],\n    'Sales': [200, 150, 300, 250, 400, 350]\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to calculate the month-over-month percentage change in sales and add this as a new column called 'Percentage Change'. The first row will be marked as NaN (Not a Number) since there is no previous month to compare it to. \n\nThe desired output should look like this:\n\n```\n     Month  Sales  Percentage Change\n0  2021-01    200                 NaN\n1  2021-02    150                -25.0\n2  2021-03    300                100.0\n3  2021-04    250                -16.67\n4  2021-05    400                60.0\n5  2021-06    350                -12.5\n```\n\nI need help with the following code:\n\n```python\ndf['Percentage Change'] = df['Sales'].pct_change() * 100\n```\n\nPlease fill in the blank to apply this in the context of the given DataFrame. \nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df\ndf['Percentage Change'] = df['Sales'].pct_change() * 100\n```"
  },
  {
    "input": "Problem:\n\nI have a 2D sparse tensor using PyTorch, representing an adjacency matrix for a graph. The tensor has shape (5, 5) but is mostly empty, as the graph is sparse. I want to create a dense representation from this sparse tensor in a way that efficiently handles the zeros.\n\nThe sparse tensor is created as follows:\n\n```python\nimport torch\nfrom torch.nn import functional as F\n\nsparse_tensor = torch.sparse_coo_tensor(\n    indices=torch.tensor([[0, 1, 2], [1, 2, 3]]),\n    values=torch.tensor([1, 2, 3]),\n    size=(5, 5)\n)\n```\n\nTo convert this sparse tensor to a dense tensor without creating unnecessary overhead from the zeros, you can use the `to_dense` method. However, I noticed that I would like to efficiently handle the conversion without it leading to memory issues when the tensor is particularly large.\n\nA:\n```python\nsparse_tensor = torch.sparse_coo_tensor(indices, values, size=(5, 5))\n```\ndense_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndense_tensor = sparse_tensor.to_dense()\n```"
  },
  {
    "input": "### Problem:\nYou have a DataFrame that contains a list of customer feedback comments and their ratings. Each comment may have additional notes that you want to extract. The feedback has a specific format where each comment follows the structure: \"Comment: {text} | Note: {note}\". You want to extract the notes and create a new column in your DataFrame for those notes.\n\nGiven the following DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'Feedback': [\n        'Comment: Great service! | Note: Quick delivery',\n        'Comment: Not satisfied | Note: Late arrival',\n        'Comment: Decent experience | Note: Could be better',\n        'Comment: Excellent | Note: Will recommend',\n        'Comment: Poor quality | Note: Did not meet expectations'\n    ]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the blank code below to create a new column `Extracted_Note` that holds only the note part from the `Feedback` column.\n\nA:\n```python\ndf['Extracted_Note'] = df['Feedback'].str.extract(r'\\| Note: (.*)')\n```",
    "output": "\n```python\ndf['Extracted_Note'] = df['Feedback'].str.extract(r'\\| Note: (.+)')\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame that contains information about sales transactions, structured like this:\n\n```\n   transaction_id    product_id    quantity\n0               1            101          2\n1               2            102          4\n2               3            103          1\n3               4            101          3\n4               5            102          2\n```\n\nI want to create a function that computes the total quantity sold for each product and returns a new DataFrame that lists each unique `product_id` along with its corresponding total quantity sold. \n\nHere\u2019s how the DataFrame should look after the operation:\n\n```\n   product_id    total_quantity\n0          101               5\n1          102               6\n2          103               1\n```\n\nWhat code can I use to achieve this? \n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4, 5],\n    'product_id': [101, 102, 103, 101, 102],\n    'quantity': [2, 4, 1, 3, 2]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('product_id', as_index=False)['quantity'].sum().rename(columns={'quantity': 'total_quantity'})\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset that contains daily temperature readings for a city over a span of two months. The DataFrame looks like this:\n\n```\n          date  temperature\n0   2023-01-01          30\n1   2023-01-02          32\n2   2023-01-03          31\n3   2023-01-04          29\n4   2023-01-05          33\n..         ...         ...\n57  2023-02-26          28\n58  2023-02-27          30\n59  2023-02-28          31\n```\n\nYou need to calculate the rolling average temperature over a 7-day window and format the result to include the date as `dd-MMM-YYYY`. The rolling average should be appended as a new column in the DataFrame and the output should display the date and the rolling average temperature.\n\nThe provided code initializes the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=59, freq='D'),\n        'temperature': [30, 32, 31, 29, 33, 28, 27, 26, 30, 32, 31, 29, 33, 28, 27, 26, \n                        30, 31, 32, 29, 30, 28, 27, 26, 30, 32, 29, 38, 28, 27, 32, \n                        36, 38, 37, 40, 35, 30, 28, 29, 30, 31, 28, 27, 29, 30, \n                        31, 28, 26, 30, 31, 29, 30, 28, 31, 28, 30, 31]} \n\ndf = pd.DataFrame(data)\n```\n\nWhat code should you use to create a new column `rolling_avg` in the DataFrame, which contains the rolling average temperature, formatted properly?\n\n```python\ndf['rolling_avg'] = ...\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['temperature'].rolling(window=7).mean().round(2)\ndf['date'] = df['date'].dt.strftime('%d-%b-%Y')\n```"
  },
  {
    "input": "Problem:\nI have a daily sales record in a DataFrame as follows:\n\n```\nimport pandas as pd\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n    'Sales': [200, 220, 250, 270, 300, 320, 340, 360, 380, 400]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the 3-day moving average of the sales. The result should be a Series with the same index but showing `NaN` for the first two days as there are not enough data points to compute the average.\n\nHow can I obtain this moving average?\n\nA:\n```python\nmoving_average = df['Sales'].rolling(window=3).mean()\n```",
    "output": "\n<code>\nmoving_average = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a pandas dataframe that contains sales data structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Sales_Q1': [100, 150, 200, 250, 300],\n    'Sales_Q2': [110, 160, 220, 240, 310],\n    'Sales_Q3': [120, 170, 230, 260, 320],\n    'Sales_Q4': [130, 180, 240, 270, 330]\n})\n```\n\nI want to create a new column that calculates the total annual sales for each product by summing the sales from all four quarters. I want to implement this calculation in a reusable function called `calculate_annual_sales()` that takes the dataframe as an argument and returns the modified dataframe with the new column.\n\nThe resulting dataframe should look like this:\n\n```python\n  Product  Sales_Q1  Sales_Q2  Sales_Q3  Sales_Q4  Total_Sales\n0       A       100       110       120       130          460\n1       B       150       160       170       180          660\n2       C       200       220       230       240          890\n3       D       250       240       260       270         1020\n4       E       300       310       320       330         1260\n```\n\nHere is what I have so far:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Sales_Q1': [100, 150, 200, 250, 300],\n    'Sales_Q2': [110, 160, 220, 240, 310],\n    'Sales_Q3': [120, 170, 230, 260, 320],\n    'Sales_Q4': [130, 180, 240, 270, 330]\n})\n\ndef calculate_annual_sales(df):\n    df['Total_Sales'] = ...\n    return df\n```\n\nCan you help me fill in the blank with the correct implementation?",
    "output": "\n```python\n    df['Total_Sales'] = df[['Sales_Q1', 'Sales_Q2', 'Sales_Q3', 'Sales_Q4']].sum(axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI have a large sparse matrix represented as a `csr_matrix` in SciPy that contains customer purchase data across different product categories. Each customer is a row, and each product category is a column. Some product categories may have missing data (zeros), which I want to identify. \n\nTo optimize for memory, I would like to find the indices of all non-zero elements in the sparse matrix and store them in a list of tuples, each representing the (row_index, column_index) pairs. For example, if I have a sparse matrix that looks like this:\n\n```\n[[0, 1, 0],\n [0, 0, 3],\n [4, 0, 0]]\n```\n\nThe output should be:\n```\n[(0, 1), (1, 2), (2, 0)]\n```\n\nHow can I achieve this using the `tocoo()` method of the sparse matrix to get the necessary indices?\n\nA:\n<code>\nfrom scipy import sparse\n\n# Assuming `sparse_matrix` is your csr_matrix\nsparse_matrix = sparse.csr_matrix([[0, 1, 0], [0, 0, 3], [4, 0, 0]])\n</code>\nnon_zero_indices = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnon_zero_indices = list(zip(*sparse_matrix.nonzero()))\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains sales data for different products across several months. I would like to create a custom function that computes the total sales for each product over a specified range of months. The DataFrame looks like this:\n\n```\n   Month  Product_A  Product_B  Product_C\n0      1         200        150        300\n1      2         250        200        350\n2      3         300        250        400\n3      4         350        300        450\n4      5         400        350        500\n```\n\nThe function should take the month range as input (e.g., from month 2 to month 4) and return the total sales for each product in that range. I want to call this function that I will define as `calculate_total_sales(df, start_month, end_month)`. Here\u2019s how you can initialize the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Month': [1, 2, 3, 4, 5],\n    'Product_A': [200, 250, 300, 350, 400],\n    'Product_B': [150, 200, 250, 300, 350],\n    'Product_C': [300, 350, 400, 450, 500]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, write the function call to compute the total sales from month 2 to month 4:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndef calculate_total_sales(df, start_month, end_month):\n    filtered_df = df[(df['Month'] >= start_month) & (df['Month'] <= end_month)]\n    total_sales = filtered_df[['Product_A', 'Product_B', 'Product_C']].sum()\n    return total_sales\n\nresult = calculate_total_sales(df, 2, 4)\n```"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame with a column of addresses that look like this:\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n\nI want to extract the city and state from each address and create separate columns for them. If the address does not contain a state, I want the state column to be None.\n\nThe final DataFrame should look like this:\n\naddress                     city          state\n0 123 Main St, Springfield, IL  Springfield            IL\n1 456 Elm St, Gotham City, NY  Gotham City            NY\n2 789 Oak St, Metropolis, CA  Metropolis            CA\n3 101 Maple Ave, Star City, TX  Star City            TX\n\nI've attempted to use string manipulation to achieve this, but I'm unsure how to split and extract the components correctly. Can you help me get this working?\n\nA:\n<code>\nimport pandas as pd\n\naddress_df = pd.DataFrame({'address': ['123 Main St, Springfield, IL', \n                                       '456 Elm St, Gotham City, NY', \n                                       '789 Oak St, Metropolis, CA', \n                                       '101 Maple Ave, Star City, TX']})\n</code>\naddress_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\naddress_df[['city', 'state']] = address_df['address'].str.extract(r',\\s*([^,]+),\\s*([A-Z]{2})$')\n</code>"
  },
  {
    "input": "### Problem\nYou have a dataset with multiple sales records, and you want to calculate the total sales per product while ensuring that the code is reusable for any product. You have a DataFrame `df` that contains sales data structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C'],\n    'Sales': [100, 150, 200, 300, 250, 400, 150, 300, 350],\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a function `calculate_total_sales(product)` that takes a product name as input and returns the total sales for that product. \n\nYour current implementation to call the function looks like this:\n\n```python\ntotal_sales_A = calculate_total_sales('A')\n```\n\nWhat do you need to fill in for the function `calculate_total_sales` to achieve this? \n\n<!-- The variable to put your solution inside -->\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>",
    "output": "\n```python\n<code> \ndef calculate_total_sales(product):\n    return df[df['Product'] == product]['Sales'].sum()\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI'm working on a sentiment analysis project using TensorFlow and I have a tensor containing the embeddings of sentences. The shape of my tensor is (50, 300), representing 50 sentences each with 300 features. I want to create a simple feedforward model with TensorFlow that predicts sentiment scores between 0 and 1. I am looking for the appropriate layer to use in TensorFlow to achieve this output shape of (50, 1) after applying a dense layer to my input tensor. \n\nWhat should I use to create this single output layer?\n\nA:\n<code>\nimport tensorflow as tf\n\ninput_tensor = tf.random.uniform((50, 300))\nmodel = tf.keras.Sequential()\n# Add an appropriate layer below to predict sentiment scores\n### BEGIN SOLUTION",
    "output": "\n<code>\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working on a recommendation system where user-item interactions are represented as a sparse tensor. The shapes of the tensors for users and items are both (num_users, num_items, num_features). I need to compute a similarity score for each user against all items based on the non-zero interactions in this sparse tensor. \n\nGiven the sparse interaction tensor `interaction_tensor`, how would I create a mask that represents only the non-zero interactions for all users and items, where the tensor components are in the form:\n\ninteraction_tensor[user_index, item_index, feature_index] = value\n\nFor example:\n\ninteraction_tensor = [[[[0, 0], [1, 0]], [[0, 0], [0, 2]]], \n                      [[[0, 3], [0, 0]], [[4, 0], [0, 0]]]]\n\nI want to get a mask like this:\n\nmask = [[[[0, 0], [1, 0]], [[0, 0], [0, 1]]], \n        [[[0, 1], [0, 0]], [[1, 0], [0, 0]]]]\n\nA:\n<code>\nimport numpy as np\nimport torch\ninteraction_tensor = load_data()\n</code>\nmask = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmask = (interaction_tensor != 0).int()\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing monthly sales data for a retail store over two years, structured as follows:\n\n```\n           month   sales\n0    2022-01-01    5000\n1    2022-02-01    6000\n2    2022-03-01    7000\n3    2022-04-01    8000\n4    2022-05-01    9000\n5    2022-06-01    10000\n6    2022-07-01    11000\n7    2022-08-01    12000\n8    2022-09-01    13000\n9    2022-10-01    14000\n10   2022-11-01    15000\n11   2022-12-01    16000\n12   2023-01-01    17000\n13   2023-02-01    18000\n14   2023-03-01    19000\n15   2023-04-01    20000\n```\n\nYou wish to calculate the moving average of sales over the last three months while ensuring that the DataFrame keeps the same length and that NaN values are filled with the average of the available previous figures when not enough data points exist. What code would fill in the blank below to accomplish this?\n\n```python\nimport pandas as pd\n\ndata = {\n    'month': pd.date_range(start='2022-01-01', periods=16, freq='MS'),\n    'sales': [5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000]\n}\ndf = pd.DataFrame(data)\n\nmoving_average = df['sales'].__________\nprint(moving_average)\n```\nA:\n<code>\n",
    "output": "\n```python\nmoving_average = df['sales'].rolling(window=3, min_periods=1).mean()\n```"
  },
  {
    "input": "Problem:\n\nI have a pandas DataFrame with a column 'product_info' that contains strings representing product details in the format: \"ProductName - Brand - Price\". For example:\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n\nI want to create a new DataFrame that extracts the 'ProductName' and 'Price' into separate columns while removing the 'Brand' from 'product_info'. If 'product_info' does not adhere to the expected format, I want it to remain unchanged.\n\nThe expected output is:\n\n  ProductName       Price\n0      Laptop   1200 USD\n1  Smartphone    999 USD\n2   Smartwatch    300 USD\n3      Laptop   1150 USD\n\nHere is my starting point:\n\n<code>\nimport pandas as pd\n\nproduct_data = pd.DataFrame({\n    'product_info': [\n        'Laptop - Dell - 1200 USD',\n        'Smartphone - Apple - 999 USD',\n        'Smartwatch - Samsung - 300 USD',\n        'Laptop - HP - 1150 USD'\n    ]\n})\n</code>\nnew_df = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnew_df = product_data['product_info'].str.extract(r'([^ -]+) - [^-]+ - (.+)')[0].rename('ProductName').to_frame().join(\n    product_data['product_info'].str.extract(r'[^ -]+ - [^-]+ - (.+)')[0].rename('Price')\n)\n</code>"
  },
  {
    "input": "Problem:\nYou are analyzing a time series of daily temperatures over a month. You have a DataFrame that records the date and temperature for each day, but there are some missing days. Your goal is to fill in the missing dates and impute the temperature on those dates with the average temperature of their neighboring dates. \n\nHere is the DataFrame you start with:\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05', '2023-01-07', '2023-01-08'],\n    'temperature': [30, 32, 31, 29, 28, 30]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nYou need to expand the DataFrame to include all dates from `2023-01-01` to `2023-01-08`, filling the missing dates with the average temperature of their immediate neighbors.\n\nFill in the following line with the required code to achieve this:\n```python\nfilled_df = ... # insert your solution here\n```",
    "output": "\n```python\nfilled_df = df.set_index('date').reindex(pd.date_range(start='2023-01-01', end='2023-01-08')).interpolate(method='linear').reset_index()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of employees in a company represented as a Pandas dataframe with their details as shown below:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [101, 102, 103, 104, 105],\n    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'salary': [70000, 80000, 60000, 75000, 85000],\n    'department': ['HR', 'Engineering', 'HR', 'Marketing', 'Engineering']\n})\n```\n\nYou need to create a function called `average_salary_by_department` that takes this dataframe as an input and returns a new dataframe showing the average salary for each department. The resulting dataframe should have two columns: `department` and `average_salary`.\n\nFor example, the output should look like this:\n\n```\n    department  average_salary\n0  Engineering         82500.0\n1             HR         65000.0\n2      Marketing         75000.0\n```\n\nPlease fill in the code below to complete your solution.\n\n```python\nresult = ...\ndef average_salary_by_department(df):\n    ...\n```",
    "output": "\n```python\nresult = df.groupby('department')['salary'].mean().reset_index(name='average_salary')\ndef average_salary_by_department(df):\n    return result\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing customer orders, and you want to calculate the total quantity of items ordered per customer. Your dataset looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['C001', 'C002', 'C001', 'C003', 'C002', 'C001', 'C003'],\n    'OrderID': [101, 102, 103, 104, 105, 106, 107],\n    'Quantity': [5, 3, 2, 4, 1, 7, 8]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a function that sums the quantities for each customer and returns the results in a new DataFrame with columns: `CustomerID` and `TotalQuantity`. \n\nA:\n```python\n# Define your function here\ndef calculate_total_quantity(df):\n    ...\n```\n\nUse this function to get the total quantities for each customer. For the provided data, the expected result should look like:\n\n```\n  CustomerID  TotalQuantity\n0       C001             14\n1       C002              4\n2       C003             12\n```\n\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndef calculate_total_quantity(df):\n    return df.groupby('CustomerID', as_index=False)['Quantity'].sum().rename(columns={'Quantity': 'TotalQuantity'})\n\nresult = calculate_total_quantity(df)\n```"
  },
  {
    "input": "### Problem:\nYou have a time series dataset representing the daily average temperature (in degrees Celsius) recorded over several months. The dataset contains two columns: `Date` and `Temperature`. Your task is to calculate a 7-day rolling average for the temperature values.\n\nHere is an example of your DataFrame:\n\n```\n        Date      Temperature\n0  2023-01-01             15.0\n1  2023-01-02             16.0\n2  2023-01-03             14.0\n3  2023-01-04             17.0\n4  2023-01-05             15.0\n5  2023-01-06             20.0\n6  2023-01-07             18.0\n7  2023-01-08             19.0\n8  2023-01-09             20.0\n9  2023-01-10             22.0\n```\n\nThe resulting DataFrame should display the date and the rolling average temperature for the past 7 days in a new column named `7-Day Average Temperature`.\n\nImplement the code to compute this without using any explicit loops.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', \n                 '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10'],\n        'Temperature': [15.0, 16.0, 14.0, 17.0, 15.0, 20.0, 18.0, 19.0, 20.0, 22.0]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\ndf['7-Day Average Temperature'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['7-Day Average Temperature'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a time series data set containing daily temperature readings for a month. The data is represented as a pandas DataFrame with a `Date` column and a `Temperature` column. I want to compute a new column `7_day_avg` that contains the average temperature of the past 7 days for each entry, while handling the first 6 days where there aren't enough previous entries for a full 7-day average (you can set those values to NaN). \n\nHere is an example of my DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n    'Temperature': np.random.randint(low=-10, high=35, size=30)\n}\ndf = pd.DataFrame(data)\n```\n\nWhat is the code to calculate the `7_day_avg` column in this DataFrame? Fill in the blank below:\n\nA:\n<code>\ndf['7_day_avg'] = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf['7_day_avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame containing daily temperature data for a city over several months, structured like this:\n\n```\n          Date        Temperature\n0   2023-01-01        15.0\n1   2023-01-02        16.5\n2   2023-01-03        15.5\n3   2023-02-01        14.0\n4   2023-02-02        13.5\n5   2023-03-01        16.0\n6   2023-03-02        18.0\n7   2023-03-03        17.5\n```\n\nI want to calculate the rolling average temperature over a window of 7 days and then return the DataFrame with an additional column showing these rolling averages. The resulting DataFrame should look like this:\n\n```\n          Date        Temperature  Rolling_Avg\n0   2023-01-01        15.0            NaN\n1   2023-01-02        16.5            NaN\n2   2023-01-03        15.5            NaN\n3   2023-02-01        14.0            NaN\n4   2023-02-02        13.5            NaN\n5   2023-03-01        16.0          15.2\n6   2023-03-02        18.0          15.8\n7   2023-03-03        17.5          16.5\n```\n\nI've started by creating the DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', \n                 '2023-02-01', '2023-02-02', '2023-03-01', \n                 '2023-03-02', '2023-03-03'], \n        'Temperature': [15.0, 16.5, 15.5, 14.0, 13.5, 16.0, 18.0, 17.5]}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, I need to compute the rolling average. Can you help me fill in the blank in this code?\n```python\ndf['Rolling_Avg'] = df['Temperature'].___(window=7)\n```\nBEGIN SOLUTION\n<code>rolling</code>",
    "output": "\n<code>rolling</code>"
  },
  {
    "input": "Problem:\n\nI am working on a voice recognition project using PyTorch. I have a training dataset where each input sample is a spectrogram tensor of shape (50, 30), representing frequencies over time, and the corresponding labels are in a tensor of shape (50,) containing class indices. I want to transform these spectrograms to eliminate any silence regions so that the output tensor retains only the relevant frequencies that have non-zero values, while preserving the original shape's aspect ratio. The silence regions are represented by zeros. \n\nHere's how I have my tensors set up:\n\nspectrograms: shape (50, 30)\nlabels: shape (50,)\n\nI want to perform this operation using a masking technique that results in a tensor that retains only the non-zero entries while keeping them structured as a 2D tensor.\n\nFill in the code below to accomplish this task:\n\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = ...\n</code>\n",
    "output": "\n<code>\nimport torch\n\nspectrograms = load_spectrograms()  # Assume this function loads a tensor of shape (50, 30)\nmask = spectrograms != 0\nfiltered_spectrograms = spectrograms[mask].view(-1, spectrograms.size(1))\n</code>"
  },
  {
    "input": "Problem:\nI am working with a dataset containing information about users and their activity on a website. There are several unique user IDs, and I want to categorize users based on their number of visits into three groups: \"High\", \"Medium\", and \"Low\". The definitions for these groups are as follows: \n\n- \"High\" for users with more than 20 visits\n- \"Medium\" for users with between 11 and 20 visits\n- \"Low\" for users with 10 or fewer visits\n\nCurrently, I have a DataFrame as shown below:\n\n```\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 2, 3, 4, 5],\n    'visits': [25, 14, 10, 31, 8]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to create a new column in this DataFrame called \"activity_level\" that will contain the activity level of each user based on the number of visits. I would like to implement a custom function to determine the activity level for reuse in the DataFrame.\n\nHow can I structure the code to achieve this?\n\nA:\n<code>\ndef categorize_activity(visits):\n    # return the activity level based on visits\n    pass\n\nresult = ...\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef categorize_activity(visits):\n    if visits > 20:\n        return \"High\"\n    elif 11 <= visits <= 20:\n        return \"Medium\"\n    else:\n        return \"Low\"\n\ndf['activity_level'] = df['visits'].apply(categorize_activity)\n</code>"
  },
  {
    "input": "Problem:\nI am working with a pandas DataFrame that contains sales data for a retail store. The DataFrame looks like this:\n\n```\nstore_id    sale_date      sale_amount\n1           2023-01-01     200.00\n1           2023-01-02     150.00\n1           2023-01-03     300.00\n2           2023-01-01     250.00\n2           2023-01-03     350.00\n2           2023-01-05     300.00\n```\n\nI want to calculate the rolling average of the `sale_amount` for each store over a window of 2 days but want to ensure that the rolling average includes only values from same store and looks like this:\n\n```\nstore_id    sale_date      sale_amount  rolling_avg\n1           2023-01-01     200.00       200.00\n1           2023-01-02     150.00       175.00\n1           2023-01-03     300.00       225.00\n2           2023-01-01     250.00       250.00\n2           2023-01-03     350.00       300.00\n2           2023-01-05     300.00       325.00\n```\n\nHow can I achieve this using pandas? \n\nHere is the code to create the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'store_id': [1, 1, 1, 2, 2, 2],\n    'sale_date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-03', '2023-01-05']),\n    'sale_amount': [200.00, 150.00, 300.00, 250.00, 350.00, 300.00]\n}\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['rolling_avg'] = df.groupby('store_id')['sale_amount'].apply(lambda x: x.rolling(window=2, min_periods=1).mean())\n```"
  },
  {
    "input": "Problem:\nI have a sparse matrix represented in coordinate format (COO) and I'm trying to convert it into a dense NumPy array while rearranging the non-zero values in a specific order. The sparse matrix is as follows:\n\n```\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\n```\n\nThis creates a sparse matrix where only the specified (row, col) pairs have non-zero values. I want to convert this sparse matrix into a dense 3x3 NumPy array in a way that the values appear in descending order of their row indices first, and if there are duplicates in the row indices, they should be sorted by their column indices. \n\nHow can I achieve this? \n\nA:\n<code>\nimport numpy as np\nfrom scipy.sparse import coo_matrix\n\n# Create the sparse matrix\nrow = [0, 3, 1, 0, 1, 2]\ncol = [0, 1, 1, 2, 0, 2]\ndata = [1, 2, 3, 4, 5, 6]\nsparse_matrix = coo_matrix((data, (row, col)), shape=(3, 3))\n</code>\ndense_array = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndense_array = np.zeros((3, 3))\nsorted_indices = sorted(zip(row, col, data), key=lambda x: (-x[0], x[1]))\nfor r, c, v in sorted_indices:\n    dense_array[r, c] = v\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing customer feedback messages that may include a rating scale from 1 to 5 (e.g., \"5 stars\"). The DataFrame looks like this:\n\n```\nfeedback\n0   Great service, 5 stars!\n1   Not what I expected, 2 stars.\n2   Mediocre experience, 3.\n3   Excellent, 4 ratings given.\n4   Would not recommend, 1 star available.\n```\n\nYou want to extract the rating from each feedback entry into a new column called \"rating\". If there is no rating present, the new column should contain NaN. The final DataFrame should look like this:\n\n```\nfeedback                                 rating\n0   Great service, 5 stars!               5\n1   Not what I expected, 2 stars.         2\n2   Mediocre experience, 3.                3\n3   Excellent, 4 ratings given.            4\n4   Would not recommend, 1 star available. 1\n```\n\nHere is the initial setup for your DataFrame:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'feedback': [\n        'Great service, 5 stars!',\n        'Not what I expected, 2 stars.',\n        'Mediocre experience, 3.',\n        'Excellent, 4 ratings given.',\n        'Would not recommend, 1 star available.'\n    ]\n})\n```\n\nWhat code should you use to create the \"rating\" column? \n\ndf['rating'] = df.feedback.replace(r'.*(\\d)\\s*stars.*', r'\\1', regex=True)",
    "output": "\n```python\ndf['rating'] = df.feedback.str.extract(r'(\\d)\\s*stars?')[0].astype(float)\n```"
  },
  {
    "input": "Problem:\nI have a list of employee records where each record contains an employee's name and their respective department. I want to create a function that organizes these records into a dictionary, where each key is a department name and the corresponding value is a list of employee names belonging to that department. \n\nThe input is a list structured like this:\n\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\nHow can I implement such a function that populates a dictionary with this information? \n\nPlease define the function to achieve this task and output the result into the variable 'department_dict'. \n\n<code>\nrecords = [\n    ('Alice', 'HR'),\n    ('Bob', 'Finance'),\n    ('Charlie', 'HR'),\n    ('David', 'Finance'),\n    ('Eve', 'Marketing'),\n]\n\n### Define the function and populate the department_dict variable\n</code>\ndepartment_dict = ... # put solution in this variable",
    "output": "\n<code>\ndef organize_records(records):\n    department_dict = {}\n    for name, department in records:\n        if department not in department_dict:\n            department_dict[department] = []\n        department_dict[department].append(name)\n    return department_dict\n\ndepartment_dict = organize_records(records)\n</code>"
  },
  {
    "input": "## Problem:\nI am working on a time series prediction model using PyTorch. I have defined a simple recurrent neural network (RNN) model, and I want to train it on a dataset of sequential data. However, I'm encountering an issue with the input tensor sizes. The input tensor should be of shape `(sequence_length, batch_size, input_size)`. \n\nHere is the structure of my dataset:\n\n```python\nimport torch\n\n# Sample data where each entry is a sequence of length 5 and input size is 1\ndata = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0], \n                     [6.0], [7.0], [8.0], [9.0], [10.0]])\n```\n\nI want to reshape this data into the correct format for the RNN. The expected shape is `(5, 2, 1)` which means 5 time steps, 2 sequences in a batch, and 1 feature. \n\nHow can I reshape my data into the required input format for the RNN?\n\nA:\n```python\nimport torch\n\ndata = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0], \n                     [6.0], [7.0], [8.0], [9.0], [10.0]])\n\n# Reshape the data into the expected input format for RNN\ndata = data.view(...)  # Fill in the appropriate transformation here\n```",
    "output": "\n```python\ndata = data.view(5, 2, 1)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing product descriptions, and I want to extract the product names and their respective prices from a column that combines both elements into a single string. The format is as follows: \"ProductName - $Price\". I need to split this into two separate columns: 'ProductName' and 'Price'. My DataFrame looks like this:\n\ndescription\n0   \"Laptop - $999.99\"\n1   \"Smartphone - $499.49\"\n2   \"Tablet - $299.00\"\n3   \"Monitor - $199.99\"\n\nI've managed to apply some string methods but can't figure out how to effectively create these new columns. \n\nExpected output:\n\nProductName      Price  \n0   Laptop         999.99  \n1   Smartphone     499.49  \n2   Tablet         299.00  \n3   Monitor        199.99  \n\nHere's the starting code:\n\nimport pandas as pd\n\ndf = pd.DataFrame({'description': ['Laptop - $999.99', \n                                    'Smartphone - $499.49', \n                                    'Tablet - $299.00', \n                                    'Monitor - $199.99']})\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = df['description'].str.split(' - \\$', expand=True)\nresult.columns = ['ProductName', 'Price']\nresult['Price'] = result['Price'].astype(float)\n</code>"
  },
  {
    "input": "Problem:\nI have a time series DataFrame containing daily temperature readings for a city over a year, indexed by date. I want to calculate a rolling average temperature over the last 7 days for each date. After calculating the rolling average, I want to create a new DataFrame that contains only the dates where the rolling average was above a specified threshold. The DataFrame is defined as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range(start='2023-01-01', periods=365)\ntemperatures = np.random.normal(loc=20, scale=5, size=len(dates))  # Average temperature around 20\u00b0C\ntemp_df = pd.DataFrame(data=temperatures, index=dates, columns=['Temperature'])\n```\n\nNow, I want to extract the dates where the rolling average is greater than a threshold of 22\u00b0C. To achieve this, I'm looking to complete the following code:\n\n```python\nrolling_avg = temp_df['Temperature'].rolling(window=7).mean()\nfiltered_dates = ... # put solution in this variable\n```\n",
    "output": "\n```python\nfiltered_dates = temp_df[rolling_avg > 22].index\n```"
  },
  {
    "input": "## Problem\n\nYou are tasked with training a simple neural network using both TensorFlow and PyTorch to classify images of handwritten digits (from the MNIST dataset). You need to preprocess the images by normalizing the pixel values to the range [0, 1] and then create a model that consists of one hidden layer with 128 neurons and a ReLU activation function. Finally, you will compile and train the model using the Adam optimizer and categorical crossentropy loss.\n\nGiven a TensorFlow and PyTorch setup, you have the following variable declarations:\n\n```python\nimport tensorflow as tf\nimport torch\nfrom torchvision import datasets, transforms\n\n# TensorFlow part\ntrain_images = tf.keras.datasets.mnist.load_data()[0][0]\nnormalized_images_tf = train_images.astype('float32') / 255.0\n\n# PyTorch part\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_images_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\nYou need to define the model architecture and the training process in TensorFlow:\n\n```python\nmodel_tf = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```\n\nYour task is to fill in the training code for the TensorFlow model to fit the normalized_images_tf. Please provide the code snippet that goes in the blank below:\n\n```python\nmodel_tf.fit(_____, epochs=5)\n```",
    "output": "\n```python\nnormalized_labels_tf = tf.keras.datasets.mnist.load_data()[0][1]\nmodel_tf.fit(normalized_images_tf, normalized_labels_tf, epochs=5)\n```"
  },
  {
    "input": "### Problem:\nYou have a pandas DataFrame that contains sales information for various products over different months, structured as follows:\n\n```\n   Month  ProductA  ProductB  ProductC\n0      1       500       300       200\n1      2       450       320       250\n2      3       600       280       300\n3      4       700       350       350\n4      5       750       400       370\n```\n\nNow, you want to create a new column that calculates the total sales for each month across all products. In order to keep your code reusable and modular, you would like to define a custom function that takes the DataFrame as an argument and returns a new DataFrame with the additional column named 'TotalSales'.\n\nThe DataFrame has already been created using:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Month': [1, 2, 3, 4, 5],\n    'ProductA': [500, 450, 600, 700, 750],\n    'ProductB': [300, 320, 280, 350, 400],\n    'ProductC': [200, 250, 300, 350, 370]\n})\n```\n\nHow can you implement a function called `calculate_total_sales` that accurately computes the total sales?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Month': [1, 2, 3, 4, 5],\n    'ProductA': [500, 450, 600, 700, 750],\n    'ProductB': [300, 320, 280, 350, 400],\n    'ProductC': [200, 250, 300, 350, 370]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndef calculate_total_sales(dataframe):\n    dataframe['TotalSales'] = dataframe[['ProductA', 'ProductB', 'ProductC']].sum(axis=1)\n    return dataframe\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a large dataset represented as a sparse matrix in the form of a list of dictionaries, where each dictionary represents a row in the matrix. The keys are the column indices, and the values are the corresponding non-zero entries. For instance, a sparse matrix like this:\n\n```python\nsparse_data = [\n    {0: 1, 2: 3},\n    {1: 2},\n    {0: 4, 1: 5, 3: 6}\n]\n```\n\nWould represent a matrix of shape (3, 4) that looks like:\n\n```\n[[1, 0, 3, 0],\n [0, 2, 0, 0],\n [4, 5, 0, 6]]\n```\n\nYou want to convert this sparse representation into a dense NumPy array. How can you achieve this?\n\nAssuming you've already loaded the sparse_data into a variable, fill in the blank to achieve the conversion:\n\nA:\n\n```python\nimport numpy as np\n\nsparse_data = load_data()\n```\ndense_array = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndense_array = np.array([[row.get(col, 0) for col in range(max_col)] for row in sparse_data])\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a sparse matrix representing user-item interactions in a recommendation system, where a user has interacted with a limited number of items. Given the following components:\n\n1. A sparse matrix `user_item` of shape (1000, 5000) representing interactions, where rows correspond to users and columns to items.\n2. A list `user_ids` containing the indices of users whose interactions you want to extract.\n\nYou need to create a new sparse matrix `selected_users` that contains only the interactions of the specified users.\n\nThe `user_item` matrix is defined as follows:\n\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]  # example user indices\n```\n\nHow can you fill the variable `selected_users` to contain only the rows of `user_item` corresponding to the users in `user_ids`?\n\nA:\n```python\nfrom scipy import sparse\nuser_item = sparse.random(1000, 5000, density=0.01, format='csr')\nuser_ids = [0, 5, 23, 97]\n```\nselected_users = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_users = user_item[user_ids, :]\n```"
  },
  {
    "input": "Problem:\nI have a tensor representing image data, specifically for a batch of images in the format (batch_size, channels, height, width). I want to apply a basic thresholding operation to each image in the batch. The thresholding will set all pixel values below a certain threshold to zero and leave the others unchanged. I want to achieve this efficiently without converting to a numpy array. \n\nGiven a 4D tensor for the images and a specified threshold, how can I perform this operation directly on the tensor?\n\nFor example, if I have:\n\n```python\nimport torch \nimages = torch.rand((5, 3, 256, 256))  # 5 images, 3 channels, 256x256 pixels\nthreshold = 0.5\n```\n\nI want to apply the thresholding operation with:\n\n```python\nresult_tensor = ...\n```\n\nFill in the blank with the appropriate PyTorch operation to achieve this.",
    "output": "\n```python\nresult_tensor = images * (images >= threshold).float()\n```"
  },
  {
    "input": "Problem:\n\nI have a list of dictionaries representing sales data from a store, and I want to summarize the total sales for each product category. The data structure looks like this:\n\n```python\nsales_data = [\n    {'product': 'A', 'category': 'electronics', 'sales': 200},\n    {'product': 'B', 'category': 'groceries', 'sales': 150},\n    {'product': 'C', 'category': 'electronics', 'sales': 300},\n    {'product': 'D', 'category': 'furniture', 'sales': 400},\n    {'product': 'E', 'category': 'groceries', 'sales': 200},\n]\n```\n\nI would like to create a function called `calculate_total_sales` that takes this list and returns a dictionary with the total sales for each category.\n\nHere is how I want to use it:\n\n```python\nresult = calculate_total_sales(sales_data)\n```\n\nThe expected output for `result` should look like this:\n\n```python\n{\n    'electronics': 500,\n    'groceries': 350,\n    'furniture': 400\n}\n```\n\nPlease fill in the function definition below to achieve this:\n\n```python\ndef calculate_total_sales(sales_data):\n    # return the solution in this function\n    ### BEGIN SOLUTION\n```",
    "output": "\n```python\n    total_sales = {}\n    for entry in sales_data:\n        category = entry['category']\n        sales = entry['sales']\n        if category in total_sales:\n            total_sales[category] += sales\n        else:\n            total_sales[category] = sales\n    return total_sales\n```"
  },
  {
    "input": "## Problem\nYou have a pandas DataFrame containing timestamps and some measurement values taken every hour over a month. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Timestamp': pd.date_range(start='2023-03-01', freq='H', periods=48),\n    'Measurement': [i + (i % 24) for i in range(48)]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to create a new column in this DataFrame that calculates the rolling average of the 'Measurement' values over the last 24 hours, using the `shift` method for proper alignment with the corresponding timestamp.\n\nHow can you achieve this? Fill in the blank in the following line to complete the task:\n\n```python\ndf['Rolling_Avg'] = df['Measurement'].______ \n```",
    "output": "\n```python\ndf['Rolling_Avg'] = df['Measurement'].rolling(window=24).mean().shift(1)\n```"
  },
  {
    "input": "### Problem\nI have a dataset represented as a Pandas DataFrame containing a column with email addresses, and I want to extract the domain part from each email to create a new column called 'domain'. For example, if the email is 'user@example.com', the domain should be 'example.com'. \n\nHere is what my DataFrame looks like:\n\n```\n           email\n0  user1@gmail.com\n1  user2@yahoo.com\n2  user3@hotmail.com\n3  user4@outlook.com\n4  user5@company.org\n```\n\nHow can I achieve this? Here is my current attempt to create the new column:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'email': ['user1@gmail.com', 'user2@yahoo.com', \n                             'user3@hotmail.com', 'user4@outlook.com', \n                             'user5@company.org']})\n```\n\nI want to fill in the blank for this line in my code to extract the domain:\n```python\ndf['domain'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['domain'] = df['email'].str.split('@').str[1]\n```"
  },
  {
    "input": "Problem:\nI have a sparse tensor representation of some text documents using TensorFlow and I need to perform a transpose operation on it. The tensor is currently in the shape (3, 5, 0) representing 3 documents with 5 unique words, and I need to access the non-zero entries only. However, I'm unsure how to efficiently transpose the necessary axis while preserving the sparse structure.\n\nHere is my sparse tensor creation:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nind = np.array([[0, 1, 2], [0, 2, 1]])\nvals = np.array([1, 2, 3])\nshape = (3, 5)\nsparse_tensor = tf.sparse.SparseTensor(indices=ind, values=vals, dense_shape=shape)\n```\n\nNow, how can I efficiently transpose the tensor while maintaining its sparsity and getting a tensor of shape (5, 3) as output?\n\nA:\n<code>\nsparse_tensor_transposed = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nsparse_tensor_transposed = tf.sparse.transpose(sparse_tensor)\n</code>"
  },
  {
    "input": "### Problem:\nI have a dataset that contains daily sales data for a retail store. The data includes two columns: 'Date' and 'Sales'. Here is a snippet of the dataframe:\n\n```\n        Date      Sales\n0 2023-01-01      200\n1 2023-01-02      250\n2 2023-01-03      300\n3 2023-01-04      350\n4 2023-01-05      400\n```\n\nI want to calculate the moving average of sales over a rolling window of 3 days. I previously tried using the `rolling()` method, but I am unsure how to apply it properly to get the desired output.\n\nI would like the final dataframe to look like this, with an additional 'Moving_Avg' column showing the 3-day moving average of sales:\n\n```\n        Date      Sales  Moving_Avg\n0 2023-01-01      200         NaN\n1 2023-01-02      250         NaN\n2 2023-01-03      300       250.0\n3 2023-01-04      350       300.0\n4 2023-01-05      400       350.0\n```\n\nI have already set up the dataframe but need to fill in the missing part to compute the moving average.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n        'Sales': [200, 250, 300, 350, 400]}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n</code>\ndf['Moving_Avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['Moving_Avg'] = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "### Problem:\nI have a pandas DataFrame containing product information as follows:\n```python\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nI want to extract the product name and price into two separate columns: `product_name` and `product_price`. The final DataFrame should look like this:\n```\n  product_name  product_price\n0        Apple          1.50\n1       Banana          0.75\n2       Cherry          3.00\n3         Date          2.50\n```\nI've attempted to use string splitting but it hasn't worked as intended. The column entries always include unwanted spaces. Please help me extract these values properly.\n\nA:\n```python\nimport pandas as pd\n\nproduct_df = pd.DataFrame({'product_info': ['Apple - $1.50', 'Banana - $0.75', 'Cherry - $3.00', 'Date - $2.50']})\n```\nproduct_df = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\nproduct_df[['product_name', 'product_price']] = product_df['product_info'].str.split(' - \\$', expand=True)\nproduct_df['product_price'] = product_df['product_price'].astype(float)\nproduct_df['product_name'] = product_df['product_name'].str.strip()\nproduct_df = product_df[['product_name', 'product_price']]\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a pandas dataframe containing several numerical columns representing the daily sales of different products. The dataframe is structured like this:\n\n```\n      product_A  product_B  product_C\ndate\n2023-01-01        20        10         15\n2023-01-02        25        30         20\n2023-01-03        30        20         25\n```\n\nYou need to calculate the percentage change in sales for each product over the specified period. To make your code reusable, define a function named `calculate_percentage_change` that takes a dataframe and a column name as input, and returns a new series containing the percentage change for that column.\n\nTo test your function, you can use this sample dataframe:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_A': [20, 25, 30],\n    'product_B': [10, 30, 20],\n    'product_C': [15, 20, 25]\n}, index=pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03']))\n```\n\nFill in the following blank with your function call to get the percentage change of 'product_A'.\n\n```python\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndef calculate_percentage_change(df, column):\n    return df[column].pct_change() * 100\n\nresult = calculate_percentage_change(df, 'product_A')\n</code>"
  },
  {
    "input": "Problem:\nYou are working with TensorFlow 2.10.0 and PyTorch 1.10.0. You have a dataset of images represented as a tensor in PyTorch, and you want to compute and display statistics about pixel intensity values across the dataset. The pixels are represented in a 4D tensor of shape (batch_size, height, width, channels), where you want to calculate the mean pixel intensity for each channel separately.\n\nGiven a PyTorch tensor named 'image_tensor' with shape (8, 64, 64, 3) representing 8 images of size 64x64 with 3 color channels, you need to calculate the means and convert the result into a TensorFlow tensor.\n\nHow can you compute the mean pixel intensity for each channel and convert it into a TensorFlow tensor? \n\nA:\n<code>\nimport torch\nimport tensorflow as tf\n\nimage_tensor = torch.rand((8, 64, 64, 3))\n</code>\nmean_intensity_tf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmean_intensity = image_tensor.mean(dim=(0, 1, 2))\nmean_intensity_tf = tf.convert_to_tensor(mean_intensity.numpy())</code>"
  },
  {
    "input": "Problem:\nYou are working with sparse matrices using SciPy and need to create a function that generates a compressed sparse row (CSR) matrix from a dense 2D list representation. The dense list may contain both zeros and non-zero elements, and the function should efficiently handle and return the CSR matrix. Given the following dense list:\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n\nHow can you create a CSR matrix from this dense representation?\n\nA:\n<code>\nfrom scipy import sparse\n\ndense_matrix = [\n    [0, 0, 3, 0],\n    [0, 5, 0, 0],\n    [0, 0, 0, 7]\n]\n</code>\ncsr_matrix_result = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ncsr_matrix_result = sparse.csr_matrix(dense_matrix)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset that contains information about user activities on a website, structured as follows:\n\n```\nuser_id  activity          timestamp\n1        login             2023-01-01 10:00:00\n1        view_product      2023-01-01 10:05:00\n1        logout            2023-01-01 10:15:00\n2        login             2023-01-01 10:10:00\n2        view_product      2023-01-01 10:20:00\n2        logout            2023-01-01 10:30:00\n1        view_product      2023-01-02 11:00:00\n```\n\nI want to extract the first and last activity for each user across multiple days ensuring that the activities are logged in a proper order by using the 'timestamp'. The expected output should include the `user_id`, the `first_activity` corresponding to the earliest `timestamp`, and the `last_activity` corresponding to the latest `timestamp` for each user.\n\nA function is provided to load the data into a DataFrame, and you should create a custom function that will process this data to give the desired output.\n\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 1, 2, 2, 2, 1],\n    'activity': ['login', 'view_product', 'logout', 'login', 'view_product', 'logout', 'view_product'],\n    'timestamp': pd.to_datetime(['2023-01-01 10:00:00', '2023-01-01 10:05:00', '2023-01-01 10:15:00', \n                                  '2023-01-01 10:10:00', '2023-01-01 10:20:00', '2023-01-01 10:30:00', \n                                  '2023-01-02 11:00:00'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('user_id').agg(\n    first_activity=('activity', 'first'),\n    last_activity=('activity', 'last')\n).reset_index()\n```"
  },
  {
    "input": "## Problem\nI have a DataFrame containing sales data over several months for a product with daily sales figures. The DataFrame looks like this:\n\n```\n        Date         Sales\n0 2019-01-01           100\n1 2019-01-02           150\n2 2019-01-03           120\n3 2019-01-04           130\n4 2019-01-05           200\n5 2019-02-01           170\n6 2019-02-02           160\n7 2019-02-03           180\n8 2019-02-04           190\n9 2019-02-05           220\n```\n\nI want to resample this DataFrame to get the total sales for each month, but I need to maintain the original date format. I have started by converting the `Date` column to datetime format:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Date': ['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', \n             '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05'],\n    'Sales': [100, 150, 120, 130, 200, 170, 160, 180, 190, 220]\n})\ndf['Date'] = pd.to_datetime(df['Date'])\n```\n\nNow, what is the code I should use to resample the DataFrame to monthly sales totals while keeping the date format as the first date of the month?\n\n```python\nmonthly_sales = ... # put solution in this variable\n```",
    "output": "\n```python\nmonthly_sales = df.resample('M', on='Date').sum().reset_index()\nmonthly_sales['Date'] = monthly_sales['Date'].dt.to_period('M').dt.to_timestamp()\n```"
  },
  {
    "input": "Problem:\nI have a sparse tensor that represents a multi-dimensional dataset. The tensor is initialized as follows:\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\nshape = (10, 10, 10)  # 3D tensor\nsparse_tensor = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 3], [4, 5, 6]], values=[1, 2, 3], dense_shape=shape)\n```\n\nI want to convert this sparse tensor to a dense numpy array where all unspecified elements are filled with zeros, and then reshape it into a 5x20 array.\n\nHow can I achieve this with a single line of code? \n\nA:\n<code>\nresult = ...  # put solution in this variable\n</code>\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = tf.sparse.to_dense(sparse_tensor).numpy().reshape(5, 20)  \n</code>"
  },
  {
    "input": "Problem:\n\nYou are working with a large sparse matrix representing user interactions in a recommendation system. The matrix is stored as a list of tuples, with each tuple containing the row index, column index, and the value (indicating the interaction score). Your task is to convert this sparse representation into a dense matrix using NumPy. Specifically, given a sparse matrix in the form of `sparse_data = [(0, 1, 5), (1, 0, 3), (2, 2, 2)]`, which indicates that user 0 interacted with item 1 with a score of 5, user 1 with item 0 with a score of 3, and user 2 with item 2 with a score of 2, how can you represent this as a dense matrix of shape (3, 3)?\n\nA:\n\n<code>\nimport numpy as np\nsparse_data = load_data()\ndef solve(sparse_data):\n    # return the solution in this function\n    # dense_matrix = solve(sparse_data)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    dense_matrix = np.zeros((3, 3))\n    for row, col, value in sparse_data:\n        dense_matrix[row, col] = value\n    return dense_matrix\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "## Problem\nI'm utilizing TensorFlow 2.10.0 alongside PyTorch for my deep learning project. I have a tensor of shape (2, 3, 4) in PyTorch and I want to convert this tensor into a 2D NumPy array after performing a specific operation. First, I need to concatenate two tensors along a new axis (0) and then convert the resulting tensor into a NumPy array.\n\nThe initial tensor in PyTorch looks like this:\n```python\nimport torch\ntensor_a = torch.randn(2, 3, 4)  # Random tensor with given dimensions\ntensor_b = torch.randn(2, 3, 4)  # Another random tensor with the same dimensions\n```\n\nI want to concatenate `tensor_a` and `tensor_b` to create a new tensor and then convert it to a NumPy array, `result_array`, which should have the shape (4, 3, 4). Here's how you can start:\n\n```python\nimport numpy as np\n\ntensor_a = torch.randn(2, 3, 4)\ntensor_b = torch.randn(2, 3, 4)\n```\nNow, fill in the missing step to create `result_array`:\n\n```python\nresult_tensor = ...  # Fill in to concatenate the tensors and modify the shape\nresult_array = result_tensor.numpy()  # Convert to NumPy array\n```",
    "output": "\n```python\nresult_tensor = torch.cat((tensor_a, tensor_b), dim=0).permute(1, 0, 2)  # Concatenate and reshape\n```"
  },
  {
    "input": "### Problem\n\nYou are given a dataset representing images, where each image is stored as a 3D tensor in a batch format (batch_size, height, width, channels). You want to preprocess these images using TensorFlow by subtracting the mean pixel value from each channel of the images in the batch. \n\nGiven a batch of images with shape (batch_size, height, width, channels), the goal is to compute a tensor `normalized_images` which contains the images with the mean normalized.\n\nFor example:\n\n```python\nimages = tf.random.normal((10, 64, 64, 3))  # A batch of 10 images of size 64x64 with 3 channels\n```\n\nWrite the code to perform the mean normalization for the images so that `normalized_images` contains the result of subtracting the mean of each channel.\n\n```python\nimport tensorflow as tf\n\nimages = load_data()  # shapes as indicated above\n```\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean_values = tf.reduce_mean(images, axis=[0, 1, 2], keepdims=True)\nnormalized_images = images - mean_values\n</code>"
  },
  {
    "input": "### Problem:\nI have a time series dataset represented in a Pandas DataFrame where the index is a datetime object. The DataFrame contains daily sales data for a store. I want to calculate a moving average of the sales over a 7-day window, and I also want to retain the original index format.\n\nHere is an example of the DataFrame structure:\n\n```\n             sales\ndate               \n2023-01-01    200\n2023-01-02    210\n2023-01-03    180\n2023-01-04    240\n2023-01-05    220\n2023-01-06    190\n2023-01-07    210\n2023-01-08    250\n2023-01-09    260\n2023-01-10    240\n```\n\nHow can I compute the moving average and save it in a new column named `moving_average` in the same DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n        'sales': [200, 210, 180, 240, 220, 190, 210, 250, 260, 240]}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\n```\ndf['moving_average'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_average'] = df['sales'].rolling(window=7).mean()\n```"
  }
]