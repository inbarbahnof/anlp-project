[
  {
    "input": "Problem:\nI have a dataset in a pandas DataFrame containing temperature readings in degrees Celsius for different cities over a week. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n    'Temperature': [29.0, 25.0, 31.5, 28.0, 30.2, 27.5, 28.0, 26.5],\n    'Day': ['Monday', 'Monday', 'Tuesday', 'Tuesday', 'Wednesday', 'Wednesday', 'Thursday', 'Thursday']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the average temperature for each city across the week and plot the results using Matplotlib. \n\nHere\u2019s the code snippet I have so far to calculate the mean temperature:\n\n```python\nmean_temp = df.groupby('City')['Temperature'].mean()\n```\n\nNow, I wish to plot the average temperature for each city with the following code:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Average temperature\nmean_temp = ...\n# Plotting\nplt.bar(mean_temp.index, mean_temp.values)\nplt.ylabel('Average Temperature (\u00b0C)')\nplt.title('Average Temperature by City')\nplt.show()\n```\n\nWhat should I put in the blank for `mean_temp` so that it correctly computes the average temperature? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles', 'New York', 'Los Angeles'],\n    'Temperature': [29.0, 25.0, 31.5, 28.0, 30.2, 27.5, 28.0, 26.5],\n    'Day': ['Monday', 'Monday', 'Tuesday', 'Tuesday', 'Wednesday', 'Wednesday', 'Thursday', 'Thursday']\n}\n\ndf = pd.DataFrame(data)\n</code>\nmean_temp = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmean_temp = df.groupby('City')['Temperature'].mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customers and their purchase amounts, structured as follows:\n\n| customer_id | purchase_date | amount |\n|-------------|---------------|--------|\n| c1          | 2023-01-05    | 150    |\n| c2          | 2023-01-05    | 300    |\n| c1          | 2023-01-06    | 200    |\n| c2          | 2023-01-07    | 350    |\n| c3          | 2023-01-05    | 450    |\n| c3          | 2023-01-08    | 150    |\n\nI want to calculate the total purchase amount for each customer over the entire period. The output should be a new DataFrame that includes the customer_ids and their corresponding total purchase amounts.\n\nHow can I achieve this in Python?\nI would like to use pandas for this operation and provide the code/solution with details on the Python version.\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': ['c1', 'c2', 'c1', 'c2', 'c3', 'c3'],\n    'purchase_date': ['2023-01-05', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-05', '2023-01-08'],\n    'amount': [150, 300, 200, 350, 450, 150]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('customer_id')['amount'].sum().reset_index()\nresult.columns = ['customer_id', 'total_amount']\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about house prices in a CSV file named \"house_prices.csv\". The data includes columns for \"area\", \"bedrooms\", \"bathrooms\", and \"price\". You need to create a linear regression model using Scikit-learn that predicts house prices based on the area of the house (in square feet). After fitting the model, you want to visualize the relationship between the area and the price using Matplotlib.\n\nHow can you load the data, fit the model, and create this visualization in a single concise implementation?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Load data\ndf = pd.read_csv(\"house_prices.csv\")\nX = df[['area']]  # Feature\ny = df['price']   # Target\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Prediction\ny_pred = model.predict(X_test)\n\n# Visualization\nplt.scatter(X_test, y_test, color='blue', label='True Prices')\nplt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted Prices')\nplt.xlabel('Area (sq ft)')\nplt.ylabel('Price')\nplt.title('House Price Prediction')\nplt.legend()\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df, X, y, X_train, X_test, y_train, y_test, model, y_pred, plt</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing features of different houses along with their prices. I want to build a simple linear regression model using Scikit-learn to predict house prices based on their features, and then visualize the regression line using Matplotlib.\n\nI have this DataFrame representing the features and a target variable:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'age': [10, 15, 20, 5, 8],\n    'price': [300000, 320000, 340000, 360000, 400000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI have trained the model using the following code, but I am getting an error when trying to predict the house prices and visualize them:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\nX = df[['size','bedrooms','age']]\ny = df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# I want to plot the predictions against the actual prices for the test set using a scatter plot\nplt.scatter(X_test['size'], y_test, color='blue', label='Actual Prices')\nplt.scatter(X_test['size'], model.predict(X_test), color='red', label='Predicted Prices')\nplt.xlabel('Size')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n```\n\nHowever, I'm receiving a ValueError because I mistakenly defined `X_test` without accounting for the expected dimensions in the prediction function. How can I correct this?\n\nA:\n```python\nX_test = ... # put solution in this variable\n```",
    "output": "\n```python\nX_test = X_test[['size']]\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset of customer transactions stored in a Pandas DataFrame. Each transaction includes the customer ID, transaction amount, and transaction date. I want to calculate the total amount spent by each customer in the last 30 days from today and plot this data in a bar chart. Below is how I've set up my data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 2, 1, 2, 3, 3, 1],\n    'amount': [100, 200, 150, 300, 400, 150, 50],\n    'date': pd.date_range(start='2023-10-01', periods=7)\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nI would like to fill in the code that computes the total amount spent per customer in the last 30 days and then plots it using Matplotlib.\n\nA:\n\n```python\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=30)\n\n# Filter transactions within the last 30 days\nfiltered_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n\ntotal_spent = filtered_df.groupby('customer_id')['amount'].sum()\n\n# Plotting\nplt.bar(total_spent.index, total_spent)\nplt.xlabel('Customer ID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer in the Last 30 Days')\nplt.show()\n```\n\ntotal_spent = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ntotal_spent = filtered_df.groupby('customer_id')['amount'].sum()\n```"
  },
  {
    "input": "## Problem:\nYou are working with a dataset containing customer purchase records in a Pandas DataFrame. Each record has a customer ID and a list of items they purchased. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    \"customer_id\": [1, 2, 1, 3, 2],\n    \"items\": [\n        [\"apple\", \"banana\"],\n        [\"orange\", \"banana\", \"grape\"],\n        [\"banana\", \"kiwi\"],\n        [\"apple\"],\n        [\"grape\"]\n    ]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to create a new DataFrame that represents each item as a separate column, and for each customer ID, indicate whether they purchased that item (1 for yes, 0 for no). The final DataFrame should look like this:\n\n```\ncustomer_id  apple  banana  orange  grape  kiwi\n1            1      1      0      0      1\n2            0      1      1      1      0\n3            1      0      0      0      0\n```\n\nWhat is the Pandas code that will transform the original DataFrame into this desired format?\n\nA:\n```python\nnew_df = ... # put solution in this variable\n```",
    "output": "\n```python\nnew_df = df.explode('items').groupby('customer_id')['items'].apply(lambda x: x.unique()).reset_index()\nnew_df = new_df.set_index('customer_id').reindex(df['customer_id'].unique()).fillna(0).astype(int)\nnew_df = new_df.join(pd.get_dummies(df.explode('items')['items']).groupby(df['customer_id']).sum()).fillna(0).astype(int)\n```"
  },
  {
    "input": "```python\nProblem:\nI am working with a dataset containing customer purchases. I have the following NumPy array representing the total purchase amounts over five months for different customers:\n\n```python\npurchases = np.array([[120.5, 150.0, 90.0],\n                      [200.5, 300.0, 250.0],\n                      [190.0, 120.0, 220.0],\n                      [300.0, 400.5, 350.0],\n                      [150.0, 130.0, 180.0]])\n```\n\nI would like to calculate the average purchase for each customer over the months and store the results in a Pandas Series. \n\nCan you help me fill in the blank to achieve this?\n```python\nimport numpy as np\nimport pandas as pd\n\npurchases = np.array([[120.5, 150.0, 90.0],\n                      [200.5, 300.0, 250.0],\n                      [190.0, 120.0, 220.0],\n                      [300.0, 400.5, 350.0],\n                      [150.0, 130.0, 180.0]])\n\naverage_purchases = ...  # fill in this blank\n``` \n```",
    "output": "\n```python\naverage_purchases = pd.Series(np.mean(purchases, axis=1))\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Create a DataFrame from the synthetic data\ndata = pd.DataFrame(np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['Feature']], data['Target'])\n\n# Now, we want to plot the original data and the regression line.\nplt.scatter(data['Feature'], data['Target'], label='Data Points')\nplt.plot(data['Feature'], model.predict(data[['Feature']]), color='red', label='Regression Line')\n\n# Add title and labels\nplt.title('Linear Regression Example')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# Calculate the Mean Squared Error (MSE) of the predictions\nmse = np.mean((model.predict(data[['Feature']]) - data['Target']) ** 2)\n\n# Get the blank for the MSE variable.\nprint(\"Calculated Mean Squared Error (MSE):\", mse)\nmse_result = ...  # fill in the blank for the MSE output\n```",
    "output": "\n```python\nmse_result = mse\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing sales data for different products across multiple regions, structured as follows:\n\n| Product | Region  | 2021 | 2022 | 2023 |\n|---------|---------|------|------|------|\n| A       | North   | 200  | 250  | 300  |\n| A       | South   | 150  | 175  | 200  |\n| B       | North   | 300  | 350  | 400  |\n| B       | South   | 100  | 120  | 130  |\n\nYou want to reshape this dataset from wide format to long format, while also calculating the total sales for each product over the years. The expected long format should include a year column and a total sales column, looking like this:\n\n| Product | Year | Total Sales |\n|---------|------|-------------|\n| A       | 2023 | 500         |\n| A       | 2022 | 425         |\n| A       | 2021 | 350         |\n| B       | 2023 | 530         |\n| B       | 2022 | 470         |\n| B       | 2021 | 400         |\n\nPlease complete the code snippet to reshape and calculate the total sales, starting from this:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Product': ['A', 'A', 'B', 'B'],\n    'Region': ['North', 'South', 'North', 'South'],\n    '2021': [200, 150, 300, 100],\n    '2022': [250, 175, 350, 120],\n    '2023': [300, 200, 400, 130]\n})\n\n# Code to reshape and calculate total sales\nresult = ...\n```",
    "output": "\n```python\nresult = df.melt(id_vars=['Product'], value_vars=['2021', '2022', '2023'], \n                 var_name='Year', value_name='Sales')\nresult['Year'] = result['Year'].astype(int)\ntotal_sales = result.groupby(['Product', 'Year'])['Sales'].sum().reset_index()\ntotal_sales = total_sales.rename(columns={'Sales': 'Total Sales'})\ntotal_sales = total_sales.sort_values(by=['Product', 'Year'], ascending=[True, False])\n```"
  },
  {
    "input": "### Problem\nI'm working with a dataset that contains various measurements recorded from different sensors, and I need to apply feature scaling on multiple columns using Min-Max normalization. The input is a pandas DataFrame, `df`, structured like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'SensorA': [62, 80, 75, 90, 70],\n    'SensorB': [300, 400, 350, 450, 380],\n    'SensorC': [30, 25, 35, 20, 28]\n}\n\ndf = pd.DataFrame(data)\n```\n\nThe desired output is the same DataFrame but with each sensor's measurements normalized to a [0, 1] range. I attempted to use `MinMaxScaler` from `sklearn.preprocessing`, but I'm unsure how to properly apply it to multiple columns. Specifically, I want to scale the values in all three sensor columns.\n\nCan someone help me fill in the solution to achieve this normalization, saving the result in the variable `df_normalized`? Here's the starting point for the solution:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf_normalized = ...\n```",
    "output": "\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf_normalized = df.copy()\ndf_normalized[['SensorA', 'SensorB', 'SensorC']] = scaler.fit_transform(df[['SensorA', 'SensorB', 'SensorC']])\n```"
  },
  {
    "input": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\n\n# I have a dataset containing features and a target. \n# I wish to standardize the features, where the feature data is stored in a Pandas DataFrame `df` \n# and the target values are in a NumPy array `y`. \n# After standardization, I would like to create a simple linear regression model using TensorFlow, \n# fitting it with the standardized features and target values. \n# How can I achieve this?\n\n# Here is how my data looks like:\n# df = pd.DataFrame({\n#     'feature1': [5, 10, 15, 20, 25],\n#     'feature2': [1, 1, 1, 0, 0]\n# })\n# y = np.array([0, 1, 1, 0, 1])\n\n# I want to fill in the code below:\nstandardization = StandardScaler()\nX_standardized = standardization.fit_transform(df)\n\n# Create and fit the TensorFlow model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(1, input_shape=(X_standardized.shape[1],))\n])\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.fit(X_standardized, y, epochs=100)\n\n# Fill in the blank for the variable where the model is fitted\nmodel_fitted = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nmodel_fitted = model.fit(X_standardized, y, epochs=100)  \n</code>"
  },
  {
    "input": "### Problem:\nYou have a dataset comprised of features and a target variable stored in a Pandas DataFrame. The features include several numerical columns that you want to standardize using Scikit-learn's `StandardScaler`. After scaling, you want to create a scatter plot using Matplotlib to visualize the first two principal components obtained from the scaled features via PCA (Principal Component Analysis). Your DataFrame is named `df`, and your target variable is a column labeled `target`.\n\nHere is the current code you have for scaling:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n```\n\nIn the code above, fill in the blank for `X_scaled`. \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...  # Fill in this part\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n</code>",
    "output": "\n<code>\nX_scaled = scaler.fit_transform(X)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset of house prices and their features. I want to perform a linear regression analysis using TensorFlow to predict house prices based on features like square footage and number of bedrooms. I've already prepared my feature matrix X and target vector y. How can I create a simple linear regression model in TensorFlow and fit it to my data? What should I include in the fit method to ensure the model is trained on the dataset?\n\nA:\n<code>\nimport numpy as np\nimport tensorflow as tf\n\n# Sample data\nX = np.array([[1500, 3], [2000, 4], [2500, 4], [3000, 5]], dtype=float)\ny = np.array([300000, 400000, 500000, 600000], dtype=float)\n\n# Define a sequential model\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(2,))])\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Now how do I fit the model?\nresult = ...  # put your solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = model.fit(X, y, epochs=100, verbose=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing the monthly sales data of different products in a retail store. The dataframe looks like this:\n\n```python\nimport pandas as pd\ndata = {\n    'Product': ['A', 'B', 'C', 'D'],\n    'January': [150, 200, 250, None],\n    'February': [None, 180, 220, 300],\n    'March': [200, 220, None, 260]\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to calculate the average monthly sales per product while ignoring any missing values (NaN). I want to store the result in a new column called 'Average_Sales'. \n\nWhat code can I use to accomplish this task?\nIs it possible to use `mean()` function from Pandas for this purpose?\n\n```python\n# Initializing the dataframe\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D'],\n    'January': [150, 200, 250, None],\n    'February': [None, 180, 220, 300],\n    'March': [200, 220, None, 260]\n}\ndf = pd.DataFrame(data)\n```\ndf['Average_Sales'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Average_Sales'] = df[['January', 'February', 'March']].mean(axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset in a pandas DataFrame containing temperature readings for each day of the week, and I want to calculate the moving average for a specified window size. Here's a sample of my DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'day': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n    'temperature': [70, 72, 68, 75, 74, 73, 71]\n}\ndf = pd.DataFrame(data)\n```\n\nNow I want to compute the moving average temperature with a window size of 3 days and store it in a new column called 'moving_avg'. How can I achieve that?\n\nA:\n```python\ndf['moving_avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['moving_avg'] = df['temperature'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products, including their prices and ratings. I want to normalize the prices to bring them into a similar range using Min-Max scaling, and then plot the normalized prices alongside their respective ratings in a scatter plot. Here's how my DataFrame looks:\n\n```\nimport pandas as pd\n\ndata = {\n    'product': ['A', 'B', 'C', 'D', 'E'],\n    'price': [100, 200, 300, 400, 500],\n    'rating': [5, 4, 3, 4, 5]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat is the code I can use to normalize the prices and create a scatter plot of normalized prices vs. ratings?\n\nA:\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\nprices = df[['price']]\n</code>\nnormalized_prices = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nnormalized_prices = scaler.fit_transform(prices)\nplt.scatter(normalized_prices, df['rating'])\nplt.xlabel('Normalized Prices')\nplt.ylabel('Ratings')\nplt.title('Normalized Prices vs. Ratings')\nplt.show()\n</code>",
    "output": "\n<code>\nnormalized_prices = scaler.fit_transform(prices)\nplt.scatter(normalized_prices, df['rating'])\nplt.xlabel('Normalized Prices')\nplt.ylabel('Ratings')\nplt.title('Normalized Prices vs. Ratings')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about several products along with their sales figures over multiple months. I am looking to compute the monthly growth rate in sales for each product using NumPy and Pandas. The original data is structured as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'product': ['A', 'A', 'A', 'B', 'B', 'B'],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03'],\n    'sales': [100, 150, 120, 80, 90, 100]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to create a new DataFrame that contains the monthly growth rate of sales for each product. The growth rate should be computed as the percentage change from the previous month. Your task is to fill in the blank to compute the growth rates correctly.\n\n```python\ngrowth_rates = df.groupby('product')['sales'].apply(lambda x: x.pct_change() * 100)\nresult = df.assign(growth_rate=...)\n```\nIn this case, `growth_rate` should be a new column in the original DataFrame that captures the calculated growth rates. Ensure that the NaN values for the first month of each product are handled properly.",
    "output": "\n```python\nresult = df.assign(growth_rate=growth_rates)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing daily temperature readings and I want to visualize the trend over the years. The data is structured as follows:\n\n```\n   Date        Temperature\n0  2020-01-01  5.1\n1  2020-01-02  6.3\n2  2020-01-03  4.9\n...\n364 2020-12-30  7.5\n365 2020-12-31  6.8\n```\n\nI need to calculate the annual mean temperature and plot this trend using Matplotlib. Additionally, I want to use NumPy to efficiently handle the computation of means.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('temperature_data.csv')\ndata['Date'] = pd.to_datetime(data['Date'])\ndata['Year'] = data['Date'].dt.year\n</code>\nannual_mean_temps = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nannual_mean_temps = data.groupby('Year')['Temperature'].mean().reset_index()\nplt.plot(annual_mean_temps['Year'], annual_mean_temps['Temperature'])\nplt.title('Annual Mean Temperature Trend')\nplt.xlabel('Year')\nplt.ylabel('Mean Temperature')\nplt.grid()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about different products, including their sales in multiple regions. The dataset is in a Pandas DataFrame and looks like this:\n\n```\n   Product   Region   Sales\n0  ProductA  Region1   200\n1  ProductA  Region2   150\n2  ProductB  Region1   300\n3  ProductB  Region2   250\n```\n\nI would like to calculate the total sales for each product across all regions and then visualize the total sales using a bar chart with Matplotlib. Please show me how I can compute the total sales and put the result in a variable. \n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Product': ['ProductA', 'ProductA', 'ProductB', 'ProductB'],\n    'Region': ['Region1', 'Region2', 'Region1', 'Region2'],\n    'Sales': [200, 150, 300, 250]\n}\ndf = pd.DataFrame(data)\n</code>\ntotal_sales = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ntotal_sales = df.groupby('Product')['Sales'].sum().reset_index()"
  },
  {
    "input": "Problem:\nI am working on a classification problem using PyTorch and Scikit-learn, and I need to evaluate the performance of my model by calculating the F1 score. After fitting my model on the training data, I have the predictions and the actual labels. Here\u2019s the code that I have written so far, but I am unsure how to properly calculate the F1 score from the predictions.\n\nHere are my predictions and actual labels:\npredictions = [0, 1, 0, 1, 1, 0]\nactual_labels = [0, 1, 1, 1, 0, 0]\n\nI want to store the F1 score in a variable called `f1` using Scikit-learn's `f1_score` function. Here's how I'm importing the necessary modules:\n```python\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\npredictions = np.array([0, 1, 0, 1, 1, 0])\nactual_labels = np.array([0, 1, 1, 1, 0, 0])\n```\nNow, I want to compute the F1 score. I need to fill in the blank below:\n\nf1 = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>f1 = f1_score(actual_labels, predictions)</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some sample data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # 100 random points in range 0-10\ny = 2.5 * X + np.random.randn(100, 1)  # Linear relation with some noise\n\n# Create a DataFrame\ndf = pd.DataFrame(data=np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['Feature']], df['Target'])\n\n# Plot the data and the regression line\nplt.scatter(df['Feature'], df['Target'], label='Data Points')\nplt.plot(df['Feature'], model.predict(df[['Feature']]), color='red', label='Regression Line')\n\n# Add legend, title, and labels\n# SOLUTION START\n```",
    "output": "\n```python\nplt.legend()\nplt.title('Linear Regression Example')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset representing customer purchases and would like to analyze it using various data science libraries. \n\nYou have a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'customer_id': np.arange(1, 11),\n    'purchase_amount': np.random.randint(100, 1000, size=10),\n    'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='T'),\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new column in the DataFrame that contains the z-scores of the `purchase_amount` values. Z-scores indicate how many standard deviations an element is from the mean. \n\nYou want to compute this using NumPy and add it to a new column named `z_score_purchase_amount`. \n\nHow can you do this?\n\nA:\n```python\ndf['z_score_purchase_amount'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\ndf['z_score_purchase_amount'] = (df['purchase_amount'] - np.mean(df['purchase_amount'])) / np.std(df['purchase_amount'])\n</code>\n```"
  },
  {
    "input": "Problem:\nYou have a dataset represented as a NumPy array containing temperature readings over a week. The data is in Celsius and looks like this:\n\n```python\nimport numpy as np\ntemperatures = np.array([[20.0, 22.5, 19.0, 21.0],\n                         [18.5, 20.0, 22.0, 23.0],\n                         [25.0, 24.0, 26.0, 24.5],\n                         [30.0, 29.5, 31.0, 30.5],\n                         [26.0, 27.0, 28.0, 29.0],\n                         [22.0, 21.5, 22.5, 23.0],\n                         [19.0, 20.0, 18.0, 19.5]])\n```\n\nYou want to calculate the average temperature for each day of the week and store those averages in a Pandas DataFrame with appropriate column names ('Day 1', 'Day 2', 'Day 3', 'Day 4'). \n\nHow can you compute the averages and present them in a nicely formatted DataFrame?\n\nA:\n```python\nimport pandas as pd\n\ntemperatures = np.array([[20.0, 22.5, 19.0, 21.0],\n                         [18.5, 20.0, 22.0, 23.0],\n                         [25.0, 24.0, 26.0, 24.5],\n                         [30.0, 29.5, 31.0, 30.5],\n                         [26.0, 27.0, 28.0, 29.0],\n                         [22.0, 21.5, 22.5, 23.0],\n                         [19.0, 20.0, 18.0, 19.5]])\n```\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\naverages = np.mean(temperatures, axis=0)\ndf = pd.DataFrame([averages], columns=['Day 1', 'Day 2', 'Day 3', 'Day 4'])\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing the daily sales of a product over a month, and you'd like to analyze this data. You want to normalize the sales data using the Min-Max scaling method, where each value in the dataset is transformed to be within the range of 0 to 1 based on the minimum and maximum values of the sales data.\n\nHere's an example of your sales data represented as a NumPy array:\n```python\nimport numpy as np\nsales = np.array([200, 450, 300, 600, 700, 300, 150, 400, 500, 800, 850, 900, 750, 1000, 940])\n```\n\nAfter applying Min-Max scaling, you also want to create a line chart of the original and normalized sales data.\n\nWhere should you place your Min-Max scaling solution and corresponding plotting code?\nA:\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nsales = np.array([200, 450, 300, 600, 700, 300, 150, 400, 500, 800, 850, 900, 750, 1000, 940])\n\nnormalized_sales = ... # put your Min-Max scaling solution here\n\nplt.figure(figsize=(10, 5))\nplt.plot(sales, label='Original Sales')\nplt.plot(normalized_sales, label='Normalized Sales')\nplt.title('Sales Data Normalization')\nplt.xlabel('Days')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n```\nBEGIN SOLUTION\n```python\nnormalized_sales = (sales - sales.min()) / (sales.max() - sales.min())\n```",
    "output": "\n```python\nnormalized_sales = (sales - sales.min()) / (sales.max() - sales.min())\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing various car specifications and their fuel efficiencies, structured as a Pandas DataFrame. The DataFrame has the following columns: `make`, `model`, `year`, `mpg`. I wish to use NumPy for numerical calculations and Scikit-learn for data preprocessing. I plan to normalize the `mpg` values using MinMaxScaler from Scikit-learn, but I am unsure how to apply it correctly. Here is my code:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndata = {\n    'make': ['Ford', 'Chevy', 'Toyota', 'Honda'],\n    'model': ['F150', 'Camaro', 'Corolla', 'Civic'],\n    'year': [2020, 2021, 2021, 2020],\n    'mpg': [20, 25, 30, 22]\n}\ndf = pd.DataFrame(data)\nscaler = MinMaxScaler()\ndf['mpg'] = ...\n```\n\nHow can I correctly normalize the `mpg` column using the scaler so that it fits within the range of 0 to 1? \n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['mpg'] = scaler.fit_transform(df[['mpg']])\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset representing house prices with various features, and I want to prepare it for training a machine learning model. The features are stored in a Pandas DataFrame called `df`, and I want to normalize these features using Min-Max scaling. The target variable `y` (prices) is in a separate Series.\n\nI need to retain the original DataFrame structure but scale the values between 0 and 1. After that, I want to convert the scaled DataFrame into a NumPy array for feeding into a machine learning model.\n\nThe DataFrame looks like this:\n```\n    square_feet  bedrooms  age  price\n0          1500         3   10   300000\n1          2500         4    5   500000\n2          2000         3   15   350000\n```\n\nHere's what I have so far:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf = load_data()  # Assuming df is the DataFrame with house features\ny = df['price']   # Target variable\ndf = df.drop(columns=['price'])  # Drop target variable from features\nscaler = MinMaxScaler()\n```\n\nNow I want to scale the features in `df` and convert the result to a NumPy array.\n\nA:\n```python\nscaled_features = ... # put solution in this variable\n``` \nBEGIN SOLUTION\n```python",
    "output": "\n```python\nscaled_features = scaler.fit_transform(df)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Create a pandas DataFrame with random data\nnp.random.seed(42)\ndata = {\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'target': np.random.rand(100)\n}\ndf = pd.DataFrame(data)\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['feature1', 'feature2']], df['target'])\n\n# Make predictions based on the model\npredictions = model.predict(df[['feature1', 'feature2']])\n\n# Plot actual vs predicted values\nplt.scatter(df['target'], predictions)\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Actual vs Predicted')\nplt.plot([0, 1], [0, 1], 'r--') # Line for perfect prediction\n\n# Save the plot\nplt.savefig('actual_vs_predicted.png')\n\n# Now, I want to calculate the mean squared error between the actual target and the predicted values.\n# What would be the best way to calculate that?\n\nmse = ... # put solution in this variable\n```",
    "output": "\n```python\nmse = np.mean((df['target'] - predictions) ** 2)\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset that represents sales information for a retail store. The data is contained in a pandas DataFrame with the following columns: `Product`, `Quantity_Sold`, `Price_per_Unit`, and `Sales_Date`. You want to forecast next month's sales for each product using linear regression.\n\nYour task is to write code that:\n1. Prepares the data by calculating the total sales for each product for the past three months.\n2. Splits the dataset into training and testing datasets.\n3. Trains a linear regression model to predict future sales based on the total sales from the previous three months.\n\nYou are provided with the following DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'A', 'B', 'C'],\n    'Quantity_Sold': [15, 20, 25, 10, 15, 10, 5, 12, 8, 7],\n    'Price_per_Unit': [3.0, 3.5, 4.0, 2.5, 3.0, 4.5, 5.0, 3.5, 2.5, 4.8],\n    'Sales_Date': pd.date_range(start='2023-01-01', periods=10, freq='M')\n}\ndf = pd.DataFrame(data)\n```\n\nFill in a piece of code to calculate the total sales for the past three months like this:\n\n```python\ndf['Total_Sales'] = ...\n```\nWhere `Total_Sales` should be calculated as the product of `Quantity_Sold` and `Price_per_Unit`. \n\nBEGIN SOLUTION\n```python\ndf['Total_Sales'] = df['Quantity_Sold'] * df['Price_per_Unit']\n```",
    "output": "\n```python\ndf['Total_Sales'] = df['Quantity_Sold'] * df['Price_per_Unit']\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about sales transactions. You want to preprocess this data by normalizing the 'Amount' column, which represents the sales amount, and then visualize the distribution of this normalized data. \n\nSuppose you have the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'TransactionID': [1, 2, 3, 4, 5],\n    'Amount': [100.0, 150.0, 200.0, 250.0, 300.0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to normalize the 'Amount' column using min-max normalization and create a histogram of the normalized values.\n\nFill in the code to normalize the 'Amount' column and create the histogram plot:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Normalization\ndf['Normalized_Amount'] = ...\n# Plot\nplt.hist(df['Normalized_Amount'], bins=5)\nplt.title('Distribution of Normalized Amounts')\nplt.xlabel('Normalized Amount')\nplt.ylabel('Frequency')\nplt.show()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Normalized_Amount'] = (df['Amount'] - df['Amount'].min()) / (df['Amount'].max() - df['Amount'].min())\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\n# Load the Iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Calculate the mean of each feature grouped by target class\nmean_df = df.groupby('target').mean()\n\n# Plot the means of the first two features\nplt.bar(mean_df.index, mean_df.iloc[:, 0], color='b', alpha=0.6, label='Feature 1 Mean')\nplt.bar(mean_df.index, mean_df.iloc[:, 1], color='r', alpha=0.6, label='Feature 2 Mean', bottom=mean_df.iloc[:, 0])\n\n# Set the x ticks and labels \nplt.xticks(mean_df.index, ['Setosa', 'Versicolor', 'Virginica'])\n\n# Add title and labels\nplt.title('Mean of Features by Iris Species')\nplt.xlabel('Species')\nplt.ylabel('Mean Value')\n\n# SOLUTION START\n```",
    "output": "\n```python\n# Show legend\nplt.legend()\n\n# Display the plot\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a Pandas DataFrame with various features like size, location, and year built. I want to create a scatter plot visualizing the relationship between house size (in square feet) and price, and to fit a linear regression line to the data using Scikit-learn. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size_sqft': [1500, 2000, 2500, 3000, 3500, 4000],\n    'price': [300000, 400000, 500000, 600000, 700000, 800000],\n}\ndf = pd.DataFrame(data)\n```\n\nI have set up my imports but am struggling to create the plot with the linear regression line. Here's how my import statements look:\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n```\n\nNow, I'd like to fill in the following line to create the linear regression model and predict the prices based on the size:\n\n```python\nmodel = LinearRegression() \nmodel.fit(___, ___)  # fill in the blanks with proper code\n```\n\nPlease fill in the blanks to apply the linear regression model to the DataFrame's size and price columns.",
    "output": "\n```python\nmodel.fit(df[['size_sqft']], df['price'])  # fill in the blanks with proper code\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about daily temperatures and corresponding ice cream sales. The dataset is stored in a Pandas DataFrame with columns 'Temperature' (in degrees Celsius) and 'Sales' (number of ice creams sold). To understand the relationship between temperature and ice cream sales, I want to fit a linear regression model using Scikit-learn and visualize the results using Matplotlib.\n\nHere\u2019s the initial setup:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Sample data\ndata = {\n    'Temperature': [20, 22, 25, 28, 30, 35, 37, 40, 42, 45],\n    'Sales': [50, 60, 80, 90, 100, 110, 130, 150, 170, 200]\n}\ndf = pd.DataFrame(data)\n\nX = df[['Temperature']] # feature\ny = df['Sales'] # target\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Prepare for plotting the line\nx_range = np.linspace(15, 50, 100).reshape(-1, 1)\ny_pred = model.predict(x_range)\n\n# Plotting setup\nplt.scatter(X, y, color='blue')\nplt.plot(x_range, y_pred, color='red')\nplt.title('Temperature vs Ice Cream Sales')\nplt.xlabel('Temperature (\u00b0C)')\nplt.ylabel('Sales')\n```\n\nNow, I want to save the coefficients of the linear regression model as a list of Python type. The coefficients should include the intercept as the first element followed by the coefficient corresponding to 'Temperature'.\n\nA:\n\n```python\ncoefficients = ... # put solution in this variable\n```",
    "output": "\n```python\ncoefficients = [model.intercept_, model.coef_[0]]\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of customer purchase transactions stored in a Pandas DataFrame. The DataFrame contains columns: \"customer_id\", \"purchase_amount\", and \"purchase_date\". You want to calculate the cumulative purchase amount for each customer over time and then visualize the cumulative amount for a specific customer using Matplotlib. \n\nHere is a sample of the DataFrame:\n```python\nimport pandas as pd\nfrom datetime import datetime\n\ndata = {\n    \"customer_id\": [1, 1, 1, 2, 2, 3],\n    \"purchase_amount\": [10, 20, 30, 40, 50, 60],\n    \"purchase_date\": [datetime(2023, 10, 1), datetime(2023, 10, 2), datetime(2023, 10, 3),\n                      datetime(2023, 10, 1), datetime(2023, 10, 2), datetime(2023, 10, 1)]\n}\ndf = pd.DataFrame(data)\n```\nYou want to compute the cumulative sum of \"purchase_amount\" for each \"customer_id\" and plot the cumulative amount for customer_id 1. \n\nYou need to replace the blank with the appropriate code to get the cumulative purchase amount and visualize it.\n\nA:\n```python\nimport matplotlib.pyplot as plt\n\ndf['cumulative_sum'] = df.groupby('customer_id')['purchase_amount'].cumsum()\nclient_id = 1\nclient_data = df[df['customer_id'] == client_id].sort_values('purchase_date')\n\nplt.plot(client_data['purchase_date'], client_data['cumulative_sum'])\nplt.title(f'Cumulative Purchase Amount for Customer {client_id}')\nplt.xlabel('Purchase Date')\nplt.ylabel('Cumulative Amount')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show() \n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('customer_id')['purchase_amount'].cumsum()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily temperature and humidity levels of a city over a period of one month. You want to use this data to predict the temperature of the following day using a simple linear regression model from Scikit-learn. The temperature data is stored in a pandas DataFrame called `weather_df`, and you want to create a new variable `X` containing the humidity levels and a variable `y` containing the temperature levels. However, you need to ensure that `X` has the shape appropriate for fitting the model.\n\nGiven this dataset:\n\n```python\nimport pandas as pd\n\nweather_df = pd.DataFrame({\n    'temperature': [30, 31, 29, 32, 33, 31, 30, 28, 27, 29, 30, 32, 31, 33, 34, 28, 30, 29, 31, 30, 28, 27, 26, 29, 30, 31, 32, 30, 29, 28],\n    'humidity': [70, 65, 80, 75, 72, 68, 71, 74, 73, 70, 67, 68, 69, 74, 75, 72, 70, 69, 68, 67, 72, 71, 73, 70, 66, 65, 68, 69, 70, 72]\n})\n```\n\nHow can you define `X` and `y` such that `X` contains the humidity levels in the correct shape for the regression model?\n\nA:\n<code>\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Create the variable `y` for the temperature levels\ny = weather_df['temperature']\n\n# Create the variable `X` for the humidity levels (ensure it is in the right shape)\nX = ...  # fill in the blank with your code to reshape the humidity data\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nX = weather_df['humidity'].values.reshape(-1, 1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset represented as a Pandas DataFrame containing historical sales data for a store. The DataFrame has the following structure:\n\n+------------+------------+-------+\n|    Date    | Category   | Sales |\n+------------+------------+-------+\n| 2023-01-01 | Electronics| 1000  |\n| 2023-01-02 | Groceries  | 500   |\n| 2023-01-01 | Groceries  | 300   |\n| 2023-01-03 | Electronics| 2000  |\n| 2023-01-02 | Electronics| 1500  |\n+------------+------------+-------+\n\nI want to calculate the total sales for each category on a daily basis and store the results in a new DataFrame with columns \"Date\", \"Category\", and \"Total_Sales\". How can I achieve this in a concise manner without using explicit loops?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'],\n    'Category': ['Electronics', 'Groceries', 'Groceries', 'Electronics', 'Electronics'],\n    'Sales': [1000, 500, 300, 2000, 1500]\n}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby(['Date', 'Category'], as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\n</code>"
  },
  {
    "input": "Problem:\nI am analyzing sensor data from a smart home system. I have two dataframes: one holding the raw sensor readings and another with aggregated statistics for each room. The raw data is like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\nraw_data = pd.DataFrame({\n    'room': ['Living Room', 'Living Room', 'Kitchen', 'Kitchen', 'Bedroom', 'Bedroom'],\n    'sensor_value': [22.1, 21.8, 23.5, 23.0, 20.0, 19.5],\n    'timestamp': pd.to_datetime(['2023-10-01 10:00', '2023-10-01 10:05', '2023-10-01 10:00', '2023-10-01 10:05', '2023-10-01 10:00', '2023-10-01 10:05'])\n})\n```\n\nThe aggregated statistics dataframe looks like this:\n\n```python\nagg_data = pd.DataFrame({\n    'room': ['Living Room', 'Kitchen', 'Bedroom'],\n    'average_temperature': [21.95, 23.25, 19.75],\n    'status': ['Normal', 'Normal', 'Normal']\n})\n```\n\nI want to merge both dataframes to combine the room information and include the latest sensor reading for each room along with the aggregated statistics. The expected output should resemble this:\n\n```\n             room  average_temperature  status  latest_sensor_value\n0     Living Room                21.95  Normal                 21.8\n1          Kitchen                23.25  Normal                 23.0\n2          Bedroom                19.75  Normal                 19.5\n```\n\nHow can I achieve this while ensuring the `latest_sensor_value` corresponds to the most recent timestamp for each room?\n\nA:\n```python\nimport pandas as pd\nimport numpy as np\n\nraw_data = pd.DataFrame({\n    'room': ['Living Room', 'Living Room', 'Kitchen', 'Kitchen', 'Bedroom', 'Bedroom'],\n    'sensor_value': [22.1, 21.8, 23.5, 23.0, 20.0, 19.5],\n    'timestamp': pd.to_datetime(['2023-10-01 10:00', '2023-10-01 10:05', '2023-10-01 10:00', '2023-10-01 10:05', '2023-10-01 10:00', '2023-10-01 10:05'])\n})\n\nagg_data = pd.DataFrame({\n    'room': ['Living Room', 'Kitchen', 'Bedroom'],\n    'average_temperature': [21.95, 23.25, 19.75],\n    'status': ['Normal', 'Normal', 'Normal']\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nlatest_readings = raw_data.loc[raw_data.groupby('room')['timestamp'].idxmax()]\nresult = agg_data.merge(latest_readings[['room', 'sensor_value']], on='room', how='left')\nresult.rename(columns={'sensor_value': 'latest_sensor_value'}, inplace=True)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing the daily temperature readings for a city over the last month, structured in a Pandas DataFrame. The DataFrame looks like this:\n\n```\n   Date       Temperature\n0  2023-01-01  30.5\n1  2023-01-02  29.0\n2  2023-01-03  31.2\n...\n30 2023-01-31  28.5\n```\nI want to calculate the moving average temperature over a 7-day window for the entire month and plot this moving average with respect to the dates. How can I achieve this in a single line of code after importing the necessary libraries?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=31),\n    'Temperature': [30.5, 29.0, 31.2, 30.1, 29.5, 28.9, 32.0, 31.8, 30.9, 29.7, 31.0, 30.3, 32.1, 29.6, 30.2, 31.5, 30.7, 29.8, 28.4, 30.8, 31.1, 29.5, 30.0, 30.4, 29.6, 31.3, 30.2, 28.9, 29.8, 30.1, 28.5]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code> \nresult = df.set_index('Date')['Temperature'].rolling(window=7).mean().plot(title='7-Day Moving Average Temperature', ylabel='Temperature', xlabel='Date')\nplt.show()\n</code>",
    "output": "\n<code> \nresult = df.set_index('Date')['Temperature'].rolling(window=7).mean().plot(title='7-Day Moving Average Temperature', ylabel='Temperature', xlabel='Date')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Let's say you have a DataFrame containing the monthly sales data of a store over a year:\ndata = {\n    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n    'Sales': [2400, 2700, 3000, 3500, 2900, 4000, 4500, 4800, 5000, 5300, 6000, 6500]\n}\ndf = pd.DataFrame(data)\n\n# Now, you want to create a bar plot of the monthly sales and also add a trendline. \n# The trendline is a linear regression fit of the sales data over the months.\n# Your task is to calculate the slope and intercept of the linear regression model using NumPy, and then plot the trendline on top of the bar plot.\n\n# Here's how to extract the month numbers as x and the sales as y:\nx = np.arange(len(df['Sales']))  # Assuming months as 0, 1, 2, ..., 11\ny = df['Sales'].values\n\n# Fill in the blanks below to calculate the slope and intercept, and plot the trendline\n\n# Regression calculation\n# slope, intercept = np.polyfit(____, ____, 1)  # Fill in the blanks\n\n# Plotting\nplt.bar(df['Month'], df['Sales'], color='blue', alpha=0.7, label='Monthly Sales')\nplt.plot(df['Month'], slope * x + intercept, color='red', label='Trendline')\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.title('Monthly Sales with Trendline')\nplt.legend()\n\n# Show the plot\nplt.show()\n```",
    "output": "\n```python\nslope, intercept = np.polyfit(x, y, 1)  # Fill in the blanks\n```"
  },
  {
    "input": "```python\nProblem:\n\nYou have a dataset containing information about various houses, which includes their sizes (in square feet), numbers of bedrooms, and prices. The dataset is stored in a Pandas DataFrame `df`:\n\n```\n   Size (sq ft)  Bedrooms  Price\n0          1500         3  300000\n1          2000         4  400000\n2          2400         4  500000\n3          1800         3  350000\n4          3000         5  600000\n```\n\nYou want to build a linear regression model to predict the house price based on size and number of bedrooms using Scikit-learn. You've already standardized the features and split your dataset into `X` (features) and `y` (target variable). \n\nPlease write the code to fit a linear regression model using scikit-learn and store the trained model in the variable `model`.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\ndf = pd.DataFrame({\n    'Size (sq ft)': [1500, 2000, 2400, 1800, 3000],\n    'Bedrooms': [3, 4, 4, 3, 5],\n    'Price': [300000, 400000, 500000, 350000, 600000]\n})\nX = df[['Size (sq ft)', 'Bedrooms']]\ny = df['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nmodel = LinearRegression().fit(X_train, y_train)\n</code>"
  },
  {
    "input": "## Problem\nSuppose you have a dataset with customer transactions over several months. You want to analyze the total amount spent by each customer during this period. The dataset is a pandas DataFrame named `transactions` with the following columns: `CustomerID`, `TransactionDate`, and `Amount`. Your task is to calculate the cumulative spending for each customer and visualize it with a bar graph using Matplotlib.\n\nHere is the beginning of your code:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Sample DataFrame setup\ndata = {'CustomerID': [1, 2, 1, 3, 2, 3, 1, 2],\n        'TransactionDate': pd.date_range(start='2023-01-01', periods=8, freq='D'),\n        'Amount': [100, 200, 150, 300, 250, 400, 50, 100]}\ntransactions = pd.DataFrame(data)\n\n# Group by 'CustomerID' and sum the 'Amount'\ncustomer_spending = transactions.groupby('CustomerID')['Amount'].sum()\n```\n\nYour task is to fill in the blank to create a bar graph that displays each customer's total spending.\n\nA:\n```python\ncustomer_spending.plot(kind='bar', figsize=(10,5), color='skyblue')\nplt.title('Total Spending by Customer')\nplt.xlabel('Customer ID')\nplt.ylabel('Total Amount Spent')\nplt.show()\n```",
    "output": "\n```python\ncustomer_spending.plot(kind='bar', figsize=(10,5), color='skyblue')\nplt.title('Total Spending by Customer')\nplt.xlabel('Customer ID')\nplt.ylabel('Total Amount Spent')\nplt.show()\n```"
  },
  {
    "input": "### Problem\nYou are working with a dataset containing customer reviews for a product. The reviews are stored in a Pandas DataFrame with the following columns: 'ReviewID', 'ReviewText', and 'Rating'. You want to preprocess the 'ReviewText' column by converting the text to lowercase, removing punctuation, and then transforming the words into numerical representations using TF-IDF vectorization.\n\nGiven the following code snippet:\n\n```python\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\n\ndata = {\n    'ReviewID': [1, 2, 3],\n    'ReviewText': ['Great product!', 'Not what I expected...', 'Okay, I suppose.'],\n    'Rating': [5, 2, 3]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the blank to create a TF-IDF matrix for the cleaned 'ReviewText'. The transformation should remove punctuation and convert the text to lowercase before fitting the TF-IDF vectorizer.\n\nA:\n```python\nimport numpy as np\n# Cleaning function\ndef clean_text(text):\n    text = text.lower()  # Convert to lowercase\n    return text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n\n# Preprocess the 'ReviewText' column\ndf['CleanedText'] = df['ReviewText'].apply(clean_text)\n\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(df['CleanedText'])\n\ntfidf_matrix = ...  # put solution in this variable\n```",
    "output": "\n```python\ntfidf_matrix = X.toarray()  # Convert sparse matrix to dense array\n```"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I want to analyze the relationship between multiple features and their target variable. I have a dataset in a pandas DataFrame that contains several columns of numerical data. I want to perform feature scaling using StandardScaler from scikit-learn, and then use TensorFlow to build a simple linear regression model.\n\nHere is the DataFrame I am starting with:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Feature1': [1, 2, 3, 4, 5],\n    'Feature2': [2, 3, 4, 5, 6],\n    'Target': [3, 5, 7, 9, 11]\n}\ndf = pd.DataFrame(data)\n```\n\nAfter scaling the features, I want to separate the features and the target variable and prepare them for use in a TensorFlow model. Here\u2019s how far I\u2019ve gotten with the scaling:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(df[['Feature1', 'Feature2']])\n```\n\nNow, I need to create a TensorFlow model to predict the target variable. Fill in the blank to construct a simple sequential model using TensorFlow, where the input shape corresponds to the number of features after scaling:\n\n```python\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.Sequential([\n    keras.layers.Dense(1, input_shape=(...,))  # The blank is where you need to fill in the number of input features\n])\n```\nA:\n<code>\nmodel = keras.Sequential([\n    keras.layers.Dense(1, input_shape=(2,))  # The number of input features after scaling should be filled here\n])\n</code>",
    "output": "\n<code>\nmodel = keras.Sequential([\n    keras.layers.Dense(1, input_shape=(2,))  # The number of input features after scaling should be filled here\n])\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset containing the daily temperature of a city over a month, which is stored in a Pandas DataFrame. You want to compute the moving average of the daily temperatures over a 7-day window and then plot the original temperature data alongside the moving average.\n\nGiven the following example data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndate_range = pd.date_range(start='2023-01-01', periods=30)\ntemperatures = np.random.uniform(low=10, high=30, size=(30,))\ndf = pd.DataFrame({'date': date_range, 'temperature': temperatures})\n```\n\nFill in the blank to compute the moving average and create a plot:\n\n```python\ndf['moving_average'] = df['temperature'].rolling(window=7).mean()\nplt.plot(df['date'], df['temperature'], label='Daily Temperature')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.title('Daily Temperature and Moving Average')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\ndf['moving_average'] = df['temperature'].rolling(window=7).mean()\nplt.plot(df['date'], df['temperature'], label='Daily Temperature')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.title('Daily Temperature and Moving Average')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various car models, including their fuel efficiency (in miles per gallon) and horsepower. You want to analyze the correlation between these two variables using Python. Given a Pandas DataFrame `df` that includes columns `mpg` for miles per gallon and `hp` for horsepower, how can you calculate the Pearson correlation coefficient between these two variables?\n\nA:\n<code>\nimport pandas as pd\n\n# Sample DataFrame\ndata = {\n    'mpg': [18, 15, 36, 24, 30],\n    'hp': [130, 150, 90, 110, 80]\n}\ndf = pd.DataFrame(data)\n\n# Calculate the Pearson correlation coefficient between mpg and hp\nresult = ... # put solution in this variable\n### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\nresult = df['mpg'].corr(df['hp'])\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customer purchases at a retail store. I want to extract the unique product categories and create a frequency distribution of how many times each category was purchased. I'm using pandas for data manipulation but I'm unsure about how to aggregate the counts efficiently. Here's what I have so far:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 3, 1],\n    'ProductCategory': ['Electronics', 'Groceries', 'Electronics', 'Clothing', 'Groceries', 'Electronics', 'Clothing']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to fill in the blanks to get the frequency count of each unique product category. The result should be a DataFrame showing the product categories alongside their counts.\n\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df['ProductCategory'].value_counts().reset_index()\nresult.columns = ['ProductCategory', 'Count']\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a pandas DataFrame structured as follows:\n   |    Area (sq ft)  |  Price ($)   |\n   |------------------|---------------|\n   |         1500     |     300000    |\n   |         2000     |     450000    |\n   |         2500     |     500000    |\n   |         1800     |     330000    |\n   |         2200     |     440000    |\n   |         2600     |     560000    |\n   |         3000     |     600000    |\n   |         3200     |     620000    |\n\nI want to build a linear regression model using Scikit-learn to predict the house price based on area. However, before fitting the model, I need to standardize the 'Area (sq ft)' feature using StandardScaler. Here is how I set up my DataFrame:\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.DataFrame({\n    'Area (sq ft)': [1500, 2000, 2500, 1800, 2200, 2600, 3000, 3200],\n    'Price ($)': [300000, 450000, 500000, 330000, 440000, 560000, 600000, 620000]\n})\n```\nI want to apply the StandardScaler to the 'Area (sq ft)' column and store the standardized values in a new column named 'Area (scaled)'. For the scaling process, use the following function:\n```python\nscaler = StandardScaler()\ndf['Area (scaled)'] = ...\n```\nWhat should I put in place of the ellipsis to complete this task? \nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.DataFrame({\n    'Area (sq ft)': [1500, 2000, 2500, 1800, 2200, 2600, 3000, 3200],\n    'Price ($)': [300000, 450000, 500000, 330000, 440000, 560000, 600000, 620000]\n})\nscaler = StandardScaler()\ndf['Area (scaled)'] = ... # put solution in this variable\n</code>",
    "output": "\n<code>\ndf['Area (scaled)'] = scaler.fit_transform(df[['Area (sq ft)']])\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset that includes user ratings for different movies, stored in a pandas DataFrame with the following structure:\n\n```\n   user_id  movie_id  rating\n0        1        10     4.5\n1        1        20     3.0\n2        2        10     4.0\n3        2        30     5.0\n4        3        20     4.0\n..     ...       ...     ...\n```\n\nI want to create a recommendation system using collaborative filtering. To do that, I need to normalize the ratings for each user by subtracting the mean rating of the respective user from their ratings. \n\nHere is the DataFrame and a variable for user_id:\n```python\nimport pandas as pd\n\ndata = {\n    'user_id': [1, 1, 2, 2, 3],\n    'movie_id': [10, 20, 10, 30, 20],\n    'rating': [4.5, 3.0, 4.0, 5.0, 4.0]\n}\ndf = pd.DataFrame(data)\nuser_id = 1\n```\n\nI need a line of code that calculates the normalized ratings for the specified user_id while retaining the rest of the DataFrame. The normalized rating should be the original rating minus the mean rating for that specific user.\n\nnormalization = ... # put solution in this variable  \nBEGIN SOLUTION  \n<code>",
    "output": "\n```python\nnormalization = df.loc[df['user_id'] == user_id, 'rating'] - df.loc[df['user_id'] == user_id, 'rating'].mean()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset consisting of various features that I want to standardize for use in a machine learning model. Specifically, I would like to use the StandardScaler from Scikit-learn to standardize my data. My dataset is currently in a Pandas DataFrame format. Given a DataFrame `df` with numeric columns, how can I apply the StandardScaler to these columns and store the scaled results in a new DataFrame?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample DataFrame\ndata = {\n    'feature1': [10, 20, 30],\n    'feature2': [1.5, 2.5, 3.5],\n    'feature3': [100, 200, 300]\n}\ndf = pd.DataFrame(data)\n\n# Scaling the DataFrame using StandardScaler\nscaler = StandardScaler()\nscaled_data = ...  # put solution in this variable\n\n# Creating a new DataFrame with scaled data\nscaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaled_data = scaler.fit_transform(df)\n</code>"
  },
  {
    "input": "Problem:\nI am working on a classification problem where I have some feature data and labels. I want to apply a machine learning model using Scikit-learn to classify the data and then visualize the result with Matplotlib. Below is a simple dataset:\n\nFeatures:\n```\nFeature1   Feature2\n1.0         2.0\n1.5         1.8\n2.0         2.2\n1.2         2.5\n3.0         3.5\n3.5         3.8\n```\n\nLabels:\n```\nLabel\n0\n0\n0\n0\n1\n1\n```\n\nUsing Scikit-learn, I want to fit a simple Logistic Regression model to this data. After fitting the model, I also want to visualize the decision boundary on a 2D plot with Matplotlib. What code can I use to fit the model and generate a plot of the decision boundary? \n\nSetup:\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\n# Creating the dataset\ndata = {\n    'Feature1': [1.0, 1.5, 2.0, 1.2, 3.0, 3.5],\n    'Feature2': [2.0, 1.8, 2.2, 2.5, 3.5, 3.8],\n}\nlabels = [0, 0, 0, 0, 1, 1]\n\nX = pd.DataFrame(data)\ny = np.array(labels)\n\n# Fit the Logistic Regression model\nmodel = LogisticRegression()\n```\n\nPlot the decision boundary:\n```python\n# Plotting code will go here\nplt.scatter(X['Feature1'], X['Feature2'], c=y, cmap='coolwarm')\nplt.xlabel('Feature1')\nplt.ylabel('Feature2')\nplt.title('Logistic Regression Decision Boundary')\nplt.show()\n```\n\nA:\n```python\n# put solution in this variable\n```",
    "output": "\n```python\nmodel.fit(X, y)\n\n# Create a grid to plot the decision boundary\nx_min, x_max = X['Feature1'].min() - 1, X['Feature1'].max() + 1\ny_min, y_max = X['Feature2'].min() - 1, X['Feature2'].max() + 1\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\nZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plotting code will go here\nplt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\nplt.scatter(X['Feature1'], X['Feature2'], c=y, cmap='coolwarm')\nplt.xlabel('Feature1')\nplt.ylabel('Feature2')\nplt.title('Logistic Regression Decision Boundary')\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nYou are analyzing a dataset containing several physiological features of individuals. You've calculated the z-scores for several features, and now you want to visualize the distribution of one specific feature, `heart_rate_z`, using a histogram and overlaying a kernel density estimate.\n\nYou have the following code ready:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Simulated data\nnp.random.seed(42)\nheart_rate_z = np.random.normal(loc=0, scale=1, size=1000)\n\nplt.figure(figsize=(10, 6))\nplt.hist(heart_rate_z, bins=30, density=True, alpha=0.5, color='blue')\n</code>\n\nNow, fill in the blank to add a SeaBorn kernel density estimate to this plot.\n\nkde_plot = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nkde_plot = sns.kdeplot(heart_rate_z, color='red', linewidth=2)\nplt.title('Distribution of Heart Rate Z-Scores')\nplt.xlabel('Heart Rate Z-Score')\nplt.ylabel('Density')\nplt.legend(['KDE', 'Histogram'])\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset that consists of daily temperature readings in Celsius for multiple cities. I want to convert these temperature readings to Fahrenheit, compute the average temperature in Fahrenheit for each city, and then visualize the results using a bar chart. \n\nHere is an example dataset represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n    'temperature_celsius': [22, 28, 15, 30]  # Daily temperatures\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to replace the \"temperature_celsius\" column with a new column \"temperature_fahrenheit\" containing the converted temperature values, calculated using the formula:\n\\[ F = C \\times \\frac{9}{5} + 32 \\]\n\nAfter that, I need to compute the average Fahrenheit temperature for each city and plot these averages.\n\nHow can I accomplish this in a single line of code for the conversion, followed by the average computation, and then create the bar plot?\n\nA:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n    'temperature_celsius': [22, 28, 15, 30]  # Daily temperatures\n}\n\ndf = pd.DataFrame(data)\n```\navg_temps = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['temperature_fahrenheit'] = df['temperature_celsius'] * 9/5 + 32; avg_temps = df.groupby('city')['temperature_fahrenheit'].mean(); avg_temps.plot(kind='bar', title='Average Temperature in Fahrenheit by City'); plt.ylabel('Temperature (\u00b0F)'); plt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset represented as a pandas DataFrame with temperature readings in Celsius, and I need to convert these temperatures to Fahrenheit. Here's a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n        'Temperature_C': [17, 24, 13, 29, 32]}\ndf = pd.DataFrame(data)\n```\n\nI want to create a new column `Temperature_F` that contains the converted temperatures using the formula \\( F = C \\times \\frac{9}{5} + 32 \\). What should I put to correctly perform this operation?\n\nA:\n```python\ndf['Temperature_F'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Temperature_F'] = df['Temperature_C'] * 9/5 + 32\n```"
  },
  {
    "input": "Problem:\nI have a dataset of product sales with information on the product name, quantity sold, and the sale price. The dataset looks like this:\n\n```\nProduct          Quantity_Sold      Sale_Price\nLaptop           30                 1200\nSmartphone       50                 800\nTablet           20                 300\nSmartwatch       15                 200\n```\n\nI need to calculate the total revenue for each product and sort the products by total revenue in descending order. The output should look like this:\n\n```\nProduct          Total_Revenue\nLaptop           36000\nSmartphone       40000\nTablet           6000\nSmartwatch       3000\n```\n\nHere is the code I started with to create the DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['Laptop', 'Smartphone', 'Tablet', 'Smartwatch'],\n    'Quantity_Sold': [30, 50, 20, 15],\n    'Sale_Price': [1200, 800, 300, 200]\n}\ndf = pd.DataFrame(data)\n```\n\nI am stuck on how to compute the total revenue and sort the results. Could you help me fill in the missing part of the code? \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['Total_Revenue'] = df['Quantity_Sold'] * df['Sale_Price']\nresult = df[['Product', 'Total_Revenue']].sort_values(by='Total_Revenue', ascending=False)\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset that records the daily temperatures of a city over the course of a year. The dataset is structured as follows:\n\n```\ndate       | temperature\n-----------|-------------\n2023-01-01 | 5\n2023-01-02 | 6\n...        | ...\n2023-12-30 | 2\n2023-12-31 | 3\n```\n\nYou want to create a list of boolean values indicating whether the temperature was above the average temperature of the year for each respective day. Specifically, if the temperature on a given day is above the yearly average, that day should correspond to `True`, otherwise `False`. \n\nYou will be using NumPy and Pandas libraries for this task, so you import them accordingly. \n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\n# Sample dataFrame creation\ndata = {\n    'date': pd.date_range(start='2023-01-01', end='2023-12-31'),\n    'temperature': np.random.randint(-10, 40, size=365)\n}\ndf = pd.DataFrame(data)\n\n# Calculate the average temperature of the year\naverage_temp = df['temperature'].mean()\n\n# Create a new column with boolean values\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['temperature'] > average_temp\n</code>"
  },
  {
    "input": "Problem:\nYou are working with time-series data of temperatures recorded over a week. You have a Pandas DataFrame with two columns: 'Date' and 'Temperature', where 'Temperature' can sometimes have missing values (NaNs). Your goal is to fill these missing values using linear interpolation and then visualize the resulting time series with Matplotlib.\n\nHere's a sample DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=7),\n    'Temperature': [20.5, np.nan, 21.0, np.nan, 22.5, 23.0, 23.5]\n}\ndf = pd.DataFrame(data)\n```\n\nAfter filling the missing values, how can you create a line plot of the 'Temperature' over 'Date' using Matplotlib?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Date': pd.date_range(start='2023-01-01', periods=7),\n    'Temperature': [20.5, np.nan, 21.0, np.nan, 22.5, 23.0, 23.5]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\ndf['Temperature'] = df['Temperature'].interpolate()\nplt.plot(df['Date'], df['Temperature'])\nplt.xlabel('Date')\nplt.ylabel('Temperature')\nplt.title('Temperature over Time')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n</code>"
  },
  {
    "input": "### Problem\nYou are working with a dataset of house prices, and you want to apply a machine learning model to predict house prices based on certain features. You have the following data in a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'area': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 3, 4, 4],\n    'age': [10, 15, 20, 10, 5],\n    'price': [300000, 320000, 340000, 360000, 380000]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to standardize the features `area`, `bedrooms`, and `age` before feeding them into a machine learning model. Use `StandardScaler` from `scikit-learn` to achieve this, and fill in the code in the blank below to create a standardized DataFrame, `scaled_features`, which contains the standardized values of the features:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_features = ... # put solution in this variable\n```\n\nThe expected output should be a DataFrame with the same number of rows as `df` but with the features `area`, `bedrooms`, and `age` scaled to have a mean of 0 and a standard deviation of 1.",
    "output": "\n```python\nscaled_features = pd.DataFrame(scaler.fit_transform(df[['area', 'bedrooms', 'age']]), columns=['area', 'bedrooms', 'age'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products and their monthly sales over a year. The dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': ['A101', 'A101', 'A101', 'A101', 'A102', 'A102', 'A102', 'A102'],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-04', '2023-01', '2023-02', '2023-03', '2023-04'],\n    'sales': [150, 200, 220, 250, 170, 190, 210, 230]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the percentage growth in sales for each product from one month to the next. The expected output would have the same structure but with an additional column for the percentage growth per `product_id`. If there's no previous month's data available to calculate growth, that value should be represented as `NaN`.\n\nYour implementation should efficiently handle groups and return the modified DataFrame. \n\nFill in the blank below with the appropriate code to achieve this:\n\n```python\ndf['percentage_growth'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['percentage_growth'] = df.groupby('product_id')['sales'].pct_change() * 100\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Apply PCA to reduce dimensions to 2\npca = PCA(n_components=2)\npca_result = pca.fit_transform(df.iloc[:, :-1])\n\n# Create a new DataFrame to hold the PCA results\npca_df = pd.DataFrame(data=pca_result, columns=['PCA1', 'PCA2'])\npca_df['target'] = df['target']\n\n# Now, plot PCA1 vs PCA2 and color by target\nplt.figure(figsize=(8,6))\nplt.scatter(..., c=..., cmap='viridis', edgecolor='k')\nplt.xlabel('PCA1')\nplt.ylabel('PCA2')\nplt.title('PCA of Iris Dataset')\nplt.colorbar()\nplt.show()\n```",
    "output": "\n```python\nplt.scatter(pca_df['PCA1'], pca_df['PCA2'], c=pca_df['target'], cmap='viridis', edgecolor='k')\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products in a retail store. The data includes the product name, category, and the sales figures for each month. Here\u2019s a snippet of the data:\n\n```python\nimport pandas as pd\n\ndata = {'product': ['A', 'A', 'B', 'B', 'C', 'C'],\n        'category': ['X', 'X', 'Y', 'Y', 'Z', 'Z'],\n        'month': ['2023-01', '2023-02', '2023-01', '2023-02', '2023-01', '2023-02'],\n        'sales': [100, 150, 200, 250, 300, 250]}\ndf = pd.DataFrame(data)\n```\n\nI would like to compute the average sales for each product across all months and then plot these averages as a bar chart. To do that, please fill in the following line of code with the correct calculation of averages:\n\n```python\navg_sales = df.groupby('product')['sales'].____\n```\n\nThe desired output is a DataFrame showing the average sales for each product. After that, create a bar chart to visualize these averages. Remember to import Matplotlib for the plotting. \n\nPlease provide the code to compute the averages in the `avg_sales` variable.",
    "output": "\n```python\navg_sales = df.groupby('product')['sales'].mean()\n```"
  },
  {
    "input": "## Problem\nYou are analyzing customer data for a retail business and wish to predict if a customer will make a purchase based on their age and income. You have a dataset stored in a pandas DataFrame that contains information about various customers. The DataFrame includes columns 'Age', 'Income', and 'Purchased', where 'Purchased' is a binary column indicating whether the customer made a purchase (1) or not (0).\n\nYou want to split this dataset into training and test sets, train a logistic regression model using Scikit-learn, and then calculate the accuracy of this model on the test set.\n\nYour DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Age': [22, 25, 29, 34, 36, 40, 45, 55, 60, 65],\n    'Income': [30000, 40000, 50000, 60000, 65000, 70000, 80000, 90000, 150000, 180000],\n    'Purchased': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to perform the operations needed to prepare the data, fit the model, and compute the accuracy score.\n\nFill in the blank to complete the following task which will calculate the accuracy score of your logistic regression model:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nX = df[['Age', 'Income']]\ny = df['Purchased']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = ... # put solution in this variable\n```\n",
    "output": "\n```python\naccuracy = accuracy_score(y_test, y_pred)\n```"
  },
  {
    "input": "Problem:\nYou are working on a machine learning project where you need to preprocess a dataset containing numerical features and a categorical target variable. The dataset is structured as follows, using Pandas:\n```python\nimport pandas as pd\n\ndata = {\n    'feature1': [0.5, 1.5, 2.5, 3.5, 4.5],\n    'feature2': [10, 20, 30, 40, 50],\n    'target': ['A', 'B', 'A', 'B', 'A']\n}\ndf = pd.DataFrame(data)\n```\nTo prepare this dataset for training a TensorFlow model, you want to one-hot encode the categorical `target` variable. After encoding, you want to ensure that the resulting DataFrame retains the original numeric features in the first two columns, followed by the one-hot encoded target columns. What is the correct code to achieve this transformation?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'feature1': [0.5, 1.5, 2.5, 3.5, 4.5],\n    'feature2': [10, 20, 30, 40, 50],\n    'target': ['A', 'B', 'A', 'B', 'A']\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\none_hot_encoded = pd.get_dummies(df['target'], prefix='target')\nresult = pd.concat([df[['feature1', 'feature2']], one_hot_encoded], axis=1)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing sales records with columns for 'Product', 'Sales', and 'Date'. I want to analyze the total sales for each product over time, but currently, my DataFrame looks like this:\n\n```\n      Product  Sales       Date\n0      A       10  2023-01-01\n1      B       15  2023-01-01\n2      A       20  2023-01-02\n3      C       25  2023-01-02\n4      B       30  2023-01-03\n5      C       10  2023-01-03\n```\n\nI wish to create a pivot table to summarize the total sales for each product across the dates. The pivot table's rows should be 'Date', the columns should be 'Product', and the values should be the sum of 'Sales'. I also want to fill in any missing values with 0. \n\nI have imported the necessary libraries and created the DataFrame as shown above. \n\nHere\u2019s where I'm stuck:\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C'],\n    'Sales': [10, 15, 20, 25, 30, 10],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-02', \n                             '2023-01-02', '2023-01-03', '2023-01-03'])\n}\n\ndf = pd.DataFrame(data)\n```\n\nI need to complete the pivot_table function correctly to generate the required pivot table. \n\nThe pivot table should be stored in the variable `pivot_df` as follows:\n```python\npivot_df = ...  # put solution in this variable\n```",
    "output": "\n```python\npivot_df = df.pivot_table(index='Date', columns='Product', values='Sales', aggfunc='sum', fill_value=0)\n```"
  },
  {
    "input": "Problem:\nI am working on a classification problem and have split my dataset into training and test sets using `train_test_split` from `scikit-learn`. I've trained a basic model using `LogisticRegression` but now I want to visualize the decision boundary of the model. \n\nHere's what I have so far:\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX, y = make_moons(n_samples=100, noise=0.1, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n```\nWhat I need is to create a mesh grid to visualize the decision boundary of the model after training. I've already defined `x_min`, `x_max`, `y_min`, and `y_max`. The variable `xx, yy` should hold the grid values. \n\nFill in the blank for the creation of the mesh grid:\n```python\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = ...  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))</code>"
  },
  {
    "input": "Problem:\nI have a dataset of customers' purchase histories stored in a pandas DataFrame. Each customer has made multiple purchases recorded in the 'purchase_history' column, which is a list of dictionaries, containing 'item' and 'amount' for each purchase. My goal is to create a new column 'total_spent' that contains the total amount spent by each customer. \n\nHere is a sample DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 2, 3],\n    'purchase_history': [\n        [{'item': 'apple', 'amount': 10}, {'item': 'banana', 'amount': 20}],\n        [{'item': 'orange', 'amount': 5}],\n        [{'item': 'grape', 'amount': 30}, {'item': 'kiwi', 'amount': 15}, {'item': 'peach', 'amount': 10}]\n    ]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to achieve the following DataFrame:\n\n```\n   customer_id                          purchase_history           total_spent\n0           1     [{'item': 'apple', 'amount': 10}, {'item': 'banana', 'amount': 20}]            30\n1           2                                [{'item': 'orange', 'amount': 5}]             5\n2           3     [{'item': 'grape', 'amount': 30}, {'item': 'kiwi', 'amount': 15}, {'item': 'peach', 'amount': 10}]       55\n```\n\nHere\u2019s the pseudo code for what I have in mind:\n```python\ndf['total_spent'] = df['purchase_history'].apply(lambda x: sum(item['amount'] for item in x))\n```\n\nI'm unsure how to implement the lambda function correctly to achieve the desired output. \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 2, 3],\n    'purchase_history': [\n        [{'item': 'apple', 'amount': 10}, {'item': 'banana', 'amount': 20}],\n        [{'item': 'orange', 'amount': 5}],\n        [{'item': 'grape', 'amount': 30}, {'item': 'kiwi', 'amount': 15}, {'item': 'peach', 'amount': 10}]\n    ]\n}\ndf = pd.DataFrame(data)\ndf['total_spent'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['total_spent'] = df['purchase_history'].apply(lambda x: sum(item['amount'] for item in x))\n</code>"
  },
  {
    "input": "Problem:\n\nYou have been given a dataset representing the daily temperatures (in Celsius) recorded over a year and want to evaluate the average temperature over winter months (December, January, February). Your data is structured in a pandas DataFrame with two columns: 'date' (in YYYY-MM-DD format) and 'temperature'. After calculating the average temperature, you want to visualize it using a simple line plot.\n\nHere's a sample of your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {'date': ['2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', \n                 '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n        'temperature': [3.1, 4.2, 2.3, 5.1, 3.0, 0.5, -1.2, 2.0, 0.0, -3.5]}\n\ndf = pd.DataFrame(data)\n```\n\nYour goal is to calculate the average temperature during the winter months and plot the average along with the actual temperature data over the winter. Fill in the missing code.\n\nA:\n<code>\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndata = {'date': ['2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', \n                 '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n        'temperature': [3.1, 4.2, 2.3, 5.1, 3.0, 0.5, -1.2, 2.0, 0.0, -3.5]}\n\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\nwinter_months = df[(df['date'].dt.month == 12) | (df['date'].dt.month == 1) | (df['date'].dt.month == 2)]\naverage_temperature = winter_months['temperature'].mean()\n\nplt.plot(df['date'], df['temperature'], label='Daily Temperatures', marker='o')\nplt.axhline(y=average_temperature, color='r', linestyle='-', label='Average Winter Temperature')\nplt.title('Winter Daily Temperatures with Average Line')\nplt.xlabel('Date')\nplt.ylabel('Temperature (Celsius)')\nplt.legend()\nplt.show()\n</code>",
    "output": "\n<code>\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndata = {'date': ['2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', \n                 '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05'],\n        'temperature': [3.1, 4.2, 2.3, 5.1, 3.0, 0.5, -1.2, 2.0, 0.0, -3.5]}\n\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\nwinter_months = df[(df['date'].dt.month == 12) | (df['date'].dt.month == 1) | (df['date'].dt.month == 2)]\naverage_temperature = winter_months['temperature'].mean()\n\nplt.plot(df['date'], df['temperature'], label='Daily Temperatures', marker='o')\nplt.axhline(y=average_temperature, color='r', linestyle='-', label='Average Winter Temperature')\nplt.title('Winter Daily Temperatures with Average Line')\nplt.xlabel('Date')\nplt.ylabel('Temperature (Celsius)')\nplt.legend()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing the features of different houses represented in a pandas DataFrame, where each column is a different feature such as 'square_feet', 'num_bedrooms', and 'num_bathrooms'. I want to normalize the 'square_feet' feature using the Min-Max scaling method and create a new column named 'normalized_square_feet' in the same DataFrame. \n\nHere is a snippet of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'square_feet': [1500, 2000, 2500, 3000, 3500],\n    'num_bedrooms': [3, 4, 3, 5, 4],\n    'num_bathrooms': [2, 3, 2, 4, 3]\n}\n\ndf = pd.DataFrame(data)\n```\n\nHow can I normalize the 'square_feet' feature using Min-Max scaling and assign the result to 'normalized_square_feet' in the DataFrame?\n\nA:\n```python\nimport pandas as pd\ndata = {\n    'square_feet': [1500, 2000, 2500, 3000, 3500],\n    'num_bedrooms': [3, 4, 3, 5, 4],\n    'num_bathrooms': [2, 3, 2, 4, 3]\n}\ndf = pd.DataFrame(data)\n```\ndf['normalized_square_feet'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['normalized_square_feet'] = (df['square_feet'] - df['square_feet'].min()) / (df['square_feet'].max() - df['square_feet'].min())\n</code>\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing customer information from an e-commerce platform, structured as follows:\n\n```python\ndata = {\n    'customer_id': [1, 2, 3, 4, 5],\n    'purchase_amount': [150.00, 200.00, 50.00, 300.00, 100.00],\n    'purchase_date': ['2023-01-15', '2023-01-20', '2023-01-20', '2023-01-22', '2023-01-25']\n}\n```\n\nYou want to analyze the total purchase amount by each purchase date. First, you would like to convert the 'purchase_date' column to a datetime format to ensure proper handling of dates. After this, you want to group the data by 'purchase_date', sum the 'purchase_amount', and sort the results in descending order of the total amount.\n\nYou have a solid start with the following code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame(data)\ndf['purchase_date'] = pd.to_datetime(df['purchase_date'])\n```\n\nHowever, you are unsure how to perform the grouping and summing operations in one go. You can complete the solution using:\n\n```python\nresult = ...  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('purchase_date')['purchase_amount'].sum().sort_values(ascending=False)\n```"
  },
  {
    "input": "Problem:\nGiven a synthetic dataset containing two features (feature1, feature2) created using NumPy, apply a linear regression model using Scikit-learn to predict feature2 based on feature1. Calculate the mean squared error of the model predictions and visualize the results with a scatter plot of the original data points and the regression line using Matplotlib.\n\nHere's how you can create the dataset:\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Create the dataset\nnp.random.seed(0)\nfeature1 = np.random.rand(100, 1) * 10\nfeature2 = 2.5 * feature1 + np.random.randn(100, 1) * 2\n\ndata = pd.DataFrame(data=np.hstack((feature1, feature2)), columns=['feature1', 'feature2'])\n</code>\n# Fill in the blank to create and evaluate the Linear Regression model:\nmodel = LinearRegression().fit(data[['feature1']], data[['feature2']])\npredictions = model.predict(data[['feature1']])\nmse = ... # put solution in this variable\nBEGIN SOLUTION\n<code>mean_squared_error(data[['feature2']], predictions)</code>",
    "output": "\n<code>mean_squared_error(data[['feature2']], predictions)</code>"
  },
  {
    "input": "Problem:\n\nYou are given a dataset with multiple features, specifically a pandas DataFrame containing columns for 'Age', 'Salary', and 'Loan Amount'. You want to apply a scaling technique to the numeric columns (i.e., 'Age', 'Salary', 'Loan Amount') using the StandardScaler from Scikit-learn to normalize the data. After scaling, compute the mean of the normalized 'Salary' column. \n\nThe initial DataFrame looks like this:\n\n```\n    Age  Salary  Loan Amount\n0   25   50000    200000\n1   30   60000    250000\n2   35   65000    150000\n3   40   70000    300000\n4   45   80000    280000\n```\n\nYou can assume that the DataFrame is loaded into the variable `df`. Please define a function that returns the mean of the scaled 'Salary' column.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = load_data()\ndef scaled_salary_mean(df):\n    # your solution here\n    ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n",
    "output": "\n```python\n    scaler = StandardScaler()\n    df[['Age', 'Salary', 'Loan Amount']] = scaler.fit_transform(df[['Age', 'Salary', 'Loan Amount']])\n    return df['Salary'].mean()\n</code>\nresult = scaled_salary_mean(df)\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices and their features saved in a CSV file. I want to perform a linear regression analysis and visualize the results. Here's how I start the code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Load the dataset\ndata = pd.read_csv('house_prices.csv')\n\n# Assuming the dataset has 'price' as the target and 'size' as a feature\nX = data[['size']]\ny = data['price']\n```\n\nI want to split the data into training and testing sets, fit a linear regression model, and then plot the actual prices versus the predicted prices. However, I'm missing the line of code to fit the model. Can you complete the following line?\n\n```python\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n\nplt.scatter(X_test, y_test, color='blue')  # Actual prices\nplt.scatter(X_test, predictions, color='red')  # Predicted prices\nplt.xlabel('Size')\nplt.ylabel('Price')\nplt.title('House Price Prediction')\nplt.legend(['Actual Prices', 'Predicted Prices'])\nplt.show()\n```\n\nA:\n```python\nmodel.fit(X_train, y_train)\n```",
    "output": "\n```python\nmodel.fit(X_train, y_train)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various fruits including their weights, sweetness levels, and colors in a CSV file named `fruits.csv`, structured as follows: \n\n| Fruit   | Weight (g) | Sweetness (1-10) | Color   |\n|---------|------------|------------------|---------|\n| Apple   | 150        | 8                | Red     |\n| Banana  | 120        | 7                | Yellow  |\n| Cherry  | 50         | 9                | Red     |\n| Grape   | 75         | 6                | Purple  |\n\nYou want to extract the weights of the fruits, normalize them (scale them to a range between 0 and 1), and then visualize the normalized weights using a histogram. Write the code that reads the CSV file into a Pandas DataFrame, normalizes the weights using Min-Max scaling, and plots the histogram of the normalized weights. Assume you have already imported the necessary libraries.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('fruits.csv')\nnormalized_weights = ... # put solution in this variable\nplt.hist(normalized_weights, bins=10)\nplt.title('Normalized Weights of Fruits')\nplt.xlabel('Normalized Weight')\nplt.ylabel('Frequency')\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_weights = scaler.fit_transform(df[['Weight (g)']])\nnormalized_weights = normalized_weights.flatten()\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nimport torch\n\n# Create a pandas DataFrame with random data for three features and a target variable\nnp.random.seed(42)\ndata = pd.DataFrame({\n    'Feature1': np.random.randn(100),\n    'Feature2': np.random.rand(100) * 100,\n    'Feature3': np.random.choice(['A', 'B', 'C'], 100),\n    'Target': np.random.choice([0, 1], 100)\n})\n\n# Convert categorical variable to dummy/indicator variables\ndata = pd.get_dummies(data, columns=['Feature3'], drop_first=True)\n\n# Scale all feature columns\nscaler = StandardScaler()\ndata_scaled = pd.DataFrame(scaler.fit_transform(data.drop('Target', axis=1)), columns=data.columns[:-1])\n\n# Prepare data for a simple linear model\nX = data_scaled.values\ny = data['Target'].values\n\n# Initialize a simple linear model using TensorFlow\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1, input_dim=X.shape[1], activation='sigmoid')])\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model on the scaled data for a specified number of epochs\nmodel.fit(X, y, epochs=10, verbose=0)\n\n# Plot the training process by using Matplotlib to display the loss as a function of epochs\nplt.plot(model.history.history['loss'])\nplt.title('Model Loss During Training')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Now I need to predict the Target variable using the trained model. What code do I need to fill in the blank below?\npredictions = model.predict(X).flatten()\nresult = ...  # fill in the predictions here\n```",
    "output": "\n```python\nresult = (predictions > 0.5).astype(int)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing historical temperatures for multiple cities. The dataset is stored in a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    '2021': [32, 65, 24, 77, 85],\n    '2022': [30, 67, 22, 80, 90],\n    '2023': [31, 66, 23, 78, 88]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average temperature for each city across the years available (2021, 2022, and 2023). To do this, you can use the `.mean()` method, but you want to dynamically select the years' columns without hardcoding them. How can you achieve that?\n\nA:\n```python\nresult = df[['2021', '2022', '2023']].mean(axis=1)\n```",
    "output": "\n```python\nresult = df[df.columns[1:]].mean(axis=1)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about various fruits including their names and weights. You need to use pandas to calculate the average weight of the fruits. The dataset is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Fruit': ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry'],\n    'Weight': [150, 120, 10, 30, 50]\n}\ndf = pd.DataFrame(data)\n```\n\nHow can you compute the average weight of the fruits in the dataframe? Please provide the code to fill in the blank:\n\nresult = ... # put solution in this variable",
    "output": "\n<code>\nresult = df['Weight'].mean()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing student scores and would like to preprocess it before building a machine learning model. The dataset is provided as a Pandas DataFrame (df) with the following structure:\n\n```\n  StudentID  MathScore  EnglishScore  ScienceScore\n0         1       85.0          78.0          90.0\n1         2       92.0          88.0          NaN\n2         3       NaN           72.0          80.0\n3         4       70.0          82.0          78.0\n4         5       95.0          NaN           NaN\n```\n\nMy goal is to fill in any missing values in the scores with the respective subject's mean score. After that, I want to create a feature that combines the average scores across all subjects for each student.\n\nHow can I achieve this using Pandas to first fill the missing values and then compute the averaged score for each student?\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'StudentID': [1, 2, 3, 4, 5],\n    'MathScore': [85.0, 92.0, None, 70.0, 95.0],\n    'EnglishScore': [78.0, 88.0, 72.0, 82.0, None],\n    'ScienceScore': [90.0, None, 80.0, 78.0, None]\n})\n```\naverage_score = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n<code>\ndf.fillna(df.mean(), inplace=True)\naverage_score = df[['MathScore', 'EnglishScore', 'ScienceScore']].mean(axis=1)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some random data\nnp.random.seed(0)\nx = np.random.rand(100, 1) * 10  # 100 random values between 0 and 10\ny = 2.5 * x + np.random.randn(100, 1)  # Linear relation with noise\n\n# Create a DataFrame\ndf = pd.DataFrame(np.hstack((x, y)), columns=['X', 'Y'])\n\n# Fit a linear regression model to the data\nmodel = LinearRegression()\nmodel.fit(df[['X']], df['Y'])\n\n# Create a scatter plot of the data\nplt.scatter(df['X'], df['Y'], color='blue', label='Data points')\n\n# Plot the fitted line\nplt.plot(df['X'], model.predict(df[['X']]), color='red', label='Fitted line')\n\n# Annotate the plot\nplt.title('Linear Regression Fit')\nplt.xlabel('X values')\nplt.ylabel('Y values')\nplt.legend()\n\n# How to show the plot?\n# Fill in the blank below:\nplt.____\n```",
    "output": "\n```python\nplt.show()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# I have a dataset with features and a binary target variable in a dataframe named `data`\n# The dataframe `data` has columns: ['feature1', 'feature2', 'feature3', 'target']\n# I want to split this dataset into training and testing sets with a 70-30 split using train_test_split.\n# After that, I want to create a Logistic Regression model and fit it on the training data.\n# Finally, I need to compute the accuracy of the model on the testing data and store it in a variable named `accuracy`.\n\ndata = pd.DataFrame({\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'feature3': np.random.rand(100),\n    'target': np.random.randint(0, 2, size=100)\n})\n\nX = data[['feature1', 'feature2', 'feature3']]\ny = data['target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Calculate accuracy\naccuracy = ... # put solution in this variable\n```",
    "output": "\n```python\naccuracy = accuracy_score(y_test, model.predict(X_test))\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information on various products sold over a month. The data is in the form of a Pandas DataFrame where 'sales' is the column containing daily sales figures, and 'product_id' is the corresponding product for those sales. I want to forecast the next month's sales for each product using TensorFlow. Here's the example data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n    'sales': [20, 30, 25, 40, 50, 10, 15, 20, 25]\n}\ndf = pd.DataFrame(data)\n```\n\nUsing TensorFlow, I'm trying to build a simple model to predict the total sales for each product for the next month. However, I need to structure the input data correctly first. \n\nCan you provide a line of code that creates the features and labels in the required format for training? The features will be the sales figures for the past days, and the labels will be the sales figures for the next month.\n\nA:\n```python\nimport tensorflow as tf\n\n# Assuming df is already defined as in the example\n``` \nfeatures, labels = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nfeatures, labels = df.groupby('product_id')['sales'].apply(lambda x: x.values[:-1]).tolist(), df.groupby('product_id')['sales'].apply(lambda x: x.values[1:]).tolist()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing housing prices with features like size, number of bedrooms, and location. I want to build a predictive model using Scikit-learn, and I also want to visualize the predicted vs actual prices using Matplotlib. I've already preprocessed the data into a DataFrame named `housing_data`, and I have split it into training and test sets. \n\nThe training data consists of features in `X_train` and the target variable (prices) in `y_train`. The model I'm using is a linear regression model from Scikit-learn. \n\nHere\u2019s what I have so far:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Assume housing_data has been defined and contains the relevant features and target variable.\nX = housing_data[['size', 'bedrooms', 'location']]\ny = housing_data['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Now I want to predict the prices for the test set and plot them.\npredicted_prices = ...  # put solution in this variable\n```\n\nWhat should I assign to `predicted_prices` to make predictions on the `X_test` data?",
    "output": "\n```python\npredicted_prices = model.predict(X_test)\n```"
  },
  {
    "input": "```python\nProblem:\nI have a dataset containing information about houses and their sale prices. I want to build a linear regression model to predict the sale price based on the size of the house. After fitting the model, I would like to visualize the results along with the prediction line.\n\nHere is the dataset provided as a pandas DataFrame:\n\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'size': [1500, 1600, 1700, 1800, 1900, 2000, 2100],\n    'price': [300000, 320000, 340000, 360000, 380000, 400000, 420000]\n}\ndf = pd.DataFrame(data)\n\nI have created a linear model using Scikit-learn:\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n\nI will fit the model using size (as the independent variable) and price (as the dependent variable). After fitting, I want to plot the size against the actual prices and the predicted prices.\n\nHowever, I noticed that I need to reshape the size data to properly fit the model. How can I achieve that using NumPy?\n\nTo illustrate:\nsize = np.array(df['size']).reshape(-1, 1)\n\nNow, I want you to fill in the blank for fitting the model and producing the predictions:\nmodel.fit(____)\npredictions = model.predict(size)\n\nA:\n<code>\n```",
    "output": "\n<code>\nmodel.fit(size, df['price'])\npredictions = model.predict(size)\n</code>"
  },
  {
    "input": "## Problem:\n\nI am working on a project where I need to classify images of handwritten digits using a neural network. I have preprocessed my dataset of images using `Pandas` and `NumPy` and split it into training and testing sets. Now, I want to build a simple neural network using `TensorFlow` to classify these images.\n\nMy training data is in a Pandas DataFrame `train_df` with columns 'pixels' (each containing a flattened 28x28 image as a numpy array) and 'label' (the digit classification, 0-9). \n\nFor example:\n\n```\ntrain_df = pd.DataFrame({\n    'pixels': [np.random.rand(784) for _ in range(1000)],  # 1000 flattened 28x28 images\n    'label': np.random.randint(0, 10, 1000)               # 1000 random labels between 0-9\n})\n```\n\nI have successfully created a basic structure of the neural network as follows:\n\n```python\nimport tensorflow as tf\n\ndef create_model(input_shape):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n        tf.keras.layers.Dense(10, activation='softmax')\n    ])\n    return model\n\nmodel = create_model((784,))\n```\n\nNow, I want to compile the model using the Adam optimizer and categorical crossentropy as the loss function. Can you help me fill in the blank to correctly compile this model?\n\nA:\n\n```python\nmodel.compile(____)\n```",
    "output": "\n```python\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing daily temperature readings for multiple cities, and I would like to apply a normalization technique to scale the temperature data between 0 and 1 before feeding it into a machine learning model. The dataset is stored in a Pandas DataFrame `df`, with columns `['City', 'Date', 'Temperature']`, where `Temperature` contains the readings. How can I construct a column called `Normalized_Temperature` to accomplish this normalization using NumPy and Pandas?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {'City': ['CityA', 'CityA', 'CityB', 'CityB'],\n        'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02'],\n        'Temperature': [30.0, 25.0, 20.0, 15.0]}\ndf = pd.DataFrame(data)\n\n# Normalization code\ndf['Normalized_Temperature'] = ...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>df['Normalized_Temperature'] = (df['Temperature'] - df['Temperature'].min()) / (df['Temperature'].max() - df['Temperature'].min())</code>",
    "output": "\n<code>df['Normalized_Temperature'] = (df['Temperature'] - df['Temperature'].min()) / (df['Temperature'].max() - df['Temperature'].min())</code>"
  },
  {
    "input": "Problem:\n\nYou are given a dataset containing information about various vehicles, including their weight, horsepower, and fuel efficiency (mpg). You need to analyze this dataset using Pandas, visualize the relationship between horsepower and mpg using Matplotlib, and then perform a linear regression analysis to predict mpg based on horsepower using Scikit-learn.\n\nHere is a sample DataFrame containing the vehicle data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'weight': [3000, 3500, 2800, 4000, 3200],\n    'horsepower': [130, 170, 120, 190, 150],\n    'mpg': [28, 22, 25, 20, 26]\n}\ndf = pd.DataFrame(data)\n```\n\nPlease write code to perform the following:\n1. Create a scatter plot of horsepower against mpg.\n2. Fit a linear regression model to predict mpg based on horsepower.\n3. Store the fitted model's coefficients and intercept in the variables `coefficients` and `intercept` respectively.\n\nThe code block should fill in the blanks:\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Prepare the data for the regression\nX = df[['horsepower']]\ny = df['mpg']\n\n# Initialize and fit the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Plot the data\nplt.scatter(df['horsepower'], df['mpg'])\nplt.xlabel('Horsepower')\nplt.ylabel('MPG')\nplt.title('Horsepower vs MPG')\n\n# Get model coefficients and intercept\ncoefficients = ...\nintercept = ...\n\nplt.show()\n```",
    "output": "\n```python\ncoefficients = model.coef_[0]\nintercept = model.intercept_\n```"
  },
  {
    "input": "Problem:\nYou are given the task of analyzing a toy dataset representing the heights and weights of a sample of individuals. The dataset is structured in a pandas DataFrame with the following columns: 'Height' (in cm), 'Weight' (in kg), and 'Gender' (with values 'Male' or 'Female'). Based on this dataset, you want to create a function that normalizes the weight values based on the height of individuals. You will use Min-Max normalization. Write code that computes the normalized weights for individuals who are above the average height, and returns these values as a list.\n\nHere is the sample data you will use:\n```python\nimport pandas as pd\n\ndata = {\n    'Height': [180, 165, 170, 175, 160, 185, 155],\n    'Weight': [80, 60, 70, 65, 50, 90, 55],\n    'Gender': ['Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female']\n}\n\ndf = pd.DataFrame(data)\n```\n\nThe function `normalize_weights(df)` should compute the normalized weights for individuals with a height greater than the average height in the dataset and return them.\n\nA:\n<code>\ndef normalize_weights(df):\n    average_height = df['Height'].mean()\n    filtered_df = df[df['Height'] > average_height]\n    normalized_weights = (filtered_df['Weight'] - filtered_df['Weight'].min()) / (filtered_df['Weight'].max() - filtered_df['Weight'].min())\n    return normalized_weights.tolist()\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = normalize_weights(df)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some example data\nnp.random.seed(0)\nx = np.random.rand(100, 1) * 10  # 100 random values in range 0-10\ny = 2 * x + np.random.randn(100, 1)  # y is linearly related to x with some noise\n\n# Create a DataFrame\ndf = pd.DataFrame(data=np.column_stack((x, y)), columns=['X', 'Y'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['X']], df['Y'])\n\n# Make predictions\nX_new = np.array([[0], [10]])  # Predict at the bounds\ny_pred = model.predict(X_new)\n\n# Now, plot the results\nplt.scatter(df['X'], df['Y'], color='blue', label='Data points')\nplt.plot(X_new, y_pred, color='red', label='Linear regression line')\n\n# Displaying the plot\nplt.legend()\nplt.title('Linear Regression Fit')\nplt.xlabel('X values')\nplt.ylabel('Y values')\n\n# Solution code placeholder\nA:\n<code>\nresult = ...  # put the solution for plotting or prediction in this variable\n</code>\n```",
    "output": "\n<code>\nresult = plt.show()  # Display the plot\n</code>"
  },
  {
    "input": "## Problem:\nI have a dataset containing information about various products, including their prices and sales data over several months. I want to create a function that takes this dataset, computes the percentage change in sales month-over-month for each product, and then plot the results for visual analysis. \n\nThe dataset is structured as follows:\n\n```python\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [\n        [100, 120, 90, 130, 110],  # Sales for product A over 5 months\n        [200, 210, 190, 220, 230],  # Sales for product B over 5 months\n        [150, 160, 155, 170, 180]   # Sales for product C over 5 months\n    ]\n}\n```\n\nYou need to ensure the output is a Pandas DataFrame that contains the month-over-month percentage changes of sales for each product. The resulting DataFrame should have a new column for each product with these percentage changes.\n\nAdditionally, please produce a Matplotlib line plot that displays the percentage changes over time for each product.\n\nHere is the starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'product': ['A', 'B', 'C'],\n    'sales': [[100, 120, 90, 130, 110], [200, 210, 190, 220, 230], [150, 160, 155, 170, 180]]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate the percentage change\ndf['percentage_change'] = ...\n```\n\nFill in the blank for `df['percentage_change']` to complete the task.",
    "output": "\n```python\ndf['percentage_change'] = df['sales'].apply(lambda x: np.diff(x) / x[:-1] * 100)\ndf = df.explode('percentage_change').reset_index(drop=True)\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nfor i, product in enumerate(data['product']):\n    plt.plot(df[df['product'] == product].index, df[df['product'] == product]['percentage_change'], label=f'Product {product}')\nplt.title('Month-over-Month Percentage Change in Sales')\nplt.xlabel('Months')\nplt.ylabel('Percentage Change (%)')\nplt.legend()\nplt.grid()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing historical sales data for various products, represented as a Pandas DataFrame. Each row contains a product ID, date of sale, and the amount sold on that date. I want to aggregate the total sales for each product across all dates. The DataFrame looks like this:\n\n```\nimport pandas as pd\n\ndata = {\n    'product_id': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-03'],\n    'amount_sold': [10, 20, 15, 25, 30, 5]\n}\ndf = pd.DataFrame(data)\n```\n\nTo get the total sales amount for each product, I would like to use the `groupby` method followed by an aggregation. However, I'm unsure how to fill in the missing code for this operation. \n\nThe result should be a DataFrame with `product_id` as the index and a new column `total_sales` representing the aggregated sales.\n\nA:\n<code>\ndf_grouped = df.groupby('product_id')[...] \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf_grouped = df.groupby('product_id')['amount_sold'].sum().reset_index(name='total_sales')\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about different fruits, including their weights and prices. I want to standardize the weights and prices across the dataset to analyze the data more effectively. The dataset is stored in a pandas DataFrame. How can I achieve this using Scikit-learn's StandardScaler?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {\n    'fruit': ['apple', 'banana', 'cherry'],\n    'weight': [150, 120, 200],\n    'price': [0.5, 0.3, 0.8]\n}\ndf = pd.DataFrame(data)\n\n# Here, I want to standardize the 'weight' and 'price' columns\nstandardized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaler = StandardScaler()\ndf[['weight', 'price']] = scaler.fit_transform(df[['weight', 'price']])\nstandardized_data = df\n</code>"
  },
  {
    "input": "Problem:\nYou are working on a machine learning project where you need to standardize features of a dataset prior to training a model. You have a dataset loaded in a pandas DataFrame, where some columns are features that should be standardized and prefixed with 'Feature_'. You want to standardize these columns using Scikit-learn's StandardScaler. \n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ID': [1, 2, 3, 4, 5],\n    'Feature_A': [10.0, 12.0, 14.0, 26.0, 18.0],\n    'Feature_B': [1.0, 2.0, 3.0, 4.0, 5.0],\n    'Non_Feature': [100, 200, 300, 400, 500]\n}\ndf = pd.DataFrame(data)\n```\n\nYour task is to apply the StandardScaler to the columns that begin with 'Feature_' and create a new DataFrame `standardized_df` containing the standardized features along with the 'ID' and 'Non_Feature' columns.\n\nFill in the blank with the correct code to accomplish this:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nstandardized_features = scaler.fit_transform(df.filter(like='Feature_'))\nstandardized_df = pd.DataFrame(______ )\n```\n",
    "output": "\n```python\nstandardized_features, columns=['Feature_A', 'Feature_B'])\nstandardized_df = pd.concat([df[['ID', 'Non_Feature']], standardized_df], axis=1)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing the sales of products in different regions over several months:\n\n```python\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Region': ['North', 'South', 'North', 'South', 'North', 'South'],\n    'Sales': [200, 150, 300, 250, 100, 50],\n    'Month': ['2023-01', '2023-01', '2023-01', '2023-01', '2023-01', '2023-01']\n}\n```\n\nYou want to pivot this dataset to create a matrix where each product's sales are displayed for each region, and the months become the index. The desired output should look like:\n\n```\nRegion    A    B    C\nNorth   200  300  100\nSouth   150  250   50\n```\n\nYou started with:\n```python\nimport pandas as pd\ndf = pd.DataFrame(data)\n```\n\nWhat should follow to achieve the pivoted DataFrame? \nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = df.pivot_table(index='Region', columns='Product', values='Sales', aggfunc='sum', fill_value=0)</code>"
  },
  {
    "input": "Problem:\n\nYou have a CSV file containing stock prices of a particular company over a set of dates, which looks like this:\n\n```\ndate,open,high,low,close,volume\n2022-01-01,100,110,90,105,10000\n2022-01-02,105,115,95,110,15000\n2022-01-03,110,120,100,115,12000\n...\n```\n\nYou want to analyze the closing prices and visualize the trend over time. To do that, you decide to calculate the rolling average of the closing prices over a window of 3 days and plot it.\n\nHere's the starting code:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"stock_prices.csv\", parse_dates=[\"date\"])\ndf['rolling_avg'] = df['close'].... # insert your solution here\n\nplt.plot(df['date'], df['close'], label='Closing Prices')\nplt.plot(df['date'], df['rolling_avg'], label='3-Day Rolling Average', color='orange')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.title('Stock Prices with 3-Day Rolling Average')\nplt.legend()\nplt.show()\n```\n\nWhat should you put in the blank to calculate the rolling average?\n\nA:\n```python\ndf['rolling_avg'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['rolling_avg'] = df['close'].rolling(window=3).mean()\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing information about various car models, including their horsepower, weight, and price. You want to predict the price of a car based on its horsepower and weight using a linear regression model. However, first, you need to preprocess the dataset by normalizing the features and splitting it into training and testing sets.\n\nHere is a sample code snippet to start with:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\n# Sample data\ndata = {\n    'horsepower': [130, 165, 150, 140, 110],\n    'weight': [3500, 3700, 3200, 3300, 2900],\n    'price': [40000, 50000, 45000, 42000, 35000]\n}\ndf = pd.DataFrame(data)\n\n# Split data into features and target variable\nX = df[['horsepower', 'weight']]\ny = df['price']\n\n# Normalize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n```\n\nWhat is the correct line of code to insert for fitting the model, using the variables defined above, which allows for the predictions to be made?\n\npredictions = ...  # put solution in this variable",
    "output": "\n```python\n<code>\npredictions = model.predict(X_test)\n</code>\n```"
  },
  {
    "input": "Problem:\nI am working on a project that involves image classification using TensorFlow and PyTorch. I have a dataset of grayscale images represented as 3D NumPy arrays (height x width x channels) and would like to convert them into a format suitable for training a model in TensorFlow. Specifically, I need a way to convert these images into a 4D tensor and normalize the pixel values to be between 0 and 1. Here's how my data looks:\n\n```python\nimport numpy as np\n\n# Simulating a batch of 5 grayscale images of size 28x28\nimages = np.random.randint(0, 256, (5, 28, 28), dtype=np.uint8)\n```\n\nTo prepare this data for a TensorFlow model, I need to reshape `images` into a 4D tensor with shape (batch_size, height, width, channels) and normalize the pixel values. Here is the initial code I have:\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\nimages = np.random.randint(0, 256, (5, 28, 28), dtype=np.uint8)\n```\n\nWhat should I place in the following line to achieve the desired transformation and normalization of the images?\n\n```python\nimages_tensor = tf.convert_to_tensor(images[..., np.newaxis], dtype=tf.float32) / 255.0\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = tf.convert_to_tensor(images[..., np.newaxis], dtype=tf.float32) / 255.0\n```"
  },
  {
    "input": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Suppose we have a dataset of house prices with multiple features\nnp.random.seed(0)\ndata = {\n    'Size': np.random.randint(500, 5000, size=100),\n    'Bedrooms': np.random.randint(1, 5, size=100),\n    'Age': np.random.randint(1, 30, size=100),\n    'Price': np.random.randint(100000, 500000, size=100)\n}\ndf = pd.DataFrame(data)\n\n# Now I want to visualize how the 'Size' of the house relates to its 'Price'.\n# Can you help me create a scatter plot with 'Size' on the x-axis and 'Price' on the y-axis,\n# ensuring that the points are shown with 'o' markers and a title that says \"House Size vs Price\"?\n\nplt.scatter(____)  # Fill in the blank to create the scatter plot\nplt.title('House Size vs Price')\nplt.xlabel('Size (sq ft)')\nplt.ylabel('Price ($)')\nplt.show()",
    "output": "\n<code>\nplt.scatter(df['Size'], df['Price'], marker='o')\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n# Standardize the data\nstandardized_data = (df - df.mean()) / df.std()\n\n# Apply PCA and capture the principal components\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(standardized_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'], alpha=0.5)\n\n# I want to add labels to the scatter plot for the three different species in the dataset.\n# I know that the target is stored in the iris dataset as well but I want to create a legend for it in the plot.\n\n# Replace with the actual solution to extract the target labels\ntarget_labels = ...  # put solution in this variable\n```",
    "output": "\n```python\ntarget_labels = data.target\n```"
  },
  {
    "input": "Problem:\n\nYou are working on a classification task with a dataset represented as a NumPy array of shape (100, 10), where the first 9 columns are features and the last column is the target label (0 or 1). You want to split this dataset into training and testing sets using an 80-20 split. After splitting, you intend to standardize the features using Scikit-learn's `StandardScaler` and then train a simple logistic regression model using TensorFlow. \n\nGiven the setup, please fill in the blank to create the logistic regression model after standardizing the training data. \n\nAssume `data` is your NumPy array.\n\n<code>\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\n\ndata = np.random.rand(100, 10)  # Example data\nX = data[:, :-1]\ny = data[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\nmodel = tf.keras.Sequential([\n    ...  # Initialize your model layers here\n])\n\n# Add a compile and fit step based on your specific needs.\n</code>\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(X_train_scaled.shape[1],))\n])\n```"
  },
  {
    "input": "Problem:\nI'm working on a classification task using a dataset of flowers, specifically the famous Iris dataset. I want to build a model that predicts the species of the flower based on its features (sepal length, sepal width, petal length, and petal width). I've already split the data into training and testing sets and standardized the features using `StandardScaler`. Now, I need to fit a Random Forest Classifier and make predictions on the test set. My data looks like this:\n\n```python\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n```\n\nNow I need to fill in the blank for the following code to create and fit the Random Forest Classifier:\n\n```python\nclf = RandomForestClassifier(random_state=42)\nclf.fit(...)\n\npredictions = clf.predict(X_test_scaled)\n```\n\nA:\n<code>\nX_train_scaled  # put solution in this variable\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nX_train_scaled\n</code>"
  },
  {
    "input": "Problem:\nYou are tasked with building a simple neural network model using PyTorch to classify data from a dataset stored in a Pandas DataFrame. The dataset contains two features (\u2018X1\u2019 and \u2018X2\u2019) and a binary target variable (\u2018Y\u2019). Your goal is to create a variable `model` that initializes a neural network with one hidden layer containing 5 neurons and a ReLU activation function. The output layer should have a single neuron with a sigmoid activation function for binary classification. The dataset is represented as follows:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'X1': [0.1, 0.2, 0.3, 0.4, 0.5],\n    'X2': [0.5, 0.4, 0.3, 0.2, 0.1],\n    'Y': [1, 0, 1, 0, 1]\n})\n```\n\nA:\n<code>\nimport pandas as pd\nimport torch\nimport torch.nn as nn\n\ndata = pd.DataFrame({\n    'X1': [0.1, 0.2, 0.3, 0.4, 0.5],\n    'X2': [0.5, 0.4, 0.3, 0.2, 0.1],\n    'Y': [1, 0, 1, 0, 1]\n})\n\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmodel = nn.Sequential(\n    nn.Linear(2, 5),\n    nn.ReLU(),\n    nn.Linear(5, 1),\n    nn.Sigmoid()\n)\n</code>"
  },
  {
    "input": "Problem:\nYou are provided with the following DataFrame that contains image data of various species along with their numeric labels for classification:\n```\n   Species    Pixel1    Pixel2    Pixel3  Label\n0   Cat      123      234      190       0\n1   Dog      200      120      191       1\n2   Cat      193      236      188       0\n3   Dog      180      140      215       1\n4   Fish     100      200      210       2\n5   Cat      210      199      200       0\n```\nYour task is to standardize the Pixel1, Pixel2, and Pixel3 columns such that they have a mean of 0 and a standard deviation of 1. You need to use the `StandardScaler` from `scikit-learn` to accomplish this. The result should update the original DataFrame with standardized pixel values as new columns named 'Pixel1_std', 'Pixel2_std', and 'Pixel3_std'.\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.DataFrame({\n    'Species': ['Cat', 'Dog', 'Cat', 'Dog', 'Fish', 'Cat'],\n    'Pixel1': [123, 200, 193, 180, 100, 210],\n    'Pixel2': [234, 120, 236, 140, 200, 199],\n    'Pixel3': [190, 191, 188, 215, 210, 200],\n    'Label': [0, 1, 0, 1, 2, 0]\n})\n</code>\ndf[['Pixel1_std', 'Pixel2_std', 'Pixel3_std']] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaler = StandardScaler()\ndf[['Pixel1_std', 'Pixel2_std', 'Pixel3_std']] = scaler.fit_transform(df[['Pixel1', 'Pixel2', 'Pixel3']])\n</code>"
  },
  {
    "input": "```python\nProblem:\nI have a dataset of house prices represented in a Pandas DataFrame, which includes columns for square footage and price. I want to standardize the prices using StandardScaler from Scikit-learn so that I can compare them on the same scale. Here\u2019s the DataFrame structure I have:\n\nimport pandas as pd\n\ndata = {\n    'SquareFootage': [1500, 2000, 2400, 3000, 1800],\n    'Price': [300000, 400000, 450000, 600000, 350000]\n}\ndf = pd.DataFrame(data)\n\nI would like to create a new column called `Standardized_Price` that contains the standardized prices. What line of code should I use to achieve this? \n\nA:\n<code>\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf['Standardized_Price'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n```python\ndf['Standardized_Price'] = scaler.fit_transform(df[['Price']])\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing customer purchase data in a CSV file named 'purchases.csv'. The data looks like this:\n\n| customer_id | amount | date       |\n|-------------|--------|------------|\n| 1           | 200    | 2021-01-01 |\n| 2           | 150    | 2021-01-02 |\n| 1           | 300    | 2021-01-03 |\n| 3           | 100    | 2021-01-01 |\n| 2           | 50     | 2021-01-04 |\n\nYou want to calculate the total amount spent by each customer and then visualize the results using a bar chart with Matplotlib. The bar chart should have customer IDs on the x-axis and total amounts on the y-axis.\n\nFill in the code to achieve the total amount aggregation and generate the bar chart. \n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv('purchases.csv')\n\n# Group by customer_id and sum the amount\ntotal_spent = df.groupby('customer_id')['amount'].sum()\n\n# Plotting the total spent\nplt.bar(total_spent.index, total_spent.values)\nplt.xlabel('Customer ID')\nplt.ylabel('Total Amount Spent')\nplt.title('Total Amount Spent by Each Customer')\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = total_spent\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndata = {\n    'years': [1, 2, 3, 4, 5],\n    'sales': [150, 200, 250, 300, 350]\n}\ndf = pd.DataFrame(data)\n\n# Fit a linear regression model to predict sales based on years\nmodel = LinearRegression()\nmodel.fit(df[['years']], df['sales'])\npredictions = model.predict(df[['years']])\n\n# Plot the original sales data and the regression line\nplt.scatter(df['years'], df['sales'], color='blue', label='Actual Sales')\nplt.plot(df['years'], predictions, color='red', label='Predicted Sales')\n\n# Add a title and labels\nplt.title('Sales Over Years and Linear Regression Model')\nplt.xlabel('Years')\nplt.ylabel('Sales')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# What will be the predicted sales for 6 years? (Use the model to calculate and fill in the blank)\n# PREDICTION \n```",
    "output": "\n```python\nprediction_6_years = model.predict([[6]])\nprediction_6_years\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different products and their sales figures over multiple months. The dataset is stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\ndata = {\n    'product_id': ['A', 'A', 'A', 'B', 'B', 'B'],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03'],\n    'sales': [150, 200, 250, 100, 150, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the month-over-month growth in sales for each product and present these values in a new DataFrame. To achieve that, I need a way to calculate the percentage change in sales for each product month to month. \n\nCan we dynamically calculate this percentage change for the sales column, while ensuring that the new DataFrame retains the product_id and month columns along with the corresponding growth percentages?\n\nYour goal is to provide a code that accomplishes this using pandas, which I can use to fill in the blank:\n\n```python\nresult = df.groupby('product_id')['sales'].______().reset_index()\n```",
    "output": "\n```python\nresult = df.groupby('product_id')['sales'].pct_change().reset_index()\n```"
  },
  {
    "input": "Problem:\nYou are working with time series data of sales in different regions, and you need to predict future sales based on historical data. You have a DataFrame containing sales data for three regions over time. Your task is to apply a simple linear regression model to this data and predict the sales for the next time step, then visualize the results using a line plot. The DataFrame is structured as follows:\n\n```\n  Time  Region_A  Region_B  Region_C\n0    1       100       120       130\n1    2       110       125       133\n2    3       115       130       140\n3    4       120       150       145\n4    5       130       160       150\n```\n\nYou need to create a list `predictions` that stores the predicted sales for all regions.\n\nHere is the code snippet to start:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\ndata = {\n    \"Time\": [1, 2, 3, 4, 5],\n    \"Region_A\": [100, 110, 115, 120, 130],\n    \"Region_B\": [120, 125, 130, 150, 160],\n    \"Region_C\": [130, 133, 140, 145, 150]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, fill in the blank below to complete the solution that performs linear regression for each region and appends the predictions to the `predictions` list:\n\n```python\npredictions = []\nfor region in df.columns[1:]:\n    model = LinearRegression()\n    X = df[['Time']]\n    y = df[region]\n    model.fit(X, y)\n    next_time = np.array([[6]]) # predicting for time = 6\n    predictions.append(model.predict(next_time)[0])\n\n# Plotting the historical data along with predictions:\nplt.plot(df['Time'], df['Region_A'], label='Region_A')\nplt.plot(df['Time'], df['Region_B'], label='Region_B')\nplt.plot(df['Time'], df['Region_C'], label='Region_C')\nplt.scatter(6, predictions[0], color='red') # prediction for Region A\nplt.scatter(6, predictions[1], color='red') # prediction for Region B\nplt.scatter(6, predictions[2], color='red') # prediction for Region C\nplt.legend()\nplt.show()\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = predictions\n```"
  },
  {
    "input": "Problem:\nI am working on a project where I need to analyze and visualize the distributions of values in a dataset. I have a Pandas DataFrame that contains numerical data of different categories, and I would like to create multiple box plots for each category to visualize the distribution and identify any outliers. \n\nThe DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Category': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n    'Values': np.random.randint(1, 100, size=10)\n}\ndf = pd.DataFrame(data)\n```\n\nMy goal is to use Matplotlib to effectively visualize these distributions in a single figure. I want to ensure that each box plot corresponds to a category in the DataFrame. How would I go about doing this with box plots?\n\nA:\n```python\nimport matplotlib.pyplot as plt\n\n# Create the box plots\nplt.figure(figsize=(10, 6))\n... # put solution in this variable\nplt.xlabel('Category')\nplt.ylabel('Values')\nplt.title('Box Plot of Values by Category')\nplt.show()\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf.boxplot(column='Values', by='Category', grid=False)\n```"
  },
  {
    "input": "Problem:\nYou are analyzing sales data from an online store, and you have a dataset that contains the following features: order ID, customer ID, order date, and order total amount. The dataset is stored in a Pandas DataFrame with the columns: `order_id`, `customer_id`, `order_date`, and `order_amount`. Your task is to calculate the monthly sales totals and visualize them in a line plot using Matplotlib. The `order_date` is in 'YYYY-MM-DD' format.\n\nYour sales data looks like this:\n```\n   order_id customer_id  order_date order_amount\n0  1001         1      2023-01-15        250.00\n1  1002         2      2023-01-17        150.00\n2  1003         1      2023-01-20        200.00\n3  1004         3      2023-02-05        300.00\n4  1005         4      2023-02-10        400.00\n5  1006         2      2023-03-01        100.00\n```\n\nYou want to group the data by month, sum the order amounts for each month, and then plot the results. \n\nHere is your starting code:\n\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'order_id': [1001, 1002, 1003, 1004, 1005, 1006],\n    'customer_id': [1, 2, 1, 3, 4, 2],\n    'order_date': ['2023-01-15', '2023-01-17', '2023-01-20', '2023-02-05', '2023-02-10', '2023-03-01'],\n    'order_amount': [250.00, 150.00, 200.00, 300.00, 400.00, 100.00]\n}\n\ndf = pd.DataFrame(data)\n\n# Convert 'order_date' to datetime\ndf['order_date'] = pd.to_datetime(df['order_date'])\n\n# Group by month and sum order amounts\nmonthly_sales = df.groupby(df['order_date'].dt.to_period(\"M\"))['order_amount'].sum()\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nplt.plot(monthly_sales.index.astype(str), monthly_sales.values, marker='o')\nplt.title('Monthly Sales Totals')\nplt.xlabel('Month')\nplt.ylabel('Sales Amount')\nplt.xticks(rotation=45)\nplt.grid()\nplt.tight_layout()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = monthly_sales</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Create a synthetic dataset with a linear relationship\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10  # 100 random values in the range [0, 10)\ny = 2.5 * X + np.random.randn(100, 1)  # y = 2.5 * X + noise\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\npredictions = model.predict(X)\n\n# Create a scatter plot for the original data and the regression line\nplt.scatter(X, y, color='blue')\nplt.plot(X, predictions, color='red', linewidth=2)\n\n# Set the title of the plot\nplt.title(\"Original Data and Linear Regression Fit\")\n\n# Now, display the plot\n# SOLUTION START\n```",
    "output": "\n```python\nplt.xlabel(\"X values\")\nplt.ylabel(\"y values\")\nplt.grid(True)\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI would like to implement a machine learning model using Scikit-learn to predict house prices. I have a CSV file containing the dataset with features such as 'Size', 'Location', and 'Rooms'. After loading the data using Pandas, I plan to train a linear regression model. However, I need to apply data normalization before fitting the model. I would like to fill in the missing code below to scale the features using MinMaxScaler from Scikit-learn.\n\n```python\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndf = pd.read_csv('house_prices.csv')\n\n# Features and target\nX = df[['Size', 'Location', 'Rooms']]\ny = df['Price']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the scaler\nscaler = MinMaxScaler()\n\n# Fill in the blanks\nX_train_scaled = ... # put solution in this variable\n\n# Fit the model\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n```\n",
    "output": "\n```python\nX_train_scaled = scaler.fit_transform(X_train)\n```"
  },
  {
    "input": "Problem:\nI have a dataset comprised of features and labels pertaining to a binary classification problem, stored in a pandas DataFrame called `data`. The features are in columns 'feature1', 'feature2', and the label is in the column 'label'. I want to split this dataset into training and testing sets with a split ratio of 80% training and 20% testing. I intend to use `train_test_split` from Scikit-learn for this purpose. \n\nHere's a snippet of the data:\n```python\nimport pandas as pd\nimport numpy as np\n\n# Sample data creation\ndata = pd.DataFrame({\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'label': np.random.choice([0, 1], size=100)\n})\n```\n\nWhat is the correct way to use `train_test_split` in order to split `data` into training and testing sets, ensuring that the features are separated from the label, with the training and testing sets being stored in the variables `X_train`, `X_test`, `y_train`, and `y_test` respectively?\n\nA:\n```python\nfrom sklearn.model_selection import train_test_split\n```\nX_train, X_test, y_train, y_test = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nX_train, X_test, y_train, y_test = train_test_split(data[['feature1', 'feature2']], data['label'], test_size=0.2, random_state=42)\n```"
  },
  {
    "input": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# I have a dataset of house prices in a DataFrame `df` that includes features such as area, bedrooms, and age of the house. \n# I want to visualize the relationship between the area of the house and its price using polynomial regression.\n# The areas are in square feet, and prices are in thousands of dollars.\n\ndf = pd.DataFrame({\n    'area': [1500, 1800, 2400, 3000, 3500],\n    'price': [300, 340, 420, 490, 600]\n})\n\n# Fit a polynomial regression model\nX = df[['area']]\ny = df['price']\npoly = PolynomialFeatures(degree=2)\nX_poly = poly.fit_transform(X)\n\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Plotting the actual prices and the polynomial fit\nplt.scatter(df['area'], df['price'], color='blue', label='Actual Prices')\narea_range = np.linspace(1400, 3600, 100).reshape(-1, 1)\narea_poly_range = poly.transform(area_range)\nplt.plot(area_range, model.predict(area_poly_range), color='red', label='Polynomial Fit')\n\nplt.title('House Prices vs Area')\nplt.xlabel('Area (sq ft)')\nplt.ylabel('Price (in $1000)')\nplt.legend()\nplt.show()\n\n# Now I need to adjust the model to include an interaction term between area and age.\n# How can I add the age of the house, which is also in the DataFrame, to the existing polynomial regression model?\ndf['age'] = [10, 15, 5, 20, 8]  # Age in years\n\n# The below line is where you will fill in your solution.\nX_interaction = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nX_interaction = poly.fit_transform(df[['area', 'age']])  \n</code>"
  },
  {
    "input": "### Problem\nYou have a dataset containing information about house sales, and you need to perform some basic analysis using various data science libraries. The dataset includes columns for 'Price', 'Bedrooms', 'Bathrooms', and 'LotSize'. The dataset is loaded into a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Price': [300000, 450000, 500000, 350000, 600000],\n    'Bedrooms': [3, 4, 4, 3, 5],\n    'Bathrooms': [2, 3, 3, 2, 4],\n    'LotSize': [5000, 7000, 8000, 6000, 10000]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the correlation matrix of the numerical features in the DataFrame using NumPy. The output should only focus on the numeric columns.\n\nWhat is the Pandas code you can use to calculate this correlation matrix?\n\n```python\ncorrelation_matrix = ...\n```\n",
    "output": "\n```python\ncorrelation_matrix = df.corr()\n```"
  },
  {
    "input": "## Problem\nI have a dataset of customer transactions stored in a CSV file, and I want to analyze the purchasing behavior over a specific period. The CSV contains columns for `CustomerID`, `PurchaseAmount`, and `PurchaseDate`. I need to calculate the total purchasing amount for each customer, visualize their purchases over time, and normalize the total purchases using Min-Max scaling. I also need to use PyTorch to create a simple linear regression model that predicts the total purchase amount based on the number of transactions.\n\nHere's a snippet of my code so far:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch\nimport torch.nn as nn\n\n# Load the data\ndata = pd.read_csv('customer_transactions.csv')\n\n# Process the data\ngrouped_data = data.groupby('CustomerID').agg({'PurchaseAmount': 'sum', 'PurchaseDate': 'count'}).reset_index()\ngrouped_data.columns = ['CustomerID', 'TotalAmount', 'TransactionCount']\n\n# Normalize the TotalAmount\nscaler = MinMaxScaler()\ngrouped_data['NormalizedAmount'] = ...\n\n# Create a PyTorch model\nclass SimpleLinearRegression(nn.Module):\n    def __init__(self):\n        super(SimpleLinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n# Prepare the data for PyTorch\nX = torch.tensor(grouped_data['TransactionCount'].values, dtype=torch.float32).view(-1, 1)\ny = torch.tensor(grouped_data['TotalAmount'].values, dtype=torch.float32).view(-1, 1)\n\nmodel = SimpleLinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(100):\n    model.train()\n    optimizer.zero_grad()\n    output = model(X)\n    loss = criterion(output, y)\n    loss.backward()\n    optimizer.step()\n\n# Visualize the results\nplt.scatter(grouped_data['TransactionCount'], grouped_data['TotalAmount'])\nplt.plot(grouped_data['TransactionCount'], model(X).detach().numpy(), color='red')\nplt.xlabel('Transaction Count')\nplt.ylabel('Total Purchase Amount')\nplt.title('Customer Purchase Behavior')\nplt.show()\n\n# Now add the solution for the missing normalization\nnormalized_data = ...\n```\n\nFill in the blank for the normalization of `TotalAmount` so that `grouped_data['NormalizedAmount']` contains the scaled values between 0 and 1 for all customers.\nBEGIN SOLUTION\n```python\ngrouped_data['NormalizedAmount'] = scaler.fit_transform(grouped_data[['TotalAmount']])\n```",
    "output": "\n```python\ngrouped_data['NormalizedAmount'] = scaler.fit_transform(grouped_data[['TotalAmount']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing daily temperatures along with corresponding dates. I want to fit a polynomial regression model to this data in order to predict future temperatures. I have tried using numpy and pandas for data manipulation and Scikit-learn for fitting the model, but I'm unsure how to structure my model fitting code properly. Below is what I have so far:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# Sample temperature data\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': [30, 32, 35, 33, 31, 29, 28, 30, 31, 34]\n}\ndf = pd.DataFrame(data)\n\n# Converting dates to numerical representation\ndf['days'] = (df['date'] - df['date'].min()).dt.days\n\n# Prepare the polynomial features\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(df[['days']])\n\n# Fit the regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, df['temperature'])\n\n# Predict future temperatures using the model for the next 5 days\nfuture_days = np.array([df['days'].max() + i for i in range(1, 6)]).reshape(-1, 1)\nfuture_days_poly = poly.transform(future_days)\npredictions = model.predict(future_days_poly)\nprint(predictions)\n```\n\nThe problem I am facing is how to correctly generate the `future_days_poly` from `future_days` and make predictions. \n\nExpected:\nYou need to place your code for transformation and prediction in the designated area below.\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# Sample temperature data\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': [30, 32, 35, 33, 31, 29, 28, 30, 31, 34]\n}\ndf = pd.DataFrame(data)\n\n# Converting dates to numerical representation\ndf['days'] = (df['date'] - df['date'].min()).dt.days\n\n# Prepare the polynomial features\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(df[['days']])\n\n# Fit the regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, df['temperature'])\n\n# Predict future temperatures using the model for the next 5 days\nfuture_days = np.array([df['days'].max() + i for i in range(1, 6)]).reshape(-1, 1)\nfuture_days_poly = ... # place your solution here\npredictions = model.predict(future_days_poly)\nprint(predictions)\n</code>\nBEGIN SOLUTION\n<code>\nfuture_days_poly = poly.transform(future_days)\n</code>",
    "output": "\n<code>\nfuture_days_poly = poly.transform(future_days)\n</code>"
  },
  {
    "input": "Problem:\nYou are working with a dataset containing various features related to customer purchases. The dataframe is structured as follows:\n\n```\n   customer_id  age  purchase_amount\n0          101   25            120.0\n1          102   30            150.5\n2          103   22            90.0\n3          104   35            0.0\n4          105   40            200.0\n..         ...  ...              ...\n```\n\nI want to calculate the z-score of the `purchase_amount` to identify how many standard deviations away each purchase amount is from the mean. The z-score is calculated using the formula: \\( z = \\frac{(X - \\mu)}{\\sigma} \\), where \\( X \\) is the purchase amount, \\( \\mu \\) is the mean, and \\( \\sigma \\) is the standard deviation. \n\nTo do this in Python using Pandas and SciPy, fill in the blank below to compute the z-score for each `purchase_amount` and store the result in a new column named `z_score`.\n\nA:\n<code>\nimport pandas as pd\nfrom scipy.stats import zscore\n\ndf = pd.DataFrame({\n    'customer_id': [101, 102, 103, 104, 105],\n    'age': [25, 30, 22, 35, 40],\n    'purchase_amount': [120.0, 150.5, 90.0, 0.0, 200.0]\n})\n\n</code>\ndf['z_score'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\ndf['z_score'] = zscore(df['purchase_amount'])\n",
    "output": "\n<code>\ndf['z_score'] = zscore(df['purchase_amount'])\n</code>"
  },
  {
    "input": "### Problem\nYou have a dataset representing daily average temperatures for a city over a year in a pandas DataFrame, with some missing values. Your goal is to fill these missing temperature values with the mean temperature for that day of the week. \n\nHere's how your DataFrame looks:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': pd.date_range(start='2021-01-01', periods=365, freq='D'),\n    'Temperature': [np.nan if i % 30 == 0 else np.random.randint(15, 35) for i in range(365)]\n}\ndf = pd.DataFrame(data)\ndf.set_index('Date', inplace=True)\n```\n\nNow, using the `fillna` method, fill the NaN values with the mean of the temperatures for the respective day of the week. The desired DataFrame should have no NaN entries.\n\nYour code should replace the ellipsis with the appropriate solution to complete this task.\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby(df.index.dayofweek)['Temperature'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various products sold in a store, including their sales data and whether they were discounted. You need to calculate the average sales for each product category and visualize the results using a bar chart. Here's a sample dataframe to help you get started:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'C'],\n    'Category': ['Electronics', 'Clothing', 'Electronics', 'Home', 'Clothing', 'Home', 'Electronics', 'Home'],\n    'Sales': [100, 200, 150, 300, 250, 400, 350, 150],\n    'Discounted': [True, False, True, False, True, False, True, False]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the average sales per category and visualize them as a bar chart. Fill in the missing code below to achieve this:\n\n```python\nimport matplotlib.pyplot as plt\n\navg_sales = df.groupby('Category')['Sales'].mean()  # Calculate average sales per category\nplt.bar(avg_sales.index, avg_sales)  # Create a bar chart\nplt.xlabel('Category')\nplt.ylabel('Average Sales')\nplt.title('Average Sales per Category')\nplt.show()  # Display the bar chart\n```\n\nThe filled in line of code below is where you need to focus to complete the average sales calculation and visualization.\n\nA:\n<code>\navg_sales = ... # put solution in this variable\n</code>",
    "output": "\n<code>\navg_sales = df.groupby('Category')['Sales'].mean()  # Calculate average sales per category\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset of house prices and I want to predict the price based on various features. The dataset is stored in a CSV file named \"housing_data.csv\". I have already loaded the dataset into a DataFrame, and now I want to standardize the numerical features before passing them to a machine learning model. I want to use `StandardScaler` from scikit-learn to achieve this. However, I have set up my code with the following line:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\ndf = pd.read_csv('housing_data.csv')\nscaler = StandardScaler()\n```\n\nThe problem is that I am not sure how to apply the scaler to the numerical features, which are in the columns 'size', 'bedrooms', and 'bathrooms'.\n\nA:\n<code>\nscaled_features = scaler.fit_transform(df[['size', 'bedrooms', 'bathrooms']])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = pd.DataFrame(scaled_features, columns=['size', 'bedrooms', 'bathrooms'])\n</code>"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I have to preprocess a dataset that contains missing values in multiple columns. I want to impute these missing values with the mean of their respective columns. After imputation, I want to standardize the dataset such that each feature has a mean of 0 and a standard deviation of 1. Finally, I want to convert the preprocessed dataset into a TensorFlow tensor for further model training. Given a DataFrame `df` and necessary imports, please complete the code to achieve this.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample DataFrame with missing values\ndata = {\n    'feature1': [1, 2, np.nan, 4],\n    'feature2': [np.nan, 2, 3, 4],\n    'feature3': [1, 2, 3, np.nan]\n}\ndf = pd.DataFrame(data)\n\n# Step 1: Impute missing values with the mean of each column\n# Step 2: Standardize the dataset\n# Step 3: Convert to TensorFlow tensor\n\nresult_tensor = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf.fillna(df.mean(), inplace=True)\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\nresult_tensor = tf.convert_to_tensor(scaled_data, dtype=tf.float32)\n```"
  },
  {
    "input": "Problem:  \nI have a dataset containing customer orders with the following structure:  \n```\nCustomerID   OrderDate                    Amount\n01           2020-03-15 09:15:00         150.50\n01           2020-03-20 11:30:00         200.00\n02           2020-03-18 14:05:00         450.25\n02           2020-03-22 10:00:00         100.00\n03           2020-03-19 16:25:00         300.00\n```\n\nI want to add a new column to rank the amounts for each customer such that the highest amount receives rank 1. I tried using:  \n`df['Rank'] = df.groupby('CustomerID')['Amount'].rank(method='min', ascending=False)`  \nbut encountered an issue with the DataFrame format.\n\nHere is an example of how to set up your DataFrame:  \n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['01', '01', '02', '02', '03'],\n    'OrderDate': ['2020-03-15 09:15:00', '2020-03-20 11:30:00', \n                  '2020-03-18 14:05:00', '2020-03-22 10:00:00', \n                  '2020-03-19 16:25:00'],\n    'Amount': [150.50, 200.00, 450.25, 100.00, 300.00]\n}\n\ndf = pd.DataFrame(data)\ndf['OrderDate'] = pd.to_datetime(df['OrderDate'])\n```\n\nFill in the following code to correctly compute the ranks:  \n```python\ndf['Rank'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Rank'] = df.groupby('CustomerID')['Amount'].rank(method='min', ascending=False)\n```"
  },
  {
    "input": "Problem:\nI have a dataset of customer purchases stored in a pandas DataFrame like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 3, 1, 2, 3],\n    'PurchaseAmount': [100, 150, 200, 75, 50, 100],\n    'PurchaseDate': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-10', '2023-01-15', '2023-01-10']\n}\ndf = pd.DataFrame(data)\n```\n\nI would like to calculate the total amount spent by each customer over all purchases. I have tried using `groupby()`, but I am stuck on how to apply the aggregation correctly to get the desired output.\n\nThe expected result should look like this:\n\n```\n   CustomerID  TotalSpent\n0           1          175\n1           2          200\n2           3          300\n```\n\nCould you help me out with the aggregation step? \n\nA:\n```python\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf = df.groupby('CustomerID', as_index=False)['PurchaseAmount'].sum().rename(columns={'PurchaseAmount': 'TotalSpent'})\nEND SOLUTION\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing multiple features for different samples, and I would like to apply a Random Forest Classifier to predict the target variable. My dataset is structured as follows:\n\n```python\nimport pandas as pd\ndata = {\n    'feature1': [5, 10, 15, 20, 25],\n    'feature2': [2, 4, 6, 8, 10],\n    'target': [0, 1, 0, 1, 0]\n}\ndf = pd.DataFrame(data)\n```\n\nSo far, I have imported the necessary libraries and prepared the data. I have a piece of code to initialize the model and fit it to the training data. What I'm missing is the code to get the feature importances after training the model. How can I extract and store the feature importances in a variable named `feature_importances`?\n\nA:\n```python\nfrom sklearn.ensemble import RandomForestClassifier\n\nX = df[['feature1', 'feature2']]\ny = df['target']\nmodel = RandomForestClassifier()\nmodel.fit(X, y)\n```\nfeature_importances = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nfeature_importances = model.feature_importances_\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing customer information, and I want to preprocess it to feed into a machine learning model. The dataset has some missing values represented by NaNs, and I need to impute these missing values with the mean of their respective columns. Additionally, I want to standardize the numerical features so that they have a mean of 0 and a standard deviation of 1. The dataset looks like this:\n\n```\n         Age   Income  Score\n0      25.0   50000.0     5\n1      NaN    60000.0     6\n2      30.0   NaN        NaN\n3      35.0   70000.0     7\n4      NaN    NaN        8\n```\n\nAfter preparing this dataframe, I want to ensure that the standardized data is returned as a new dataframe. I've already imported the necessary libraries and created the dataframe but need help with the processing part:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {'Age': [25.0, None, 30.0, 35.0, None],\n        'Income': [50000.0, 60000.0, None, 70000.0, None],\n        'Score': [5, 6, None, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Your code starts here\ndf_imputed = ...\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\ndf_imputed = df.fillna(df.mean())\nscaler = StandardScaler()\nresult = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df_imputed.columns)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset that records the daily temperatures and humidity levels over a month. The data is stored in a CSV file named `weather_data.csv`. You want to normalize the temperature values to a scale of 0 to 1 for further analysis. The CSV file contains two columns: 'temperature' and 'humidity'. Here's a sample of how to load the dataset:\n\n```python\nimport pandas as pd\n\ndata = pd.read_csv('weather_data.csv')\ndata.head()\n```\nTo normalize the 'temperature' column, you can use the following equation:\n```\nnormalized_temp = (temperature - min(temperature)) / (max(temperature) - min(temperature))\n```\nHow would you apply this normalization to the dataset?\n\nA:\n```python\nimport pandas as pd\n\ndata = pd.read_csv('weather_data.csv')\ndata['normalized_temp'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndata['normalized_temp'] = (data['temperature'] - data['temperature'].min()) / (data['temperature'].max() - data['temperature'].min())\n```"
  },
  {
    "input": "## Problem\nYou are analyzing a dataset containing information about house prices. Your dataset is available as a Pandas DataFrame with features such as 'size', 'bedrooms', and 'price'. You need to create a NumPy array that contains the standardized values of the 'price' column, meaning each value in the 'price' column should be transformed to have a mean of 0 and a standard deviation of 1. \n\nAssuming you have the DataFrame `df`, how can you achieve this using NumPy? \n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'size': [1500, 2000, 2500, 3000, 3500],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'price': [300000, 400000, 500000, 600000, 700000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean_price = np.mean(df['price'])\nstd_price = np.std(df['price'])\nresult = (df['price'] - mean_price) / std_price\n</code>"
  },
  {
    "input": "Problem:\nI am working on a predictive model for housing prices using a dataset that includes various features such as square footage, number of bedrooms, and location. After conducting feature engineering, I want to ensure that the features have been standardized for better performance with machine learning algorithms. However, I need to apply the same transformation to both the training and testing datasets.\n\nGiven that you have already split your dataset into training and testing subsets, how can you use Scikit-learn's `StandardScaler` to fit the scaler on the training set and then transform both the training and testing sets correspondingly? Here\u2019s a starting point:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\n# Example DataFrames for training and testing features\nX_train = pd.DataFrame({'square_footage': [1500, 2000, 2500],\n                        'num_bedrooms': [3, 4, 5]})\n\nX_test = pd.DataFrame({'square_footage': [1800, 2200],\n                       'num_bedrooms': [3, 4]})\n\nscaler = StandardScaler()\n```\n\nYou need to fill in the blank in the following line to properly fit and transform the training data and then transform the testing data using the same scaling parameters:\n\n```python\nX_train_scaled = ...  # Fit and transform the training data\nX_test_scaled = ...   # Transform the testing data using the fitted scaler\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nX_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\nX_test_scaled = scaler.transform(X_test)         # Transform the testing data using the fitted scaler\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generating some random data for x and y\nnp.random.seed(0)\nx = np.random.rand(100, 1) * 10  # Feature ranging from 0 to 10\ny = 2.5 * x + np.random.randn(100, 1)  # Linear relationship with some noise\n\n# Creating a DataFrame\ndata = pd.DataFrame(data=np.hstack((x, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['Feature']], data['Target'])\n\n# Predicting values for the feature\ndata['Predicted'] = model.predict(data[['Feature']])\n\n# Plot the original data points\nplt.scatter(data['Feature'], data['Target'], label='Original Data', color='blue')\n\n# Plot the predicted line\nplt.plot(data['Feature'], data['Predicted'], label='Regression Line', color='red')\n\n# Show the plot with legend\nplt.legend()\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.title('Linear Regression Example')\n\n# Save the figure\nplt.savefig('linear_regression_plot.png')\n\n# Now we want to calculate the mean squared error\nmse = ((data['Target'] - data['Predicted']) ** 2).mean()\n\n# Return the computed mean squared error in a variable\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = mse\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'feature1': [10, 20, 30, 40],\n    'feature2': [1, 2, 3, 4],\n    'label': [0, 1, 0, 1]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to fit a logistic regression model using Scikit-learn to predict the 'label' based on 'feature1' and 'feature2', and store the fitted model in a variable named `model`. Here's what I have so far:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX = df[['feature1', 'feature2']]\ny = df['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n```\n\nWhat code should I use to fit the logistic regression model?\n\nA:\n```python\nfrom sklearn.linear_model import LogisticRegression\nmodel = ... # put solution in this variable\n```",
    "output": "\n```python\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n```"
  },
  {
    "input": "Problem:\nYou are analyzing a dataset containing information about customer purchases from a retail store. The dataset consists of columns including 'CustomerID', 'PurchaseAmount', and 'PurchaseDate'. You need to calculate the average purchase amount by customer per month. However, you also want to make sure to visualize this data alongside a trend line representing the overall average monthly purchase amount across all customers. \n\nGiven the following imports and sample data:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'CustomerID': [1, 1, 2, 2, 3, 3, 3],\n    'PurchaseAmount': [100, 200, 150, 300, 400, 250, 100],\n    'PurchaseDate': [\"2023-01-15\", \"2023-01-20\", \"2023-01-18\", \"2023-02-01\", \"2023-02-12\", \"2023-02-15\", \"2023-02-20\"]\n}\ndf = pd.DataFrame(data)\n\ndf['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'])\n```\n\nYou need to create a new DataFrame to summarize the average purchase amount by CustomerID per month and create a plot. Fill in the blank in the following code to achieve the summary DataFrame:\n\n```python\nmonthly_avg = df.groupby([df['PurchaseDate'].dt.to_period('M'), 'CustomerID'])['PurchaseAmount'].mean().reset_index()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = monthly_avg.rename(columns={'PurchaseDate': 'Month', 'PurchaseAmount': 'AveragePurchaseAmount'})\n```"
  }
]