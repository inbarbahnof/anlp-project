[
  {
    "input": "### Problem:\nYou have a dataset comprised of features and a target variable stored in a Pandas DataFrame. The features include several numerical columns that you want to standardize using Scikit-learn's `StandardScaler`. After scaling, you want to create a scatter plot using Matplotlib to visualize the first two principal components obtained from the scaled features via PCA (Principal Component Analysis). Your DataFrame is named `df`, and your target variable is a column labeled `target`.\n\nHere is the current code you have for scaling:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n```\n\nIn the code above, fill in the blank for `X_scaled`. \n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load your DataFrame\ndf = load_data()\n\n# Separate features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = ...  # Fill in this part\n\n# Perform PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot PCA results\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('PCA of Scaled Features')\nplt.colorbar(label='Target')\nplt.show()\n</code>",
    "output": "\n<code>\nX_scaled = scaler.fit_transform(X)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\n# Load iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n# Standardize the data\nstandardized_data = (df - df.mean()) / df.std()\n\n# Apply PCA and capture the principal components\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(standardized_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Plot the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'], alpha=0.5)\n\n# I want to add labels to the scatter plot for the three different species in the dataset.\n# I know that the target is stored in the iris dataset as well but I want to create a legend for it in the plot.\n\n# Replace with the actual solution to extract the target labels\ntarget_labels = ...  # put solution in this variable\n```",
    "output": "\n```python\ntarget_labels = data.target\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about houses including their sizes (in square feet), number of bedrooms, and prices. The dataset is structured as follows:\n\n| size | bedrooms | price  |\n|------|----------|--------|\n| 1500 | 3        | 300000 |\n| 1800 | 4        | 400000 |\n| 1200 | 2        | 250000 |\n| 2000 | 5        | 500000 |\n\nYou want to load this dataset into a Pandas DataFrame, normalize the features (size and bedrooms) using `MinMaxScaler`, and then fit a linear regression model to predict house prices. However, you would like to see how the size variable is normalized and stored in a new variable before fitting the model.\n\nLoad the data into a DataFrame and write the code to perform the following operations:\n\n1. Normalize the 'size' column using `MinMaxScaler` from `sklearn.preprocessing`.\n2. Store the normalized values in a new variable called `normalized_size`.\n\nA:\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndata = {\n    'size': [1500, 1800, 1200, 2000],\n    'bedrooms': [3, 4, 2, 5],\n    'price': [300000, 400000, 250000, 500000]\n}\n\ndf = pd.DataFrame(data)\n\nscaler = MinMaxScaler()\nscaler.fit(df[['size']])\n```\nnormalized_size = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nnormalized_size = scaler.transform(df[['size']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices in a Pandas DataFrame with various features like size, location, and year built. I want to create a scatter plot visualizing the relationship between house size (in square feet) and price, and to fit a linear regression line to the data using Scikit-learn. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size_sqft': [1500, 2000, 2500, 3000, 3500, 4000],\n    'price': [300000, 400000, 500000, 600000, 700000, 800000],\n}\ndf = pd.DataFrame(data)\n```\n\nI have set up my imports but am struggling to create the plot with the linear regression line. Here's how my import statements look:\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n```\n\nNow, I'd like to fill in the following line to create the linear regression model and predict the prices based on the size:\n\n```python\nmodel = LinearRegression() \nmodel.fit(___, ___)  # fill in the blanks with proper code\n```\n\nPlease fill in the blanks to apply the linear regression model to the DataFrame's size and price columns.",
    "output": "\n```python\nmodel.fit(df[['size_sqft']], df['price'])  # fill in the blanks with proper code\n```"
  },
  {
    "input": "Problem:\nYou have a dataset representing customer purchases at a retail store. The dataset is structured as follows:\n\n```\n   CustomerID  PurchaseAmount  PurchaseDate\n0           1           150.0    2023-01-01\n1           2           200.0    2023-01-01\n2           1           100.0    2023-01-05\n3           3           300.0    2023-01-05\n4           2           250.0    2023-01-07\n```\n\nYou want to calculate the total purchase amount for each customer and visualize the results in a bar chart. The final output should be a DataFrame showing the total purchases per customer, and then a bar chart displaying this data.\n\nFill in the blank to calculate the total purchase amount and store it in a variable named `total_purchases`:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create DataFrame\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2],\n    'PurchaseAmount': [150.0, 200.0, 100.0, 300.0, 250.0],\n    'PurchaseDate': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-05', '2023-01-05', '2023-01-07'])\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate total purchases per customer\ntotal_purchases = ...  # put solution in this variable\n\n# Plotting\ntotal_purchases.plot(kind='bar', title='Total Purchases per Customer')\nplt.xlabel('CustomerID')\nplt.ylabel('Total Purchase Amount')\nplt.show()\n```",
    "output": "\n```python\ntotal_purchases = df.groupby('CustomerID')['PurchaseAmount'].sum()\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generating synthetic data\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10  # Features\ny = 2.5 * X + np.random.randn(100, 1)  # Target with some noise\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predicting values for plotting\nX_fit = np.linspace(0, 10, 100).reshape(-1, 1)\ny_pred = model.predict(X_fit)\n\nplt.scatter(X, y, color='blue', label='Data points')\nplt.plot(X_fit, y_pred, color='red', label='Regression line')\nplt.title('Linear Regression Fit')\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.legend()\n\n# Display the plot\nplt.show()\n\n# Now, using the model, I also want to compute the R\u00b2 score of the fitted model.\n# The dataset and the fitted model are already prepared.\nscore = ... # put your solution here \n```",
    "output": "\n```python\nscore = model.score(X, y)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various vehicles, including their horsepower, weight, and fuel efficiency (mpg). I want to build a linear regression model to predict fuel efficiency based on horsepower and weight. After fitting the model, I want to visualize the predicted vs actual mpg values using Matplotlib. Given the following code snippet:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Sample vehicle data\ndata = {\n    'horsepower': [130, 165, 150, 140, 198],\n    'weight': [3504, 3693, 3436, 3433, 3534],\n    'mpg': [18, 15, 18, 16, 15]\n}\ndf = pd.DataFrame(data)\n\n# Prepare the features and target\nX = df[['horsepower', 'weight']]\ny = df['mpg']\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Make predictions\npredictions = model.predict(X)\n\n# Visualize predicted vs actual mpg\nplt.scatter(y, predictions)\nplt.xlabel(\"Actual MPG\")\nplt.ylabel(\"Predicted MPG\")\nplt.title(\"Predicted vs Actual MPG\")\nplt.plot([y.min(), y.max()], [y.min(), y.max()], '--', color='red')  # Add a line for perfect predictions\n```\n\nFill in the blank to compute the coefficient of determination (R\u00b2 score) for the predictions.\n\nA:\n```python\nr_squared = ...  # put solution in this variable\n```",
    "output": "\n```python\nr_squared = model.score(X, y)  # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing the monthly sales data for a retail company, structured in a DataFrame with two columns: \"Month\" (in 'YYYY-MM' format) and \"Sales\" (numeric values). You want to standardize the sales data to have a mean of 0 and a standard deviation of 1 for further analysis. \n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    \"Month\": [\"2020-01\", \"2020-02\", \"2020-03\", \"2020-04\", \"2020-05\", \"2020-06\"],\n    \"Sales\": [200, 220, 190, 250, 230, 240]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to compute the standardized sales values and add them as a new column called \"Standardized_Sales\".\n\nStandardization formula:\n\\[ \\text{Standardized Value} = \\frac{(X - \\text{mean})}{\\text{std}} \\]\n\nA solution should be assigned to the variable `result` that contains the updated DataFrame.\n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\nmean_sales = df['Sales'].mean()\nstd_sales = df['Sales'].std()\ndf['Standardized_Sales'] = (df['Sales'] - mean_sales) / std_sales\nresult = df\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset and apply PCA to reduce it to 2 dimensions\niris = load_iris()\ndata = pd.DataFrame(data=iris.data, columns=iris.feature_names)\npca = PCA(n_components=2)\ntransformed_data = pca.fit_transform(data)\n\n# Now, I want to visualize the two principal components with a scatter plot.\n# The desired output is to plot the transformed data with matplotlib while coloring points by their iris species.\n# The variable 'species' should hold the species labels (0, 1, 2), mapped from the iris target.\n\nspecies = iris.target\nplt.scatter(..., ...)  # put solution in this line to plot the data\n```",
    "output": "\n```python\nplt.scatter(transformed_data[:, 0], transformed_data[:, 1], c=species, cmap='viridis')\n```"
  },
  {
    "input": "Problem:\nI have a dataset of customer transactions stored in a Pandas DataFrame. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 1],\n    'PurchaseAmount': [100, 150, 200, 50, 100, 300],\n    'TransactionDate': pd.to_datetime(['2023-01-10', '2023-01-11', '2023-01-12', '2023-01-11', '2023-01-10', '2023-01-12'])\n}\ndf = pd.DataFrame(data)\n```\n\nI need to calculate the total purchase amount for each customer and visualize the total amounts in a bar chart. I'm going to use Matplotlib for plotting.\n\nHere's code for creating the bar chart:\n\n```python\nimport matplotlib.pyplot as plt\n\ntotal_purchase = df.groupby('CustomerID')['PurchaseAmount'].sum()\n\nplt.bar(total_purchase.index, total_purchase.values)\nplt.xlabel('Customer ID')\nplt.ylabel('Total Purchase Amount')\nplt.title('Total Purchase Amount per Customer')\nplt.show()\n```\n\nHowever, I need to modify the `plt.bar()` function to include a color gradient where customers who made higher purchases are represented with darker colors. You can use a simple colormap for this purpose. What should the modified `plt.bar()` line look like?\n\nA:\n<code>\nplt.bar(total_purchase.index, total_purchase.values, color=plt.cm.viridis(total_purchase.values / max(total_purchase.values)))\n</code>",
    "output": "\n<code>\nplt.bar(total_purchase.index, total_purchase.values, color=plt.cm.viridis(total_purchase.values / total_purchase.max()))\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset representing sales data of different products across several months. The data is structured as follows, with each product's sales figures in a separate column:\n\n```\nproduct    Jan   Feb   Mar   Apr   May\nA          100   120   130   110   150\nB          200   210   220   215   250\nC          150   160   170   175   180\n```\n\nI want to calculate each month's monthly sales percentage contribution of each product over the total sales for that month. My expected output format should be similar to this:\n\n```\nproduct    Jan     Feb     Mar     Apr     May\nA           0.20    0.24    0.23    0.21    0.25\nB           0.40    0.41    0.40    0.42    0.45\nC           0.30    0.35    0.37    0.37    0.30\n```\n\nHere is the code I started with:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product': ['A', 'B', 'C'],\n    'Jan': [100, 200, 150],\n    'Feb': [120, 210, 160],\n    'Mar': [130, 220, 170],\n    'Apr': [110, 215, 175],\n    'May': [150, 250, 180]\n})\n\n# I want to use ...\n```\n\nHow can I calculate the percentage contributions efficiently and fill in the blank in my code?\n\nA:\n<code>\ndf = df.set_index('product')\ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf = df.div(df.sum(axis=0), axis=1)\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Generate synthetic data\nnp.random.seed(42)\nX = np.random.rand(100, 1) * 10\ny = 2.5 * X.flatten() + np.random.randn(100) * 2\n\n# Create a DataFrame from the synthetic data\ndata = pd.DataFrame({'X': X.flatten(), 'y': y})\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['X']], data['y'])\n\n# Make predictions\npredictions = model.predict(data[['X']])\n\n# Calculate the mean squared error\nmse = mean_squared_error(data['y'], predictions)\n\n# Plot the results\nplt.scatter(data['X'], data['y'], color='blue', label='Data Points')\nplt.plot(data['X'], predictions, color='red', label='Regression Line')\nplt.title('Linear Regression Fit')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n# What is the value of MSE calculated from the predictions?\nmse_value = ... # put solution in this variable\n```",
    "output": "\n```python\nmse_value = mse\n```"
  },
  {
    "input": "Problem:\nI have a dataset where I want to predict a continuous target variable based on a set of features. After preprocessing the data using standard scaling, I will train a neural network model to make predictions. I have already imported the necessary libraries and defined my features and target variable. However, I need to finalize my model by defining its architecture using TensorFlow and compile it with an appropriate optimizer and loss function.\n\nI currently have:\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\n\n# Assume X_train and y_train are predefined\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n\n# Compilation is missing\n```\nWhat should I use to compile the model by choosing 'adam' as the optimizer and 'mean_squared_error' as the loss function?\n\nA:\n```python\nmodel.compile(____)  # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing customer information from an e-commerce platform, structured as follows:\n\n```python\ndata = {\n    'customer_id': [1, 2, 3, 4, 5],\n    'purchase_amount': [150.00, 200.00, 50.00, 300.00, 100.00],\n    'purchase_date': ['2023-01-15', '2023-01-20', '2023-01-20', '2023-01-22', '2023-01-25']\n}\n```\n\nYou want to analyze the total purchase amount by each purchase date. First, you would like to convert the 'purchase_date' column to a datetime format to ensure proper handling of dates. After this, you want to group the data by 'purchase_date', sum the 'purchase_amount', and sort the results in descending order of the total amount.\n\nYou have a solid start with the following code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame(data)\ndf['purchase_date'] = pd.to_datetime(df['purchase_date'])\n```\n\nHowever, you are unsure how to perform the grouping and summing operations in one go. You can complete the solution using:\n\n```python\nresult = ...  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('purchase_date')['purchase_amount'].sum().sort_values(ascending=False)\n```"
  },
  {
    "input": "Problem:\nI have a dataset representing the sales figures for different products over time, stored in a pandas DataFrame with the following structure:\n\n```\n   Product   Date      Sales\n0  A        2023-01-01  150\n1  A        2023-01-02  200\n2  A        2023-01-03  180\n3  B        2023-01-01  90\n4  B        2023-01-02  120\n5  B        2023-01-03  160\n```\n\nI want to calculate the moving average of sales for each product over a window of 2 days, then plot the results using Matplotlib. The final output DataFrame should retain all original columns and include a new column 'Moving_Avg' for the moving average.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame({\n    'Product': ['A', 'A', 'A', 'B', 'B', 'B'],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', \n                            '2023-01-01', '2023-01-02', '2023-01-03']),\n    'Sales': [150, 200, 180, 90, 120, 160]\n})\n\ndf['Moving_Avg'] = ...  # put solution in this variable\n\n# Plotting\nfor product in df['Product'].unique():\n    plt.plot(df[df['Product'] == product]['Date'], \n             df[df['Product'] == product]['Moving_Avg'], label=product)\nplt.legend()\nplt.title('Moving Average Sales')\nplt.xlabel('Date')\nplt.ylabel('Moving Average Sales')\nplt.show()\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['Moving_Avg'] = df.groupby('Product')['Sales'].transform(lambda x: x.rolling(window=2).mean())\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Simulate some data: x values from 0 to 10\nx = np.arange(0, 10, 0.5)\n# y values as a function of x with some noise\ny = 3 * x + np.random.normal(0, 2, size=x.shape)\n\n# Create a DataFrame from the simulated data\ndata = pd.DataFrame({'x': x, 'y': y})\n\n# Fit a linear regression model using sklearn\nmodel = LinearRegression()\nmodel.fit(data[['x']], data['y'])\n\n# Now, let's predict the y values for the x values in the original data\npredictions = model.predict(data[['x']])\n\n# Plot the original data and the linear regression line\nplt.scatter(data['x'], data['y'], label='Data points')\nplt.plot(data['x'], predictions, color='red', label='Regression line')\nplt.legend()\n\n# To evaluate the model performance, we also want to calculate the mean squared error\n# Here is where you need to add the code to compute the mean squared error\nmse = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(data['y'], predictions)\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing information about customers and their purchase amounts in a Pandas DataFrame. You want to normalize the purchase values using Min-Max scaling, and after that, visualize the original and normalized purchase values side by side in a Matplotlib bar chart.\n\nAssuming you have the following DataFrame:\n```python\nimport pandas as pd\n\ndata = {\n    'Customer': ['A', 'B', 'C', 'D', 'E'],\n    'PurchaseAmount': [200, 450, 300, 150, 500]\n}\ndf = pd.DataFrame(data)\n```\nYou would like to fill in the missing code to apply Min-Max normalization to the `PurchaseAmount` column using Scikit-learn's `MinMaxScaler`. \n\nWhat is the code to normalize the purchase amounts and prepare for plotting them in a bar chart?\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\ndf['NormalizedPurchase'] = ...\n\nplt.bar(df['Customer'], df['PurchaseAmount'], alpha=0.5, label='Original')\nplt.bar(df['Customer'], df['NormalizedPurchase'], alpha=0.5, label='Normalized')\nplt.legend()\nplt.show()\n```\nA:\n\n```python\ndf['NormalizedPurchase'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['NormalizedPurchase'] = scaler.fit_transform(df[['PurchaseAmount']])\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset that records the daily temperatures of a city over the course of a year. The dataset is structured as follows:\n\n```\ndate       | temperature\n-----------|-------------\n2023-01-01 | 5\n2023-01-02 | 6\n...        | ...\n2023-12-30 | 2\n2023-12-31 | 3\n```\n\nYou want to create a list of boolean values indicating whether the temperature was above the average temperature of the year for each respective day. Specifically, if the temperature on a given day is above the yearly average, that day should correspond to `True`, otherwise `False`. \n\nYou will be using NumPy and Pandas libraries for this task, so you import them accordingly. \n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\n# Sample dataFrame creation\ndata = {\n    'date': pd.date_range(start='2023-01-01', end='2023-12-31'),\n    'temperature': np.random.randint(-10, 40, size=365)\n}\ndf = pd.DataFrame(data)\n\n# Calculate the average temperature of the year\naverage_temp = df['temperature'].mean()\n\n# Create a new column with boolean values\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['temperature'] > average_temp\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate synthetic data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # 100 random points in the range [0, 10)\ny = 3 * X.squeeze() + np.random.randn(100) * 2  # y = 3x + noise\n\n# Create a pandas DataFrame\ndata = pd.DataFrame({'X': X.squeeze(), 'y': y})\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(data[['X']], data['y'])\n\n# Plot the data points\nplt.scatter(data['X'], data['y'], color='blue')\n\n# Show the linear regression line\n# SOLUTION START\nplt.plot(data['X'], model.predict(data[['X']]), color='red')\n# SOLUTION END\n\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Linear Regression Fit')\nplt.show()\n```",
    "output": "\n```python\nplt.plot(data['X'], model.predict(data[['X']]), color='red')\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing daily temperature readings from multiple cities over a year, and I want to analyze how the average temperature changes over the year for each city. Here's a sample of the DataFrame `temperature_df`:\n\n```\nDate         City       Temperature\n2023-01-01  New York   30\n2023-01-01  Los Angeles 65\n2023-01-02  New York   31\n2023-01-02  Los Angeles 70\n...\n2023-12-31  New York   40\n2023-12-31  Los Angeles 60\n```\n\nI want to create a line plot that shows the trend of average temperatures over the entire year for each city on the same plot. \n\nHowever, I'm not sure how to group the data by city and date to calculate the average temperature for that day before plotting. Here\u2019s how the initial DataFrame looks:\n\n```python\nimport pandas as pd\n\ntemperature_df = pd.DataFrame({\n    'Date': pd.date_range(start='2023-01-01', periods=365),\n    'City': ['New York'] * 365 + ['Los Angeles'] * 365,\n    'Temperature': np.random.randint(30, 100, size=730)\n})\n```\n\nThe plotting part has been done, but I need code to compute the average temperature for each city over the year. \n\nA:\n```python\nimport matplotlib.pyplot as plt\n\n# Assuming `temperature_df` is already defined as above\naverage_temps = ...  # put your solution in this variable\n```",
    "output": "\n```python\naverage_temps = temperature_df.groupby(['Date', 'City'])['Temperature'].mean().reset_index()\naverage_temps = average_temps.groupby('City').agg({'Temperature': 'mean'}).reset_index()\n```"
  },
  {
    "input": "Problem:\nI am analyzing a dataset of customer reviews for a product. Each review has a rating from 1 to 5 and a corresponding text. I would like to visualize the distribution of ratings and also apply some natural language processing to analyze the sentiment of the reviews. Here\u2019s the current structure of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Review': [\n        \"Great product and great value!\", \n        \"Did not like it at all.\", \n        \"It's okay, nothing special.\", \n        \"Absolutely loved it!\", \n        \"Would not recommend.\"\n    ],\n    'Rating': [5, 1, 3, 5, 2]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI already imported the necessary libraries and preprocessed the text for sentiment analysis but I'm stuck on how to plot the distribution of ratings. I want to create a bar chart displaying the count of each rating from 1 to 5 along with appropriate labels and a title. \n\nCan you provide the line of code I need to fill in below?\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.bar(df['Rating'].value_counts().index, df['Rating'].value_counts(), color='blue')\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.title('Distribution of Ratings')\nplt.xticks(rotation=0)\nplt.show()\n``` \ndf = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf = df['Rating'].value_counts().sort_index()\n```"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I need to generate synthetic data to simulate a classification problem. Specifically, I need to create a dataset with two features and a binary target variable. I want to make sure that the classes are imbalanced, with 80% of the data belonging to class 0 and 20% to class 1. I want to use NumPy for generating the features, Pandas for wrapping it into a DataFrame, and Matplotlib for visualizing the distribution of the classes.\n\nHere's what I've done so far:\n1. I generated 1000 samples of feature data using NumPy.\n2. I created an imbalanced target variable such that 800 examples belong to class 0 and 200 belong to class 1.\n\nNow, I\u2019m trying to combine this data into a Pandas DataFrame and plot the distribution of the target variable using Matplotlib. I want to fill in the blanks in my code below to achieve that:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Generate synthetic features\nnp.random.seed(0)\nfeature_1 = np.random.randn(1000)\nfeature_2 = np.random.randn(1000)\n\n# Create an imbalanced target variable\ntarget = np.array([0]*800 + [1]*200)\n\n# Shuffle the dataset\nnp.random.shuffle(target)\n\n# Combine features and target into a DataFrame\ndf = pd.DataFrame({\n    'feature_1': feature_1,\n    'feature_2': feature_2,\n    'target': target\n})\n\n# Plotting the distribution of the target variable\ndf['target'].value_counts().plot(kind='bar')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.title('Distribution of Target Variable')\nplt.show()\n\n# Fill in the blank to create a new DataFrame with shuffled data:\ndata = ...\n```\ndata = ... # put solution in this variable",
    "output": "\n```python\ndata = df.sample(frac=1).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI have a dataset of images stored in a NumPy array (e.g., shape (n_samples, height, width, channels)) that I want to categorize into various labels based on their pixel values. I already have a trained TensorFlow model for classification, and I want to apply this model to predict the labels for my dataset. However, I need a method to preprocess the images by normalizing the pixel values to a range of [0, 1] before feeding them into the model. Given the image data, how can I achieve this normalization?\n\nHere\u2019s my code snippet:\n```python\nimport numpy as np\n\n# Sample dataset of images\nimage_data = np.random.randint(0, 256, (100, 32, 32, 3), dtype=np.uint8)\n\n# To do: normalize image data\nresult = ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = image_data.astype(np.float32) / 255.0\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various houses and their sale prices. This dataset is in a pandas DataFrame and contains features such as the number of bedrooms, bathrooms, and area (in square feet). I need to normalize the 'SalePrice' column using Min-Max scaling so that its values are within the range from 0 to 1.\n\nHere's a sample of the DataFrame:\n\n```\nimport pandas as pd\n\ndata = {\n    'Bedrooms': [3, 4, 2, 5],\n    'Bathrooms': [2, 3, 1, 2],\n    'Area': [1500, 2300, 1200, 3000],\n    'SalePrice': [300000, 450000, 250000, 650000],\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter normalizing the 'SalePrice', I want to save this transformed DataFrame into a new variable.\n\nA:\n<code>\ndf['SalePrice_normalized'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['SalePrice_normalized'] = (df['SalePrice'] - df['SalePrice'].min()) / (df['SalePrice'].max() - df['SalePrice'].min())\n</code>"
  },
  {
    "input": "Problem:\nSuppose I have a dataset containing information about various car models, including their horsepower and weight. I want to predict the horsepower of a car based on its weight using a linear regression model from Scikit-learn and visualize the fitted line using Matplotlib.\n\nGiven the following setup, how do I fit the model and predict horsepower while getting the coefficients and generating the plot?\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Sample data\ndata = {\n    'weight': [1500, 1600, 1700, 1800, 1900, 2000, 2100],\n    'horsepower': [130, 140, 150, 160, 170, 180, 190]\n}\ndf = pd.DataFrame(data)\n\nX = df[['weight']]\ny = df['horsepower']\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# After fitting the model, how do I predict the horsepower for the test set and plot it?\nresult = ... # put solution in this variable\n```\nBEGIN SOLUTION \n<code>\n",
    "output": "\n```python\nresult = model.predict(X_test)\n\n# Get the coefficients\nslope = model.coef_[0]\nintercept = model.intercept_\n\n# Plotting\nplt.scatter(X, y, color='blue', label='Data points')\nplt.plot(X, model.predict(X), color='red', label='Fitted line')\nplt.xlabel('Weight')\nplt.ylabel('Horsepower')\nplt.title('Horsepower vs Weight')\nplt.legend()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a time series dataset containing daily temperatures recorded in a Pandas DataFrame. I want to calculate the rolling average of the temperatures over a 7-day window and then plot the original temperatures alongside the rolling average using Matplotlib. The initial dataset looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndates = pd.date_range('2023-01-01', periods=14)\ntemperatures = np.random.rand(14) * 30  # Random temperatures between 0 and 30 degrees\ndf = pd.DataFrame({'Date': dates, 'Temperature': temperatures})\n```\n\nMy goal is to perform the rolling average calculation and create a plot. I initiated the rolling calculation with:\n\n```python\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=7)...\n```\n\nWhat should I fill in to complete this code snippet? \n\nA:\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=7).mean()\n</code>\nThen, to create the plot:\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(df['Date'], df['Temperature'], label='Daily Temperature', marker='o')\nplt.plot(df['Date'], df['Rolling_Avg'], label='7-Day Rolling Average', color='orange')\nplt.title('Daily Temperatures and 7-Day Rolling Average')\nplt.xlabel('Date')\nplt.ylabel('Temperature (\u00b0C)')\nplt.legend()\nplt.show()\n```",
    "output": "\n<code>\ndf['Rolling_Avg'] = df['Temperature'].rolling(window=7).mean()\n</code>"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I have a dataset containing information about houses. The dataset consists of features including 'size', 'num_rooms', 'num_bathrooms', and 'price'. I want to normalize the 'size' and 'price' features using Min-Max scaling, which transforms the features into a range of [0, 1].\n\nGiven the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 2400, 3000, 2000, 1800],\n    'num_rooms': [3, 4, 5, 3, 4],\n    'num_bathrooms': [2, 3, 2, 2, 3],\n    'price': [300000, 450000, 600000, 400000, 350000]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to apply Min-Max scaling on 'size' and 'price', and store the results in a new DataFrame called `normalized_df` with the same columns. You can use `MinMaxScaler` from `scikit-learn` to achieve this.\n\nThe result should look like this:\n```\n   size  num_rooms  num_bathrooms  price\n0  0.00         3               2   0.00\n1  0.60         4               3   0.75\n2  1.00         5               2   1.00\n3  0.40         3               2   0.50\n4  0.20         4               3   0.25\n```\n\nYou need to fill in the blank in the following code:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_data = scaler.fit_transform(df[['size', 'price']])\nnormalized_df = pd.DataFrame(normalized_data, columns=['size', 'price']) # Put the code to add num_rooms and num_bathrooms here\n```\n\nnormalized_df = ... # put solution in this variable",
    "output": "\n```python\nnormalized_df = pd.concat([normalized_df, df[['num_rooms', 'num_bathrooms']].reset_index(drop=True)], axis=1)\n```"
  },
  {
    "input": "Problem:\nYou have a dataset containing information about different products sold by various stores. The dataset is represented as a Pandas DataFrame, `df`, and has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Store': ['Store A', 'Store A', 'Store B', 'Store B', 'Store C', 'Store C'],\n    'Product': ['Item 1', 'Item 2', 'Item 1', 'Item 3', 'Item 2', 'Item 1'],\n    'Sales': [150, 200, 80, 45, 120, 95],\n    'Price': [10, 20, 15, 30, 25, 10]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new column in this DataFrame that calculates the total revenue generated from each product, defined as `Revenue = Sales * Price`. \n\nA:\n```python\ndf['Revenue'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Revenue'] = df['Sales'] * df['Price']\n```"
  },
  {
    "input": "Problem:\nYou have collected data on customer purchases across different stores in a retail chain, represented in a DataFrame called `df`. The DataFrame contains the following columns: `Store`, `CustomerID`, `PurchaseAmount`, and `Date`, where `Date` is in the format 'YYYY-MM-DD'. Your goal is to calculate the total sales for each store and the average purchase amount per customer within a specific date range, which you will provide as input parameters `start_date` and `end_date`.\n\nThe expected output should be a DataFrame that contains `Store`, `TotalSales`, and `AveragePurchaseAmount` for each store, sorted by `TotalSales` in descending order.\n\nYour code should start by filtering the original DataFrame based on the given date range, then perform the necessary calculations.\n\nHere is the initial DataFrame setup:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Store': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'],\n    'CustomerID': [1, 2, 1, 3, 2, 4, 3, 4],\n    'PurchaseAmount': [100, 200, 150, 300, 250, 120, 400, 320],\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08']\n}\ndf = pd.DataFrame(data)\n```\n\nYou are to fill in the blank with the necessary code logically following the description.\n\n```python\nstart_date = '2023-01-01'\nend_date = '2023-01-07'\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nfiltered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\nresult = filtered_df.groupby('Store').agg(TotalSales=('PurchaseAmount', 'sum'), AveragePurchaseAmount=('PurchaseAmount', 'mean')).reset_index()\nresult = result.sort_values(by='TotalSales', ascending=False)\n```"
  },
  {
    "input": "Problem:\nI am analyzing a dataset of features and labels using a neural network. The dataset is in a pandas dataframe format and contains a column for features ('feature') and another for labels ('label'). I want to normalize the features using Min-Max scaling and then convert the normalized features into a TensorFlow tensor for further processing. I have already imported the necessary libraries and created a dataframe. \n\nHere is what I have:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\ndata = {\n    'feature': [20, 30, 40, 50, 60],\n    'label': [0, 1, 1, 0, 1]\n}\ndf = pd.DataFrame(data)\n```\n\nNow I need to normalize the 'feature' column and create a TensorFlow tensor from it.\n\nA:\n```python\nnormalized_features = ... # put solution in this variable\n```",
    "output": "\n```python\nnormalized_features = (df['feature'] - df['feature'].min()) / (df['feature'].max() - df['feature'].min())\nnormalized_tensor = tf.convert_to_tensor(normalized_features, dtype=tf.float32)\n```"
  },
  {
    "input": "### Problem\nYou are working with a dataset containing customer reviews for a product. The reviews are stored in a Pandas DataFrame with the following columns: 'ReviewID', 'ReviewText', and 'Rating'. You want to preprocess the 'ReviewText' column by converting the text to lowercase, removing punctuation, and then transforming the words into numerical representations using TF-IDF vectorization.\n\nGiven the following code snippet:\n\n```python\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\n\ndata = {\n    'ReviewID': [1, 2, 3],\n    'ReviewText': ['Great product!', 'Not what I expected...', 'Okay, I suppose.'],\n    'Rating': [5, 2, 3]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to fill in the blank to create a TF-IDF matrix for the cleaned 'ReviewText'. The transformation should remove punctuation and convert the text to lowercase before fitting the TF-IDF vectorizer.\n\nA:\n```python\nimport numpy as np\n# Cleaning function\ndef clean_text(text):\n    text = text.lower()  # Convert to lowercase\n    return text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n\n# Preprocess the 'ReviewText' column\ndf['CleanedText'] = df['ReviewText'].apply(clean_text)\n\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(df['CleanedText'])\n\ntfidf_matrix = ...  # put solution in this variable\n```",
    "output": "\n```python\ntfidf_matrix = X.toarray()  # Convert sparse matrix to dense array\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\n\n# Apply PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\nreduced_data = pca.fit_transform(df)\n\n# Create a scatter plot of the first and second PCA components\nplt.scatter(reduced_data[:, 0], reduced_data[:, 1], alpha=0.5)\nplt.title(\"PCA of Iris Dataset\")\nplt.xlabel(\"First Principal Component\")\nplt.ylabel(\"Second Principal Component\")\n\n# Add a grid to the plot\n# SOLUTION START\n```",
    "output": "\n```python\nplt.grid(True)\n# SOLUTION END\nplt.show()\n```"
  },
  {
    "input": "### Problem:\nI have a dataset containing time series data on daily temperatures for multiple cities over a month. The dataset looks like this, with city names as columns and dates as rows:\n\n|        | City A | City B | City C |\n|--------|--------|--------|--------|\n| 2023-01-01 | 30     | 25     | 20     |\n| 2023-01-02 | 32     | 27     | 22     |\n| 2023-01-03 | NaN    | 24     | 23     |\n| 2023-01-04 | 31     | NaN    | 21     |\n| 2023-01-05 | 29     | 26     | 20     |\n\nI want to calculate the daily average temperature for each day while excluding any NaN values. Additionally, I would like to plot this daily average temperature using Matplotlib.\n\nI realize that I can use the `mean` function for this, but I'm not sure how to handle the NaN values when calculating the average.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'City A': [30, 32, np.nan, 31, 29],\n    'City B': [25, 27, 24, np.nan, 26],\n    'City C': [20, 22, 23, 21, 20]\n}\n\ndf = pd.DataFrame(data, index=pd.date_range(start='2023-01-01', periods=5))\n\ndaily_average = ... # put solution in this variable\nplt.plot(daily_average.index, daily_average.values)\nplt.title(\"Daily Average Temperature\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Average Temperature\")\nplt.show()\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndaily_average = df.mean(axis=1, skipna=True)\n</code>"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I have to preprocess a dataset that consists of both numerical and categorical features. I want to standardize the numerical features and one-hot encode the categorical features using Scikit-learn\u2019s `ColumnTransformer`. Here is the initial setup:\n\n```python\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# Sample dataframe\ndata = pd.DataFrame({\n    'age': [25, 32, 28, 45],\n    'salary': [50000, 60000, 52000, 58000],\n    'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles']\n})\n\n# Columns to transform\nnumerical_features = ['age', 'salary']\ncategorical_features = ['city']\n```\n\nWhat is the correct way to apply the `ColumnTransformer` to standardize the numerical features and one-hot encode the categorical features?\n\nA:\n```python\ntransformer = ColumnTransformer(transformers=[\n    ('num', StandardScaler(), numerical_features),\n    ('cat', OneHotEncoder(), categorical_features)\n])\n\ntransformed_data = ... # put solution in this variable\n```",
    "output": "\n```python\ntransformed_data = transformer.fit_transform(data)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\n\n# Load the Iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Calculate the mean of each feature grouped by the target class\n# I want to visualize this in a bar plot with the class labels on the x-axis.\n# Let's start plotting the mean of each feature for each class. \n# The first step is to obtain the mean values.\n\nmean_values = df.groupby('target').mean()\n\n# Now, create a bar plot of these mean values.\n# SOLUTION START\n```",
    "output": "\n```python\nmean_values.plot(kind='bar')\nplt.title('Mean Feature Values by Iris Class')\nplt.xlabel('Iris Class')\nplt.ylabel('Mean Feature Value')\nplt.xticks(rotation=0)\nplt.legend(title='Features')\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset of housing prices in a DataFrame that contains the following columns: 'price', 'area', 'bedrooms', and 'location'. I want to create a simple linear regression model to predict house prices based on the area and number of bedrooms. After training the model, I want to predict the price for a new house with a given area and number of bedrooms. \n\nHere\u2019s the setup:\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\ndata = {\n    'price': [150000, 200000, 250000, 300000, 350000],\n    'area': [1500, 2000, 2500, 3000, 3500],\n    'bedrooms': [3, 4, 3, 5, 4],\n    'location': ['A', 'B', 'A', 'B', 'A']\n}\ndf = pd.DataFrame(data)\n\nX = df[['area', 'bedrooms']]\ny = df['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Now I want to predict the price for a new house \nnew_house = [[2400, 4]]  # area, bedrooms\n```\nI need to fill in the blank to get the predicted price:\n```python\npredicted_price = ...\n```\n",
    "output": "\n```python\npredicted_price = model.predict(new_house)\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset in a Pandas DataFrame consisting of sales data for different products over a year. Each row represents daily sales of a product, and the columns include 'product_id', 'date', and 'sales'. You want to predict future sales using a simple linear regression model implemented with Scikit-learn and visualize the forecast using Matplotlib.\n\nAssuming you already have the DataFrame df structured as described and the necessary libraries imported, how would you fill in the code to train a linear regression model on historical sales data for a specific product (with id = 1) and then plot the predicted sales over the next 30 days?\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Sample DataFrame creation (Not part of the solution)\n# df = pd.DataFrame({'product_id': [1]*365, 'date': pd.date_range('2022-01-01', periods=365), 'sales': np.random.randint(1, 100, 365)})\n\n# Filter for product_id = 1\nproduct_sales = df[df['product_id'] == 1]\n\n# Convert 'date' to ordinal\nproduct_sales['date'] = product_sales['date'].apply(lambda x: x.toordinal())\n\n# Prepare the input (X - date) and output (y - sales)\nX = product_sales[['date']].values\ny = product_sales['sales'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Create the Linear Regression model\nmodel = LinearRegression()\n\n# Fit the model to the training data\nmodel.fit(X_train, y_train)\n\n# Generate future dates for the next 30 days\nfuture_dates = np.array([(pd.to_datetime(product_sales['date'].max(), origin='1970-01-01') + pd.Timedelta(days=i)).toordinal() for i in range(1, 31)])\n\n# Predict future sales\npredicted_sales = model.predict(future_dates.reshape(-1, 1))\n\n# Plotting the results\nplt.figure(figsize=(10, 5))\nplt.plot(product_sales['date'], product_sales['sales'], label='Historical Sales')\nplt.plot(future_dates, predicted_sales, label='Predicted Sales', color='orange')\nplt.title('Sales Prediction for Product ID 1')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n\n# Fill in the code to predict future sales\npredicted_sales = ... # put your solution here\n```",
    "output": "\n```python\npredicted_sales = model.predict(future_dates.reshape(-1, 1))\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Generate some sample data\nnp.random.seed(42)\nx = np.random.rand(100, 1) * 10  # 100 random values between 0 and 10\ny = 2.5 * x + np.random.randn(100, 1)  # Linear relationship with noise\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(x, y)\n\n# Now I want to predict y values for x = 5, 6, 7, 8\n# I want to store predictions in a variable named predictions\npredictions = ...  # put solution in this variable\n```",
    "output": "\n```python\n<code>\npredictions = model.predict(np.array([[5], [6], [7], [8]]))\n</code>\n```"
  },
  {
    "input": "Problem:\n\nYou have a dataset containing information about a series of products, where the data is structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [25.50, 45.00, 15.75, 85.00, 20.00],\n    'quantity_sold': [200, 150, 300, 50, 400]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the total revenue generated by each product and add this information as a new column named 'total_revenue' to the existing DataFrame. The total revenue for each product can be calculated using the formula:\n\n```\ntotal_revenue = price * quantity_sold\n```\n\nHow can you achieve this using pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [25.50, 45.00, 15.75, 85.00, 20.00],\n    'quantity_sold': [200, 150, 300, 50, 400]\n}\n\ndf = pd.DataFrame(data)\n\n# Calculate total revenue and store it in a new column\n# total_revenue = ...\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['total_revenue'] = df['price'] * df['quantity_sold']\n</code>"
  },
  {
    "input": "Problem:\n\nYou have a time series dataset containing daily stock prices. You want to normalize the 'closing_price' column using Min-Max Scaling, which transforms the values to a range between 0 and 1. Given the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n    'closing_price': [100, 150, 200]\n}\ndf = pd.DataFrame(data)\n```\n\nFill in the code to perform Min-Max Scaling on the 'closing_price' column and store the normalized values in a new column called 'normalized_price'.\n\nA:\n\n```python\n# Assuming df is already defined\ndf['normalized_price'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['normalized_price'] = (df['closing_price'] - df['closing_price'].min()) / (df['closing_price'].max() - df['closing_price'].min())\n```"
  },
  {
    "input": "## Problem\nYou are working with a dataset that tracks the daily temperature across different cities. You have it loaded as a Pandas DataFrame, and now you want to calculate a rolling average of the temperature values over a specified window size. Here is the structure of your data:\n\n```python\nimport pandas as pd\n\ndata = {\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Day1': [30, 70, 20, 50, 100],\n    'Day2': [32, 72, 22, 49, 105],\n    'Day3': [31, 68, 18, 51, 102],\n    'Day4': [29, 75, 24, 48, 104],\n    'Day5': [30, 73, 21, 50, 101],\n}\ndf = pd.DataFrame(data).set_index('City')\n```\n\nYou need to calculate the rolling average over a window of 3 days, but for this task, you want to rename the resulting DataFrame to indicate that these are moving averages and you want to fill any resulting NaN values with 0. Here is how you started:\n\n```python\nwindow_size = 3\n```\n\nFill in the blanks to calculate the rolling average and generate the final result:\n\n```python\nresult = df.rolling(window=window_size).mean().fillna(0)\n```\n\nNow, make sure `result` is renamed to reflect that it contains rolling averages by applying the appropriate string modification to the column names.\n\n```python\nresult.columns = ...\n```\n\nWhat code should go in the blank to appropriately rename the columns of the resulting DataFrame? \n\n```python\n# The answer goes here\n```",
    "output": "\n```python\nresult.columns = [f'Rolling_Avg_{col}' for col in result.columns]\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about customers, including their ages and spending scores. I\u2019ve been using Pandas to manage my data. I need to standardize the 'Age' column to ensure it has a mean of 0 and a standard deviation of 1, so that it can be effectively processed by machine learning models. \n\nHowever, I\u2019m unsure how to apply the standardization formula where the standardized value for each data point is calculated as: \n\\[ z = \\frac{(X - \\mu)}{\\sigma} \\]\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) is the standard deviation.\n\nHere's a sample DataFrame with my data:\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 3, 4, 5],\n    'Age': [23, 45, 31, 35, 29],\n    'SpendingScore': [39, 81, 6, 77, 40]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat would be the correct way to apply this standardization to the 'Age' column and store it in a new column called 'Standardized_Age'?\n\nA:\n```python\nstandardized_age = ... # put solution in this variable\n```",
    "output": "\n```python\nmean_age = df['Age'].mean()\nstd_age = df['Age'].std()\ndf['Standardized_Age'] = (df['Age'] - mean_age) / std_age\n```"
  },
  {
    "input": "Problem:\nYou are working on a dataset that contains information about customers' monthly spending on various products. Each row in the dataset contains the following columns: `customer_id`, `product`, and `spending`. You would like to compute the average monthly spending for each product and then visualize this information using a bar chart. \n\nHere is a sample dataframe:\n```\nimport pandas as pd\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nWhat line of code should you write to calculate the average spending by product?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 1, 2, 2, 3, 3],\n    'product': ['A', 'B', 'A', 'B', 'A', 'C'],\n    'spending': [100, 150, 200, 50, 250, 300]\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df.groupby('product')['spending'].mean().reset_index()</code>"
  },
  {
    "input": "Problem:\nI have a dataset that contains information about customer purchases in a retail store, represented as a Pandas DataFrame:\n```python\ndata = {\n    'customer_id': [101, 102, 103, 104, 105],\n    'purchase_amount': [250, 150, 300, 200, 350],\n    'purchase_date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']\n}\ndf = pd.DataFrame(data)\n```\nI would like to calculate the cumulative sum of the purchase amounts over the days and visualize the results using Matplotlib. \n\nCan you help me fill in the missing code to compute the cumulative sum and create a line plot showing the cumulative purchase amounts over time? The resulting plot should have the x-axis labeled as 'Date', the y-axis labeled as 'Cumulative Purchase Amount', and a title 'Cumulative Purchase Amount Over Time'. \n\nHere's the beginning of my code:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [101, 102, 103, 104, 105],\n    'purchase_amount': [250, 150, 300, 200, 350],\n    'purchase_date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']\n}\ndf = pd.DataFrame(data)\n\n# Convert 'purchase_date' to datetime\ndf['purchase_date'] = pd.to_datetime(df['purchase_date'])\n\n# Calculate cumulative sum\ndf['cumulative_sum'] = ...  # put solution in this variable\n\n# Plotting\nplt.plot(df['purchase_date'], df['cumulative_sum'])\nplt.xlabel('Date')\nplt.ylabel('Cumulative Purchase Amount')\nplt.title('Cumulative Purchase Amount Over Time')\nplt.show()\n```\nBEGIN SOLUTION\n```python\ndf['cumulative_sum'] = df['purchase_amount'].cumsum()\n```",
    "output": "\n```python\ndf['cumulative_sum'] = df['purchase_amount'].cumsum()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales information for a product over a week. The data looks like this:\n\n```\n   Day      Sales\n0  Mon      120\n1  Tue      150\n2  Wed      130\n3  Thu      170\n4  Fri      160\n5  Sat      180\n6  Sun      190\n```\n\nI want to calculate the moving average of sales over a period of 3 days, starting from the first day of data. I wrote the following code:\n\n```python\nimport pandas as pd\n\ndata = {'Day': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n        'Sales': [120, 150, 130, 170, 160, 180, 190]}\ndf = pd.DataFrame(data)\n```\n\nThen I tried to calculate the moving average using:\n```python\ndf['Moving_Average'] = df['Sales'].rolling(window=3).mean()\n```\n\nHowever, I need the `Moving_Average` computed to only show values starting from the third day, meaning the first two entries should be NaN. My goal is to achieve this while also plotting both `Sales` and `Moving_Average` using Matplotlib.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'Day': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n        'Sales': [120, 150, 130, 170, 160, 180, 190]}\ndf = pd.DataFrame(data)\n\ndf['Moving_Average'] = ...\n# Plotting code follows\nplt.plot(df['Day'], df['Sales'], label='Sales')\nplt.plot(df['Day'], df['Moving_Average'], label='Moving Average', color='orange')\nplt.legend()\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['Moving_Average'] = df['Sales'].rolling(window=3).mean()\n</code>"
  },
  {
    "input": "Problem:\nYou are analyzing a dataset containing sales information for a retail store. The dataset consists of three columns: 'date', 'store_id', and 'sales', with daily sales figures. You want to visualize the total sales per store over the entire timeframe, generating a line plot with the date on the x-axis and total sales on the y-axis. Furthermore, you want each store's line in the plot to have a distinct color while adding labels for each store. \n\nGiven the following sample data:\n\n```python\nimport pandas as pd\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10).tolist() * 3,\n    'store_id': ['A'] * 10 + ['B'] * 10 + ['C'] * 10,\n    'sales': [100, 150, 200, 130, 120, 160, 180, 220, 190, 170] + \n             [110, 140, 210, 130, 125, 165, 175, 215, 185, 160] + \n             [90, 160, 185, 140, 130, 150, 170, 200, 195, 180]\n}\ndf = pd.DataFrame(data)\n```\n\nHow can you summarize the total sales for each store by date and then create a line plot using Matplotlib that fulfills this description? \n\nThe command to set up the plot should begin with:\n```python\nimport matplotlib.pyplot as plt\ntotal_sales = ...\n```\n\nThe variable `total_sales` must store the DataFrame resulting from the aggregation of sales data, ensuring that each store's sales for each date are summed correctly.",
    "output": "\n```python\nimport matplotlib.pyplot as plt\ntotal_sales = df.groupby(['date', 'store_id'])['sales'].sum().unstack()\ntotal_sales.plot(kind='line', marker='o')\nplt.title('Total Sales per Store Over Time')\nplt.xlabel('Date')\nplt.ylabel('Total Sales')\nplt.legend(title='Store ID')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n```"
  },
  {
    "input": "Problem:\n\nI am working with a dataset using Pandas that contains information on various products sold in a store, including their prices and quantities sold. I want to calculate the total revenue generated by each product and store this new information in a new column called \"Revenue\". The revenue for each product is calculated as the product of its price and the quantity sold. Here\u2019s a snippet of the code I'm working with:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C'],\n    'Price': [15.0, 20.0, 25.0],\n    'Quantity Sold': [10, 5, 8]\n}\n\ndf = pd.DataFrame(data)\n```\n\nHow can I calculate and assign the revenue to a new column \"Revenue\"?\n\nA:\n\n```python\nimport pandas as pd\ndata = {\n    'Product': ['A', 'B', 'C'],\n    'Price': [15.0, 20.0, 25.0],\n    'Quantity Sold': [10, 5, 8]\n}\ndf = pd.DataFrame(data)\ndf['Revenue'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Revenue'] = df['Price'] * df['Quantity Sold']\n```"
  },
  {
    "input": "Problem:\nI am working with an image dataset that I want to preprocess before feeding it into a neural network model. The dataset contains images stored in a directory and has a corresponding CSV file with labels. I want to resize all images to a uniform size of (128, 128) pixels, normalize the pixel values to be between 0 and 1, and then convert them into a NumPy array along with their labels. The images are in a folder named 'images/' and the labels are in a CSV file named 'labels.csv'.\n\nHere's how the CSV file looks:\n\n```\nfilename,label\nimage1.jpg,0\nimage2.jpg,1\nimage3.jpg,0\n```\n\nThe desired output should be a tuple containing the NumPy array of the processed images and a NumPy array of the labels.\n\nA:\n<code>\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n# Load the labels\nlabels_df = pd.read_csv('labels.csv')\nimage_array = []\n\nfor index, row in labels_df.iterrows():\n    img = Image.open(os.path.join('images', row['filename']))\n    img = img.resize((128, 128))  # Resize images\n    img = np.array(img) / 255.0   # Normalize pixel values\n    image_array.append(img)\n\nimage_data = np.array(image_array)\nlabels = labels_df['label'].values\n\nresult = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = (image_data, labels)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing customer information, and I want to preprocess it to feed into a machine learning model. The dataset has some missing values represented by NaNs, and I need to impute these missing values with the mean of their respective columns. Additionally, I want to standardize the numerical features so that they have a mean of 0 and a standard deviation of 1. The dataset looks like this:\n\n```\n         Age   Income  Score\n0      25.0   50000.0     5\n1      NaN    60000.0     6\n2      30.0   NaN        NaN\n3      35.0   70000.0     7\n4      NaN    NaN        8\n```\n\nAfter preparing this dataframe, I want to ensure that the standardized data is returned as a new dataframe. I've already imported the necessary libraries and created the dataframe but need help with the processing part:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = {'Age': [25.0, None, 30.0, 35.0, None],\n        'Income': [50000.0, 60000.0, None, 70000.0, None],\n        'Score': [5, 6, None, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Your code starts here\ndf_imputed = ...\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\ndf_imputed = df.fillna(df.mean())\nscaler = StandardScaler()\nresult = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df_imputed.columns)\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset in a pandas DataFrame that contains sales data for an e-commerce platform. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'order_id': [1, 2, 3, 4, 5],\n    'customer_id': [101, 102, 101, 103, 102],\n    'order_amount': [250, 150, 200, 300, 400],\n    'order_date': pd.to_datetime(['2023-08-01', '2023-08-02', '2023-08-01', '2023-08-03', '2023-08-02'])\n}\ndf = pd.DataFrame(data)\n```\n\nI want to analyze this data and calculate the total sales amount for each customer. I also want to visualize this information using a bar chart. However, I'm unsure how to aggregate the sales by customer and plot the results clearly.\n\nTo achieve this, I need to use the `groupby` method to calculate the total sales amount per customer and then use Matplotlib to display a bar chart of total sales per customer.\n\nHere is where I'm stuck. I want to fill in the blanks for the aggregation and plotting:\n\n```python\ntotal_sales = df.groupby('customer_id')['order_amount'].sum()  # fill this in\ntotal_sales.plot(kind='bar', ... )  # fill this in\n```\n\nWhat should I put in place of the blanks to obtain the total sales per customer and create a bar plot? \nA:\n\n```python\ntotal_sales = ... # put solution in this variable\ntotal_sales.plot(kind='bar', title='Total Sales by Customer', xlabel='Customer ID', ylabel='Total Sales Amount')  # fill this in\n```",
    "output": "\n```python\ntotal_sales = df.groupby('customer_id')['order_amount'].sum()  \ntotal_sales.plot(kind='bar', title='Total Sales by Customer', xlabel='Customer ID', ylabel='Total Sales Amount')  \n```"
  },
  {
    "input": "## Problem\nYou have a dataset representing customer purchases with columns for `customer_id` and `purchase_amount`. The purchase amounts are in dollars and you want to analyze this data.\n\n```python\nimport pandas as pd\n\ndata = {\n    'customer_id': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n    'purchase_amount': [100, 200, 150, 300, 250, 100, 200, 50]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to create a new DataFrame that summarizes the total purchase amount by each `customer_id`, showing the `customer_id` and their corresponding `total_purchase_amount` in descending order.\n\nWhat code should you use to produce the expected result? Store the result in a variable named `summary`.\n\nA:\n```python\nsummary = ...\n```",
    "output": "\n```python\nsummary = df.groupby('customer_id')['purchase_amount'].sum().reset_index(name='total_purchase_amount').sort_values(by='total_purchase_amount', ascending=False)\n```"
  },
  {
    "input": "Problem:\nYou have collected data on a number of customers and their purchasing behavior over a month, and you stored this data in a pandas DataFrame. The DataFrame contains the following columns: `customer_id`, `purchase_amount`, and `purchase_date`. Your goal is to determine the total purchase amount for each customer, as well as their average purchase amount, but you need to calculate and display these results visually.\n\nHere\u2019s a snippet of the creation of your DataFrame:\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': ['C1', 'C2', 'C1', 'C3', 'C2', 'C1'],\n    'purchase_amount': [100, 200, 150, 300, 250, 50],\n    'purchase_date': pd.date_range('2023-10-01', periods=6, freq='D')\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour task is to:\n1. Group this data by `customer_id` and calculate the total and average purchase amounts.\n2. Create a bar plot to visualize each customer's total purchase amount.\n\nThe output should be in the following format:\n- `total_amount` - total purchase for each customer.\n- `average_amount` - average purchase for each customer.\n- A bar plot showing `customer_id` on the x-axis and `total_amount` on the y-axis.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': ['C1', 'C2', 'C1', 'C3', 'C2', 'C1'],\n    'purchase_amount': [100, 200, 150, 300, 250, 50],\n    'purchase_date': pd.date_range('2023-10-01', periods=6, freq='D')\n}\n\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('customer_id').agg(total_amount=('purchase_amount', 'sum'), \n                                       average_amount=('purchase_amount', 'mean')).reset_index()\n\nplt.bar(result['customer_id'], result['total_amount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Purchase Amount')\nplt.title('Total Purchase Amount by Customer')\nplt.show()\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about customer purchases at a retail store. The data is structured as follows:\n\n```plaintext\nCustomerID, Age, Gender, ProductID, PurchaseAmount\n1, 25, M, A1, 19.99\n2, 30, F, A2, 29.99\n3, 22, M, A1, 9.99\n4, 35, F, A3, 39.99\n5, 45, M, A2, 15.00\n```\n\nI want to calculate the average purchase amount for each product regardless of the customer's details, and I also want to visualize this average purchase amount using a bar chart. \n\nProvide the solution that computes the average purchase amount for each ProductID and stores it in a variable named `average_purchase`, and then uses Matplotlib to plot the averages.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {'CustomerID': [1, 2, 3, 4, 5],\n        'Age': [25, 30, 22, 35, 45],\n        'Gender': ['M', 'F', 'M', 'F', 'M'],\n        'ProductID': ['A1', 'A2', 'A1', 'A3', 'A2'],\n        'PurchaseAmount': [19.99, 29.99, 9.99, 39.99, 15.00]}\ndf = pd.DataFrame(data)\n</code>\naverage_purchase = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\naverage_purchase = df.groupby('ProductID')['PurchaseAmount'].mean().reset_index()\nplt.bar(average_purchase['ProductID'], average_purchase['PurchaseAmount'])\nplt.xlabel('ProductID')\nplt.ylabel('Average Purchase Amount')\nplt.title('Average Purchase Amount by Product')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a time series dataset of monthly sales data for multiple products, stored in a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'month': pd.date_range(start='2021-01-01', periods=12, freq='M'),\n    'product_A': [150, 200, 220, 190, 250, 275, 300, 320, 350, 370, 400, 450],\n    'product_B': [120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 230, 240],\n    'product_C': [100, 140, 160, 120, 180, 210, 240, 230, 260, 270, 290, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to create a new column called `total_sales` that represents the total sales across all products for each month. How can I achieve this? \n\nPlease write the code to compute the `total_sales` and add it to the DataFrame.\n\ntotal_sales = ... # put solution in this variable",
    "output": "\n```python\n<code>\ndf['total_sales'] = df[['product_A', 'product_B', 'product_C']].sum(axis=1)\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset that contains customer orders and their shipping details as follows:\n\n```plaintext\norder_id     order_date           product       quantity    shipping_date\n1           2023-01-15 09:30:00  Laptop        2           2023-01-20 10:00:00\n2           2023-01-16 10:15:00  Smartphone     1           NaT\n3           2023-01-17 12:00:00  Tablet         5           2023-01-19 09:00:00\n4           2023-01-18 15:45:00  Headphones     4           2023-01-21 11:30:00\n5           2023-01-19 08:00:00  Charger        10          NaT\n```\n\nI want to calculate the delivery time in days for each order and create a new column called \"delivery_time\". For the orders with NaT in \"shipping_date\", the delivery time should be recorded as NaN. \n\nI've tried using the following code to calculate the difference, but it doesn't work:\n\n```python\ndf['delivery_time'] = (df['shipping_date'] - df['order_date']).dt.days\n```\n\nCan you help me correct this and successfully create the \"delivery_time\" column?\n\nA:\n<code>\nimport pandas as pd\nfrom pandas import NaT\n\ndata = {\n    'order_id': [1, 2, 3, 4, 5],\n    'order_date': pd.to_datetime(['2023-01-15 09:30:00', '2023-01-16 10:15:00', \n                                   '2023-01-17 12:00:00', '2023-01-18 15:45:00', \n                                   '2023-01-19 08:00:00']),\n    'product': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Charger'],\n    'quantity': [2, 1, 5, 4, 10],\n    'shipping_date': pd.to_datetime(['2023-01-20 10:00:00', NaT, \n                                       '2023-01-19 09:00:00', \n                                       '2023-01-21 11:30:00', NaT])\n}\ndf = pd.DataFrame(data)\n</code>\ndf['delivery_time'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['delivery_time'] = (df['shipping_date'] - df['order_date']).dt.days\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different species of flowers with the following columns: `sepal_length`, `sepal_width`, `petal_length`, `petal_width`, and `species`. The dataset is stored in a CSV file named `flowers.csv`. I want to visualize the relationship between `sepal_length` and `sepal_width` for each species using a scatter plot, and I would like to color the points based on the species. \n\nHere is a code snippet to read the dataset:\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('flowers.csv')\n```\nI would like to fill in the code that creates and displays the scatter plot. \n\nA:\n<code>\nplt.scatter(df['sepal_length'], df['sepal_width'], c=df['species'].astype('category').cat.codes, cmap='viridis')\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\nplt.title('Sepal Length vs Sepal Width per Species')\nplt.colorbar(label='Species')\nplt.show()\n### BEGIN SOLUTION",
    "output": "\n<code>\nplt.scatter(df['sepal_length'], df['sepal_width'], c=df['species'].astype('category').cat.codes, cmap='viridis')\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\nplt.title('Sepal Length vs Sepal Width per Species')\nplt.colorbar(label='Species')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nYou have a time series dataset of daily sales from a retail store, represented as a Pandas DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': pd.date_range(start='2022-01-01', periods=10, freq='D'),\n    'sales': [200, 220, np.nan, 250, 300, np.nan, 320, np.nan, np.nan, 350]\n}\ndf = pd.DataFrame(data)\n```\n\nYou notice that there are missing sales values and would like to fill these gaps in sales data using a rolling mean of the previous three days. Additionally, you want to create a new column that indicates whether sales were above or below the average sales over the entire time period. \n\nCan you compute and store this result in a new column called 'above_average' where values are `True` if the sales for that day were above the average and `False` otherwise? Please put your solution to compute the rolling mean and the 'above_average' into the following variable:\n\n```python\nresult = ...\n```\n\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf['sales'] = df['sales'].fillna(df['sales'].rolling(window=3, min_periods=1).mean())\naverage_sales = df['sales'].mean()\ndf['above_average'] = df['sales'] > average_sales\nresult = df\n</code>\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some random data\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1)\ny = 4 + 3 * X + np.random.randn(100, 1)\n\n# Create a pandas DataFrame from the data\ndf = pd.DataFrame(np.hstack((X, y)), columns=['Feature', 'Target'])\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(df[['Feature']], df['Target'])\n\n# Predict values using the fitted model\ndf['Predictions'] = model.predict(df[['Feature']])\n\n# Plot the original data and the regression line\nplt.scatter(df['Feature'], df['Target'], color='blue', label='Original Data')\nplt.plot(df['Feature'], df['Predictions'], color='red', linewidth=2, label='Regression Line')\n\n# Fill in the blank to set the x and y limits to enhance the visualization\nplt.xlim(0, ...)  # Solve for x limit\nplt.ylim(0, ...)  # Solve for y limit\nplt.xlabel('Feature')\nplt.ylabel('Target')\nplt.title('Linear Regression')\nplt.legend()\nplt.show()\n```",
    "output": "\n```python\nplt.xlim(0, 2)  # Solve for x limit\nplt.ylim(0, 15)  # Solve for y limit\n```"
  },
  {
    "input": "Problem:\n\nI am working with a dataset containing information about sales transactions. I have a DataFrame that holds transaction data, and I want to normalize the sales amount using `MinMaxScaler` from Scikit-learn. Additionally, I need to plot the original and normalized sales amounts using Matplotlib. Here's my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'sales_amount': [150, 200, 50, 300, 100]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to perform the following actions:\n\n1. Normalize the `sales_amount` column to a scale from 0 to 1 using `MinMaxScaler`.\n2. Create a line plot with the original sales amount and the normalized sales amount on the same graph.\n\nYour task is to fill in the following lines of code to apply normalization and plot the results:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n\nscaler = MinMaxScaler()\ndf['normalized_sales'] = ... # put solution in this variable\n\nplt.plot(df['transaction_id'], df['sales_amount'], label='Original Sales', marker='o')\nplt.plot(df['transaction_id'], df['normalized_sales'], label='Normalized Sales', marker='x')\nplt.title('Sales Amount Normalization')\nplt.xlabel('Transaction ID')\nplt.ylabel('Sales Amount')\nplt.legend()\nplt.show()\n```\n\nFill in the blank with the correct code to create the `normalized_sales` column.",
    "output": "\n```python\ndf['normalized_sales'] = scaler.fit_transform(df[['sales_amount']])\n```"
  },
  {
    "input": "## Problem\n\nYou are working with a dataset that consists of features about different houses and their sale prices. You want to create a predictive model to determine the sale price based on house features using a neural network approach with TensorFlow.\n\nYou have the following data in a Pandas DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Square_Feet': [1500, 1800, 2400, 3000, 3500],\n    'Bedrooms': [3, 3, 4, 5, 5],\n    'Age': [10, 15, 20, 5, 1],\n    'Sale_Price': [300000, 350000, 500000, 600000, 650000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou want to define a simple feedforward neural network model to predict the sale price. Define a model with one hidden layer having 5 neurons with `relu` activation and output layer for sale price prediction.\n\nPlease fill in the line marked with \"...\" to create the neural network model using TensorFlow's Keras API.\n\n```python\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(3,)),  # input layer corresponding to 3 features\n    tf.keras.layers.Dense(5, activation='relu'),  # hidden layer\n    ...\n])\n```\n",
    "output": "\n```python\n    tf.keras.layers.Dense(1)  # output layer for sale price prediction\n```"
  },
  {
    "input": "Problem:\nYou are working with a dataset consisting of daily temperature records and their corresponding humidity levels. You have two NumPy arrays: one for temperatures in degrees Celsius and another for humidity percentages. The temperature data covers 30 days, while the humidity data contains fluctuations for the same period. Your goal is to create a Pandas DataFrame that includes the maximum temperature and its corresponding humidity level in each row. Additionally, calculate the correlation coefficient between temperature and humidity using SciPy. Your arrays look like this:\n\n```python\nimport numpy as np\nimport pandas as pd\n\ntemperatures = np.array([15, 17, 20, 25, 28, 30, 22, 19, 18, 16, 14, 12, 10, 8, 7, 11, 13, 15, 14, 16, 20, 24, 27, 26, 21, 19, 18, 20, 22, 25, 29, 31])\nhumidity = np.array([30, 35, 40, 45, 38, 50, 55, 60, 65, 70, 75, 80, 85, 90, 85, 80, 78, 75, 70, 65, 60, 55, 50, 48, 45, 40, 35, 30, 28, 25, 24, 23])\n```\n\nYou need to find the correlation coefficient between the maximum temperature and its corresponding humidity for each day.\n\nA:\n<code>\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import pearsonr\n\ntemperatures = np.array([15, 17, 20, 25, 28, 30, 22, 19, 18, 16, 14, 12, 10, 8, 7, 11, 13, 15, 14, 16, 20, 24, 27, 26, 21, 19, 18, 20, 22, 25, 29, 31])\nhumidity = np.array([30, 35, 40, 45, 38, 50, 55, 60, 65, 70, 75, 80, 85, 90, 85, 80, 78, 75, 70, 65, 60, 55, 50, 48, 45, 40, 35, 30, 28, 25, 24, 23])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndf = pd.DataFrame({'Temperature': temperatures, 'Humidity': humidity})\nmax_temp_humidity = df.loc[df['Temperature'].idxmax()]\ncorrelation_coefficient, _ = pearsonr(temperatures, humidity)\nresult = (max_temp_humidity['Temperature'], max_temp_humidity['Humidity'], correlation_coefficient)\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different products, including their prices, categories, and features. I want to normalize the 'price' column values to a range of 0 to 1, while keeping the DataFrame structure intact. Here is the DataFrame I have:\n\n```python\nimport pandas as pd\n\ndata = {\n    'ProductID': [1, 2, 3, 4],\n    'Category': ['A', 'B', 'A', 'C'],\n    'Price': [100, 200, 150, 300],\n    'Feature1': [5, 7, 6, 9],\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter applying normalization to the 'Price' column, I want the resulting DataFrame to still include the 'ProductID', 'Category', and 'Feature1' columns. \n\nA:\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnormalized_prices = ... # put solution in this variable\n```",
    "output": "\n```python\nnormalized_prices = scaler.fit_transform(df[['Price']])\ndf['Price'] = normalized_prices\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing customer information, and I want to preprocess it to feed into a machine learning model. The dataset has some missing values represented by NaNs, and I need to impute these missing values with the mean of their respective columns. Additionally, I want to standardize the numerical features after imputing. \n\nHere is the initial code:\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# Sample DataFrame creation\ndata = {\n    'Age': [25, np.nan, 30, 22, np.nan],\n    'Salary': [50000, 60000, np.nan, 40000, 45000],\n    'City': ['New York', 'Los Angeles', 'New York', np.nan, 'Chicago']\n}\ndf = pd.DataFrame(data)\n\n# Impute missing values\nimputer = SimpleImputer(strategy='mean')\ndf[['Age', 'Salary']] = imputer.fit_transform(df[['Age', 'Salary']])\n\n# Standardize the numerical features\nscaler = StandardScaler()\ndf[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])\nprint(df)\n\n# I need to fill in the missing part of the code represented by `...` in the imputer line.\n\nimputed_data = ...  # put solution in this variable",
    "output": "\n<code>\nimputed_data = imputer.fit_transform(df[['Age', 'Salary']])\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load iris dataset\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train a RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Generate a classification report and store the result\n# SOLUTION START\n```",
    "output": "\n```python\nreport = classification_report(y_test, y_pred, target_names=data.target_names)\nprint(report)\n# SOLUTION END\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing customer purchases with the following columns: `customer_id`, `purchase_amount`, and `purchase_date`. I need to calculate the monthly total purchases for each customer and visualize the data using a line plot where the x-axis represents the months, and the y-axis represents the total purchase amount.\n\nHere is a simplified view of the DataFrame:\n\n```\n   customer_id purchase_amount purchase_date\n0            1            120    2023-01-15\n1            2            150    2023-01-22\n2            1             80    2023-02-10\n3            2            200    2023-02-15\n4            3            220    2023-01-05\n```\n\nMy code so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'customer_id': [1, 2, 1, 2, 3],\n    'purchase_amount': [120, 150, 80, 200, 220],\n    'purchase_date': pd.to_datetime(['2023-01-15', '2023-01-22', '2023-02-10', '2023-02-15', '2023-01-05'])\n}\ndf = pd.DataFrame(data)\n\nmonthly_totals = ... # put solution in this variable\n```\n\nHow can I compute `monthly_totals` and plot the results?",
    "output": "\n```python\nmonthly_totals = df.groupby([df['purchase_date'].dt.to_period('M'), 'customer_id'])['purchase_amount'].sum().unstack(fill_value=0)\n\nmonthly_totals.plot(kind='line', marker='o')\nplt.title('Monthly Total Purchases by Customer')\nplt.xlabel('Month')\nplt.ylabel('Total Purchase Amount')\nplt.xticks(rotation=45)\nplt.legend(title='Customer ID')\nplt.tight_layout()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing several features, and I would like to preprocess the data by normalizing it. My dataset, `data`, is a Pandas DataFrame with columns 'feature1', 'feature2', and 'feature3'. The normalization of each feature can be performed using the formula:\n\nnormalized_value = (value - mean) / std_dev\n\nTo achieve this, I want to use Scikit-learn's `StandardScaler`. However, I want to apply the transformation and also convert the result back into a DataFrame with the same column names. Given the code snippet, how can I fill in the blank to perform this normalization?\n\nA:\n<code>\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndata = pd.DataFrame({\n    'feature1': [10, 20, 30, 40, 50],\n    'feature2': [5, 10, 15, 20, 25],\n    'feature3': [1, 2, 3, 4, 5]\n})\n\nscaler = StandardScaler()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nnormalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses and their prices. The dataset is in a CSV format with the following columns: `area` (in square feet), `bedrooms`, `age` (in years), and `price`. I want to perform a simple linear regression analysis to predict house prices based on the other features. After training the model using Scikit-learn, I want to visualize the predicted prices against the actual prices using Matplotlib.\n\nGiven the CSV file as `houses.csv`, I've already loaded the data into a Pandas DataFrame like this:\n\n```python\nimport pandas as pd\ndata = pd.read_csv('houses.csv')\n```\n\nThe dataset looks like this:\n```\n   area  bedrooms  age   price\n0  1500        3    5  300000\n1  2000        4   10  500000\n...\n```\n\nI would like to fit a linear regression model to predict `price` based on `area`, `bedrooms`, and `age`, and subsequently create a plot to compare the predicted prices with the actual prices. The code to fit the model is written, but I need to fill in the blank in the code snippet below to produce the plot. \n\n```python\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\nX = data[['area', 'bedrooms', 'age']]\ny = data['price']\nmodel = LinearRegression().fit(X, y)\npredicted_prices = model.predict(X)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(y, predicted_prices)\n\n# Fill in the blank with the solution for setting x and y labels, and title.\nplt.xlabel('Actual Prices')  # solution should be here\nplt.ylabel('Predicted Prices')  # solution should be here\nplt.title('Actual vs Predicted House Prices')  # solution should be here\nplt.grid(True)\nplt.show()\n```\n\nPlease provide the appropriate code to fill in the blank above for setting the labels and title of the plot.",
    "output": "\n```python\nplt.xlabel('Actual Prices')\nplt.ylabel('Predicted Prices')\nplt.title('Actual vs Predicted House Prices')\n```"
  },
  {
    "input": "Problem:\n\nYou are working with a dataset containing customer transactions over time, and you aim to visualize the monthly sales trends. The data is available in a Pandas DataFrame with the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'date': ['2022-01-15', '2022-01-20', '2022-02-15', '2022-03-10', '2022-03-15'],\n    'amount': [150, 200, 300, 450, 500]\n}\ndf = pd.DataFrame(data)\n```\n\nYou need to group the transactions by month and sum the total sales for each month, then create a bar plot of this monthly sales data. The x-axis should display the months in `YYYY-MM` format.\n\nYour task is to fill in the blank for creating the bar plot.\n\n```python\nimport matplotlib.pyplot as plt\n\n# Convert the 'date' column to datetime\ndf['date'] = pd.to_datetime(df['date'])\n\n# Group by month and aggregate sales\nmonthly_sales = df.groupby(df['date'].dt.to_period('M'))['amount'].sum()\n\n# Create a bar plot to show monthly sales trends\nmonthly_sales.plot(kind='bar', xlabel='Month', ylabel='Total Sales', title='Monthly Sales Trends')\n\nplt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\nplt.show()\n```\n\nTo complete this task, fill in the missing line with the appropriate code for grouping and summing the sales by month.\n\n```python\nmonthly_sales = ...  # put solution in this variable\n```",
    "output": "\n```python\nmonthly_sales = df.groupby(df['date'].dt.to_period('M'))['amount'].sum()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing latitudes and longitudes of multiple locations, and I'm trying to calculate the distance of each location from a reference point (latitude, longitude) using the Haversine formula. The dataset is in a Pandas DataFrame format and looks like this:\n\n```\n    id     latitude    longitude\n0   1      34.0522    -118.2437\n1   2      40.7128    -74.0060\n2   3      51.5074    -0.1278\n3   4      48.8566    2.3522\n4   5      35.6895    139.6917\n```\n\nThe reference point I want to calculate the distances from is (34.0522, -118.2437). I'm aware that I can use numpy for mathematical operations involved in the formula. \n\nHere's my starting code:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'id': [1, 2, 3, 4, 5],\n    'latitude': [34.0522, 40.7128, 51.5074, 48.8566, 35.6895],\n    'longitude': [-118.2437, -74.0060, -0.1278, 2.3522, 139.6917]\n}\ndf = pd.DataFrame(data)\n\nreference_point = (34.0522, -118.2437)\n\n# Haversine formula calculations\ndef haversine(lat1, lon1, lat2, lon2):\n    R = 6371  # Earth radius in kilometers\n    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arcsin(np.sqrt(a))\n    return R * c\n\n# The result variable should contain the distances calculated\n    \n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = df.apply(lambda row: haversine(reference_point[0], reference_point[1], row['latitude'], row['longitude']), axis=1)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products in a retail store, including their prices, categories, and sales figures. I want to compute the z-score of the sales figures for each product to identify which products are performing exceptionally well or poorly. I need to add a new column called \"z_score\" to the dataframe that reflects this calculation. Here is how my dataset looks:\n\n```python\nimport pandas as pd\ndata = pd.DataFrame({'product': ['A', 'B', 'C', 'D', 'E'],\n                     'category': ['Electronics', 'Electronics', 'Clothing', 'Grocery', 'Clothing'],\n                     'price': [150, 200, 50, 30, 25],\n                     'sales': [120, 130, 90, 40, 50]})\ndata.head()\n```\n\nTo compute the z-score, I will use `scipy.stats.zscore`. How do I fill in the following code to get the desired result?\n\n```python\nfrom scipy.stats import zscore\n\ndf = data.copy()\n```\n\ndf['z_score'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>zscore(df['sales'])</code>"
  },
  {
    "input": "Problem:\n\nYou have a dataset in CSV format that contains information about online advertising campaigns. The columns include 'CampaignId', 'Clicks', 'Impressions', and 'Conversions'. You load this data into a Pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CampaignId': [1, 2, 1, 2, 3],\n    'Clicks': [100, 150, 200, 250, 300],\n    'Impressions': [1000, 1500, 1500, 2500, 3000],\n    'Conversions': [5, 10, 15, 20, 30]\n}\ndf = pd.DataFrame(data)\n```\n\nNow, you want to calculate the Click-Through Rate (CTR) for each campaign and add this as a new column 'CTR' to the DataFrame. The Click-Through Rate is defined as the total number of clicks divided by the total number of impressions. Each campaign should have its CTR calculated by grouping the data by 'CampaignId'. \n\nHow would you fill in the following line to achieve this?\n\n```python\ndf['CTR'] = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf['CTR'] = df.groupby('CampaignId')['Clicks'].transform('sum') / df.groupby('CampaignId')['Impressions'].transform('sum')\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about different car models, such as their horsepower, weight, and fuel efficiency. I am trying to perform a linear regression to predict fuel efficiency based on horsepower and weight. After fitting the model using scikit-learn, I want to visualize the predicted vs actual fuel efficiency values using Matplotlib.\n\nHere is my setup:\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n# Sample data\ndata = {\n    'horsepower': [130, 150, 170, 190, 210, 250],\n    'weight': [3500, 3200, 2800, 3000, 3600, 4000],\n    'fuel_efficiency': [30, 28, 24, 22, 20, 18]\n}\ndf = pd.DataFrame(data)\n\n# Splitting the dataset\nX = df[['horsepower', 'weight']]\ny = df['fuel_efficiency']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fitting the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n```\n\nNow, I want to predict the fuel efficiency on the test set and plot the predicted vs actual values. I have already imported Matplotlib, and I just need to place the code for prediction and plotting in the blank below.\n\n```python\ny_pred = model.predict(X_test)\n\nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual Fuel Efficiency')\nplt.ylabel('Predicted Fuel Efficiency')\nplt.title('Predicted vs Actual Fuel Efficiency')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\nplt.show()\n```\n\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = y_pred\n```"
  },
  {
    "input": "Problem:\nYou are tasked with building a simple neural network model using PyTorch to classify data from a dataset stored in a Pandas DataFrame. The dataset contains two features (\u2018X1\u2019 and \u2018X2\u2019) and a binary target variable (\u2018Y\u2019). Your goal is to create a variable `model` that initializes a neural network with one hidden layer containing 5 neurons and a ReLU activation function. The output layer should have a single neuron with a sigmoid activation function for binary classification. The dataset is represented as follows:\n\n```python\nimport pandas as pd\n\ndata = pd.DataFrame({\n    'X1': [0.1, 0.2, 0.3, 0.4, 0.5],\n    'X2': [0.5, 0.4, 0.3, 0.2, 0.1],\n    'Y': [1, 0, 1, 0, 1]\n})\n```\n\nA:\n<code>\nimport pandas as pd\nimport torch\nimport torch.nn as nn\n\ndata = pd.DataFrame({\n    'X1': [0.1, 0.2, 0.3, 0.4, 0.5],\n    'X2': [0.5, 0.4, 0.3, 0.2, 0.1],\n    'Y': [1, 0, 1, 0, 1]\n})\n\nmodel = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmodel = nn.Sequential(\n    nn.Linear(2, 5),\n    nn.ReLU(),\n    nn.Linear(5, 1),\n    nn.Sigmoid()\n)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about sales transactions in a store. The dataset is stored in a Pandas DataFrame and includes columns for 'transaction_id', 'product_name', 'quantity_sold', and 'sale_date'. I want to calculate the total sales for each product and visualize the results using a bar chart. \n\nThe DataFrame looks like this:\n```python\nimport pandas as pd\n\ndata = {\n    'transaction_id': [1, 2, 3, 4, 5],\n    'product_name': ['apple', 'banana', 'apple', 'orange', 'banana'],\n    'quantity_sold': [3, 2, 5, 1, 2],\n    'sale_date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03']\n}\n\ndf = pd.DataFrame(data)\n```\n\nI have calculated the total sales using groupby, but I'm not sure how to create a bar plot from the results. Here is my current code:\n\n```python\ntotal_sales = df.groupby('product_name')['quantity_sold'].sum()\n```\n\nNow, I want to create a bar plot to visualize `total_sales`. The code for creating a bar plot of `total_sales` is incomplete:\n```python\nimport matplotlib.pyplot as plt\n\ntotal_sales.plot(kind='bar', ... # put solution in this variable\n```\nBEGIN SOLUTION\n<code> \n",
    "output": "\n```python\nxlabel='Product Name', ylabel='Total Quantity Sold', title='Total Sales per Product')\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a pandas DataFrame `df` that contains sales data with the following structure:\n\n```python\nimport pandas as pd\n\ndata = {\n    \"Date\": pd.date_range(start=\"2021-01-01\", periods=10, freq='D'),\n    \"Sales_A\": [150, 200, 120, 300, 270, 230, 320, 400, 450, 500],\n    \"Sales_B\": [90, 120, 80, 150, 130, 110, 180, 200, 210, 250]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the correlation between `Sales_A` and `Sales_B`, and then plot this correlation in a scatter plot with a regression line using `Matplotlib`. The x-axis should represent `Sales_A`, while the y-axis should represent `Sales_B`. Additionally, I want to display the correlation coefficient on the plot.\n\nGiven that I have the DataFrame `df`, how can I achieve this? Here's where I need code:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.regplot(x=\"Sales_A\", y=\"Sales_B\", data=df)\nplt.title('Sales A vs Sales B with Regression Line')\nplt.xlabel('Sales A')\nplt.ylabel('Sales B')\n\n# Code to calculate correlation goes here\ncorrelation = ...\nplt.text(0.05, 0.95, f'Correlation: {correlation:.2f}', transform=plt.gca().transAxes, fontsize=14)\n\nplt.show()\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\ncorrelation = df['Sales_A'].corr(df['Sales_B'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing historic temperatures from multiple cities, structured as follows:\n\n```\n   Date       City       Temperature\n0 2021-01-01  New York   30\n1 2021-01-01  Los Angeles 70\n2 2021-01-01  Chicago     25\n3 2021-01-02  New York   32\n4 2021-01-02  Los Angeles 68\n5 2021-01-02  Chicago     28\n6 2021-01-03  New York   31\n7 2021-01-03  Los Angeles 72\n8 2021-01-03  Chicago     26\n```\n\nI would like to compute the moving average temperature for each city over the last two days. The resultant DataFrame should add a new column 'Moving_Avg_Temp' indicating this average. The first two rows for each city should contain `NaN` for the moving average due to insufficient data.\n\nHere's the initial DataFrame setup:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Date': ['2021-01-01', '2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02', '2021-01-02', \n             '2021-01-03', '2021-01-03', '2021-01-03'],\n    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago', \n             'New York', 'Los Angeles', 'Chicago'],\n    'Temperature': [30, 70, 25, 32, 68, 28, 31, 72, 26]\n}\ndf = pd.DataFrame(data)\n```\n\nPlease fill in the blank for the line of code that computes the moving average:\n\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().reset_index(drop=True)\n```\n\nWhat would the complete line look like to create the `Moving_Avg_Temp` column? \n\nA:\n```python\ndf['Moving_Avg_Temp'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['Moving_Avg_Temp'] = df.groupby('City')['Temperature'].rolling(window=2).mean().shift(1).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI am working on a predictive model for housing prices using a dataset that includes various features such as square footage, number of bedrooms, and location. After conducting feature engineering, I want to ensure that the features have been standardized for better performance with machine learning algorithms. However, I need to apply the same transformation to both the training and testing datasets.\n\nGiven that you have already split your dataset into training and testing subsets, how can you use Scikit-learn's `StandardScaler` to fit the scaler on the training set and then transform both the training and testing sets correspondingly? Here\u2019s a starting point:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\n# Example DataFrames for training and testing features\nX_train = pd.DataFrame({'square_footage': [1500, 2000, 2500],\n                        'num_bedrooms': [3, 4, 5]})\n\nX_test = pd.DataFrame({'square_footage': [1800, 2200],\n                       'num_bedrooms': [3, 4]})\n\nscaler = StandardScaler()\n```\n\nYou need to fill in the blank in the following line to properly fit and transform the training data and then transform the testing data using the same scaling parameters:\n\n```python\nX_train_scaled = ...  # Fit and transform the training data\nX_test_scaled = ...   # Transform the testing data using the fitted scaler\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nX_train_scaled = scaler.fit_transform(X_train)  # Fit and transform the training data\nX_test_scaled = scaler.transform(X_test)         # Transform the testing data using the fitted scaler\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about houses including their prices, sizes, and locations, and I wish to predict house prices using a linear regression model. Here's how my data looks:\n\n```python\nimport pandas as pd\n\ndata = {\n    'size': [1500, 1600, 1700, 1800, 1900],\n    'price': [300000, 320000, 340000, 360000, 380000],\n}\ndf = pd.DataFrame(data)\n```\n\nCould you help me implement a linear regression model using Scikit-learn? I want to create, train, and return the fitted model after training on the `size` feature to predict the `price`. Here\u2019s where I need to fill in the blank:\n\n```python\nfrom sklearn.linear_model import LinearRegression\n\nX = df[['size']]\ny = df['price']\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# I want to return the trained model from this function\ndef train_model():\n    return ________  # Fill this in\n```",
    "output": "\n```python\n    return model\n```"
  },
  {
    "input": "Problem:\nI have a time series DataFrame that contains daily temperatures for multiple cities over a year. The DataFrame, `df`, looks like this:\n\n```\n         Date        City  Temperature\n0  2023-01-01  New York      30.0\n1  2023-01-01  Los Angeles   60.0\n2  2023-01-02  New York      31.0\n3  2023-01-02  Los Angeles   62.0\n...\n364 2023-12-31  New York      28.0\n365 2023-12-31  Los Angeles   65.0\n```\n\nI want to calculate the daily average temperature for each day across all cities and store the results in a new DataFrame. However, I've attempted to use an incorrect groupby method, leading to an error. Currently, I have this code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Date': pd.date_range(start='2023-01-01', periods=366),\n    'City': ['New York', 'Los Angeles'] * 183,\n    'Temperature': np.random.uniform(low=20.0, high=70.0, size=366)\n})\n```\n\n## How do I group by `Date` and calculate the average temperature correctly?\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = df.groupby('Date')['Temperature'].mean().reset_index()</code>"
  },
  {
    "input": "Problem:\nI am currently analyzing a dataset of house prices and I need to create a scatter plot of the prices against the number of bedrooms. The dataset is in a Pandas DataFrame called `df`, which contains two columns: 'bedrooms' and 'price'. I would like to customize the plot by adding labels to the axes, a title, and changing the marker color to blue. Below is the code I've written so far. \n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Example data\ndata = {\n    'bedrooms': [1, 2, 3, 4, 2, 3, 4, 5],\n    'price': [150000, 200000, 250000, 300000, 220000, 275000, 350000, 400000]\n}\ndf = pd.DataFrame(data)\n\nplt.scatter(df['bedrooms'], df['price'], color='red')\n# What should I do next to complete my plot?\n```\nA:\n<code>\n# Add your solution here\nplt.xlabel('Number of Bedrooms')\nplt.ylabel('Price')\nplt.title('House Prices vs. Number of Bedrooms')\nplt.show()\n</code>",
    "output": "\n<code>\nplt.scatter(df['bedrooms'], df['price'], color='blue')\nplt.xlabel('Number of Bedrooms')\nplt.ylabel('Price')\nplt.title('House Prices vs. Number of Bedrooms')\nplt.show()\n</code>"
  },
  {
    "input": "```python\nProblem:\nYou are working with a dataset containing information about houses, including their sizes in square feet and corresponding sale prices. You have a pandas DataFrame `df` structured as follows:\n\n   size          price\n0  1500         300000\n1  1800         350000\n2  2400         450000\n3  3000         600000\n\nYou want to create a scatter plot displaying the relationship between house size and sale price, with a fitted line using linear regression. The fitted line will help visualize the trend. How can you achieve this with the appropriate libraries?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndf = pd.DataFrame({\n    'size': [1500, 1800, 2400, 3000],\n    'price': [300000, 350000, 450000, 600000]\n})\n\nmodel = LinearRegression()\nX = df[['size']]\ny = df['price']\nmodel.fit(X, y)\n</code>\nplt.scatter(df['size'], df['price'], color='blue')\nplt.plot(df['size'], model.predict(X), color='red')\nplt.xlabel('Size (sq ft)')\nplt.ylabel('Price ($)')\nplt.title('House Price vs. Size')\nplt.show()\n```",
    "output": "\n<code>\nplt.scatter(df['size'], df['price'], color='blue')\nplt.plot(df['size'], model.predict(X), color='red')\nplt.xlabel('Size (sq ft)')\nplt.ylabel('Price ($)')\nplt.title('House Price vs. Size')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about house prices in a certain area. The dataframe looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'area': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'bedrooms': [3, 2, 4, 3, 2, 3],\n    'price': [300000, 250000, 400000, 350000, 200000, 250000]\n}\n\ndf = pd.DataFrame(data)\n```\n\nNow, I want to calculate the average price of houses for each area. Once I have that, I am interested in comparing these averages to see how they differ. However, instead of using the default method to calculate means and create a new dataframe, I would like a solution that uses NumPy's capability to operate on the groups directly after grouping by 'area'. I would like the final result to be stored in a variable `result` that shows the area and the corresponding average price.\n\nA:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'area': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'bedrooms': [3, 2, 4, 3, 2, 3],\n    'price': [300000, 250000, 400000, 350000, 200000, 250000]\n}\n\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = df.groupby('area')['price'].apply(np.mean).reset_index(name='average_price')\n```"
  },
  {
    "input": "Problem:\nYou have a Pandas DataFrame `df` containing customer purchase data with the following structure:\n\n| CustomerID | PurchaseAmount | PurchaseDate          |\n|------------|----------------|-----------------------|\n| 1          | 100.50         | 2023-01-01            |\n| 2          | 200.75         | 2023-01-02            |\n| 1          | 150.00         | 2023-01-03            |\n| 3          | 300.00         | 2023-01-01            |\n| 2          | 50.25          | 2023-01-03            |\n\nFurthermore, you are required to create a new column `CumulativeSum` that reflects the cumulative sum of `PurchaseAmount` for each `CustomerID` over the time, sorted by `PurchaseDate`. The expected output for the new DataFrame would include the same columns with an additional `CumulativeSum` column, showing the cumulative totals for each customer. \n\nHow would you compute this cumulative sum, ensuring that it is grouped by `CustomerID` and respect the order of `PurchaseDate`?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    \"CustomerID\": [1, 2, 1, 3, 2],\n    \"PurchaseAmount\": [100.50, 200.75, 150.00, 300.00, 50.25],\n    \"PurchaseDate\": pd.to_datetime([\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-01\", \"2023-01-03\"])\n}\n\ndf = pd.DataFrame(data)\n</code>\ndf['CumulativeSum'] = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\ndf['CumulativeSum'] = df.sort_values('PurchaseDate').groupby('CustomerID')['PurchaseAmount'].cumsum()\n</code>"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nimport seaborn as sns\n\n# Load the Iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\ndf['target'] = iris.target\n\n# Now, I'd like to visualize the relationship between the features 'sepal length (cm)' and 'sepal width (cm)',\n# using a scatter plot with color-coded classes based on 'target'.\n\n# I'm attempting to create the scatter plot but it seems I'm missing a critical step to display it properly.\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', hue='target', style='target')\n\nplt.title('Iris Dataset: Sepal Length vs Sepal Width')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\n\n# What line should I add to display the plot?\nplt.show()  # put solution in this variable\n```",
    "output": "\n```python\nplt.show()  # put solution in this variable\n```"
  },
  {
    "input": "### Problem\nProblem:\nYou have a dataset of customer transactions for a retail store that is stored in a Pandas DataFrame. The DataFrame includes columns for 'CustomerID', 'TransactionAmount', and 'TransactionDate'. You want to investigate the total spending by each customer for a specific period and visualize the results in a bar chart. Additionally, any negative transaction amounts should be ignored in the total spending calculation.\n\nHere's a sample of your DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'CustomerID': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n    'TransactionAmount': [100, 200, -50, 150, 300, 50, -10],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the total spending for each customer in January 2023 (you can filter the DataFrame first), create a bar chart showing the total spending by customer, and output the results as a new DataFrame containing 'CustomerID' and 'TotalSpending'.\n\nYour code snippet should initialize the necessary libraries and perform the required calculations. \n\nPlease fill in the blank for the DataFrame containing the total spending per customer:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'CustomerID': ['A', 'B', 'A', 'C', 'D', 'B', 'C'],\n    'TransactionAmount': [100, 200, -50, 150, 300, 50, -10],\n    'TransactionDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n\n# Filter for January 2023\n# Calculate total spending for each customer, ignoring negative values\ntotal_spending = df[df['TransactionAmount'] > 0].groupby('CustomerID')['TransactionAmount'].sum().reset_index()\n\n# Visualize the total spending\nplt.bar(total_spending['CustomerID'], total_spending['TransactionAmount'])\nplt.xlabel('Customer ID')\nplt.ylabel('Total Spending')\nplt.title('Total Spending by Customer in January 2023')\nplt.show()\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = total_spending.rename(columns={'TransactionAmount': 'TotalSpending'})\n```"
  },
  {
    "input": "## Problem\nYou are analyzing customer data for a retail business and wish to predict if a customer will make a purchase based on their age and income. You have a dataset stored in a pandas DataFrame that contains information about various customers. The DataFrame includes columns 'Age', 'Income', and 'Purchased', where 'Purchased' is a binary column indicating whether the customer made a purchase (1) or not (0).\n\nYou want to split this dataset into training and test sets, train a logistic regression model using Scikit-learn, and then calculate the accuracy of this model on the test set.\n\nYour DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Age': [22, 25, 29, 34, 36, 40, 45, 55, 60, 65],\n    'Income': [30000, 40000, 50000, 60000, 65000, 70000, 80000, 90000, 150000, 180000],\n    'Purchased': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYou need to perform the operations needed to prepare the data, fit the model, and compute the accuracy score.\n\nFill in the blank to complete the following task which will calculate the accuracy score of your logistic regression model:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nX = df[['Age', 'Income']]\ny = df['Purchased']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = ... # put solution in this variable\n```\n",
    "output": "\n```python\naccuracy = accuracy_score(y_test, y_pred)\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generate some sample data\nnp.random.seed(0)\nX = np.random.rand(100, 1) * 10  # 100 random points in the range [0, 10]\ny = 3 * X.squeeze() + np.random.randn(100) * 3  # Linear relationship with noise\n\n# Fit a linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Prepare data for plotting the regression line\nX_plot = np.linspace(0, 10, 100).reshape(-1, 1)\ny_plot = model.predict(X_plot)\n\n# Now you want to create a scatter plot of the data points and add the regression line.\n# Fill in the blank with the correct code to create the plot.\nplt.scatter(X, y, color='blue', alpha=0.5)  # Scatter plot\nplt.plot(X_plot, y_plot, color='red')  # Regression line\nplt.title('Linear Regression Fit')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.grid(True)\nplt.show()\n\n# Code to put in result variable\nresult = ...  # Fill in with the visualizations created\n```",
    "output": "\n```python\nresult = plt\n```"
  },
  {
    "input": "Problem:\nYou are working on a sentiment analysis project. You need to preprocess your text data stored in a pandas DataFrame. The DataFrame contains two columns: 'id' and 'text'. Your goal is to convert the text to lowercase, remove punctuation, and tokenize the sentences. \n\nHere is the initial DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'id': [1, 2, 3],\n    'text': ['I love Python! It is great.', \n             'Data science with Python is awesome!!!', \n             'Let\\'s build amazing models...']\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter preprocessing, you want to create a new column 'tokens' that contains the list of tokens for each text entry.\n\nTo achieve this, you are using the following setup:\n\n```python\nimport string\n\ndef preprocess_text(text):\n    # Your preprocessing steps will go here\n    pass\n\ndf['tokens'] = df['text'].apply(preprocess_text)\n```\n\nWhat completes the `preprocess_text` function so that it correctly processes the text?\n\nA:\n```python\ntext = ... # put solution in this variable\n```",
    "output": "\n```python\ntext = text.lower()  # Convert to lowercase\ntext = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\ntokens = text.split()  # Tokenize the text\nreturn tokens  # Return the list of tokens\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing customer information in a Pandas DataFrame named `customer_data`. The DataFrame includes a column named `purchase_amount` that lists the total purchase amount for each customer. I want to apply a classification model to determine if a purchase is considered \"high\" (above the median value) or \"low\" (below or equal to the median value) based on the purchase amount. \n\nAfter applying the classification, I want to add a new column called `purchase_class` to the DataFrame that contains either \"high\" or \"low\". I have computed the `median_value` of `purchase_amount`, but I am unsure how to implement this step efficiently without using loops.\n\nHere\u2019s my code until now:\n```python\nimport pandas as pd\nimport numpy as np\n\ncustomer_data = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4, 5],\n    'purchase_amount': [100, 250, 150, 300, 50]\n})\n\nmedian_value = customer_data['purchase_amount'].median()\n```\nI need to fill in the following line to create the new `purchase_class` column based on this median value:\n```python\ncustomer_data['purchase_class'] = ...\n```\nBEGIN SOLUTION\n<code>",
    "output": "\ncustomer_data['purchase_class'] = np.where(customer_data['purchase_amount'] > median_value, 'high', 'low')"
  },
  {
    "input": "Problem:\nI have a dataset comprised of features and labels pertaining to a binary classification problem, stored in a pandas DataFrame called `data`. The features are in columns 'feature1', 'feature2', and the label is in the column 'label'. I want to split this dataset into training and testing sets with a split ratio of 80% training and 20% testing. I intend to use `train_test_split` from Scikit-learn for this purpose. \n\nHere's a snippet of the data:\n```python\nimport pandas as pd\nimport numpy as np\n\n# Sample data creation\ndata = pd.DataFrame({\n    'feature1': np.random.rand(100),\n    'feature2': np.random.rand(100),\n    'label': np.random.choice([0, 1], size=100)\n})\n```\n\nWhat is the correct way to use `train_test_split` in order to split `data` into training and testing sets, ensuring that the features are separated from the label, with the training and testing sets being stored in the variables `X_train`, `X_test`, `y_train`, and `y_test` respectively?\n\nA:\n```python\nfrom sklearn.model_selection import train_test_split\n```\nX_train, X_test, y_train, y_test = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nX_train, X_test, y_train, y_test = train_test_split(data[['feature1', 'feature2']], data['label'], test_size=0.2, random_state=42)\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various fruits, including their weights and prices. I need to normalize the weights using Min-Max scaling, and then visualize the distribution of the normalized weights using a histogram. The dataset is represented as a Pandas DataFrame, as shown below:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'fruit': ['apple', 'banana', 'cherry', 'date', 'elderberry'],\n    'weight': [120, 150, 200, 90, 300],\n    'price': [1, 0.5, 2, 1.5, 3]\n})\n```\n\nI can compute the normalized weights using code similar to the following:\n\n```python\ndf['normalized_weight'] = (df['weight'] - df['weight'].min()) / (df['weight'].max() - df['weight'].min())\n```\n\nNow, I want to visualize the distribution of the normalized weights. Please output your answer into the variable `histogram_code` that will create a histogram using Matplotlib.\n\n```python\nimport matplotlib.pyplot as plt\n```\n\nA:\n<code>\n### Output your answer into variable 'histogram_code'\n</code>\nhistogram_code = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nhistogram_code = \"\"\"\nplt.hist(df['normalized_weight'], bins=5, alpha=0.7, color='blue')\nplt.title('Distribution of Normalized Weights')\nplt.xlabel('Normalized Weight')\nplt.ylabel('Frequency')\nplt.show()\n\"\"\"\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# I have a DataFrame containing sales data with 'Month' and 'Sales' columns.\n# I want to fit a linear regression model to predict future sales based on existing data.\n# Additionally, I'd like to visualize the original sales data and the regression line.\n# The DataFrame looks like this:\n# df = pd.DataFrame({'Month': [1, 2, 3, 4, 5], 'Sales': [200, 300, 400, 500, 600]})\n\n# After fitting the model, please fill in the variable 'predicted_sales' \n# with the predicted sales for the next 3 months based on the model.\n\ndf = pd.DataFrame({'Month': [1, 2, 3, 4, 5], 'Sales': [200, 300, 400, 500, 600]})\nX = df[['Month']]\ny = df['Sales']\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# SOLUTION START\npredicted_sales = model.predict(np.array([[6], [7], [8]]))\n# SOLUTION END\n```",
    "output": "\n```python\npredicted_sales = model.predict(np.array([[6], [7], [8]]))\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various cars, structured as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'make': ['Toyota', 'Honda', 'Ford', 'Chevrolet', 'BMW'],\n    'model': ['Camry', 'Civic', 'Focus', 'Malibu', '3 Series'],\n    'year': [2010, 2012, 2015, 2018, 2020],\n    'mileage': [150000, 120000, 80000, 60000, 30000],\n    'price': [10000, 12000, 15000, 18000, 30000]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to classify each car as 'High', 'Medium', or 'Low' value based on its price. The classification should be as follows:\n- Price >= 20000: 'High'\n- 10000 <= Price < 20000: 'Medium'\n- Price < 10000: 'Low'\n\nCreate a new column named 'value_class' in the dataframe with the above classifications.\n\nThe expected output should have the 'value_class' column in the dataframe as shown below:\n\n```\n       make         model  year  mileage  price value_class\n0   Toyota         Camry  2010   150000  10000      Medium\n1    Honda         Civic  2012   120000  12000      Medium\n2     Ford         Focus  2015    80000  15000      Medium\n3  Chevrolet       Malibu  2018    60000  18000      Medium\n4      BMW   3 Series  2020    30000  30000        High\n```\n\nYour task is to fill in the following solution in the variable df:\n\n```python\ndf['value_class'] = ...\n```",
    "output": "\n```python\ndf['value_class'] = pd.cut(df['price'], bins=[-1, 9999, 19999, float('inf')], labels=['Low', 'Medium', 'High'])\n```"
  },
  {
    "input": "Problem:\nI have a dataset stored in a CSV file that contains information about various products. The dataset includes columns like `Product_ID`, `Price`, and `Category`. I want to build a simple recommendation model using scikit-learn. To begin with, I would like to normalize the `Price` column using Min-Max scaling to fit between 0 and 1. I've already loaded the dataset into a Pandas DataFrame, shown below:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product_ID': [1, 2, 3, 4, 5],\n    'Price': [100, 200, 300, 400, 500],\n    'Category': ['A', 'B', 'A', 'B', 'A']\n}\ndf = pd.DataFrame(data)\n```\n\nNow I want to normalize the `Price` column and store the results back into the DataFrame. I have attempted to use `MinMaxScaler`, but I'm not sure how to implement it correctly. This is my attempt:\n\n```python\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\ndf['Normalized_Price'] = scaler.fit_transform(df[['Price']])  # This line is incomplete\n```\n\nWhat should I fill in for the missing part to complete the normalization step correctly?\n\nA:\n<code>\ndf['Normalized_Price'] = ...  # put your solution in this variable\nBEGIN SOLUTION",
    "output": "\n<code>\ndf['Normalized_Price'] = scaler.fit_transform(df[['Price']])\n</code>"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Generate a DataFrame with 100 samples and 5 features, filled with random numbers\ndata = pd.DataFrame(np.random.rand(100, 5), columns=list(\"ABCDE\"))\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n\n# Apply PCA to reduce dimensions to 2\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(scaled_data)\n\n# Create a DataFrame for the principal components\npc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n\n# Create a scatter plot of the first two principal components\nplt.scatter(pc_df['PC1'], pc_df['PC2'])\nplt.title('PCA of Random Data')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.axhline(0, color='black',linewidth=0.5, ls='dashed')\nplt.axvline(0, color='black',linewidth=0.5, ls='dashed')\nplt.grid()\n\n# Show the plot and return the explained variance ratio\nexplained_variance = pca.explained_variance_ratio_\n\n# Insert your code here to generate the explained variance values \n# as a numpy array or similar output\nsolution = ...  # put your solution here\n```",
    "output": "\n```python\nsolution = np.array(explained_variance)\n```"
  },
  {
    "input": "## Problem:\n\nI have a dataset containing the monthly sales data of a retail store over the past two years. The data is structured in a Pandas DataFrame and has the following columns: 'Month', 'Sales', and 'Returns'. I want to analyze the sales performance by calculating the monthly sales growth rate, which is defined as the percentage change in sales from one month to the next.\n\nGiven this initial DataFrame:\n\n```\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Month': pd.date_range(start='2021-01-01', periods=24, freq='M'),\n    'Sales': np.random.randint(1000, 5000, size=24),\n    'Returns': np.random.randint(50, 300, size=24)\n}\n\ndf = pd.DataFrame(data)\n```\n\nI would like to create a new column in the DataFrame called 'GrowthRate' that stores the growth rate of sales as a percentage change from the previous month. Please fill in the blank for the code below:\n\nA:\n```python\ndf['GrowthRate'] = ... # put solution in this variable\n```",
    "output": "\n```python\ndf['GrowthRate'] = df['Sales'].pct_change() * 100\n```"
  },
  {
    "input": "## Problem\n\nYou are analyzing a dataset containing information about various products in a retail store. The dataset is structured as follows:\n\n```python\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [20.99, 35.50, 15.00, 50.75, 22.80],\n    'quantity_sold': [100, 150, 200, 80, 120],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to calculate the total revenue generated from each product and add it as a new column called `revenue` to the dataframe. The revenue for each product can be computed as the product of `price` and `quantity_sold`.\n\nHow can you perform this operation to obtain the required dataframe with the new column added? \n\nA:\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [101, 102, 103, 104, 105],\n    'price': [20.99, 35.50, 15.00, 50.75, 22.80],\n    'quantity_sold': [100, 150, 200, 80, 120],\n    'date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'])\n}\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\ndf['revenue'] = df['price'] * df['quantity_sold']\nresult = df\n```"
  },
  {
    "input": "Problem:\nI am analyzing customer purchase behavior over time and I want to visualize the moving average of total purchases. I have a DataFrame containing daily purchase data with columns 'date' and 'total_purchases'. I would like to calculate the 7-day moving average and create a plot that shows both the daily total purchases and the moving average. Below is an example of the DataFrame.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = {'date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n        'total_purchases': np.random.randint(10, 100, 30)}\ndf = pd.DataFrame(data)\n```\n\nWhat is the code to compute the 7-day moving average of 'total_purchases' and visualize it along with the original data in a single plot?\n\nA:\n<code>\ndf['moving_average'] = df['total_purchases'].rolling(window=7).mean()\nplt.figure(figsize=(12, 6))\nplt.plot(df['date'], df['total_purchases'], label='Daily Purchases')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xticks(rotation=45)\nplt.legend()\nplt.show()\n</code>",
    "output": "\n<code>\ndf['moving_average'] = df['total_purchases'].rolling(window=7).mean()\nplt.figure(figsize=(12, 6))\nplt.plot(df['date'], df['total_purchases'], label='Daily Purchases')\nplt.plot(df['date'], df['moving_average'], label='7-Day Moving Average', color='orange')\nplt.xticks(rotation=45)\nplt.legend()\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing images of handwritten digits, and I'm trying to build a classification model using TensorFlow's Keras API. After training the model, I want to evaluate its performance on a test set. Here's the code I have so far for the training process:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Assuming train_images and train_labels are preloaded and of proper shape\nmodel = models.Sequential([\n    layers.Flatten(input_shape=(28, 28)),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\nmodel.fit(train_images, train_labels, epochs=5)\n```\n\nNow, I want to evaluate the model using the `test_images` and `test_labels`. I need to fill in the blank for the evaluation method to determine the model's accuracy and other metrics on this test set.\n\nWhat is the correct way to do this? Fill in the following code placeholder:\n\n```python\ntest_loss, test_acc = model.evaluate(______________)\n```\n\nMake sure to specify both the test data and corresponding labels.",
    "output": "\n```python\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\n```"
  },
  {
    "input": "Problem:\nI am working with a dataset that represents the sales of products over several months. The dataset is in a Pandas DataFrame called `sales_data` with the following columns: `product_id`, `month`, and `sales_amount`. I want to calculate the average sales amount for each product across all months.\n\nHere is the sample DataFrame:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03'],\n    'sales_amount': [250, 300, 400, 150, 200, 250, 100, 100, 200]\n})\n```\n\nI need to group the data by `product_id` and calculate the average `sales_amount` for each product. I would like the output to be a new DataFrame called `average_sales` with columns `product_id` and `average_sales_amount`. \n\nHere\u2019s how the output should be structured:\n\n```python\naverage_sales = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'average_sales_amount': [x, y, z]  # Replace x, y, z with the actual average values\n})\n```\n\nHow can I achieve this? \n\nA:\n<code>\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n    'month': ['2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03', '2023-01', '2023-02', '2023-03'],\n    'sales_amount': [250, 300, 400, 150, 200, 250, 100, 100, 200]\n})\n\naverage_sales = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\naverage_sales = sales_data.groupby('product_id', as_index=False)['sales_amount'].mean()\naverage_sales.rename(columns={'sales_amount': 'average_sales_amount'}, inplace=True)\n</code>"
  },
  {
    "input": "Problem:\nYou have a dataset representing sales data for various products over the last year. The data is structured as follows in a Pandas DataFrame:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'product_id': ['p1', 'p2', 'p3', 'p4', 'p5'],\n    'sales': [300, 400, np.nan, 500, 600],\n    'date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05']\n}\n\ndf = pd.DataFrame(data)\n```\n\nTo analyze this data more effectively, you want to fill any missing sales values with the average sales of all products. Afterward, you want to visualize the sales data using Matplotlib, specifically by plotting the sales against the date.\n\nYou need to perform the following operation:\n\n1. Compute the average sales while ignoring the NaN values.\n2. Fill the missing sales in the DataFrame with this average value.\n\nBelow is the initial setup for the code:\n\n```python\naverage_sales = ... # fill in the blank\ndf['sales'].fillna(average_sales, inplace=True)\n```\n\nWhat code should you put in the blank to compute the average sales? Assume you are using Python 3.6 or above.",
    "output": "\n```python\naverage_sales = df['sales'].mean()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about different species of flowers, and I want to visualize the relationship between sepal length and petal length using a scatter plot. The dataset is loaded into a Pandas DataFrame called `df`, and it has the following columns: `species`, `sepal_length`, `petal_length`. I already have the following code to create the plot, but I am missing the part that actually plots the data. Here is the code I have so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assuming df is already defined with the appropriate data\nplt.figure(figsize=(10, 6))\nplt.title('Sepal Length vs Petal Length')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Petal Length (cm)')\nplt.scatter(..., ...)  # Missing code\nplt.legend(df['species'].unique())\nplt.show()\n```\n\nWhat should I put in the `...` to complete the scatter plot, such that the x-axis represents `sepal_length` and the y-axis represents `petal_length`?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\n# Sample data for demonstration\ndata = {\n    'species': ['setosa', 'versicolor', 'virginica', 'setosa', 'versicolor', 'virginica'],\n    'sepal_length': [5.1, 7.0, 6.3, 4.9, 6.4, 5.8],\n    'petal_length': [1.4, 4.7, 3.3, 1.4, 2.8, 2.7]\n}\ndf = pd.DataFrame(data)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>df['sepal_length'], df['petal_length']</code>",
    "output": "\n<code>df['sepal_length'], df['petal_length']</code>"
  },
  {
    "input": "## Problem:\nYou have a dataset containing house prices, and you need to perform some analysis to build a predictive model. Your DataFrame looks like this:\n\n```\n    Area    Bedrooms    Price\n0  1500        3       300000\n1  2000        4       400000\n2  1000        2       200000\n3  1200        3       250000\n4  1300        3       275000\n```\n\nYou would like to normalize the `Price` column using Min-Max scaling (i.e., scaling the values to a range between 0 and 1) before you create a linear regression model using Scikit-learn that predicts price based on area and number of bedrooms. \n\nAfter you normalize the `Price`, you want to assign the normalized prices back to the original DataFrame. Can you find a way to achieve this in a single line of code?\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({'Area': [1500, 2000, 1000, 1200, 1300],\n                   'Bedrooms': [3, 4, 2, 3, 3],\n                   'Price': [300000, 400000, 200000, 250000, 275000]})\n```\ndf['Normalized_Price'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndf['Normalized_Price'] = (df['Price'] - df['Price'].min()) / (df['Price'].max() - df['Price'].min())\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales data for multiple products over several months. The dataset is structured as follows:\n\n| Month  | Product | Sales |\n|--------|---------|-------|\n| Jan    | A       | 150   |\n| Jan    | B       | 200   |\n| Feb    | A       | 180   |\n| Feb    | B       | 210   |\n| Mar    | A       | 170   |\n| Mar    | B       | 190   |\n\nI want to analyze this data to find out the month with the highest sales for each product and visualize the sales trends over the months using a line plot. \n\nHere is the initial code I have to load and process the data:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Month': ['Jan', 'Jan', 'Feb', 'Feb', 'Mar', 'Mar'],\n    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Sales': [150, 200, 180, 210, 170, 190]\n}\ndf = pd.DataFrame(data)\n\n# Group by Product and Month, then sum sales\nsales_by_month = ...\n```\n\nI need to fill in the blank to complete the code for grouping the data. After that, I want to create a line plot to visualize the sales trends over each month.\n\nsales_by_month = ... # put solution in this variable  \nBEGIN SOLUTION  \n<code>",
    "output": "\n<code>sales_by_month = df.groupby(['Month', 'Product']).sum().reset_index()</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing sales data for a retail store represented as a Pandas DataFrame. Each row in the DataFrame represents a transaction, and I want to calculate the total sales for each product category. Here's a simplified version of my DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Transaction_ID': [1, 2, 3, 4, 5],\n    'Product': ['A', 'B', 'A', 'C', 'B'],\n    'Category': ['Electronics', 'Electronics', 'Electronics', 'Home', 'Electronics'],\n    'Amount': [200, 300, 150, 400, 250]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to aggregate the total sales amount for each category in a new DataFrame. The new DataFrame should have two columns: 'Category' and 'Total_Sales'.\n\nWhat is the line of code that would achieve this aggregation?\n\n```python\n# Your solution here:\ntotal_sales = df.groupby('Category')['Amount'].______  # fill in the blank\n```",
    "output": "\n```python\ntotal_sales = df.groupby('Category')['Amount'].sum().reset_index(name='Total_Sales')\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.decomposition import PCA\n\n# Load the iris dataset\ndata = load_iris()\ndf = pd.DataFrame(data.data, columns=data.feature_names)\ndf['target'] = data.target\n\n# Apply PCA to reduce dimensions to 2\npca = PCA(n_components=2)\npca_result = pca.fit_transform(df.iloc[:, :-1])\n\n# Create a new DataFrame to hold the PCA results\npca_df = pd.DataFrame(data=pca_result, columns=['PCA1', 'PCA2'])\npca_df['target'] = df['target']\n\n# Now, plot PCA1 vs PCA2 and color by target\nplt.figure(figsize=(8,6))\nplt.scatter(..., c=..., cmap='viridis', edgecolor='k')\nplt.xlabel('PCA1')\nplt.ylabel('PCA2')\nplt.title('PCA of Iris Dataset')\nplt.colorbar()\nplt.show()\n```",
    "output": "\n```python\nplt.scatter(pca_df['PCA1'], pca_df['PCA2'], c=pca_df['target'], cmap='viridis', edgecolor='k')\n```"
  },
  {
    "input": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the Iris dataset\ndata = load_iris()\nX = data.data\ny = data.target\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Create a DataFrame from scaled features\ndf_scaled = pd.DataFrame(X_scaled, columns=data.feature_names)\n\n# Now, I want to create a scatter plot of the first two features, \n# coloring the points based on the target species. What's the \n# correct code to produce this scatter plot?\n# Fill in the blank below:\n\nplt.scatter(df_scaled.iloc[:, 0], df_scaled.iloc[:, 1], c=y, cmap='viridis')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title('Scatter Plot of Scaled Features')\nplt.colorbar(label='Species')\nplt.show()\n```",
    "output": "\n```python\n<code>\nplt.scatter(df_scaled.iloc[:, 0], df_scaled.iloc[:, 1], c=y, cmap='viridis')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title('Scatter Plot of Scaled Features')\nplt.colorbar(label='Species')\nplt.show()\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset of house prices along with their features, including area (in square feet), number of bedrooms, number of bathrooms, and year built. I want to predict the house prices using a neural network model. I have created arrays for features and prices but need help with the model building.\n\nHere\u2019s the data I have:\n```python\nimport numpy as np\nimport pandas as pd\n\n# Features: [Area, Bedrooms, Bathrooms, Year Built]\nX = np.array([[1500, 3, 2, 2000],\n              [1800, 4, 3, 2005],\n              [2400, 4, 2, 2010],\n              [3000, 5, 4, 2015]])\n# Prices in thousands\ny = np.array([300, 400, 500, 600])\n\n# Create a neural network model in TensorFlow\nimport tensorflow as tf\nmodel = tf.keras.Sequential()\n```\n\nWhat should I add next to initialize the neural network with two hidden layers of 64 neurons each and a final output layer that has a single neuron (for price prediction)? I also want to use the 'relu' activation function for the hidden layers and 'linear' activation for the output layer.\n\nA:\n```python\nmodel.add(...)  # put solution in this variable\n```",
    "output": "\n```python\nmodel.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='linear'))\n```"
  },
  {
    "input": "Problem:\nYou are given a dataset containing information about various products, including their names, prices, and quantities sold. The data is in a pandas DataFrame format as shown below:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Price': [10.5, 20.0, 5.0, 15.5, 8.0],\n    'Quantity': [100, 200, 150, 80, 300]\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour goal is to compute the total sales for each product, which is defined as the product of the price and quantity sold. You then want to normalize these sales figures to get values between 0 and 1, where the maximum sales value is scaled to 1, and the minimum sales value to 0. The normalized sales should be added as a new column to the DataFrame.\n\nPlease fill in the following code to achieve this:\n\n```python\ndf['Total_Sales'] = df['Price'] * df['Quantity']\nmax_sales = df['Total_Sales'].max()\nmin_sales = df['Total_Sales'].min()\ndf['Normalized_Sales'] = (df['Total_Sales'] - min_sales) / (max_sales - min_sales)\n```\n\nYour task is to calculate the normalized sales and store the result back into the DataFrame `df`. What would be the complete DataFrame after executing the normalization code? \n\nProvide the modified DataFrame below:\n\n```python\ndf = ...  # put solution in this variable\n```",
    "output": "\n```python\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'D', 'E'],\n    'Price': [10.5, 20.0, 5.0, 15.5, 8.0],\n    'Quantity': [100, 200, 150, 80, 300],\n    'Total_Sales': [1050.0, 4000.0, 750.0, 1240.0, 2400.0],\n    'Normalized_Sales': [0.0, 1.0, 0.0, 0.3103448275862069, 0.5862068965517241]\n})\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# I have a set of satellite data over a 10-day period. \n# The data includes the following columns: 'date', 'temperature', 'humidity', and 'wind_speed'. \n# I need to aggregate the data to get the average temperature, humidity, and wind speed for each day.\n\ndata = {\n    'date': pd.date_range(start='2023-01-01', periods=10),\n    'temperature': np.random.uniform(low=15.0, high=30.0, size=10),\n    'humidity': np.random.uniform(low=30.0, high=70.0, size=10),\n    'wind_speed': np.random.uniform(low=0.0, high=15.0, size=10)\n}\ndf = pd.DataFrame(data)\n\n# Plot the average temperature, humidity and wind speed over the 10-day period.\n# Create subplots for each metric.\nfig, axs = plt.subplots(3, figsize=(10, 15))\n\n# SOLUTION START\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('date').agg({'temperature': 'mean', 'humidity': 'mean', 'wind_speed': 'mean'}).reset_index()\naxs[0].plot(result['date'], result['temperature'], label='Average Temperature', color='r')\naxs[1].plot(result['date'], result['humidity'], label='Average Humidity', color='b')\naxs[2].plot(result['date'], result['wind_speed'], label='Average Wind Speed', color='g')\naxs[0].set_title('Average Temperature Over 10 Days')\naxs[1].set_title('Average Humidity Over 10 Days')\naxs[2].set_title('Average Wind Speed Over 10 Days')\nfor ax in axs:\n    ax.legend()\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Value')\nplt.tight_layout()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset with multiple features and a target variable, stored in a Pandas DataFrame. I need to preprocess the data by normalizing the feature columns using Min-Max scaling, then splitting the data into training and testing sets. Finally, I want to train a linear regression model using Scikit-learn on the training data and evaluate its performance on the test data using mean squared error.\n\nHere\u2019s a sample of the DataFrame:\n\n```\n   Feature_1  Feature_2  Feature_3  Target\n0        5.0        2.1        8.0      1\n1        8.0        3.6        4.0      0\n2        3.0        2.5        7.0      1\n3        6.0        3.1        5.0      0\n4        2.0        1.3        9.0      1\n```\n\nPlease write the code to fill in the missing parts, starting from the normalization of the feature columns. Ensure to output the mean squared error of the model after evaluation.\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Sample data\ndf = pd.DataFrame({\n    'Feature_1': [5.0, 8.0, 3.0, 6.0, 2.0],\n    'Feature_2': [2.1, 3.6, 2.5, 3.1, 1.3],\n    'Feature_3': [8.0, 4.0, 7.0, 5.0, 9.0],\n    'Target': [1, 0, 1, 0, 1]\n})\n\n# Normalize the feature columns\nscaler = MinMaxScaler()\nX = ... # Fill this part with the code to normalize feature columns\ny = df['Target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Calculate mean squared error\nmse = ... # Fill this part to calculate the mean squared error\n```",
    "output": "\n```python\nX = scaler.fit_transform(df[['Feature_1', 'Feature_2', 'Feature_3']])\nmse = mean_squared_error(y_test, y_pred)\n```"
  },
  {
    "input": "Problem:\nI am working on a project involving customer data, and I have a dataset with transaction records in a pandas DataFrame. Each transaction includes a customer ID, transaction amount, and transaction date:\n\n```python\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 4, 1, 3],\n    'TransactionAmount': [100, 200, 150, 300, 250, 400, 50, 600],\n    'TransactionDate': [\n        '2023-01-01',\n        '2023-01-02',\n        '2023-01-03',\n        '2023-01-01',\n        '2023-01-04',\n        '2023-01-05',\n        '2023-01-02',\n        '2023-01-03'\n    ]\n}\n\ndf = pd.DataFrame(data)\ndf['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n```\n\nI want to find the total transaction amounts for each customer but only for transactions that occurred in January 2023. Additionally, I want to simplify my DataFrame to only include customers who spent more than a specified threshold (e.g., 300).\n\nHow can I modify my DataFrame to show only the `CustomerID` and their total spending above this threshold? \n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'CustomerID': [1, 2, 1, 3, 2, 4, 1, 3],\n    'TransactionAmount': [100, 200, 150, 300, 250, 400, 50, 600],\n    'TransactionDate': [\n        '2023-01-01',\n        '2023-01-02',\n        '2023-01-03',\n        '2023-01-01',\n        '2023-01-04',\n        '2023-01-05',\n        '2023-01-02',\n        '2023-01-03'\n    ]\n}\n\ndf = pd.DataFrame(data)\ndf['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\nthreshold = 300\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df[df['TransactionDate'].dt.month == 1].groupby('CustomerID')['TransactionAmount'].sum().reset_index()\nresult = result[result['TransactionAmount'] > threshold]\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various cars in a pandas DataFrame with the following columns: 'Make', 'Year', 'Horsepower', and 'Weight'. I want to compute the Z-score of the 'Horsepower' column to standardize these values. My DataFrame looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Make': ['Ford', 'Chevrolet', 'Toyota', 'Honda'],\n    'Year': [2001, 2002, 2001, 2003],\n    'Horsepower': [130, 200, 140, 160],\n    'Weight': [2900, 3100, 2400, 2600]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to calculate the Z-score for the 'Horsepower' column using SciPy, but I couldn't figure out how to apply it on my DataFrame. I tried using `stats.zscore()` but got stuck on how to insert that correctly. How can I compute the Z-score for the 'Horsepower' column?\n\nA:\n```python\nfrom scipy import stats\n\ndf = pd.DataFrame(data)\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = stats.zscore(df['Horsepower'])\nEND SOLUTION\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Generate a random dataset with 5 features and 100 samples\ndata = np.random.rand(100, 5)\ndf = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(5)])\n\n# Standardize the features using StandardScaler\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df)\n\n# Perform PCA to reduce the dimensionality to 2 components\npca = PCA(n_components=2)\npca_result = pca.fit_transform(scaled_data)\n\n# Create a scatter plot of the PCA results\nplt.scatter(pca_result[:, 0], pca_result[:, 1])\n\n# Set the title of the plot to 'PCA of Random Dataset'\nplt.title('PCA of Random Dataset')\n\n# Display the plot with a specific size of 8x6\n# SOLUTION START\n```",
    "output": "\n```python\nplt.figure(figsize=(8, 6))\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid()\nplt.show()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing various features of houses, stored in a pandas DataFrame as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'area': [1500, 1800, 2400, 3000],\n    'bedrooms': [3, 4, 3, 5],\n    'price': [300000, 400000, 500000, 650000]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to standardize the 'price' column using `scikit-learn`'s `StandardScaler`, which will transform the 'price' values to have a mean of 0 and a standard deviation of 1. After applying the scaler, I would like to append the standardized 'price' values as a new column named 'standardized_price' to the original DataFrame.\n\nHere\u2019s the code I\u2019m currently using to create and fit the scaler:\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(df[['price']])\n```\n\nHow can I extract the standardized values and add them back to the `df` DataFrame under the 'standardized_price' column?\n\nA:\n```python\n# put solution in this variable\ndf['standardized_price'] = ... \n```",
    "output": "\n```python\ndf['standardized_price'] = scaler.transform(df[['price']])\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing sales information for various products, structured as a pandas DataFrame. The DataFrame has columns for 'Product', 'Price', 'Quantity Sold', and 'Date'. I am interested in calculating the total revenue generated for each product over the entire dataset. The revenue is defined as Price multiplied by Quantity Sold. \n\nCurrently, I am trying to use the following line of code, but it's returning an error:\n```python\ndf['Revenue'] = df['Price'] * df['Quantity Sold']\n```\nThis operation seems correct, but I'm not sure how to aggregate this data by 'Product' to get the total revenue per product.\n\nA: \n```python\nimport pandas as pd\nimport numpy as np\n\n# Sample data\ndata = {\n    'Product': ['A', 'B', 'A', 'C', 'B'],\n    'Price': [10, 20, 10, 30, 20],\n    'Quantity Sold': [1, 2, 3, 1, 4],\n    'Date': pd.to_datetime(['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03'])\n}\ndf = pd.DataFrame(data)\n\n# Your current line of code\n# df['Revenue'] = df['Price'] * df['Quantity Sold']\n\n# Fill in the blank to get total revenue per product\nresult = ...\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = df.groupby('Product').apply(lambda x: (x['Price'] * x['Quantity Sold']).sum()).reset_index(name='Total Revenue')\n```"
  },
  {
    "input": "```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Assume we have a dataset with two features and we want to standardize these features\ndata = np.array([[1.0, 2.0],\n                 [2.0, 3.0],\n                 [3.0, 4.0]])\ndf = pd.DataFrame(data, columns=['feature1', 'feature2'])\n\n# Normalize the features using StandardScaler\nscaler = StandardScaler()\n# Fit and transform the data with the scaler and convert it back to a DataFrame\nnormalized_df = scaler.fit_transform(df)\n\n# Next, we will build a simple neural network model using TensorFlow\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(4, activation='relu', input_shape=(2,)),\n    tf.keras.layers.Dense(1)\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Plot the normalized data\nplt.scatter(normalized_df[:, 0], normalized_df[:, 1])\nplt.xlabel('Normalized Feature 1')\nplt.ylabel('Normalized Feature 2')\n\n# SOLUTION START\n```",
    "output": "\n```python\nplt.title('Normalized Features Scatter Plot')\nplt.grid(True)\nplt.show()\n# SOLUTION END\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products sold by a company. The dataset includes the columns `product_id`, `price`, and `units_sold`. I want to create a new column that calculates the total revenue for each product. The total revenue is simply the product of `price` and `units_sold`.\n\nHere's a sample of my DataFrame:\n\n```\n   product_id  price  units_sold\n0          1   10.0          5\n1          2   15.5          3\n2          3   7.25          10\n3          4   12.0          7\n```\n\nI need to compute the total revenue for each product and add it as a new column named `total_revenue`.\n\nThis is my code:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'product_id': [1, 2, 3, 4],\n    'price': [10.0, 15.5, 7.25, 12.0],\n    'units_sold': [5, 3, 10, 7]\n})\n\ndf['total_revenue'] = df['price'] * df['units_sold']\n```\n\nBut I want to modify it to ensure that if any `units_sold` is negative, it should not impact the calculation and instead return zero for the `total_revenue`.\n\nWhat would be the correct way to handle this in the code below?\n\n```python\ndf['total_revenue'] = df['price'] * df['units_sold'] if df['units_sold'] >= 0 else 0\n```\n\nA:\n<code>\ndf['total_revenue'] = ...\n</code>",
    "output": "\n<code>\ndf['total_revenue'] = df.apply(lambda row: row['price'] * row['units_sold'] if row['units_sold'] >= 0 else 0, axis=1)\n</code>"
  },
  {
    "input": "## Problem:\n\nI am working on a project to predict house prices based on various features such as area, number of bedrooms, and location. I have a dataset in a pandas DataFrame, and I'm trying to standardize my feature values before passing them to a TensorFlow neural network model. I want to use `StandardScaler` from scikit-learn to standardize my features. Here\u2019s a snippet of my code:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Sample dataset\ndata = {\n    'Area': [1500, 2000, 1200, 1800, 1600],\n    'Bedrooms': [3, 4, 2, 3, 3],\n    'Location': [1, 2, 1, 2, 1]  # Encoded locations\n}\ndf = pd.DataFrame(data)\n\n# I want to standardize only the 'Area' and 'Bedrooms' columns\nscaler = StandardScaler()\n```\n\nHowever, I'm unsure how to apply the scaler to my DataFrame and store the standardized values back in a new DataFrame. What should I fill in for the following line to complete this task?\n\n```python\nscaled_features = ... # put solution in this variable\n```",
    "output": "\n```python\nscaled_features = scaler.fit_transform(df[['Area', 'Bedrooms']])\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset containing information about various customers, including their age, annual income, and spending score. I want to create a scatter plot using Matplotlib to visualize how annual income affects spending score. The dataset is stored in a Pandas DataFrame called `customers`. The relevant columns are named 'Annual Income' and 'Spending Score'. Write the code that prepares the plot and displays it.\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assuming customers DataFrame is already defined and looks like this:\n# customers = pd.DataFrame({'Age': [...], 'Annual Income': [...], 'Spending Score': [...]})\n\nplt.scatter(customers['Annual Income'], customers['Spending Score'], alpha=0.5)\nplt.title('Annual Income vs Spending Score')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.grid(True)\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = plt.scatter(customers['Annual Income'], customers['Spending Score'], alpha=0.5)  \nplt.title('Annual Income vs Spending Score')  \nplt.xlabel('Annual Income')  \nplt.ylabel('Spending Score')  \nplt.grid(True)  \nplt.show()  \n</code>"
  },
  {
    "input": "Problem: \n\nI have a dataset containing historical stock prices of a company stored in a CSV file. Each row includes the date, opening price, closing price, and volume of stocks traded. I want to read this data into a Pandas DataFrame, compute the daily return of the stock prices, and then use Matplotlib to create a line chart of the closing prices over time.\n\nHere is my code so far:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the data from CSV\ndata = pd.read_csv('stock_prices.csv')\n\n# Calculate the daily returns\ndata['Daily Return'] = ...\n\n# Plot the closing prices\nplt.plot(data['Date'], data['Close'])\nplt.title('Stock Prices Over Time')\nplt.xlabel('Date')\nplt.ylabel('Closing Price')\nplt.xticks(rotation=45)\nplt.show()\n```\n\nWhat should I fill in the blank for calculating the daily return of the stock prices, where the daily return is calculated as the percentage change in closing prices from the previous day? \n\nA:\n\n```python\ndata['Daily Return'] = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\ndata['Daily Return'] = data['Close'].pct_change()\n```"
  },
  {
    "input": "Problem:\n\nI have a dataset represented as a Pandas DataFrame containing information about the sales of different products across multiple stores. The DataFrame structure looks like this:\n\n```python\nimport pandas as pd\n\ndata = {\n    'Store': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'C'],\n    'Product': ['X', 'Y', 'X', 'Z', 'Y', 'Y', 'Z', 'X'],\n    'Sales': [100, 150, 200, 50, 300, 400, 250, 150]\n}\ndf = pd.DataFrame(data)\n```\n\nI want to group this DataFrame by 'Product' and calculate the total sales per product across all stores. Additionally, I want to plot the total sales using Matplotlib to visualize the results.\n\nCan you provide the code to get the total sales in a new DataFrame and create a bar plot from it? \n\nThe resulting DataFrame should look like this:\n\n```\n Product    Total_Sales\n     X             550\n     Y             600\n     Z             300\n```\n\nThe plot should be a bar chart with 'Product' on the x-axis and 'Total_Sales' on the y-axis.\n\n```python\nimport matplotlib.pyplot as plt\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nresult = df.groupby('Product', as_index=False)['Sales'].sum().rename(columns={'Sales': 'Total_Sales'})\nplt.bar(result['Product'], result['Total_Sales'])\nplt.xlabel('Product')\nplt.ylabel('Total Sales')\nplt.title('Total Sales per Product')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about products sold in a store. The dataset consists of the following three attributes represented as lists:\n\nproduct_ids = [\"P001\", \"P002\", \"P003\", \"P001\", \"P002\", \"P003\"]\nsales_dates = [\"2023-01-01\", \"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-02\"]\nsales_amounts = [100, 150, 200, 120, 180, 160]\n\nI want to analyze the total sales for each product across the two days using pandas. After aggregating the total sales, I also want to visualize the results with a bar chart using Matplotlib.\n\nThe expected output should look like this after grouping and summing:\nproduct_id    total_sales\nP001                220\nP002                330\nP003                360\n\nHow can I achieve this using pandas for data manipulation and Matplotlib for visualization?\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nproduct_ids = [\"P001\", \"P002\", \"P003\", \"P001\", \"P002\", \"P003\"]\nsales_dates = [\"2023-01-01\", \"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-02\"]\nsales_amounts = [100, 150, 200, 120, 180, 160]\n\ndf = pd.DataFrame({'product_id': product_ids, 'sales_date': sales_dates, 'sales_amount': sales_amounts})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.groupby('product_id')['sales_amount'].sum().reset_index(name='total_sales')\nplt.bar(result['product_id'], result['total_sales'])\nplt.xlabel('Product ID')\nplt.ylabel('Total Sales')\nplt.title('Total Sales per Product')\nplt.show()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a dataset containing customer purchases which has the following columns: 'CustomerID', 'PurchaseAmount', and 'PurchaseDate'. I want to analyze the daily average purchase amount for each customer over a specific date range. The dataframe looks like this:\n\n```\n CustomerID   PurchaseAmount   PurchaseDate\n1     1           100.00          2023-01-01\n2     1           150.00          2023-01-02\n3     2           200.00          2023-01-01\n4     2           250.00          2023-01-03\n5     3           50.00           2023-01-02\n```\n\nI have started by filtering the date range from '2023-01-01' to '2023-01-03' and then I want to group by 'CustomerID' and calculate the average purchase amount per day. I am currently using the following code snippet:\n\n```python\nimport pandas as pd\n\ndata = {'CustomerID': [1, 1, 2, 2, 3],\n        'PurchaseAmount': [100.00, 150.00, 200.00, 250.00, 50.00],\n        'PurchaseDate': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-02'])}\ndf = pd.DataFrame(data)\n\nstart_date = '2023-01-01'\nend_date = '2023-01-03'\n```\n\nI got stuck trying to find a one-liner to compute the daily average purchase amount while removing any purchases outside the specified date range. It should return a dataframe with 'CustomerID' and 'AveragePurchaseAmount'. I would like to put the solution in the variable `avg_purchases`.\n\nA:\n\n```python\navg_purchases = ... # put solution in this variable\n```",
    "output": "\n```python\navg_purchases = df[(df['PurchaseDate'] >= start_date) & (df['PurchaseDate'] <= end_date)].groupby('CustomerID').agg(AveragePurchaseAmount=('PurchaseAmount', 'mean')).reset_index()\n```"
  },
  {
    "input": "Problem:\n\nI am working on a dataset that contains sales data for a retail store, structured in a pandas DataFrame like this:\n\n| product_id | sale_date  | quantity | price_per_unit |\n|------------|------------|----------|-----------------|\n| 1          | 2023-01-01 | 10       | 5.0             |\n| 1          | 2023-01-02 | 4        | 5.0             |\n| 2          | 2023-01-01 | 3        | 10.0            |\n| 2          | 2023-01-01 | 7        | 10.0            |\n| 1          | 2023-01-03 | 5        | 5.0             |\n| 2          | 2023-01-03 | 6        | 10.0            |\n\nI want to compute the total revenue generated for each product on each sale date. The total revenue for each entry can be calculated by multiplying the quantity sold by the price per unit.\n\nAfter computing the total revenue, I want to reshape the resulting DataFrame to have a summary that displays the total revenue for each product by date in a wider format.\n\nHow can I achieve this using Pandas?\n\nHere is the DataFrame that you start with:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 2, 2, 1, 2],\n    'sale_date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-01', '2023-01-03', '2023-01-03'],\n    'quantity': [10, 4, 3, 7, 5, 6],\n    'price_per_unit': [5.0, 5.0, 10.0, 10.0, 5.0, 10.0]\n}\n\ndf = pd.DataFrame(data)\n```\n\nAfter computing and reshaping, I want to obtain a DataFrame that looks like this:\n\n| product_id | 2023-01-01 | 2023-01-02 | 2023-01-03 |\n|------------|-------------|-------------|-------------|\n| 1          | total_revenue_for_1_on_2023-01-01 | total_revenue_for_1_on_2023-01-02 | total_revenue_for_1_on_2023-01-03 |\n| 2          | total_revenue_for_2_on_2023-01-01 | 0           | total_revenue_for_2_on_2023-01-03 |\n\nWhat code can be placed in this variable to get the desired output?\n\n```python\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n```",
    "output": "\n<code>\ndf['total_revenue'] = df['quantity'] * df['price_per_unit']\nresult = df.pivot_table(index='product_id', columns='sale_date', values='total_revenue', aggfunc='sum', fill_value=0)\n</code>"
  },
  {
    "input": "Problem:\nI have a dataset containing information about products sold in a store, including price and quantity sold. I want to analyze how the total sales (calculated as price * quantity) vary by product category and visualize the results. However, I also want to add a smoothing component to the sales data for each category to better observe trends.\n\nHere is the code I have so far to create the initial DataFrame and calculate total sales:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Category': ['A', 'B', 'A', 'B', 'A', 'C', 'C', 'B', 'A', 'C'],\n    'Price': [10, 15, 10, 20, 10, 25, 25, 20, 10, 25],\n    'Quantity': [1, 2, 1, 2, 1, 1, 1, 2, 1, 1]\n}\ndf = pd.DataFrame(data)\ndf['TotalSales'] = df['Price'] * df['Quantity']\n```\nI need to calculate the average total sales for each category and then apply a moving average with a window size of 2 that can be used as smoothing. How can I accomplish this in a single concise operation?\n\nA:\n```python\nsmoothing_sales = ... # put solution in this variable\n```",
    "output": "\n```python\nsmoothing_sales = df.groupby('Category')['TotalSales'].mean().rolling(window=2).mean()\n```"
  },
  {
    "input": "Problem:\nYou have a dataset of customer purchase transactions stored in a Pandas DataFrame. The DataFrame contains columns: \"customer_id\", \"purchase_amount\", and \"purchase_date\". You want to calculate the cumulative purchase amount for each customer over time and then visualize the cumulative amount for a specific customer using Matplotlib. \n\nHere is a sample of the DataFrame:\n```python\nimport pandas as pd\nfrom datetime import datetime\n\ndata = {\n    \"customer_id\": [1, 1, 1, 2, 2, 3],\n    \"purchase_amount\": [10, 20, 30, 40, 50, 60],\n    \"purchase_date\": [datetime(2023, 10, 1), datetime(2023, 10, 2), datetime(2023, 10, 3),\n                      datetime(2023, 10, 1), datetime(2023, 10, 2), datetime(2023, 10, 1)]\n}\ndf = pd.DataFrame(data)\n```\nYou want to compute the cumulative sum of \"purchase_amount\" for each \"customer_id\" and plot the cumulative amount for customer_id 1. \n\nYou need to replace the blank with the appropriate code to get the cumulative purchase amount and visualize it.\n\nA:\n```python\nimport matplotlib.pyplot as plt\n\ndf['cumulative_sum'] = df.groupby('customer_id')['purchase_amount'].cumsum()\nclient_id = 1\nclient_data = df[df['customer_id'] == client_id].sort_values('purchase_date')\n\nplt.plot(client_data['purchase_date'], client_data['cumulative_sum'])\nplt.title(f'Cumulative Purchase Amount for Customer {client_id}')\nplt.xlabel('Purchase Date')\nplt.ylabel('Cumulative Amount')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show() \n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('customer_id')['purchase_amount'].cumsum()\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing information about various products sold in a store, structured as follows:\n\n| Product | Sales_Q1 | Sales_Q2 | Sales_Q3 | Sales_Q4 |\n|---------|----------|----------|----------|----------|\n| A       | 100      | 200      | 150      | 250      |\n| B       | 80       | 90       | 120      | 110      |\n| C       | 180      | 160      | 130      | 100      |\n\nI would like to visualize the quarterly sales trends using a line plot. How can I create a line plot showing the sales for each product across the four quarters using Matplotlib?\n\nA:\n<code>\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = {\n    'Product': ['A', 'B', 'C'],\n    'Sales_Q1': [100, 80, 180],\n    'Sales_Q2': [200, 90, 160],\n    'Sales_Q3': [150, 120, 130],\n    'Sales_Q4': [250, 110, 100]\n}\n\ndf = pd.DataFrame(data)\ndf.set_index('Product', inplace=True)\n\n# Plotting sales data\nplt.figure(figsize=(10, 6))\nplt.plot(df.index, df['Sales_Q1'], marker='o', label='Q1')\nplt.plot(df.index, df['Sales_Q2'], marker='o', label='Q2')\nplt.plot(df.index, df['Sales_Q3'], marker='o', label='Q3')\nplt.plot(df.index, df['Sales_Q4'], marker='o', label='Q4')\nplt.title('Quarterly Sales Trend by Product')\nplt.xlabel('Product')\nplt.ylabel('Sales')\nplt.legend()\nplt.grid()\nplt.show()\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>result = plt.show()</code>"
  }
]