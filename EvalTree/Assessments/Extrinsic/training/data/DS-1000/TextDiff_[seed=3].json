[
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ____(0.2, 0.2, 0.2, 0.2)  # I need to fill in this part for color jitter\n])\n```\n\nWhat goes in the blank to complete the transformations for color jittering with the specified parameters for brightness, contrast, saturation, and hue? \n\nA:\n\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(____)  # Fill in with the correct method\n])\n</code>",
    "output": "\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)  # Fill in with the correct method\n])\n</code>"
  },
  {
    "input": "Problem:\nI am working on a machine learning project where I need to perform element-wise operations on a batch of tensors. Specifically, I want to scale the first dimension of a tensor using a scaling factor that is also a tensor. My current tensor has the shape (N, C, H, W) where N is the batch size, and the scaling factor is simply a 1D tensor of shape (N). \n\nHere is the initial setup I have:\n\n```python\nimport torch\nN, C, H, W = 4, 3, 16, 16\ntensors = torch.randn(N, C, H, W)  # Sample tensor\nscaling_factors = torch.tensor([1, 0.5, 2, 1.5])  # Scaling factors for each batch\n```\n\nI want to apply the scaling factors to each slice of the tensor along the first dimension (N) while maintaining the same dimensions of the tensor. The desired output is a tensor with the same shape as the input tensor but scaled according to the corresponding factor. \n\nHow do I perform this operation? Please provide the code to fill in the blank.\n\nscaled_tensors = ...  # put solution in this variable",
    "output": "\n```python\nscaled_tensors = tensors * scaling_factors.view(N, 1, 1, 1)  # Scale each slice\n```"
  },
  {
    "input": "Problem:\n\nI am working with a PyTorch tensor representing a batch of images from the MNIST dataset. The tensor has the shape (batch_size, 1, 28, 28), where each image is a grayscale image of size 28x28 pixels. I want to apply a transformation to normalize the pixel values of each image to the range [0, 1].\n\nThe pixel values are currently in the range [0, 255], so I need to divide all the pixel values by 255. However, I also want to ensure that I retain the original tensor shape. \n\nHow can I achieve this normalization using PyTorch, while ensuring that the output tensor maintains the same shape after the operation?\n\nTo illustrate, if my input tensor is:\n\ntensor([[[[255, 0, 127, ..., 30],\n          [50, 255, 255, ..., 10],\n          ...\n          [255, 0, 10, ..., 0]]]])\n\nI want my output tensor to be:\n\ntensor([[[[1.0, 0.0, 0.4980, ..., 0.1176],\n          [0.1961, 1.0, 1.0, ..., 0.0392],\n          ...\n          [1.0, 0.0, 0.0392, ..., 0.0]]]])\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n\ninput_tensor = load_data() # shape should be (batch_size, 1, 28, 28)\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_tensor = input_tensor / 255.0\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter( ________ )  # provide the correct parameters for brightness, contrast, saturation, and hue\n])\n```\n\nWhat parameters should I pass into the `ColorJitter` to randomly change the image brightness, contrast, saturation, and hue? \n\nA:\n\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1)\n])\n</code>\nresult = ... # put solution in this variable",
    "output": "\n<code>\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1)\n])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information on employees as follows:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'employee_id': [1, 2, 3, 4, 5],\n    'department': ['HR', 'IT', 'IT', 'HR', None],\n    'salary': [50000, 60000, None, 55000, 58000],\n    'hire_date': ['2018-01-10', '2019-02-20', '2020-03-15', None, '2021-05-30']\n})\n\n```\n\nI would like to fill in the missing values in the `department` column with the mode of the existing values and fill the missing values in the `salary` column with the median salary of employees in the same department. The dates should be kept as they are for the existing values in the `hire_date` column. The expected DataFrame after processing should look like this:\n\n```\n   employee_id department   salary   hire_date\n0            1        HR  50000.0  2018-01-10\n1            2        IT  60000.0  2019-02-20\n2            3        IT  55000.0  2020-03-15\n3            4        HR  55000.0        NaN\n4            5        HR  58000.0  2021-05-30\n```\n\nSo far I have processed the DataFrame to remove any missing values but need help to fill the missing ones appropriately. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmode_department = df['department'].mode()[0]\ndf['department'].fillna(mode_department, inplace=True)\n\nmedian_salary = df.groupby('department')['salary'].transform('median')\ndf['salary'].fillna(median_salary, inplace=True)\n\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI have a collection of images represented as a 4D tensor for a deep learning task. The tensor has a shape of [batch_size, channels, height, width]. I would like to apply a dynamic scaling operation on this tensor such that each image within the batch is scaled by a corresponding factor provided in a 1D tensor. The scaling factors have a shape of [batch_size].\n\nHere's what I have so far:\n\n```python\nimport torch\n\nbatch_size = 4\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\nscaling_factors = torch.tensor([0.5, 1.0, 1.5, 2.0])  # Scaling factors for each image\n\n# Now, I want to scale each image in the batch without using a for loop.\n```\n\nWhat would be the appropriate way to scale the images dynamically based on the scaling factors?\n\nA:\n\n<code>\nscaled_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nscaled_images = images * scaling_factors.view(batch_size, 1, 1, 1)\n</code>"
  },
  {
    "input": "Problem:\nYou have two Pandas DataFrames that contain sales data from different regions. The first DataFrame `df_sales` contains sales made, identified by a unique `SalesID` and the amount for each sale:\n\n```python\ndf_sales = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Amount': [250, 150, 300, 400]\n})\n```\n\nThe second DataFrame `df_region` contains additional information for each sale, such as the `SalesID` and the region where the sale was made:\n\n```python\ndf_region = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Region': ['North', 'South', 'East', 'West'],\n    'Discount': [0.1, 0.2, 0.15, 0.05]\n})\n```\n\nYou want to merge these two DataFrames into one such that it contains the `SalesID`, `Amount`, and `Region`, but only include the `Discount` for sales made in the 'South' region. The resulting DataFrame should look like this (where 'South' has the discount value and others do not):\n\n```\n   SalesID  Amount Region  Discount\n0      101     250  North       NaN\n1      102     150  South       0.2\n2      103     300   East       NaN\n3      104     400   West       NaN\n```\n\nYou are unsure how to achieve this merge with conditional inclusion of the column. Fill in the solution:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Amount': [250, 150, 300, 400]\n})\n\ndf_region = pd.DataFrame({\n    'SalesID': [101, 102, 103, 104],\n    'Region': ['North', 'South', 'East', 'West'],\n    'Discount': [0.1, 0.2, 0.15, 0.05]\n})\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df_sales, df_region[['SalesID', 'Region', 'Discount']], on='SalesID', how='left')\nresult['Discount'] = result.apply(lambda x: x['Discount'] if x['Region'] == 'South' else None, axis=1)\n```"
  },
  {
    "input": "Problem:\n\nI am working on a neural network model using PyTorch, where I need to normalize the output of each layer. Given an n x m tensor representing the output of my layer, I want to compute the z-score normalization for each feature (column) individually. The z-score is defined as (X - mean) / stddev, where X is the input tensor, mean is the mean value of the column, and stddev is the standard deviation of the column.\n\nHere's a sample output tensor:\n\n[[1.0, 2.0, 3.0],\n [4.0, 5.0, 6.0],\n [7.0, 8.0, 9.0]]\n\nI need to return the z-score normalized tensor with the same dimensions. How can I achieve this in PyTorch?\n\nA:\n\n<code>\nimport torch\noutput_tensor = load_data()\ndef z_score_normalization(output_tensor):\n</code>\nnormalized_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    mean = output_tensor.mean(dim=0)\n    stddev = output_tensor.std(dim=0)\n    normalized_tensor = (output_tensor - mean) / stddev\n    return normalized_tensor\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that calculates the Mean Squared Error (MSE) based on predictions and targets, but I want to add a penalty for predictions that fall below a specific threshold (e.g., 0.5). If the prediction is less than 0.5, I want to add a fixed penalty of 0.1 to the MSE. Given the predictions and targets as tensors, how can I implement this custom loss function?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_with_penalty(predictions, targets):\n    threshold = 0.5\n    penalty = 0.1\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    penalty_magnitude = tf.reduce_sum(tf.cast(predictions < threshold, tf.float32)) * penalty\n    total_loss = mse + penalty_magnitude\n    return total_loss\n</code>",
    "output": "\n<code>\nimport tensorflow as tf\n\ndef custom_mse_with_penalty(predictions, targets):\n    threshold = 0.5\n    penalty = 0.1\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    penalty_magnitude = tf.reduce_sum(tf.cast(predictions < threshold, tf.float32)) * penalty\n    total_loss = mse + penalty_magnitude\n    return total_loss\n</code>"
  },
  {
    "input": "## Problem:\n\nI have a PyTorch tensor `data` of shape (50, 3) which represents 50 samples, each with 3 features. I also have a tensor `weights` of shape (3, 1) representing the weights for each feature. I want to compute the weighted sum for each sample in `data` such that the resulting tensor `result` has the shape (50, 1). \n\nGiven the tensors:\n\n```python\ndata.size() == torch.Size([50, 3])\nweights.size() == torch.Size([3, 1])\n```\n\nWhat code can I use to perform this operation?\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\ndata, weights = load_data()\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = data @ weights\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to implement a custom loss function to measure the difference between predicted and actual values, specifically focusing on the mean squared error but with an additional penalty when predictions exceed the actual values.\nMy predictions are provided as a tensor `predictions`, and the actual values are in a tensor `actual`. I would like to compute the custom loss as follows:\n1. Calculate the mean squared error between the predictions and actual values.\n2. If any predictions are greater than the actual values, add a penalty of 0.1 times the sum of the differences.\n\nExample tensors:\n```\npredictions = tf.constant([3.0, 5.0, 2.0])\nactual = tf.constant([2.0, 4.0, 6.0])\n```\nI need the following function that will compute the custom loss:\n```python\nimport tensorflow as tf\n\ndef custom_loss(predictions, actual):\n    # Define the custom loss calculation\n    loss = ...\n    return loss\n```\nFill in the blank with the appropriate code to calculate the custom loss.",
    "output": "\n```python\nimport tensorflow as tf\n\ndef custom_loss(predictions, actual):\n    mse = tf.reduce_mean(tf.square(predictions - actual))\n    penalty = tf.reduce_sum(tf.where(predictions > actual, predictions - actual, 0.0)) * 0.1\n    loss = mse + penalty\n    return loss\n```"
  },
  {
    "input": "Problem:\nI have two DataFrames A and B as follows:\nA\n```\n   UserID  Name\n0       1  Alice\n1       2    Bob\n2       3  Carol\n```\nB\n```\n   UserID  Age  City\n0       1   25  New York\n1       3   30  Los Angeles\n2       4   22  Chicago\n```\nI need to merge these DataFrames on 'UserID', ensuring that we keep all records from DataFrame A and only the matching records from DataFrame B. Additionally, I want to rename the columns of DataFrame B when merged to include a prefix \"B_\" for clarity.\n\nThe expected output should look like this:\n```\n   UserID   Name  B_Age          B_City\n0       1  Alice   25.0       New York\n1       2    Bob    NaN            NaN\n2       3  Carol   30.0  Los Angeles\n```\n\nSo far, my attempt using the merge function was like this:\n```python\nresult = pd.merge(A, B, on='UserID', how='left')\n```\nbut I need to add that prefix to the columns from DataFrame B. \n\nA:\n```python\nimport pandas as pd\n\nA = pd.DataFrame({'UserID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Carol']})\nB = pd.DataFrame({'UserID': [1, 3, 4], 'Age': [25, 30, 22], 'City': ['New York', 'Los Angeles', 'Chicago']})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n```",
    "output": "\n```python\nresult = pd.merge(A, B.rename(columns={'Age': 'B_Age', 'City': 'B_City'}), on='UserID', how='left')\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains information about daily sales over a few weeks for different products, but there are some missing values. The DataFrame looks like this:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({'product_id': [1, 1, 2, 2, 3, 3, 4, 4],\n                           'date': ['2023-10-01', '2023-10-02', '2023-10-01', '2023-10-03',\n                                    '2023-10-01', '2023-10-02', '2023-10-02', None],\n                           'units_sold': [20, None, None, 15, 5, None, None, 10]})\n```\n\nI want to fill in the missing values of `date` and `units_sold` with the appropriate entries based on previous entries for the same `product_id`. Specifically, I want to forward fill the `date` and use the mean of previously available `units_sold` for the respective `product_id` to fill in the missing values.\n\nThe expected DataFrame should look like this:\n\n```plaintext\n   product_id        date  units_sold\n0           1  2023-10-01         20.0\n1           1  2023-10-02         20.0\n2           2  2023-10-01         7.5\n3           2  2023-10-03         15.0\n4           3  2023-10-01         5.0\n5           3  2023-10-02         5.0\n6           4  2023-10-02        10.0\n7           4  2023-10-02        10.0\n```\n\nCurrently, I am trying to fill the missing entries but not succeeding in the way I want. Can you help me with a concise inline code that will accomplish this task?\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group.fillna({'date': group['date'].ffill(), 'units_sold': group['units_sold'].fillna(group['units_sold'].mean())})).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\n\nI am working on a deep learning project where I need to dynamically adjust the size of a tensor based on the batch size during training. In my code, I create a tensor that starts with a particular shape but need to resize it to accommodate a varying number of samples per batch.\n\nI have the following initialization for my tensor:\n\n```python\nimport torch\n\nbatch_size = 4\ninitial_tensor = torch.randn(batch_size, 3, 64, 64)  # A tensor for 4 images of size 3x64x64\n```\n\nNow, during the training process, the batch size may change, either due to the last batch being smaller or other reasons. For example, if the `new_batch_size` is 2, I want to resize `initial_tensor` to match this new batch size while keeping the other dimensions unchanged. \n\nTo change the tensor size dynamically, I need to reshape it to the new batch size like so:\n\n```python\nnew_batch_size = 2\n```\n\nWhat would the correct code be to reshape `initial_tensor` to the new size while maintaining the original dimensions?\n\n```python\nresized_tensor = initial_tensor.__________\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresized_tensor = initial_tensor.view(new_batch_size, 3, 64, 64)\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W) where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` which takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n```\n\nHowever, I am having trouble applying this function to each image in the tensor. Here\u2019s an outline of my attempt:\n\n```python\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])  # This is not working as intended.\n```\n\nI expected the images to be flipped, but it seems like I need a more efficient approach to handle this. \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips the image vertically\n\n# Given tensor of images\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels 32x32\n\n# [Your implementation here]\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\nfor i in range(images.size(0)):\n    if torch.rand(1).item() < 0.5:\n        images[i] = flip_image(images[i])\n</code>",
    "output": "\n<code>\nimages = torch.where(torch.rand(images.size(0), 1, 1, 1) < 0.5, flip_image(images), images)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 3D tensor representing different channels of data as follows:\n\ntensor([[[0.1, 0.2], \n          [0.3, 0.4]], \n        \n         [[0.5, 0.6], \n          [0.7, 0.8]], \n        \n         [[0.9, 1.0], \n          [1.1, 1.2]]])\n        \nI want to apply a mask tensor to zero out the values in the original tensor based on a 2D mask that selects specific elements. The mask tensor is a 2D tensor:\n\ntensor([[1, 0], \n        [0, 1], \n        [1, 0]])\n\nHow do I create a new tensor that retains values from the original tensor where the mask is 1 and zeros out where the mask is 0?\n\nA:\n\n<code>\nimport torch\noriginal_tensor, mask = load_data()\n</code>\nmasked_tensor = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmasked_tensor = original_tensor * mask.unsqueeze(1)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a batch of images with shape (batch_size, channels, height, width). I want to dynamically apply a random horizontal flip to each image in the batch with a probability of 0.5. The images are represented as a PyTorch tensor. Here is a part of my code:\n\nimport torch\n\ndef random_horizontal_flip(images):\n    # images: (n, c, h, w) where n is the batch size, c is the number of channels, h is height, and w is width\n    # Apply horizontal flip with probability 0.5\n    batch_size, channels, height, width = images.size()\n    flip_mask = torch.rand(batch_size) < 0.5  # Create a random mask for flipping\n\n    # Here I want to use the flip_mask to conditionally flip the images\n    flipped_images = images.clone()  # Create a copy of images for manipulation\n    return flipped_images\n\nimages = load_data()  # assumes this returns a tensor of shape (batch_size, channels, height, width)\nflipped_images = random_horizontal_flip(images)\nI want to fill in the blank below to achieve the desired flip functionality:\n\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [2])  # [2] indicates flipping along height\n</code>",
    "output": "\n<code>\nflipped_images[flip_mask] = torch.flip(flipped_images[flip_mask], [3])  # [3] indicates flipping along width\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing a sequence of time-series data for multiple features, and I want to compute the moving average using PyTorch. The tensor `data` has a shape of `(batch_size, num_features, sequence_length)`, and I want to apply a window size of `k` for the moving average calculation. \n\nHowever, the challenge is to create a new tensor that represents the moving average for each feature across the sequence, which will result in a tensor of shape `(batch_size, num_features, sequence_length - k + 1)`.\n\nGiven the following tensor:\n\n```\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\n```\n\nAnd a moving average window size of `k = 2`, how can I calculate the moving averages efficiently with PyTorch?\n\nA:\n\n<code>\nimport torch\ndata = load_data()\nk = 2\nmoving_avg = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nimport torch\ndata = torch.tensor([\n    [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], \n    [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]\n])\nk = 2\nmoving_avg = data.unfold(2, k, 1).mean(dim=3)\n</code>"
  },
  {
    "input": "Problem:\nI have two DataFrames, orders and products, that represent sales data. The orders DataFrame contains order IDs and product IDs, while the products DataFrame contains product IDs along with their names and prices. The task is to merge these two DataFrames on the product ID so that we can analyze which products were sold with their corresponding names and prices in a single DataFrame. The expected output should also contain the total price for each order by multiplying the quantity of products sold by their respective prices.\n\nHere's the setup of the DataFrames:\n\norders:\n```\n   order_id  product_id  quantity\n0        1        101         2\n1        2        102         1\n2        3        101         1\n3        4        103         3\n```\n\nproducts:\n```\n   product_id     name  price\n0        101   WidgetA   10.0\n1        102   WidgetB   15.0\n2        103   WidgetC   20.0\n```\n\nThe desired output DataFrame should include the following columns: order_id, product_id, quantity, name, price, and total_price.\n\nTo achieve this, start with this code snippet:\n```python\nimport pandas as pd\n\norders = pd.DataFrame({\n    'order_id': [1, 2, 3, 4],\n    'product_id': [101, 102, 101, 103],\n    'quantity': [2, 1, 1, 3]\n})\n\nproducts = pd.DataFrame({\n    'product_id': [101, 102, 103],\n    'name': ['WidgetA', 'WidgetB', 'WidgetC'],\n    'price': [10.0, 15.0, 20.0]\n})\n\n# Merge the DataFrames on product_id\nresult = ...\n```\nFill in the blank to obtain the desired output.",
    "output": "\n```python\nresult = orders.merge(products, on='product_id')\nresult['total_price'] = result['quantity'] * result['price']\n```"
  },
  {
    "input": "Problem:\nI have two DataFrames, `df1` and `df2`, and they look like this:\n\ndf1\n```\n   ID   Value\n0  A1     10\n1  A2     20\n2  A3     30\n```\n\ndf2\n```\n   ID   Info\n0  A1    XYZ\n1  A2    ABC\n2  A4    DEF\n```\n\nI need to merge these DataFrames on the `ID` column such that:\n- If a row exists in both DataFrames, I want to retain the `Value` from `df1` and the `Info` from `df2`.\n- If a row exists only in `df1`, I want to retain it as is with `NaN` for `Info`.\n- If a row exists only in `df2`, I want to keep it as is with `NaN` for `Value`.\n\nThe resulting DataFrame should have three columns: `ID`, `Value`, and `Info`, with an additional column `ExistsInBoth` indicating whether the `ID` is present in both DataFrames.\n\nHere are my initial DataFrames:\n```python\nimport pandas as pd\n\ndf1 = pd.DataFrame({'ID': ['A1', 'A2', 'A3'], 'Value': [10, 20, 30]})\ndf2 = pd.DataFrame({'ID': ['A1', 'A2', 'A4'], 'Info': ['XYZ', 'ABC', 'DEF']})\n```\n\nWhat single line of code can I use to accomplish this merging and create the new DataFrame while fulfilling the rules mentioned?\n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df1, df2, on='ID', how='outer').assign(ExistsInBoth=lambda x: x['Value'].notna() & x['Info'].notna())\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\n            transforms.RandomRotation(degrees=30),  # Properly defined rotation transformation\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI have two tensors, `data` of shape (50, 5) and `mask` of shape (50,). The `mask` tensor contains binary values (0s and 1s) that indicate which rows of the `data` tensor should be selected. I want to create a new tensor that contains only the rows of `data` where the corresponding value in `mask` is 1.\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\ndata, mask = load_data()\n</code>\nfiltered_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfiltered_data = data[mask == 1]\n</code>"
  },
  {
    "input": "## Problem:\n\nI have a 2D tensor representing the features of a dataset, where each row corresponds to a different example and each column corresponds to a different feature. I want to normalize this tensor by subtracting the mean of each column from the respective column values and then dividing by the standard deviation of each column.\n\nI have tried to utilize PyTorch's operations, but I'm unsure of how to compute the mean and standard deviation and apply them to each column. Given the following tensor:\n\ndata: shape (5, 4), for instance, represented as:\n\n```\n[[1.0, 2.0, 3.0, 4.0],\n [5.0, 6.0, 7.0, 8.0],\n [9.0, 10.0, 11.0, 12.0],\n [13.0, 14.0, 15.0, 16.0],\n [17.0, 18.0, 19.0, 20.0]]\n```\n\nI want to compute the normalized tensor using the following code snippet to fill in the blank:\n\n<code>\nimport torch\ndata = load_data()\n</code>\nnormalized_data = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmean = data.mean(dim=0)\nstd = data.std(dim=0)\nnormalized_data = (data - mean) / std\n</code>"
  },
  {
    "input": "Problem:\nYou have two dataframes representing sales data and product details:\n\ndf_sales:\n+----------+-------+------------+\n| OrderID  | Amount| ProductID  |\n+----------+-------+------------+\n|    1     |  150  |     A      |\n|    2     |  200  |     B      |\n|    3     |  250  |     C      |\n|    4     |  300  |     A      |\n+----------+-------+------------+\n\ndf_products:\n+-----------+------------+---------+\n| ProductID | ProductName|  Price  |\n+-----------+------------+---------+\n|     A     |  Widget A  |   75    |\n|     B     |  Widget B  |   100   |\n|     C     |  Widget C  |   150   |\n+-----------+------------+---------+\n\nYou want to create a new dataframe that includes the sales data along with the product names and total cost (calculated as Amount divided by Price). The resulting dataframe should have the following structure:\n\n+----------+-------+------------+------------+----------+\n| OrderID  | Amount| ProductID  | ProductName| TotalCost|\n+----------+-------+------------+------------+----------+\n|    1     |  150  |     A      |  Widget A  |   2.0    |\n|    2     |  200  |     B      |  Widget B  |   2.0    |\n|    3     |  250  |     C      |  Widget C  |   1.67   |\n|    4     |  300  |     A      |  Widget A  |   4.0    |\n+----------+-------+------------+------------+----------+\n\nTo achieve this, use a merge operation on the two dataframes based on 'ProductID' and compute the 'TotalCost' by dividing 'Amount' by 'Price'. Make sure to handle all necessary imports and prepare the dataframes before performing the operation.\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({'OrderID': [1, 2, 3, 4],\n                         'Amount': [150, 200, 250, 300],\n                         'ProductID': ['A', 'B', 'C', 'A']})\n\ndf_products = pd.DataFrame({'ProductID': ['A', 'B', 'C'],\n                            'ProductName': ['Widget A', 'Widget B', 'Widget C'],\n                            'Price': [75, 100, 150]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_products, on='ProductID')\nresult['TotalCost'] = (result['Amount'] / result['Price']).round(2)\nresult = result[['OrderID', 'Amount', 'ProductID', 'ProductName', 'TotalCost']]\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am building a custom loss function that calculates the mean squared error (MSE) but only for the positive values in the predictions. If the prediction is negative, it should contribute zero to the loss. Given two tensors, `y_true` (the ground truth) and `y_pred` (the predictions), both of shape `(n,)`, how can I implement this custom loss function? Here\u2019s some example code setup:\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -1.0, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # loss = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(tf.maximum(y_pred, 0) - tf.maximum(y_true, 0)))\n    return mse\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function that penalizes differences in predictions based on the mean squared error but with an additional twist. If the absolute difference between the predicted and actual value exceeds a specific threshold (for example, 1.0), an extra penalty of 2.0 should be applied. Here\u2019s my setup:\n\nI have two tensors: `predictions` and `targets` of shape (n,). Now I want to compute the custom loss based on the conditions mentioned.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.5, 1.5, 2.0, 3.5, 4.0])\ntargets = tf.constant([1.0, 1.0, 2.0, 3.0, 5.0])\n\ndef custom_loss(predictions, targets):\n    # return the solution in this function\n    # loss = custom_loss(predictions, targets)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mse = tf.reduce_mean(tf.square(predictions - targets))\n    threshold = 1.0\n    extra_penalty = tf.where(tf.abs(predictions - targets) > threshold, 2.0, 0.0)\n    total_loss = mse + tf.reduce_mean(extra_penalty)\n    return total_loss\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomRotation(degrees=30),\n            transforms.RandomHorizontalFlip(),\n            # Fill in the blank with the correct rotation implementation\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image()  # This will load an image tensor\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nresult = ...\n</code>",
    "output": "\n<code>\nresult = self.transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI want to create a custom loss function for a regression problem where the target value and the predicted value are compared using the Mean Absolute Error (MAE), but I want to add a penalty if the prediction deviates from a certain threshold. Specifically, if the absolute difference between the predicted and target values exceeds a threshold of 5, I want to multiply the MAE by a factor of 2.\n\nHere's what I've set up so far:\n\n```python\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 5.0\n    # compute the Mean Absolute Error\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    # apply the penalty if the error exceeds the threshold\n    result = ...  # fill in this blank with the correct logic\n    return result\n```\n\nHow can I implement this logic in the blank?",
    "output": "\n```python\n    penalty = tf.where(tf.abs(y_true - y_pred) > threshold, 2.0 * mae, mae)\n    result = tf.reduce_mean(penalty)\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains missing values for several product prices over time:\n\n```\n   product_id    date   price\n0           1 2023-01-01   10.0\n1           1 2023-01-08    NaN\n2           1 2023-01-15   12.0\n3           2 2023-01-01    NaN\n4           2 2023-01-08   15.0\n5           2 2023-01-15   14.0\n6           3 2023-01-01   30.0\n7           3 2023-01-08    NaN\n8           3 2023-01-15   NaN\n```\n\nI want to fill the missing prices by using forward filling for each product, but for the last row of each product, if that row still contains a missing price, I want to fill it with the average price of that product. The expected output should look like this:\n\n```\n   product_id    date   price\n0           1 2023-01-01   10.0\n1           1 2023-01-08   10.0\n2           1 2023-01-15   12.0\n3           2 2023-01-01   14.67\n4           2 2023-01-08   15.0\n5           2 2023-01-15   14.0\n6           3 2023-01-01   30.0\n7           3 2023-01-08   30.0\n8           3 2023-01-15   30.0\n```\n\nSo far, I've used forward filling with `df.fillna(method='ffill')`, but it doesn't achieve my goal of replacing the last NaN with the average. How can I accomplish this efficiently?\n\nA:\n<code>\nimport pandas as pd\n\ndata = {\n    'product_id': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n    'date': ['2023-01-01', '2023-01-08', '2023-01-15', '2023-01-01', '2023-01-08', '2023-01-15', '2023-01-01', '2023-01-08', '2023-01-15'],\n    'price': [10.0, None, 12.0, None, 15.0, 14.0, 30.0, None, None]\n}\n\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['price'] = df.groupby('product_id')['price'].ffill()\ndf['price'] = df.groupby('product_id')['price'].transform(lambda x: x.fillna(x.mean()))\nresult = df\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. \nI am building a custom loss function based on the mean absolute error (MAE) that incorporates a penalty for predictions that deviate significantly from the actual values. My goal is to multiply the MAE by a penalty factor that ramps up as the error increases. The penalty function is defined as `penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)`, where `threshold` is a fixed value. I want to implement this custom loss function. \n\nGiven `y_true` and `y_pred` as two tensors: \n```python\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\n```\nHow can I define the custom loss function that applies the penalty, where `threshold` is set to 1.0?\n\nA:\n<code>\nimport tensorflow as tf\n\ny_true = tf.constant([3.0, -0.5, 2.0, 7.0])\ny_pred = tf.constant([2.5, 0.0, 2.0, 8.0])\nthreshold = 1.0\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(y_true, y_pred)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n    penalty = tf.exp(tf.abs(y_true - y_pred) - threshold)\n    return mae * penalty\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that tracks the weekly sales of different products in a store, and it looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Product': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'Week': [1, 1, 1, 2, 2, 2],\n    'Sales': [20, np.nan, 15, np.nan, 25, np.nan]\n})\n```\n\nThe DataFrame has missing values in the Sales column for some products in week 2. I want to fill in these missing values based on the average sales of the same products from the previous week (week 1). The expected output should fill the missing Sales values accordingly.\n\nWhat I would like to achieve is to replace the missing values in the Sales column for week 2 with the average sales from week 1 for the respective products.\n\nYour current approach might involve using `apply`, but I'm looking for a more efficient way to achieve this using pandas' built-in functions.\n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df.copy()\navg_sales_week1 = df[df['Week'] == 1].set_index('Product')['Sales']\nresult.loc[result['Week'] == 2, 'Sales'] = result.loc[result['Week'] == 2, 'Sales'].fillna(avg_sales_week1)\n</code>"
  },
  {
    "input": "### Problem:\nYou are working with a 3D tensor that represents a batch of grayscale images with the shape (batch_size, channels, height, width). Let's say you have a tensor `images` with the shape (8, 1, 28, 28). You want to perform dynamic padding on this tensor so that each image becomes square by adding padding to the height or width as necessary. The target shape for each image should be (28, 28) without altering the original data. Your goal is to compute a padded tensor with the shape (8, 1, 30, 30) by applying padding only to the height to maintain the aspect ratio. Use `torch.nn.functional.pad` for padding, which takes a tensor and a tuple of padding sizes for each dimension.\n\nGiven the tensor variable `images`:\n\n```python\nimport torch\nimages = torch.randn(8, 1, 28, 28)\n```\n\nFill in the blank to perform the appropriate padding.\n\nA:\n```python\npadded_images = torch.nn.functional.pad(images, (1, 1, 1, 1)) # put solution in this variable\n```",
    "output": "\n```python\npadded_images = torch.nn.functional.pad(images, (1, 1, 1, 1)) # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes representing sales data for different regions over some time. The first dataframe (`df_sales`) contains monthly sales figures for various products in different regions. The second dataframe (`df_products`) has information about the product category for each product. \n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'region': ['North', 'South', 'East', 'West'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02'],\n    'sales': [200, 150, 300, 250]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'category': ['A', 'B', 'A', 'B']\n})\n```\n\nYou need to merge these two dataframes such that you get a single dataframe showing product sales alongside their respective categories. Ensure that all sales records are retained even if there is no corresponding product category. The resulting dataframe should be sorted by region and month, as well as by product_id in ascending order.\n\nThe expected merged dataframe should look something like this:\n\n```\n   product_id region     month  sales category\n0         101  North  2023-01    200        A\n1         102  South  2023-01    150        B\n2         103   East  2023-02    300        A\n3         104   West  2023-02    250        B\n```\n\nYour task is to write the code that merges these dataframes appropriately using pandas. \n\nFill in the blank for the merging operation below:\n```python\nresult = df_sales.____(df_products, on='product_id', how='left')\n```",
    "output": "\n```python\nresult = df_sales.merge(df_products, on='product_id', how='left').sort_values(by=['region', 'month', 'product_id'])\n```"
  },
  {
    "input": "Problem:\nI am working with two dataframes related to sales data and product information. The sales data contains transactions with associated product IDs, and the product information provides details about those products. Here are the two dataframes:\n\ndf_sales:\n```\n   transaction_id  product_id  quantity\n0               1          101         3\n1               2          102         5\n2               3          101         2\n3               4          103         1\n```\n\ndf_products:\n```\n   product_id    product_name   price\n0         101    Widget A      15.00\n1         102    Widget B      20.00\n2         103    Widget C      25.00\n3         104    Widget D      30.00\n```\n\nI want to create a new dataframe that combines sales data with product names and calculates the total revenue per transaction by multiplying the quantity sold by the product price. The resulting dataframe should include columns for `transaction_id`, `product_name`, `quantity`, and `total_revenue`. \n\nThe data from df_sales and df_products should be merged using `product_id` as the key, and total revenue should be calculated as `quantity * price`.\n\nHow can I achieve this?\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'transaction_id': [1, 2, 3, 4],\n    'product_id': [101, 102, 101, 103],\n    'quantity': [3, 5, 2, 1]\n})\n\ndf_products = pd.DataFrame({\n    'product_id': [101, 102, 103, 104],\n    'product_name': ['Widget A', 'Widget B', 'Widget C', 'Widget D'],\n    'price': [15.00, 20.00, 25.00, 30.00]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df_sales.merge(df_products, on='product_id') \\\n                  .assign(total_revenue=lambda x: x['quantity'] * x['price']) \\\n                  [['transaction_id', 'product_name', 'quantity', 'total_revenue']]\n</code>"
  },
  {
    "input": "### Problem:\nI have two DataFrames that represent sales data for products in two different regions. The DataFrames are structured as follows:\n\n**df_sales**\n```\n   product_id  region_a_sales\n0           1             100\n1           2             150\n2           3              80\n3           4             200\n```\n\n**df_product_info**\n```\n   product_id   product_name    region_b_sales\n0           1     Product A              120\n1           2     Product B              180\n2           3     Product C               NaN\n3           4     Product D              210\n4           5     Product E               90\n```\n\nI need to merge these two DataFrames on the `product_id` column, while preserving all products from `df_product_info` even if they do not have corresponding sales data in `df_sales`. After merging, I want to create a new column `total_sales` that sums the sales from both regions. If any sales data is missing (NaN), it should be treated as zero in the summation. The expected structure should look like this:\n\n```\n   product_id   product_name  region_a_sales  region_b_sales  total_sales\n0           1     Product A              100            120           220\n1           2     Product B              150            180           330\n2           3     Product C               80              NaN           80    \n3           4     Product D              200            210           410\n4           5     Product E              NaN              90            90   \n```\n\nHere's the code I have so far for the merge:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({'product_id': [1, 2, 3, 4],\n                         'region_a_sales': [100, 150, 80, 200]})\n\ndf_product_info = pd.DataFrame({'product_id': [1, 2, 3, 4, 5],\n                                 'product_name': ['Product A', 'Product B', 'Product C', 'Product D', 'Product E'],\n                                 'region_b_sales': [120, 180, None, 210, 90]})\n```\n\nWhat should I add to obtain the final DataFrame mentioned above? Fill in the following line to achieve your goal:\n\n```python\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(df_product_info, df_sales, on='product_id', how='left').fillna(0)\nresult['total_sales'] = result['region_a_sales'] + result['region_b_sales']\n```"
  },
  {
    "input": "Problem:\nI have two dataframes, sales and returns, representing transactions in a retail store. The sales dataframe contains information on items sold, while the returns dataframe contains information on items returned. Both dataframes share a common column named 'item_id' and you want to merge them such that you can analyze both sold and returned items side by side. Here are the dataframes:\n\n```python\nimport pandas as pd\n\nsales_data = {\n    'item_id': [1, 2, 3, 4, 5],\n    'item_name': ['Shirt', 'Pants', 'Shoes', 'Hat', 'Belt'],\n    'amount_sold': [100, 150, 200, 50, 60]\n}\nsales = pd.DataFrame(data=sales_data)\n\nreturns_data = {\n    'item_id': [2, 4, 3, 5, 5],\n    'returned_amount': [10, 5, 20, 15, 5]\n}\nreturns = pd.DataFrame(data=returns_data)\n```\n\nI need to merge these dataframes based on 'item_id' and include the total sold and returned amounts in the resulting dataframe consolidating the information, ensuring that for items without returns, the returned_amount should be 0. The desired output should look like this:\n\n```\n   item_id item_name  amount_sold  returned_amount\n0        1     Shirt           100                0\n1        2     Pants           150               10\n2        3     Shoes           200               20\n3        4      Hat            50                5\n4        5      Belt           60               20\n```\n\nWhat is the correct way to merge these two dataframes using pandas?\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(sales, returns.groupby('item_id', as_index=False).sum(), on='item_id', how='left').fillna({'returned_amount': 0})\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation step.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.to_tensor(transform(image))\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame with missing values like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan, 5],\n    'B': [np.nan, 2, np.nan, 4, np.nan],\n    'C': [1, 2, 3, 4, 5]\n})\n```\n\nI would like to use an efficient method to fill the missing values in column 'A' with the mean of the column, and for column 'B', I want to fill the NaN values using forward fill for the first NaN and backward fill for the remaining NaNs. The expected output should look like this:\n\n```\n     A    B  C\n0  1.0  NaN  1\n1  3.0  2.0  2\n2  3.0  2.0  3\n3  4.0  4.0  4\n4  5.0  4.0  5\n```\n\nWhat would be an efficient way to achieve this?\n\nA:\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.copy()\nresult['A'].fillna(result['A'].mean(), inplace=True)\nresult['B'].fillna(method='ffill', limit=1, inplace=True)\nresult['B'].fillna(method='bfill', inplace=True)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am implementing a custom loss function to minimize the binary cross-entropy between predicted and actual values. However, I want to apply a weight based on the prediction confidence, meaning that when the predicted probabilities are closer to 0.5, they should contribute more to the loss. Given the predictions (a tensor of shape (n,)) and actual labels (another tensor of shape (n,)), how can I achieve this?\n\nThe weight can be calculated as follows: for each element, the weight should be `abs(predict - 0.5)`, which means that predictions far from 0.5 will contribute less to the final loss. The output should be the total weighted binary cross-entropy loss.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.1, 0.4, 0.6, 0.8])\nlabels = tf.constant([0, 0, 1, 1])\n\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # result = custom_loss(labels, predictions)\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    weights = tf.abs(y_pred - 0.5)\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = bce * weights\n    return tf.reduce_mean(weighted_bce)\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function for a regression problem where I need to calculate the Mean Absolute Percentage Error (MAPE) instead of the traditional mean squared error. The MAPE is defined as the average of the absolute percentage differences between the predicted and actual values. My inputs are two tensors: `y_true` for actual values and `y_pred` for predicted values. How can I calculate MAPE using TensorFlow operations?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef mape(y_true, y_pred):\n    # return MAPE calculation here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    diff = tf.abs((y_true - y_pred) / y_true)\n    return tf.reduce_mean(diff) * 100\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly flip images horizontally and also add Gaussian noise to them before passing them to my model. With the following functions provided, I am trying to create a composite transformation in PyTorch.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndef random_horizontal_flip(image):\n    # Applies horizontal flip to the image with 50% chance\n    return transforms.RandomHorizontalFlip()(image)\n\ndef add_gaussian_noise(image, mean=0.0, std=0.1):\n    noise = torch.randn(image.size()) * std + mean\n    return image + noise\n\n# Sample tensor representing an image\nimage = torch.randn(3, 64, 64)  # A random image tensor with 3 channels (RGB) and 64x64 pixels\n\n# Applying the composite transformations\naugmented_image = ...\n```\n\nA:\n\n<code>\naugmented_image = random_horizontal_flip(image)\naugmented_image = add_gaussian_noise(augmented_image)\n</code>",
    "output": "\n<code>\naugmented_image = add_gaussian_noise(random_horizontal_flip(image))\n</code>"
  },
  {
    "input": "Problem:\nSuppose you have two pandas DataFrames that contain information about employees and their respective departments:\n\nEmployees DataFrame:\n```python\nimport pandas as pd\nemployees = pd.DataFrame({\n    'EmployeeID': [101, 102, 103, 104, 105],\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'DepartmentID': [1, 2, 2, 1, 3]\n})\n```\n\nDepartments DataFrame:\n```python\ndepartments = pd.DataFrame({\n    'DepartmentID': [1, 2, 3],\n    'DepartmentName': ['HR', 'IT', 'Finance'],\n    'Location': ['Building A', 'Building B', 'Building C']\n})\n```\n\nYou want to merge these two DataFrames based on the `DepartmentID` column, but since you only want the `EmployeeID`, `Name`, and `DepartmentName` in the resulting DataFrame, how can you accomplish this while avoiding the `Location` column in the final output? \n\nPlease provide the code to achieve this:\n```python\nmerged_df = ...\n```",
    "output": "\n```python\nmerged_df = pd.merge(employees, departments[['DepartmentID', 'DepartmentName']], on='DepartmentID')[['EmployeeID', 'Name', 'DepartmentName']]\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand((8, 3, 32, 32))  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[3])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()\n</code>"
  },
  {
    "input": "Problem:\n\nI have a set of image data represented as a 4D PyTorch tensor. Each image is of size (channels, height, width), and I wish to apply a resizing operation to all images in the batch to a target size of (new_height, new_width). The new dimensions vary based on the size of the original images, and I would like to apply bilinear interpolation for this resizing.\n\nGiven a tensor `images` of shape `(batch_size, channels, height, width)`, how can I resize the images to a new height of 64 and a new width of 64?\n\nFor example, if `images` is of shape `(4, 3, 128, 128)`, the goal is to transform it to shape `(4, 3, 64, 64)`.\n\nA:\n\n<code>\nimport torch\nimages = load_data()\n</code>\nresized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresized_images = torch.nn.functional.interpolate(images, size=(64, 64), mode='bilinear', align_corners=False)\n</code>"
  },
  {
    "input": "Problem:\nYou have two dataframes containing customer order information and product details:\n\norders_df:\n```\n| order_id | customer_id | product_id | quantity |\n|----------|-------------|------------|----------|\n| 1        | 101         | 2001       | 2        |\n| 2        | 102         | 2002       | 1        |\n| 3        | 101         | 2001       | 5        |\n| 4        | 103         | 2003       | 1        |\n| 5        | 102         | 2002       | 2        |\n```\n\nproducts_df:\n```\n| product_id | product_name | price |\n|------------|--------------|-------|\n| 2001      | Widget A     | 10    |\n| 2002      | Widget B     | 20    |\n| 2003      | Widget C     | 30    |\n```\n\nYou want to combine these two dataframes so that for each order, you not only get the order information but also the corresponding product name and total cost (quantity * price). The expected output dataframe should include the following columns: order_id, customer_id, product_id, quantity, product_name, total_cost.\n\nYour code should fill in the missing part to achieve this merge using an appropriate join method:\n\n```python\nimport pandas as pd\n\norders_df = pd.DataFrame({\n    'order_id': [1, 2, 3, 4, 5],\n    'customer_id': [101, 102, 101, 103, 102],\n    'product_id': [2001, 2002, 2001, 2003, 2002],\n    'quantity': [2, 1, 5, 1, 2]\n})\n\nproducts_df = pd.DataFrame({\n    'product_id': [2001, 2002, 2003],\n    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n    'price': [10, 20, 30]\n})\n\nresult = orders_df.merge(products_df, on='product_id', how='...')  # put solution in this variable\nresult['total_cost'] = result['quantity'] * result['price']\n```",
    "output": "\n```python\nresult = orders_df.merge(products_df, on='product_id', how='inner')\n```"
  },
  {
    "input": "Problem:\n\nI have a PyTorch tensor that contains RGB values of a batch of images represented as a 4D tensor of shape (batch_size, channels, height, width). I want to apply a mask to select only certain channels (for example, the red and blue channels) from this tensor. However, I faced an issue when trying to slice the tensor with a mask that is a Boolean tensor.\n\nHere is the relevant code snippet where I'm running into trouble:\n\n```python\nimport torch\n\nbatch_images = torch.rand((4, 3, 64, 64))  # Randomly generated batch of images\nchannel_mask = torch.ByteTensor([1, 0, 1])  # This mask is supposed to keep channels 0 and 2 (Red and Blue)\n```\n\nHowever, when I try to use this mask to slice the tensor:\n\n```python\nselected_channels = batch_images[:, channel_mask, :, :] # This raises an error.\n```\n\nI need to correct this error to properly select the desired channels. Can you help me with the correct slicing technique?\n\nA:\n\n```python\nimport numpy as np\nimport pandas as pd\nimport torch\nbatch_images, channel_mask = load_data()\n```\nselected_channels = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nselected_channels = batch_images[:, channel_mask.bool(), :, :]\n```"
  },
  {
    "input": "Problem:\nContext\nI have two datasets that represent purchases and customer information. \n\nDataset A (purchases):\n```\nPurchaseID   CustomerID   Amount\n-----------------------------------\n1            101          150\n2            102          200\n3            101          50\n4            103          100\n```\n\nDataset B (customers):\n```\nCustomerID   Name         Age\n---------------------------------\n101          John Doe    30\n102          Jane Smith   25\n103          Alice Johnson 27\n104          Bob Gray     40\n```\n\nI want to merge these datasets to create a final DataFrame that shows PurchaseID, Amount, Name, and Age. However, for any customers in Dataset B who do not have purchases recorded in Dataset A, I want to record `NaN` for the PurchaseID and Amount. \n\nHow can I achieve this with pandas?\n\nA:\n<code>\nimport pandas as pd\n\npurchases = pd.DataFrame({'PurchaseID':[1, 2, 3, 4],\n                           'CustomerID':[101, 102, 101, 103],\n                           'Amount':[150, 200, 50, 100]})\n\ncustomers = pd.DataFrame({'CustomerID':[101, 102, 103, 104],\n                          'Name':['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Gray'],\n                          'Age':[30, 25, 27, 40]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(customers, purchases, on='CustomerID', how='left')[['PurchaseID', 'Amount', 'Name', 'Age']]"
  },
  {
    "input": "Problem:\n\nYou have a 3D tensor `data` with the shape of (2, 5, 4) representing batches of features, where each batch contains 5 samples with 4 feature values each. Your goal is to perform a dynamic manipulation to calculate the mean across the first dimension (batch dimension) for each feature across all samples.\n\nThe resulting tensor should have a shape of (5, 4), containing the mean feature values for each of the 5 samples.\n\nHere is the setup you have:\n\n```python\nimport torch\ndata = load_data()  # should be a tensor of shape (2, 5, 4)\n```\n\nHow can you compute the means across the batches to achieve the desired shape in a single line of code?\n\nA:\n\n```python\nmeans = ...  # put solution in this variable\n```",
    "output": "\n```python\nmeans = data.mean(dim=0)\n```"
  },
  {
    "input": "Problem:\nYou are working with two pandas dataframes representing sales data for different products. The first dataframe, `df_sales`, contains information about sales transactions and includes the columns `TransactionID`, `ProductID`, and `Amount`. The second dataframe, `df_products`, includes `ProductID`, `ProductName`, and `Category`. \n\nHere are the details of the dataframes:\n\ndf_sales:\n```\n+----------------+------------+--------+\n| TransactionID  | ProductID  | Amount |\n+----------------+------------+--------+\n|        1       |     A      |  250   |\n|        2       |     B      |  400   |\n|        3       |     A      |  150   |\n|        4       |     C      |  300   |\n|        5       |     B      |  200   |\n+----------------+------------+--------+\n```\n\ndf_products:\n```\n+------------+--------------+-----------+\n| ProductID  | ProductName  | Category  |\n+------------+--------------+-----------+\n|     A      | Product A    | Category 1|\n|     B      | Product B    | Category 1|\n|     C      | Product C    | Category 2|\n|     D      | Product D    | Category 2|\n+------------+--------------+-----------+\n```\n\nYour task is to merge these two dataframes so that for each transaction in `df_sales`, you can display the `TransactionID`, `ProductName`, and `Amount`. If a transaction references a `ProductID` that does not exist in `df_products`, the `ProductName` should display `None`. \n\nTo achieve this, fill in the following Python code snippet where `result` will store the merged data:\n\n```python\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'TransactionID': [1, 2, 3, 4, 5],\n    'ProductID': ['A', 'B', 'A', 'C', 'B'],\n    'Amount': [250, 400, 150, 300, 200]\n})\n\ndf_products = pd.DataFrame({\n    'ProductID': ['A', 'B', 'C', 'D'],\n    'ProductName': ['Product A', 'Product B', 'Product C', 'Product D'],\n    'Category': ['Category 1', 'Category 1', 'Category 2', 'Category 2']\n})\n\nresult = ... # put solution in this variable\n```\n",
    "output": "\n```python\nresult = pd.merge(df_sales, df_products[['ProductID', 'ProductName']], on='ProductID', how='left')[['TransactionID', 'ProductName', 'Amount']]\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame that tracks sales data for different products over several months. Some sales data are missing or represented as null values in specific months. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'Product': ['A', 'A', 'B', 'B', 'C', 'C'],\n    'Month': ['2021-01', '2021-02', '2021-01', '2021-02', '2021-01', '2021-02'],\n    'Sales': [200, np.nan, np.nan, 300, 400, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nYour task is to intelligently fill the missing sales data in such a way that:\n1. If sales for the previous month (same product) are available, fill the current month with the previous month's sales if it is missing.\n2. If there is no previous month data available for a product, fill it with the average sales for that product across the months.\n\nYou should return the DataFrame after filling in the missing values.\n\nCurrent DataFrame:\n```\n  Product    Month  Sales\n0       A  2021-01  200.0\n1       A  2021-02    NaN\n2       B  2021-01    NaN\n3       B  2021-02  300.0\n4       C  2021-01  400.0\n5       C  2021-02    NaN\n```\n\nUse the following code to fill in the missing values:\n\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = df.groupby('Product').apply(lambda group: group['Sales'].fillna(method='ffill').fillna(group['Sales'].mean())).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\n\nI have two dataframes that I want to merge, one containing information about students and their scores, and another containing their extra-curricular activities. Here are the dataframes:\n\n```python\nimport pandas as pd\n\ndf_scores = pd.DataFrame({\n    'student_id': [1, 2, 3],\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'score': [88, 92, 85]\n})\n\ndf_activities = pd.DataFrame({\n    'student_id': [1, 2, 4],\n    'activities': [['Soccer', 'Drama'], ['Chess'], ['Music', 'Art']]\n})\n```\n\nI want to perform a merge operation based on `student_id` and keep all students from the scores dataframe, filling in NaNs for those without extra-curricular activities. The resulting dataframe should look like this:\n\n```\n   student_id     name  score          activities\n0           1    Alice     88      [Soccer, Drama]\n1           2      Bob     92              [Chess]\n2           3  Charlie     85                  NaN\n```\n\nWhat code can I write to achieve this result? \n\nA:\n<code>\nimport pandas as pd\n\ndf_scores = pd.DataFrame({\n    'student_id': [1, 2, 3],\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'score': [88, 92, 85]\n})\n\ndf_activities = pd.DataFrame({\n    'student_id': [1, 2, 4],\n    'activities': [['Soccer', 'Drama'], ['Chess'], ['Music', 'Art']]\n})\n\nresult = ... # put solution in this variable\n</code>",
    "output": "\n<code>\nresult = pd.merge(df_scores, df_activities, on='student_id', how='left')\n</code>"
  },
  {
    "input": "Problem:\n\nI need to normalize a batch of images represented as a PyTorch tensor. The images are stored in a tensor with shape `[batch_size, channels, height, width]`, and I would like to perform a per-channel normalization using the mean and standard deviation for each channel. Here is a snippet of my code that loads the images:\n\n```python\nimport torch\n\nimages = load_data()  # Assuming images is a tensor of shape [batch_size, channels, height, width]\n```\n\nHow can I apply this normalization? The expected output should also be a tensor of the same shape `[batch_size, channels, height, width]`.\n\nA:\n\n```python\nnormalized_images = ...  # put solution in this variable\n```",
    "output": "\n```python\nmean = images.mean(dim=[0, 2, 3], keepdim=True)\nstd = images.std(dim=[0, 2, 3], keepdim=True)\nnormalized_images = (images - mean) / std\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame that contains temperature readings with missing values over time. The DataFrame is structured as follows:\n\n```python\ndf = pd.DataFrame({\n    'timestamp': ['2023-01-01 00:00', '2023-01-01 01:00', '2023-01-01 02:00', \n                  '2023-01-01 03:00', '2023-01-01 04:00', '2023-01-01 05:00'],\n    'temperature': [22.5, NaN, 23.0, NaN, 22.8, 22.9]\n})\n```\n\nYou need to fill in the missing temperature values by using forward fill for the previous readings and then backward fill for any remaining missing values. The desired final output should retain the original DataFrame structure but with all temperature values filled in. \n\nWhat is the single line of Python code that accomplishes this data imputation using pandas? \n\nPlease fill this response with your solution.\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.fillna(method='ffill').fillna(method='bfill')\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am developing a custom loss function to evaluate the performance of a neural network that predicts continuous values. I want to implement a custom loss that calculates the Mean Absolute Error (MAE) only for predictions that exceed a certain threshold. For the loss function, if the absolute error is less than the threshold, the contribution should be zero. How can I implement this as a custom loss function?\n\nHere is a sample implementation of your function:\n\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        # return the solution in this function\n        pass\n    return loss\n```\n\nIn the `loss` function, you will receive the ground truth values `y_true` and the predicted values `y_pred`. Complete the implementation based on the above requirements.",
    "output": "\n```python\nimport tensorflow as tf\n\ndef custom_mae_loss(threshold=1.0):\n    def loss(y_true, y_pred):\n        absolute_error = tf.abs(y_true - y_pred)\n        mask = tf.cast(absolute_error > threshold, tf.float32)\n        return tf.reduce_mean(mask * absolute_error)\n    return loss\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing sales data for a store represented as follows:\n\n```python\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\n\nThe DataFrame has missing values for the `Date` and `Sales` columns. I want to fill in the missing `Sales` values for the same `ProductID` by using the mean sales value of products with the same `ProductID`, while keeping the original `Date` as is. For the missing `Date`, I would like to fill it with the string \"Unknown Date\".\n\nHere is my current DataFrame before processing:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02    NaN\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04    NaN\n6          5        NaN    NaN\n```\n\nWhat I want to achieve is to apply the necessary imputation method to get the following resulting DataFrame:\n\n```\n   ProductID        Date  Sales\n0          1  2023-01-01  100.0\n1          2  2023-01-01  200.0\n2          2  2023-01-02  200.0\n3          3  2023-01-02  150.0\n4          4  2023-01-03  300.0\n5          4  2023-01-04  300.0\n6          5  Unknown Date    NaN\n```\n\nI would like the code that fills in the missing values in `Sales` with the mean sales for the respective `ProductID` and replaces the missing `Date` with \"Unknown Date\".\n\nA:\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'ProductID': [1, 2, 2, 3, 4, 4, 5],\n    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-04', None],\n    'Sales': [100, 200, None, 150, 300, None, None]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```python\n\n",
    "output": "\n```python\ndf['Date'].fillna('Unknown Date', inplace=True)\nmean_sales = df.groupby('ProductID')['Sales'].transform('mean')\ndf['Sales'].fillna(mean_sales, inplace=True)\nresult = df\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to my dataset. I have already set up a `transform` variable that should include both transformations, but I'm unsure how to implement the color jitter with the specified parameters.\n\nHere's what I have so far:\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    # Fill in the blank with the color jitter transform\n])\n```\n\nI would like to apply color jittering with brightness=0.2, contrast=0.2, saturation=0.2, and hue=0.1.\n\nA:\n\n<code>\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n])\n</code>\nresult = ... # put solution in this variable",
    "output": "\n<code>\nresult = transform\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame with missing values in some columns, which looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'id': [1, 2, 3, 4, 5],\n    'age': [25, np.nan, np.nan, 30, 35],\n    'income': [50000, 60000, np.nan, np.nan, 70000],\n    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n}\n\ndf = pd.DataFrame(data)\n```\n\nYour objective is to fill in the missing values in the 'age' column using the method of forward filling based on the previous non-null value, and the missing values in the 'income' column by filling them with the mean income of the individuals in the DataFrame.\n\nHow can you update the DataFrame accordingly? \n\nPlease provide the line of code that achieves this result and assign it to the variable `result`.",
    "output": "\n<code>\nresult = df.fillna({'age': df['age'].ffill(), 'income': df['income'].mean()})\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am trying to implement a custom loss function to calculate the Hinge loss for a binary classification problem. My predictions are in a tensor format (e.g., [0.6, -0.8, 0.1, -0.3]) and my true labels are in the format [1, -1, 1, -1]. The Hinge loss is calculated as max(0, 1 - true * prediction) for each element. \nI want to compute the average Hinge loss across all samples.\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([0.6, -0.8, 0.1, -0.3])\ntrue_labels = tf.constant([1, -1, 1, -1])\ndef hinge_loss(predictions, true_labels):\n    # return the solution in this function\n    # loss = hinge_loss(predictions, true_labels)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    loss = tf.maximum(0.0, 1 - true_labels * predictions)\n    return tf.reduce_mean(loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am trying to create a composite transformation:\n\n```python\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\n# Assuming 'image' is a PIL Image that I want to transform\naugmented_image = transform(image)\n```\n\nHowever, I forgot to import the necessary library to handle image loading. \n\nA:\n<code>\nfrom PIL import Image\nimage = Image.open('path/to/image.jpg')\n</code>\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n\n\n\n",
    "output": "\n<code>\nresult = augmented_image\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that tracks daily sales for multiple stores:\n\n```python\nsales_data = pd.DataFrame({\n    'store_id': ['S1', 'S1', 'S2', 'S2', 'S3', 'S3'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'sales': [200, 300, None, 150, None, 100]\n})\n```\n\nThe dates in the DataFrame are not continuous, and some stores have missing sales data for certain dates. I want to generate a complete dataset that includes all dates between the minimum and maximum dates, for each store, while filling in missing sales with the previous day\u2019s sales (if available) or zero otherwise. The desired output should look similar to this:\n\n```\n   store_id        date  sales\n0       S1  2023-01-01  200.0\n1       S1  2023-01-02    0.0\n2       S1  2023-01-03  300.0\n3       S2  2023-01-01    0.0\n4       S2  2023-01-02  150.0\n5       S2  2023-01-03    0.0\n6       S3  2023-01-01    0.0\n7       S3  2023-01-02    0.0\n8       S3  2023-01-03  100.0\n```\n\nWhat is the best way to achieve this using pandas? \n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'store_id': ['S1', 'S1', 'S2', 'S2', 'S3', 'S3'],\n    'date': ['2023-01-01', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n    'sales': [200, 300, None, 150, None, 100]\n})\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n```\n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\ndate_range = pd.date_range(start=sales_data['date'].min(), end=sales_data['date'].max())\nall_stores = sales_data['store_id'].unique()\ncomplete_data = pd.MultiIndex.from_product([all_stores, date_range], names=['store_id', 'date']).to_frame(index=False)\ncomplete_data = complete_data.merge(sales_data, on=['store_id', 'date'], how='left').fillna(0)\ncomplete_data['sales'] = complete_data['sales'].ffill().fillna(0)\nresult = complete_data\n```"
  },
  {
    "input": "Problem:\nI have a DataFrame containing user activity over time:\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'user_id': ['U1', 'U1', 'U2', 'U2', 'U3'],\n    'activity_date': ['2021-03-01', '2021-03-02', '2021-03-01', None, '2021-03-05'],\n    'activity_score': [10, None, 15, None, 20]\n})\n```\n\nWhat I would like to achieve is to fill in the missing values in the `activity_date` column with sequential dates starting from the minimum date for each user in a way such that if a user has missing `activity_date`, their most recent previous date is used to fill it in. Additionally, I want to fill the `activity_score` column with the average score of each user for any missing entries.\n\nThe desired output should look like this:\n```\n  user_id activity_date  activity_score\n0     U1    2021-03-01             10\n1     U1    2021-03-02             10\n2     U2    2021-03-01             15\n3     U2    2021-03-02             15\n4     U3    2021-03-05             20\n```\n\nPlease fill in the code below to solve this problem:\n\n```python\n# Your solution starts here\nresult = ...\n```",
    "output": "\n```python\n# Your solution starts here\ndf['activity_date'] = pd.to_datetime(df['activity_date'])\ndf['activity_score'] = df.groupby('user_id')['activity_score'].transform(lambda x: x.fillna(x.mean()))\ndf = df.sort_values(by=['user_id', 'activity_date'])\ndf['activity_date'] = df.groupby('user_id')['activity_date'].ffill()\ndf['activity_date'] = df.groupby('user_id')['activity_date'].apply(lambda x: x.ffill().bfill().sort_values().reset_index(drop=True))\nresult = df.drop_duplicates().reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I am developing a custom loss function that penalizes the model based on the mean squared error for a specific class in a multi-class classification problem. Consider that I have one-hot encoded predictions and true labels and want to focus the loss on the class specified by its index. For example, if the index is 2, the loss should only be calculated for this class.\n\nGiven two tensors: `y_true` representing the true labels and `y_pred` representing the predicted labels, how can I implement this custom loss function to compute the loss focusing only on the designated class index? The `y_true` and `y_pred` tensors have the shape (n, 5) for a 5-class problem.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred, class_index):\n    # calculate the loss focused on class_index\n    pass\n</code>",
    "output": "\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred, class_index):\n    # Extract the specific class predictions and true labels\n    y_true_class = y_true[:, class_index]\n    y_pred_class = y_pred[:, class_index]\n    \n    # Calculate the mean squared error for the specific class\n    loss = tf.reduce_mean(tf.square(y_true_class - y_pred_class))\n    \n    return loss\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing image data where each image is flattened into a 1D tensor. The tensor has a shape of (batch_size, num_pixels), where `num_pixels` represents the total pixels in each image. For example:\n\ntensor([[0.2, 0.3, 0.4],\n        [0.1, 0.8, 0.7],\n        [0.4, 0.1, 0.5]])\n\nI want to normalize each image individually so that the values in each row sum up to 1. How can I achieve this using PyTorch without using explicit loops?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = load_data()\n</code>\nnormalized_images = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nnormalized_images = images / images.sum(dim=1, keepdim=True)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI have a batch of images represented as a 4D tensor with dimensions (batch_size, channels, height, width). I want to apply a random horizontal flip to each image in the batch. I need to generate a mask tensor of the same height and width as the images that randomly assigns a value of 1 for pixels that will be flipped and 0 for pixels that will not be flipped. This mask will later be used to apply the flip. How can I create this mask using PyTorch?\n\nA:\n\n<code>\nimport numpy as np\nimport torch\nimages = load_data()\ndef generate_flip_mask(images):\n    # return the solution in this function\n    # mask = generate_flip_mask(images)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    batch_size, channels, height, width = images.shape\n    flip_mask = torch.randint(0, 2, (batch_size, 1, height, width), dtype=torch.float32)\n    return flip_mask\n    ### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nYou have a DataFrame containing sales data for a retail store structured as follows:\n\n```\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 104, 105, 101, 102, 103],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', \n             '2023-01-03', '2023-01-03', '2023-01-04'],\n    'units_sold': [23, 45, np.nan, np.nan, 30, 12, np.nan, np.nan]\n})\n```\n\nSome rows in the `units_sold` column have missing values (NaNs), and you want to fill these missing values using the mean of `units_sold` for the same `product_id`, but only considering previous dates. Your goal is to ensure that when a product has missing sales in a certain date, it is filled with the average sales of the previous entries for that product.\n\nPlease provide the code that accomplishes this task and fills the NaN values accordingly, while keeping the remaining data intact. The final DataFrame should reflect the updated sales data with the NaN values filled. \n\nFill in the blank:\n```python\nimport pandas as pd\nimport numpy as np\n\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 104, 105, 101, 102, 103],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', \n             '2023-01-03', '2023-01-03', '2023-01-04'],\n    'units_sold': [23, 45, np.nan, np.nan, 30, 12, np.nan, np.nan]\n})\n\n# Convert 'date' to datetime\nsales_data['date'] = pd.to_datetime(sales_data['date'])\n\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.groupby('product_id').apply(lambda group: group['units_sold'].fillna(group['units_sold'].expanding().mean())).reset_index(drop=True)\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes, `sales` and `customers`, with the following structure:\n\n```python\nimport pandas as pd\n\nsales = pd.DataFrame({\n    'order_id': [1, 2, 3, 4, 5],\n    'customer_id': [1, 2, 1, 3, 2],\n    'amount': [100, 200, 150, 300, 250]\n})\n\ncustomers = pd.DataFrame({\n    'customer_id': [1, 2, 3, 4],\n    'customer_name': ['Alice', 'Bob', 'Charlie', 'David']\n})\n```\n\nYou want to merge these two dataframes to create a new dataframe that includes every order along with the corresponding customer's name. However, if a customer has not made any orders, you want to still include the customer in the output with a default amount of zero. The final dataframe should have the structure:\n\n```\n   order_id  customer_id  amount customer_name\n0         1            1     100          Alice\n1         2            2     200            Bob\n2         3            1     150          Alice\n3         4            3     300        Charlie\n4         5            2     250            Bob\n5       NaN            4       0          David\n```\n\nHow can you achieve this merging operation?\n\n```python\nmerged_df = ... # put solution in this variable\n```",
    "output": "\n```python\nmerged_df = pd.merge(customers, sales, on='customer_id', how='left').fillna({'amount': 0})\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I need to implement a custom loss function that penalizes predictions based on the deviation from the target values, but with an emphasis on the mispredictions of a particular class (let's say class index 1). I want to create a function that calculates the custom loss where the loss for class index 1 is doubled compared to other classes. The function should take true labels and predicted labels as inputs, and return the computed custom loss.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Custom loss function to penalize class index 1 predictions more\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    class_weights = tf.where(tf.equal(y_true, 1), 2.0, 1.0)\n    loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n    weighted_loss = loss * class_weights\n    return tf.reduce_mean(weighted_loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to apply this function to each image in the dataset based on the provided probability.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flip the image vertically (along height)\n```\n\nYou need to fill in the following code to apply the augmentation:\n\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>\n```\n\nresult = ... # put solution in this variable\n\nBEGIN SOLUTION\n<code>flip_image(images[i])</code>",
    "output": "\n```python\nfor i in range(images.shape[0]):\n    if torch.rand(1).item() < 0.5:\n        images[i] = <code>flip_image(images[i])</code>\n```"
  },
  {
    "input": "### Problem:\nI have two DataFrames representing sales information of products across different regions. The first DataFrame contains the sales data for 2021, while the second one contains the sales data for 2022. Here are their structures:\n\nDataFrame 1 (sales_2021):\n```\n   product_id   region    sales\n0          1   North      500\n1          2   South      300\n2          3   East       400\n3          4   West       600\n```\n\nDataFrame 2 (sales_2022):\n```\n   product_id   region    sales\n0          1   North      700\n1          2   South      200\n2          3   East       500\n3          5   Central    300\n```\n\nI want to merge these two DataFrames such that I can see the sales of each product for both years, while also including regions. If a product only appears in one of the DataFrames, its sales in the other year should show as NaN. The expected structure looks like this:\n\n```\n   product_id   region    sales_2021    sales_2022\n0          1   North        500              700\n1          2   South        300              200\n2          3   East         400              500\n3          4   West         600              NaN\n4          5   Central      NaN              300\n```\n\nHow can I achieve this in Python using pandas? \n\nA:\n<code>\nimport pandas as pd\n\nsales_2021 = pd.DataFrame({\n    'product_id': [1, 2, 3, 4],\n    'region': ['North', 'South', 'East', 'West'],\n    'sales': [500, 300, 400, 600]\n})\n\nsales_2022 = pd.DataFrame({\n    'product_id': [1, 2, 3, 5],\n    'region': ['North', 'South', 'East', 'Central'],\n    'sales': [700, 200, 500, 300]\n})\n</code>\nmerged_result = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\n",
    "output": "\n<code>\nmerged_result = pd.merge(sales_2021, sales_2022, on=['product_id', 'region'], how='outer', suffixes=('_2021', '_2022'))\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function for my regression model that emphasizes the prediction errors more heavily for large differences. Specifically, I'd like to implement a modified Mean Absolute Error (MAE) where any absolute difference greater than a threshold (let's say 1.0) is penalized more heavily by a factor (let's say 2.0). I have already defined my true values and prediction values as tensors:\n\n```python\ntrue_values = tf.constant([1.0, 2.0, 3.0, 4.0])\npredicted_values = tf.constant([1.5, 1.0, 4.0, 3.0])\n```\n\nNow, I need to define the custom loss function called `custom_mae_loss` which will compute the loss based on the criteria mentioned.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mae_loss(true, predicted, threshold=1.0, penalty=2.0):\n    # return the calculated custom MAE loss\n    ### BEGIN SOLUTION\n```",
    "output": "\n<code>\n    abs_diff = tf.abs(true - predicted)\n    loss = tf.where(abs_diff > threshold, abs_diff * penalty, abs_diff)\n    return tf.reduce_mean(loss)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[3])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()\n</code>"
  },
  {
    "input": "Problem:\nYou are tasked with merging two datasets related to customer orders and product details. The first dataframe (`orders`) contains the order IDs along with customer IDs and product IDs they ordered. The second dataframe (`products`) has product IDs and their corresponding names and prices. You need to produce a new dataframe that combines the information from both dataframes based on product IDs and includes the following columns: `order_id`, `customer_id`, `product_name`, and `product_price`. \n\nThe given dataframes are as follows:\n\n```python\nimport pandas as pd\n\norders = pd.DataFrame({\n    'order_id': [101, 102, 103, 104],\n    'customer_id': ['C1', 'C2', 'C1', 'C3'],\n    'product_id': [1, 2, 3, 1]\n})\n\nproducts = pd.DataFrame({\n    'product_id': [1, 2, 3],\n    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n    'product_price': [10.99, 12.99, 15.99]\n})\n```\n\nYour task is to perform the merge operation such that the resulting dataframe has no duplicate rows for `order_id` and includes product details. \n\nA:\n```python\nresult = ... # put solution in this variable\n```",
    "output": "\n```python\nresult = pd.merge(orders, products, on='product_id')[['order_id', 'customer_id', 'product_name', 'product_price']]\n```"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I have a scenario where I want to implement a custom loss function that penalizes predictions based on their proximity to the true values but dampens the loss for predictions closer to a specified threshold. The threshold is set at 0.5. For instance, if the difference between the true values and predictions is less than 0.5, I want the loss to be half of the grounded difference. Otherwise, I want it to apply a standard mean absolute error.\n\nGiven predictions `y_pred` and true values `y_true`, what would the implementation of this custom loss function look like?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # return the custom loss in this function\n    pass\n</code>",
    "output": "\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    diff = tf.abs(y_true - y_pred)\n    threshold = 0.5\n    loss = tf.where(diff < threshold, diff / 2, diff)\n    return tf.reduce_mean(loss)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to create a custom loss function that calculates the Huber loss for regression tasks. The Huber loss is defined as follows:\n\nL(delta) = 0.5 * (y_true - y_pred)^2 for |y_true - y_pred| <= delta,\nL(delta) = delta * (|y_true - y_pred| - 0.5 * delta) otherwise.\n\nI want to implement this as a function that takes in a delta value and returns the Huber loss function. \n\nA:\n<code>\nimport tensorflow as tf\n\ndef huber_loss(delta):\n    def loss_fn(y_true, y_pred):\n        # return the solution in this function\n        # result = loss_fn(y_true, y_pred)\n        ### BEGIN SOLUTION\n",
    "output": "\n<code>\n        error = y_true - y_pred\n        is_small_error = tf.abs(error) <= delta\n        squared_loss = 0.5 * tf.square(error)\n        linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n        return tf.where(is_small_error, squared_loss, linear_loss)\n    return loss_fn\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomRotation(degrees=30),\n            transforms.RandomHorizontalFlip(),\n            # Fill in the blank with the correct rotation implementation\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image()  # This will load an image tensor\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nresult = ...\n</code>",
    "output": "\n<code>\nresult = self.transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific implementation for the color jitter.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    ________________  # I need to fill in this blank with the proper color jitter transformation\n])\n```\n\nWhat should I put in the blank to apply random brightness, contrast, saturation, and hue adjustments?",
    "output": "\n```python\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n```"
  },
  {
    "input": "Problem:\nI have two DataFrames defined as follows:\n```python\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4],\n    'Name': ['John', 'Alice', 'Bob', 'Eva'],\n    'Department': ['HR', 'Finance', 'IT', 'HR']\n})\n\ndf2 = pd.DataFrame({\n    'EmployeeID': [2, 3, 5],\n    'Salary': [70000, 80000, 90000]\n})\n```\n\nI want to merge these two DataFrames on 'EmployeeID', but I need to ensure that for employees who do not appear in df2, the resulting DataFrame still lists them with a NaN value for Salary. Additionally, I want to add a new column called 'ExistsInSalary' that indicates whether the employee exists in df2 (True if they do, False otherwise).\n\nThe output DataFrame should look like this:\n```\n   EmployeeID   Name Department   Salary ExistsInSalary\n0           1   John         HR     NaN          False\n1           2  Alice    Finance  70000.0           True\n2           3    Bob        IT  80000.0           True\n3           4    Eva         HR     NaN          False\n```\n\nA:\n```python\nresult = pd.merge(df1, df2, on='EmployeeID', how='left').assign(ExistsInSalary=lambda x: x['Salary'].notna())\n```",
    "output": "\n```python\n<code>\nresult = pd.merge(df1, df2, on='EmployeeID', how='left').assign(ExistsInSalary=lambda x: x['Salary'].notna())\n</code>\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `vertical_flip(image)` that takes an image tensor and returns the flipped image. \n\nHere\u2019s what I have so far:\n\n```python\nimport torch\n\ndef vertical_flip(image):\n    return torch.flip(image, [1])  # Flips the image vertically along height (C dimension)\n\nimages = load_data()  # This function loads the image tensor\n```\n\nI want to create a new tensor `augmented_images` that applies the `vertical_flip` function to each image in `images` with a probability of 0.5. I am trying to use a list comprehension for this purpose, but I am not sure how to implement the condition for random flipping.\n\nComplete the following line of code:\n\n```python\naugmented_images = torch.stack([vertical_flip(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```\n\nFill in the blank:\n\n```python\naugmented_images = torch.stack([____ for img in images])\n```",
    "output": "\n```python\naugmented_images = torch.stack([vertical_flip(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```"
  },
  {
    "input": "Problem:\n\nI have a sequence of images represented as a 4D tensor in PyTorch with dimensions (batch_size, channels, height, width). I want to create a new tensor that contains the mean of each image over the channel dimension, resulting in a 3D tensor. However, I need to ensure that the resulting tensor retains the same batch and spatial dimensions. How can I achieve this?\n\nHere is my code below, how to fill in the blank for the mean calculation?\n\n```python\nimport torch\n\nbatch_size = 8\nchannels = 3\nheight = 32\nwidth = 32\nimages = torch.randn(batch_size, channels, height, width)\n\n# Calculate the mean over channels\nmean_images = images._____  # put solution in this variable\n```\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmean_images = images.mean(dim=1)  # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI want to create a custom loss function that penalizes predictions based on a dynamic threshold. Specifically, I need to implement a loss function that computes the mean squared error (MSE) but only for predictions greater than a given threshold (e.g., 0.5). Inputs are two tensors: `y_true` (true labels) and `y_pred` (predicted values). If a predicted value is less than or equal to the threshold, it should not contribute to the loss. \n\nYou should define the function `custom_loss` and ensure it returns the dynamic MSE based on the defined threshold.\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred, threshold=0.5):\n    # Compute the solution in this function\n    # result = custom_loss(y_true, y_pred, threshold)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mask = tf.greater(y_pred, threshold)\n    mse = tf.square(y_true - y_pred)\n    masked_mse = tf.where(mask, mse, tf.zeros_like(mse))\n    return tf.reduce_mean(masked_mse)\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am trying to implement a custom loss function to penalize incorrect predictions in a predictive model that should be more sensitive to false negatives. The goal is to create a modified binary cross-entropy loss where false negatives incur a larger penalty than false positives. How can I calculate this custom loss based on the true labels and predicted probabilities?\n\nThe function should take in two tensors: `y_true` (a tensor of shape `(n_samples,)` containing binary labels) and `y_pred` (a tensor of shape `(n_samples,)` containing predicted probabilities). The custom loss should be computed as follows:\n\n\\[ \\text{custom\\_loss} = - \\frac{1}{n} \\sum_{i=1}^{n} (w_1 \\cdot y_{true}[i] \\cdot \\log(y_{pred}[i]) + w_2 \\cdot (1 - y_{true}[i]) \\cdot \\log(1 - y_{pred}[i])) \\]\n\nWhere \\( w_1 \\) is the weight for false negatives (e.g., 2.0) and \\( w_2 \\) is the weight for false positives (e.g., 1.0).\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    w1 = 2.0  # weight for false negatives\n    w2 = 1.0  # weight for false positives\n    n = tf.cast(tf.shape(y_true)[0], tf.float32)\n</code>\nloss = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\n    loss = -tf.reduce_mean(w1 * y_true * tf.math.log(y_pred + tf.keras.backend.epsilon()) +\n                           w2 * (1 - y_true) * tf.math.log(1 - y_pred + tf.keras.backend.epsilon()))\n</code>"
  },
  {
    "input": "Problem:\n\nI have a 2D PyTorch tensor that represents image pixel intensities. It is shaped like (5, 5) and contains random values between 0 and 1. I want to apply a threshold of 0.5 to binarize the image, such that any pixel value greater than 0.5 becomes 1, and all others become 0.\n\nHere is my starting code:\n\n```python\nimport torch\n\nimage_tensor = torch.rand((5, 5))  # Random pixel intensities\n```\n\nWhat is the correct line of code to achieve this binarization?\n\nA:\n\n```python\nbinarized_image = ...  # put solution in this variable\n```",
    "output": "\n```python\nbinarized_image = (image_tensor > 0.5).float()  # put solution in this variable\n```"
  },
  {
    "input": "Problem:\nYou are given a DataFrame that tracks daily sales across multiple stores, with some gaps in the data. The DataFrame looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Store': ['Store A', 'Store A', 'Store B', 'Store B', 'Store C'],\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'Sales': [200, None, 150, 300, None]\n})\n```\n\nYour goal is to fill in the missing sales figures using forward filling for each store while ensuring that if a store has no sales recorded for a day, it should still show up in the DataFrame with 0 sales for that date. The expected output format should include all unique dates for each store, even if no sales were recorded, with sales data filled accordingly.\n\nWrite the following code to achieve this goal:\n\n```python\nimport pandas as pd\n\nsales_data['Date'] = pd.to_datetime(sales_data['Date'])\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = (sales_data.set_index(['Store', 'Date'])\n          .resample('D')\n          .sum()\n          .fillna(0)\n          .groupby(level=0)\n          .ffill()\n          .reset_index())\n```"
  },
  {
    "input": "Problem:\nI have two DataFrames, invoices and payments, structured as follows:\n\ninvoices\n```\n   invoice_id  amount       date     customer\n0           1     300 2023-01-15      Customer A\n1           2     500 2023-01-16      Customer B\n2           3     200 2023-01-17      Customer A\n3           4     700 2023-01-18      Customer C\n```\n\npayments\n```\n   invoice_id  payment_date  payment_amount\n0           1     2023-01-20             300\n1           2     2023-01-17             300\n2           3     2023-01-19             200\n3           5     2023-01-21             150\n```\n\nI need to create a DataFrame that merges the invoices and payments on the `invoice_id` and fills in the `payment_amount` from the payments DataFrame where it matches. If there is no matching record in payments, the original invoice information should be retained. The merged DataFrame should also include a status column that indicates whether the invoice has been fully paid, partially paid, or is unpaid.\n\nThe expected output should look like this:\n\n```\n   invoice_id  amount       date     customer  payment_amount  status\n0           1     300 2023-01-15      Customer A           300.0  Fully Paid\n1           2     500 2023-01-16      Customer B             NaN  Unpaid\n2           3     200 2023-01-17      Customer A           200.0  Fully Paid\n3           4     700 2023-01-18      Customer C             NaN  Unpaid\n```\n\nIf an invoice has a payment amount that equals the invoice amount, the status should be \"Fully Paid\". If there is a payment amount present but less than the invoice amount, the status should be \"Partially Paid\". If there is no payment for that invoice, the status should be \"Unpaid\".\n\nA:\n```python\nimport pandas as pd\n\ninvoices = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 4],\n    'amount': [300, 500, 200, 700],\n    'date': ['2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18'],\n    'customer': ['Customer A', 'Customer B', 'Customer A', 'Customer C']\n})\n\npayments = pd.DataFrame({\n    'invoice_id': [1, 2, 3, 5],\n    'payment_date': ['2023-01-20', '2023-01-17', '2023-01-19', '2023-01-21'],\n    'payment_amount': [300, 300, 200, 150]\n})\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\nresult = invoices.merge(payments, on='invoice_id', how='left')\nresult['status'] = result.apply(lambda x: 'Fully Paid' if x['payment_amount'] == x['amount'] else \n                                  ('Partially Paid' if pd.notna(x['payment_amount']) and x['payment_amount'] < x['amount'] else 'Unpaid'), axis=1)\n```"
  },
  {
    "input": "Problem:\nYou have two Pandas DataFrames as follows:\n\nDataFrame A:\n| id | name   | salary |\n|----|--------|--------|\n| 1  | John   | 50000  |\n| 2  | Jane   | 60000  |\n| 3  | Mike   | 45000  |\n\nDataFrame B:\n| id | department | location      |\n|----|------------|---------------|\n| 1  | HR         | New York      |\n| 2  | Engineering| San Francisco  |\n| 4  | Marketing  | Los Angeles   |\n\nYou need to merge these two DataFrames on the 'id' column, such that the resulting DataFrame includes all records from DataFrame A and only the matching records from DataFrame B. If there is no matching record in DataFrame B, the result should include NaN for the columns from DataFrame B. However, you want to drop the 'location' column from the final merged DataFrame. \n\nThe expected structure should look like this:\n\n| id | name   | salary | department  |\n|----|--------|--------|-------------|\n| 1  | John   | 50000  | HR          |\n| 2  | Jane   | 60000  | Engineering  |\n| 3  | Mike   | 45000  | NaN         |\n\nHow can you achieve this using Pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf_a = pd.DataFrame({'id': [1, 2, 3],\n                     'name': ['John', 'Jane', 'Mike'],\n                     'salary': [50000, 60000, 45000]})\n\ndf_b = pd.DataFrame({'id': [1, 2, 4],\n                     'department': ['HR', 'Engineering', 'Marketing'],\n                     'location': ['New York', 'San Francisco', 'Los Angeles']})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = pd.merge(df_a, df_b[['id', 'department']], on='id', how='left')"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor as input and returns the flipped image. Here's how my images tensor looks like:\n\n```python\nimages = torch.randn(10, 3, 32, 32)  # Example tensor for 10 images of 3 channels, 32x32 pixels\n```\n\nNow, I want to apply the `flip_image` function to each image in the `images` tensor based on the flip probability. I need to fill in the blank for the following line of code:\n\n```python\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```\n\nWhat would be the correct approach to perform this operation? \n\nA:\n\n<code>\nimport torch\n\ndef flip_image(image):\n    return torch.flip(image, [1])  # Flips vertically\n\nimages = torch.randn(10, 3, 32, 32)  # Example tensor\naugmented_images = ...  # put solution in this variable\n</code>",
    "output": "\n<code>\naugmented_images = torch.tensor([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame like:\n```plaintext\n   employee_id department   salary\n0            1      HR      50000\n1            2      IT      70000\n2            3      Sales   60000\n3            4      IT      NaN\n4            5      Sales   72000\n5            6      HR      NaN\n```\n\nThe `salary` column contains some missing values. I want to fill these NaN values in the `salary` column using the median salary of their respective departments. The expected DataFrame should look like this:\n```plaintext\n   employee_id department   salary\n0            1      HR      50000\n1            2      IT      70000\n2            3      Sales   60000\n3            4      IT      70000  # filled with median salary of IT\n4            5      Sales   72000\n5            6      HR      50000  # filled with median salary of HR\n```\n\nCurrently, I have this code implemented, but need your help to fill the NaN values:\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'employee_id': [1, 2, 3, 4, 5, 6],\n    'department': ['HR', 'IT', 'Sales', 'IT', 'Sales', 'HR'],\n    'salary': [50000, 70000, 60000, np.nan, 72000, np.nan]\n}\n\ndf = pd.DataFrame(data)\n```\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nmedian_salaries = df.groupby('department')['salary'].median()\ndf['salary'] = df['salary'].fillna(df['department'].map(median_salaries))\nresult = df\n</code>\n```"
  },
  {
    "input": "Problem:\nI have a dataset containing monthly sales data for different products in a grocery store. The data is represented in the following DataFrame:\n\n```python\nimport pandas as pd\n\ndata = {\n    'product': ['apple', 'banana', 'apple', 'banana', 'orange', 'orange'],\n    'month': ['2023-01', '2023-01', '2023-02', '2023-02', '2023-01', '2023-02'],\n    'sales': [150, None, 200, 250, None, 300]\n}\ndf = pd.DataFrame(data)\n```\n\nIn this DataFrame, some sales figures are missing (`None`). I want to fill in these missing values. To fill the missing sales data, I would like to use the sales figures from the previous month for the same product if available. If there are no previous month sales figures, default the missing sales to 0.\n\nThe desired output after filling in the missing values should look like this:\n\n```\n   product    month  sales\n0    apple  2023-01  150.0\n1   banana  2023-01    0.0\n2    apple  2023-02  200.0\n3   banana  2023-02  250.0\n4   orange  2023-01    0.0\n5   orange  2023-02  300.0\n```\n\nWhat code should I use to achieve this? \n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = df.groupby('product').apply(lambda x: x['sales'].fillna(method='ffill').fillna(0)).reset_index(level=0, drop=True)\ndf['sales'] = result\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            # Other transformations can be added here\n            transforms.RandomRotation(30),  # I need to ensure the rotation is properly defined\n            transforms.RandomHorizontalFlip(),\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image_tensor()  # This should be a 3D tensor representing an image\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\n<rotation_transformation_here>\n</code>\nresult = ...  # put solution in this variable",
    "output": "\n<code>\ntransforms.RandomRotation(degrees=30)\n</code>"
  },
  {
    "input": "Problem:\nYou are given a DataFrame containing daily sales data for a retail store. The DataFrame has the following structure:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [np.nan, 200, np.nan, 300, np.nan]\n}\ndf = pd.DataFrame(data)\n```\n\nYou want to fill in the missing sales data using forward fill for the non-leading NaN values and use a rolling average of the previous three days to fill the leading NaN values. After performing imputation, the DataFrame should look like this:\n\n```plaintext\n        date  sales\n0  2023-01-01   200\n1  2023-01-02   200\n2  2023-01-03   200\n3  2023-01-04   300\n4  2023-01-05   300\n```\n\nWhat one line of code can you use to achieve this filling strategy efficiently on the `sales` column of the DataFrame? \n\n```python\ndf['sales'] = ...\n```",
    "output": "\n```python\ndf['sales'] = df['sales'].fillna(method='ffill').combine_first(df['sales'].rolling(window=3, min_periods=1).mean())\n```"
  },
  {
    "input": "## Problem\nYou are working with two DataFrames that represent sales data from different stores. DataFrame `sales_a` contains the sales data for Store A, and DataFrame `sales_b` contains the sales data for Store B. The structure of each DataFrame is as follows:\n\n`sales_a`:\n```\n+------------+-------+\n|   Product  |  Price|\n+------------+-------+\n|   Widget A |  25   |\n|   Widget B |  30   |\n|   Widget C |  15   |\n+------------+-------+\n```\n\n`sales_b`:\n```\n+------------+-------+\n|   Product  |  Price|\n+------------+-------+\n|   Widget A |  20   |\n|   Widget D |  35   |\n|   Widget C |  18   |\n+------------+-------+\n```\n\nYour task is to merge these two DataFrames such that you create a new DataFrame that consolidates the sales data based on the `Product` column. If a product appears in both DataFrames, take the lower price. If a product appears in only one DataFrame, include it with its price. The resulting DataFrame should have the following structure:\n\n```\n+------------+-------+\n|   Product  |  Price|\n+------------+-------+\n|   Widget A |  20   |\n|   Widget B |  30   |\n|   Widget C |  15   |\n|   Widget D |  35   |\n+------------+-------+\n```\n\nMake sure that the `Price` column values are the minimum for products that exist in both DataFrames. How would you write the code to achieve this?\n\n```python\nimport pandas as pd\n\nsales_a = pd.DataFrame({'Product': ['Widget A', 'Widget B', 'Widget C'],\n                        'Price': [25, 30, 15]})\nsales_b = pd.DataFrame({'Product': ['Widget A', 'Widget D', 'Widget C'],\n                        'Price': [20, 35, 18]})\n```\nresult = ... # put solution in this variable",
    "output": "\n```python\nresult = pd.concat([sales_a, sales_b]).groupby('Product', as_index=False).min()\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame representing sales data with NaN values as follows:\n\n```python\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 4],\n    'sales': [200, np.nan, 150, np.nan, np.nan, 300],\n    'quantity': [5, np.nan, 3, 2, 4, 6],\n    'month': ['2022-01', '2022-01', '2022-02', '2022-02', '2022-03', '2022-03']\n})\n```\n\nI want to use advanced imputation techniques to fill in the missing values in the 'sales' and 'quantity' columns based on the average of each respective product across all months. I've initialized the DataFrame as shown, but how can I efficiently perform this imputation? Please complete the code below:\n```python\nimport pandas as pd\nimport numpy as np\n\nsales_data = pd.DataFrame({\n    'product_id': [1, 2, 1, 3, 2, 4],\n    'sales': [200, np.nan, 150, np.nan, np.nan, 300],\n    'quantity': [5, np.nan, 3, 2, 4, 6],\n    'month': ['2022-01', '2022-01', '2022-02', '2022-02', '2022-03', '2022-03']\n})\n\n# Fill in missing values using the average sales and quantity based on product_id\nresult = ...  # put solution in this variable\n```",
    "output": "\n```python\nresult = sales_data.copy()\nresult['sales'] = result.groupby('product_id')['sales'].transform(lambda x: x.fillna(x.mean()))\nresult['quantity'] = result.groupby('product_id')['quantity'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. \nI am implementing a custom loss function for a regression problem that penalizes predictions further away from the target by applying a quadratic penalty. If the prediction (y_pred) and target (y_true) are given as tensors, I would like to create a loss function that calculates the sum of squared differences between them. I'm trying to design the function to return a scalar tensor value representing the loss. Given that y_true is a tensor of shape (n,) and y_pred is a tensor of the same shape, how can I define the custom loss function correctly?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Calculate the loss here\n    ### BEGIN SOLUTION\n</code>",
    "output": "\n<code>\n    loss = tf.reduce_sum(tf.square(y_true - y_pred))\n    return loss\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I want to define a custom loss function to measure the Mean Absolute Error (MAE) for a regression model that predicts sales figures based on various factors. However, I also want to apply a penalty of 0.1 for predictions that are more than 50 units away from the actual values. To implement this, I need to create a function that returns the custom loss. How can I structure the custom loss function to achieve this?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mae_loss(y_true, y_pred):\n    # Compute the absolute error\n    absolute_error = tf.abs(y_true - y_pred)\n    penalty = tf.where(absolute_error > 50, 0.1, 0.0)\n    return tf.reduce_mean(absolute_error + penalty)\n\n# Sample ground truth and predictions for testing\ny_true_sample = tf.constant([100.0, 200.0, 300.0])\ny_pred_sample = tf.constant([90.0, 210.0, 350.0])\nloss_value = custom_mae_loss(y_true_sample, y_pred_sample)\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = loss_value.numpy()  # Convert the loss tensor to a numpy value for easier interpretation\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using TensorFlow 2.10.0. I want to implement a custom loss function that penalizes predictions based on their distance from the target values. Specifically, I want to create a Mean Absolute Error loss that adds an additional penalty of 0.5 for any predictions that exceed the target values. Given two tensors `y_true` and `y_pred`, how can I define this custom loss function to return a scalar loss value?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    # Compute the base Mean Absolute Error\n    base_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n    # Calculate penalty for predictions exceeding the target\n    penalty = tf.reduce_sum(tf.maximum(y_pred - y_true, 0))\n    # Combine base loss and penalty\n    total_loss = ...\n    return total_loss\n</code>",
    "output": "\n<code>\n    total_loss = base_loss + 0.5 * penalty\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that computes the Mean Squared Error (MSE) for a specific class in my multi-class regression dataset. My model predicts an output of shape (batch_size, num_classes), while the true labels are given in a similar shape. For example, if my predicted output is:\n```\npredictions = [[0.5, 0.2, 0.1],\n               [0.4, 0.6, 0.3]]\n```\nand my true labels are:\n```\nlabels = [[0, 1, 0],\n          [1, 0, 0]]\n```\nI need to calculate the MSE for class 1. I am uncertain how to apply the mask properly to only compute the MSE for the specified class index (e.g., class_idx = 1). \n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.5, 0.2, 0.1],\n                            [0.4, 0.6, 0.3]])\nlabels = tf.constant([[0, 1, 0],\n                      [1, 0, 0]])\nclass_idx = 1\n\ndef custom_loss(predictions, labels, class_idx):\n    # return the solution in this function\n    # loss = custom_loss(predictions, labels, class_idx)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    mask = tf.equal(tf.argmax(labels, axis=1), class_idx)\n    mse = tf.reduce_mean(tf.square(tf.boolean_mask(predictions[:, class_idx], mask) - \n                                    tf.boolean_mask(labels[:, class_idx], mask)))\n    return mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to develop a custom loss function to address the specific problem of overfitting in my regression model. In this case, I want to punish predictions that are more than a certain threshold (e.g., 0.5) away from the actual values. My input tensors are the predicted values and the actual values. I wish to compute the loss as follows: if the absolute error surpasses the threshold, the loss should multiply that error by two; if it does not exceed the threshold, the loss should be the error itself. \n\nHere's how to set up my function:\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss(y_true, y_pred):\n    threshold = 0.5\n    # Calculate the absolute error\n    error = tf.abs(y_true - y_pred)\n    # Apply the custom logic to compute the loss\n    loss = ...\n    return loss\n</code>",
    "output": "\n<code>\n    loss = tf.where(error > threshold, error * 2, error)\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame representing temperature records for multiple cities over several days. The DataFrame looks like this:\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'city': ['New York', 'New York', 'Los Angeles', 'Los Angeles', 'Chicago', 'Chicago'],\n    'date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-02'],\n    'temperature': [30, np.nan, 75, np.nan, 20, 25]\n}\n\ndf = pd.DataFrame(data)\n```\n\nI want to replace the missing temperature values for each city with the mean temperature of that city across the available records. I want this done in a way that minimizes the use of loops for efficiency, especially since the DataFrame may become large. The expected output for the DataFrame, after performing the operation, should be:\n\n```\n          city        date  temperature\n0     New York  2023-01-01          30.0\n1     New York  2023-01-02          30.0\n2  Los Angeles  2023-01-01          75.0\n3  Los Angeles  2023-01-02          75.0\n4      Chicago  2023-01-01          20.0\n5      Chicago  2023-01-02          25.0\n```\n\nPlease provide the line of code to achieve this data imputation. \n\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n```python\nresult = df.groupby('city')['temperature'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "## Problem:\n\nI have a 3D tensor that represents video data, with dimensions corresponding to (batch_size, num_frames, feature_dim). I want to selectively replace certain features of this tensor with a constant value based on a conditional 2D mask that indicates which frames should be replaced. \n\nThe mask has dimensions (batch_size, num_frames), where each value is either 0 (do not replace) or 1 (replace). \n\nGiven the following code:\n\n```python\nimport torch\n\n# Create a sample 3D tensor (batch_size=5, num_frames=10, feature_dim=20)\nvideo_tensor = torch.rand((5, 10, 20))\n\n# Create a mask tensor of the same batch size and num_frames\nmask = torch.randint(2, (5, 10)).byte()\n```\n\nHow can I replace the features in `video_tensor` with the value -1 wherever the mask is 1?\n\nPlace your solution in the variable `modified_video_tensor`:\n\n```python\nmodified_video_tensor = ...  # put solution in this variable\n```",
    "output": "\n```python\nmodified_video_tensor = video_tensor.clone()  # Clone the original tensor to avoid modifying it\nmodified_video_tensor[mask == 1] = -1  # Replace features where mask is 1\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to create a custom loss function that calculates the mean squared error (MSE) for a specific subset of regression outputs. My model predicts values for 10 outputs, but I only want to compute the loss based on the subset of outputs indexed by a given list (e.g., indices [1, 3, 5]). The predicted outputs and true targets are both tensors of shape `(batch_size, 10)`. How can I apply the MSE only to these specific indices and return a single scalar loss value?\n\nA:\n<code>\nimport tensorflow as tf\n\npredictions = tf.constant([[0.5, 0.2, 0.1, 0.4, 0.6, 0.3, 0.7, 0.8, 0.9, 1.0],\n                           [0.4, 0.2, 0.9, 0.3, 0.1, 0.5, 0.8, 0.6, 0.0, 1.0]])\ntargets = tf.constant([[0.0, 0.5, 0.2, 0.3, 0.5, 0.2, 0.7, 0.9, 0.8, 0.9],\n                       [0.4, 0.1, 0.8, 0.5, 0.6, 0.7, 0.3, 0.8, 0.6, 0.5]])\nindices = [1, 3, 5]\n\ndef custom_mse_loss(predictions, targets, indices):\n    # return the solution in this function\n    # loss = custom_mse_loss(predictions, targets, indices)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    selected_predictions = tf.gather(predictions, indices, axis=1)\n    selected_targets = tf.gather(targets, indices, axis=1)\n    mse = tf.reduce_mean(tf.square(selected_predictions - selected_targets))\n    return mse\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to create a custom loss function to calculate the Mean Squared Error (MSE) specifically for a regression task where the model is predicting values that may not fall within a defined range (e.g., 0 to 1). For this, I want to create a function that returns the loss value adjusted based on whether the predictions exceed a threshold value (let's say 1.0). If a prediction exceeds this threshold, I want to penalize it by multiplying the squared error for that prediction by a factor of 2. \n\nI have a true values tensor and a predicted values tensor as follows:\n\ntrue_values = tf.constant([0.5, 1.2, 0.8, 1.5])\npredicted_values = tf.constant([0.7, 1.8, 0.9, 1.3])\n\nI need to implement this custom loss function and store the resultant loss in a variable named `custom_loss`. \n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_mse_loss(y_true, y_pred):\n    # Fill in the custom loss function here\n    pass\n\ntrue_values = tf.constant([0.5, 1.2, 0.8, 1.5])\npredicted_values = tf.constant([0.7, 1.8, 0.9, 1.3])\ncustom_loss = ... # call the custom_mse_loss function here\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndef custom_mse_loss(y_true, y_pred):\n    mse = tf.square(y_true - y_pred)\n    penalty = tf.where(y_pred > 1.0, mse * 2, mse)\n    return tf.reduce_mean(penalty)\n\ncustom_loss = custom_mse_loss(true_values, predicted_values)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\nflipped_images = torch.empty_like(images)\n\n# Here's where I need the implementation to fill in\nfor i in range(images.size(0)):\n    if flip_condition[i]:\n        flipped_images[i] = torch.flip(images[i], dims=[2])  # this line needs your attention\n    else:\n        flipped_images[i] = images[i]\n\n```\n\nA:\n\n<code>\nflipped_images[i] = ...\n</code>",
    "output": "\n<code>\nflipped_images[i] = images[i].clone()  # Use clone to avoid modifying the original tensor\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\ntorchvision.transforms.functional.apply_transform(transform, image)\n</code>",
    "output": "\n<code>\ntransform(image)\n</code>"
  },
  {
    "input": "### Problem:\nYou have a dataset of customer transactions over time structured in a dataframe as follows:\n\n```python\ndf = pd.DataFrame({\n    'customer_id': ['C1', 'C1', 'C2', 'C2', 'C3'],\n    'transaction_date': ['2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03', '2023-01-01'],\n    'amount': [100, 200, None, 150, 300]\n})\n```\n\nDue to missing data in the 'amount' column for some transactions, you would like to fill these missing values. You decide to use the following techniques:\n\n1. For a customer\u2019s missing amounts, fill them with the average of their previous transactions within a 2-day window (i.e., consider transactions from that customer within two days before the missing transaction date).\n2. If there are no prior transactions within that window, fill with the average amount of all transactions for that customer.\n\nComplete the code below to achieve this:\n\n```python\nimport pandas as pd\n\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\n# Set the index for easier date operations\ndf = df.set_index('transaction_date')\n\n# Create a function to impute missing values based on the criteria above\ndef impute_amounts(df):\n    # Your code to fill in the missing amounts\n    ...\n\n# Apply the imputation function\nresult = impute_amounts(df)\n```\n\nFill in the function to effectively impute the missing values according to the described strategy.",
    "output": "\n```python\ndef impute_amounts(df):\n    for customer in df['customer_id'].unique():\n        customer_data = df[df['customer_id'] == customer]\n        for index, row in customer_data.iterrows():\n            if pd.isna(row['amount']):\n                # Get the date of the missing transaction\n                missing_date = index\n                # Get previous transactions within a 2-day window\n                window_start = missing_date - pd.Timedelta(days=2)\n                previous_transactions = customer_data[(customer_data.index < missing_date) & \n                                                      (customer_data.index >= window_start)]\n                \n                if not previous_transactions.empty:\n                    # Fill with the average of previous transactions in the window\n                    df.at[index, 'amount'] = previous_transactions['amount'].mean()\n                else:\n                    # Fill with the average amount of all transactions for that customer\n                    df.at[index, 'amount'] = customer_data['amount'].mean()\n    return df\n```"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly rotate images by up to 30 degrees and randomly flip them horizontally. I've set up a custom transformation class but I am unsure how to implement the rotation correctly in PyTorch. Here\u2019s the skeleton of my code, and I need help filling in the blank with the appropriate rotation transformation code.\n\n```python\nimport torch\nfrom torchvision import transforms\n\nclass CustomAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomRotation(degrees=30),\n            transforms.RandomHorizontalFlip(),\n            # Fill in the blank with the correct rotation implementation\n        ])\n\n    def __call__(self, image):\n        return self.transform(image)\n\n# Example usage:\n# image_tensor = load_image()  # This will load an image tensor\n# augmented_image = CustomAugmentation()(image_tensor)\n```\n\nA:\n\n<code>\nresult = ...\n</code>",
    "output": "\n<code>\nresult = self.transform(image)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI am constructing a custom loss function to address imbalanced classes in a binary classification problem. Specifically, I want to create a loss function that penalizes misclassifications of the minority class more heavily than the majority class. I have a list of true labels and predictions represented as probabilities. \nThe true labels are given as a float list (e.g., [0.0, 1.0, 0.0, 1.0]), and the predicted probabilities are given as another float list (e.g., [0.4, 0.6, 0.3, 0.8]).\nI want to compute the weighted binary cross-entropy loss where the weights for class 0 is 1 and for class 1 is 2. \nThe output should be a single tensor value representing the loss.\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = tf.constant([0.0, 1.0, 0.0, 1.0])\npredicted_probs = tf.constant([0.4, 0.6, 0.3, 0.8])\ndef custom_loss(y_true, y_pred):\n    # return the solution in this function\n    # loss = custom_loss(true_labels, predicted_probs)\n    ### BEGIN SOLUTION",
    "output": "\n<code>\n    weights = tf.constant([1.0, 2.0])  # weights for class 0 and class 1\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = tf.multiply(bce, tf.gather(weights, tf.cast(y_true, tf.int32)))\n    return tf.reduce_mean(weighted_bce)\n### END SOLUTION\n</code>"
  },
  {
    "input": "## Problem:\nYou have a DataFrame containing the daily temperature readings for multiple cities over a month. The DataFrame looks like this:\n\n```\n   City       Date  Temperature\n0  CityA 2023-10-01          20\n1  CityA 2023-10-02          NaN\n2  CityA 2023-10-03          22\n3  CityB 2023-10-01          18\n4  CityB 2023-10-02          NaN\n5  CityB 2023-10-03          NaN\n6  CityB 2023-10-04          19\n```\n\nYou noticed that some of the temperature readings are missing (NaN). You want to fill these NaN values using the forward fill method combined with the backward fill method to ensure that each city's temperature reading reflects the nearest known values. \n\nFurthermore, you would like to compute the mean temperature for each city after filling the missing values.\n\nGiven this setup, what code will fill the missing temperature values as described and store the resulting DataFrame in the variable `filled_df`?\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    'City': ['CityA', 'CityA', 'CityA', 'CityB', 'CityB', 'CityB', 'CityB'],\n    'Date': pd.to_datetime(['2023-10-01', '2023-10-02', '2023-10-03', \n                             '2023-10-01', '2023-10-02', '2023-10-03', \n                             '2023-10-04']),\n    'Temperature': [20, np.nan, 22, 18, np.nan, np.nan, 19]\n}\n\ndf = pd.DataFrame(data)\n</code>\nfilled_df = ...  # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nfilled_df = df.groupby('City')['Temperature'].ffill().bfill().reset_index()\nfilled_df['Mean_Temperature'] = filled_df.groupby('City')['Temperature'].transform('mean')\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0.\nI need to construct a custom loss function that calculates the Mean Squared Error (MSE) between the predicted and actual values for a regression task. However, I want to introduce a scaling factor based on the mean value of the actual labels. This scaling factor should amplify the loss if the mean of the actual labels is greater than a predefined threshold (e.g., 0.5). How can I implement this in a function that takes the actual and predicted values as input?\n\nA:\n<code>\nimport tensorflow as tf\n\ndef custom_loss_function(y_true, y_pred):\n    threshold = 0.5\n    mean_actual = tf.reduce_mean(y_true)\n    scaling_factor = 1.0 if mean_actual <= threshold else 2.0\n    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n    return scaling_factor * mse\n### BEGIN SOLUTION",
    "output": "\n<code>\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation in PyTorch. I want to perform random horizontal flipping and color jittering to enhance the diversity of my training set. With the following code snippet, I am setting up my transformations, but I am missing the specific augmentation function.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor()\n])\n\nimage = load_image()  # assume this function loads an image as a PIL image\naugmented_image = ...\n```\n\nA:\n\n<code>\n    \n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_image = transform(image)\n</code>",
    "output": "\n<code>\naugmented_image = transform(image)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset where I want to apply a series of transformations for data augmentation. Specifically, I want to randomly flip images horizontally and also add Gaussian noise to them before passing them to my model. With the following functions provided, I am trying to create a composite transformation in PyTorch.\n\n```python\nimport torch\nfrom torchvision import transforms\n\ndef random_horizontal_flip(image):\n    # Applies horizontal flip to the image with 50% chance\n    return transforms.RandomHorizontalFlip()(image)\n\ndef add_gaussian_noise(image, mean=0.0, std=0.1):\n    noise = torch.randn(image.size()) * std + mean\n    return image + noise\n\n# Sample tensor representing an image\nimage = torch.randn(3, 64, 64)  # A random image tensor with 3 channels (RGB) and 64x64 pixels\n\n# Applying the composite transformations\naugmented_image = ...\n```\n\nA:\n\n<code>\naugmented_image = random_horizontal_flip(image)\naugmented_image = add_gaussian_noise(augmented_image)\n</code>",
    "output": "\n<code>\naugmented_image = add_gaussian_noise(random_horizontal_flip(image))\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor `images` of shape (N, C, H, W), where N is the number of images, C is the number of channels, H is the height, and W is the width. I want to implement a custom data augmentation technique that randomly flips the images vertically with a probability of 0.5. I have already defined a function `flip_image` that takes an image tensor and flips it. My goal is to create a new tensor `augmented_images` that contains the augmented images.\n\nThe `flip_image` function is defined as follows:\n\n```python\ndef flip_image(image):\n    # This function will flip the input image tensor vertically\n    return image.flip(1)\n```\n\nI have loaded my image tensor as follows:\n\n```python\nimport torch\n\nimages = torch.randn(10, 3, 32, 32)  # 10 random images of size 32x32 with 3 channels\n```\n\nNow, I want to use a list comprehension or a loop to apply the `flip_image` function conditionally to each image in the `images` tensor, storing the results in `augmented_images`.\n\nPlease fill in the blank below:\n\n```python\naugmented_images = torch.stack([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```",
    "output": "\n```python\naugmented_images = torch.stack([flip_image(img) if torch.rand(1).item() < 0.5 else img for img in images])\n```"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I need to create a custom loss function to penalize the model based on the difference between the mean of the predicted values and a given target value. The loss function should compute the absolute difference between the mean of the predictions and the target, scaled by a factor. I want the custom loss function to be defined in a way that it accepts the predictions and the true labels. \n\nHere is a sample set of predictions and a target:\n```python\npredictions = tf.constant([0.1, 0.2, 0.3, 0.4, 0.5])\ntarget_value = 0.3\n```\n\nHow can I define a function for the loss that outputs the correct loss based on the above criteria? Please provide the content inside the function. \n\nA:\n```python\nimport tensorflow as tf\n\ndef custom_loss(predictions, target_value):\n    # return the loss calculation in this function\n    ### BEGIN SOLUTION\n```",
    "output": "\n```python\n    mean_predictions = tf.reduce_mean(predictions)\n    loss = tf.abs(mean_predictions - target_value)\n    return loss\n```"
  },
  {
    "input": "Problem:\nYou have two dataframes, where the first dataframe contains product sales data for different stores, and the second dataframe contains product prices. The structures of the dataframes are as follows:\n\ndf_sales:\n```\n+---------+--------+-------+\n| Product | Store  | Sales |\n+---------+--------+-------+\n|   A     | Store1 |  30   |\n|   B     | Store2 |  25   |\n|   A     | Store2 |  15   |\n|   C     | Store1 |  10   |\n+---------+--------+-------+\n```\n\ndf_prices:\n```\n+---------+--------+\n| Product | Price  |\n+---------+--------+\n|   A     |  5.00  |\n|   B     |  3.00  |\n|   C     |  7.50  |\n+---------+--------+\n```\n\nYou need to create a new dataframe that joins these two dataframes based on the \"Product\" column, showing the total revenue for each store from the products sold. The new dataframe should look like this:\n\nresult:\n```\n+--------+--------+------------+\n| Store  | Product| Total_Revenue|\n+--------+--------+------------+\n| Store1 | A      |  150.00    |\n| Store1 | C      |  75.00     |\n| Store2 | A      |  75.00     |\n| Store2 | B      |  75.00     |\n+--------+--------+------------+\n```\n\nTo achieve this, fill in the blank below with the appropriate pandas code.\n\nA:\n<code>\nimport pandas as pd\n\ndf_sales = pd.DataFrame({\n    'Product': ['A', 'B', 'A', 'C'],\n    'Store': ['Store1', 'Store2', 'Store2', 'Store1'],\n    'Sales': [30, 25, 15, 10]\n})\n\ndf_prices = pd.DataFrame({\n    'Product': ['A', 'B', 'C'],\n    'Price': [5.00, 3.00, 7.50]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\nresult = df_sales.merge(df_prices, on='Product') \\\n                  .assign(Total_Revenue=lambda x: x['Sales'] * x['Price']) \\\n                  .groupby(['Store', 'Product'], as_index=False) \\\n                  .agg({'Total_Revenue': 'sum'}) \\\n                  .reset_index() \n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor representing image pixel values with a shape of (batch_size, channels, height, width), where each value is in the range of [0, 255]. I want to normalize each channel of the tensor independently to the range [0, 1]. \n\nThe tensor `images` is of shape (32, 3, 256, 256), where 32 represents the batch size, 3 is the number of channels (e.g., RGB), and 256x256 are the height and width dimensions of the images.\n\nHow can I normalize each channel by subtracting its minimum value and dividing by the range (max - min) for that channel?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.randint(0, 256, (32, 3, 256, 256), dtype=torch.float32)\nnormalized_images = ... # put solution in this variable\n### BEGIN SOLUTION\n<code>",
    "output": "\n<code>\nmin_vals = images.min(dim=(0, 2, 3), keepdim=True)[0]\nmax_vals = images.max(dim=(0, 2, 3), keepdim=True)[0]\nnormalized_images = (images - min_vals) / (max_vals - min_vals)\n</code>"
  },
  {
    "input": "Problem:\n\nI am working with an image dataset represented as a tensor and want to implement a custom data augmentation technique that randomly flips the images horizontally. The images are stored in a tensor `images`, which has a shape of (batch_size, channels, height, width). After determining the random condition for flipping, I want to apply the flip operation on the images.\n\nHere is the code I have so far:\n\n```python\nimport torch\n\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\n\n# Condition for flipping\nflip_condition = torch.rand(images.size(0)) > 0.5\n\n# Apply the flip\naugmented_images = images.clone()\n```\n\nI can't seem to figure out how to apply the flip operation to `augmented_images` based on the `flip_condition`. \n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\nimages = torch.rand(8, 3, 32, 32)  # Example with 8 images, 3 channels, 32x32 pixels\nflip_condition = torch.rand(images.size(0)) > 0.5\naugmented_images = images.clone()\n...\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>",
    "output": "\n<code>\naugmented_images[flip_condition] = torch.flip(images[flip_condition], dims=[3])\n</code>"
  },
  {
    "input": "### Problem:\nYou have a dataset detailing sales transactions over several months. The dataset looks like this:\n\n```python\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\n```\n\nIn the `Sale_Date`, some transactions have missing dates denoted by '0'. Your task is to replace the '0' values in the `Sale_Date` with the average date from the existing sales dates for each product, replacing the '0' values with the average date of their respective `Product_ID`. The average date should be in the format 'YYYY-MM-DD'.\n\nHow would you achieve this in pandas? \n\nPlease fill in the code below to perform the imputation:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'Product_ID': ['P1', 'P1', 'P2', 'P2', 'P3', 'P3', 'P4'],\n    'Sale_Date': ['2023-01-01', '2023-01-15', '2023-01-05', '0', '2023-02-01', '0', '0'],\n    'Quantity_Sold': [100, 150, 200, 0, 300, 0, 0]\n})\nsales_data['Sale_Date'] = pd.to_datetime(sales_data['Sale_Date'].replace('0', pd.NaT)) \n# Your solution to fill in the blanks\nresult = ... # put your solution in this variable\n```\n",
    "output": "\n```python\nresult = sales_data.groupby('Product_ID')['Sale_Date'].transform(lambda x: x.fillna(x.mean()))\n```"
  },
  {
    "input": "Problem:\n\nI am implementing a sequence-to-sequence model using PyTorch for a text translation task. After processing the input sequences, I need to convert the output logits into predictions by applying a softmax function along the specified dimension. My current output tensor has the shape `[batch_size, seq_length, vocab_size]`. How can I apply the softmax function to obtain the predicted token probabilities for each token in the sequence?\n\nHere is my code so far:\n\n```python\nimport torch\n\n# Suppose output is the tensor with your model's logits\noutput = load_data()  # shape: [batch_size, seq_length, vocab_size]\n```\n\npredictions = ... # put solution in this variable\nBEGIN SOLUTION\n```",
    "output": "\n```python\npredictions = torch.softmax(output, dim=-1)  # Apply softmax along the vocab_size dimension\n```"
  },
  {
    "input": "Problem:\nYou have a dataframe that records sales data for a chain of stores, with entries containing missing values in the 'quantity' column. The dataframe is structured as follows:\n\n```python\nsales_data = pd.DataFrame({\n    'store_id': [1, 2, 1, 3, 2, 3, 1],\n    'date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-04'],\n    'quantity': [10, None, 12, None, 8, 7, None]\n})\n```\n\nYour task is to fill the missing values in the 'quantity' column using the following rules:\n1. Use the last available quantity for the same store from earlier dates.\n2. If there are still missing values after applying the forward fill, replace them with the average quantity of that same store.\n\nThe expected output for the filled dataframe should look like this:\n\n```python\n   store_id        date  quantity\n0        1  2023-01-01      10.0\n1        2  2023-01-01       8.0\n2        1  2023-01-02      12.0\n3        3  2023-01-02       7.0\n4        2  2023-01-03      8.0\n5        3  2023-01-03       7.0\n6        1  2023-01-04      12.0\n```\n\nYou can use the function `pd.DataFrame.fillna()` with appropriate parameters to achieve this. Simulate your filling process with the following code line which should be your answer:\n\n```python\nresult = ...\n```",
    "output": "\n```python\nresult = sales_data.groupby('store_id')['quantity'].apply(lambda x: x.ffill().fillna(x.mean())).reset_index()\n```"
  },
  {
    "input": "Problem:\nYou have a DataFrame representing the daily sales of products in a store over a specific period, but some days are missing sales data. The DataFrame looks as follows:\n\n```python\nimport pandas as pd\n\ndata = {\n    'date': ['2023-01-01', '2023-01-02', '2023-01-04', '2023-01-05'],\n    'product': ['A', 'A', 'A', 'A'],\n    'sales': [150, None, 200, None]\n}\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\n```\n\nYou want to fill in the missing `sales` values using forward fill to propagate the last valid observation forward to the next valid one. However, you also want to fill any remaining missing values at the end with the last numeric value observed. Write the code to achieve this.\n\nFill the result in the variable `result`. \n\nA:\n<code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\nresult = df['sales'].fillna(method='ffill').fillna(method='bfill')\n</code>"
  },
  {
    "input": "Problem:\nI have a DataFrame that contains the daily sales data for a store with missing values. The DataFrame looks like this:\n\n```python\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n```\n\nMy goal is to use advanced imputation techniques to fill the missing sales data based on the mean of the available sales for the last three days in the respective 'date' order (backward filling). After filling the missing values, I want the DataFrame to look like this:\n\n```\n        date  sales\n0 2023-01-01  250.0\n1 2023-01-02  250.0\n2 2023-01-03  300.0\n3 2023-01-04  316.67\n4 2023-01-05  400.0\n```\n\nWhat would be an efficient way to achieve this using pandas? I am currently considering using the rolling window function but need help to refine my approach.\n\nA:\n<code>\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'sales': [250, np.nan, 300, np.nan, 400]\n})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>",
    "output": "\n<code>\ndf['sales'] = df['sales'].fillna(df['sales'].rolling(window=3, min_periods=1).mean().shift(1))\nresult = df\n</code>"
  },
  {
    "input": "Problem:\n\nI have a tensor that represents a sequence of time-series data with shape (100, 5), where each row corresponds to a different time point, and each column corresponds to a feature. I want to create a sliding window effect where I extract overlapping segments of this tensor. Specifically, I want to define a window of size 3 that slides over the tensor with a stride of 1.\n\nFor each segment extracted, I want to compute the mean across the feature dimension (columns). The final result should be a tensor with shape (98, 5), where each row represents the mean of the previous 3 rows for each feature.\n\nCan anyone help me formulate the code to achieve this?\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\ndata = load_data()  # Assuming load_data() fetches the (100, 5) tensor\nresult = ...  # Compute the means of the sliding windows here\nBEGIN SOLUTION",
    "output": "\n<code>\nwindow_size = 3\nstride = 1\nnum_windows = data.shape[0] - window_size + 1\nresult = torch.empty((num_windows, data.shape[1]))\n\nfor i in range(num_windows):\n    result[i] = data[i:i + window_size].mean(dim=0)\n</code>"
  },
  {
    "input": "Problem:\nI'm using tensorflow 2.10.0. I want to implement a custom loss function to measure the difference between true labels and predictions for a multi-class classification problem. The loss should consider only a specific class label as relevant (e.g., class label 3) and ignore all other classes. Given the true labels in one hot encoding (e.g., [0, 0, 1, 0, 0]), and the predictions (e.g., [0.1, 0.2, 0.5, 0.1, 0.1]), how can I calculate the mean squared error for only the specified class?\n\nA:\n<code>\nimport tensorflow as tf\n\ntrue_labels = tf.constant([[0, 0, 1, 0, 0], [1, 0, 0, 0, 0]], dtype=tf.float32)\npredictions = tf.constant([[0.1, 0.2, 0.5, 0.1, 0.1], [0.9, 0.05, 0.02, 0.01, 0.02]], dtype=tf.float32)\n\ndef custom_loss(true, pred, class_index=2):\n    # return the custom loss in this function\n    # loss = custom_loss(true, pred)\n    ### BEGIN SOLUTION\n",
    "output": "\n<code>\n    relevant_true = true[:, class_index]\n    relevant_pred = pred[:, class_index]\n    loss = tf.reduce_mean(tf.square(relevant_true - relevant_pred))\n    return loss\n### END SOLUTION\n</code>"
  },
  {
    "input": "Problem:\nI have a sales dataframe that contains missing values for the 'quantity' column, and I would like to impute these missing values based on the mean quantity of each product type in the 'product_type' column. Here is what my dataframe looks like:\n\n```python\nimport pandas as pd\n\nsales_data = pd.DataFrame({\n    'product_id': [101, 102, 103, 101, 102, 103, 104, 105],\n    'product_type': ['A', 'A', 'B', 'A', 'B', 'B', 'A', 'B'],\n    'quantity': [10, None, 15, 5, None, None, 7, 3]\n})\n```\n\nAfter applying the imputation based on the mean quantity of each product type, the resulting dataframe should have the missing values filled appropriately.\n\nHere\u2019s what the data looks like after processing to fill in the missing quantities:\n\n```python\n   product_id product_type  quantity\n0         101            A      10.0\n1         102            A      7.5\n2         103            B      15.0\n3         101            A      5.0\n4         102            B      11.0\n5         103            B      15.0\n6         104            A      7.0\n7         105            B      3.0\n```\n\nCould you provide the code to accomplish this task? Please fill in the necessary part of the code below:\n\n```python\n# Fill in the missing quantity values based on the mean quantity of each product type\nsales_data['quantity'] = sales_data.groupby('product_type')['quantity'].transform(lambda x: x.fillna(x.mean()))\nresult = sales_data\n```",
    "output": "\n```python\nsales_data['quantity'] = sales_data.groupby('product_type')['quantity'].transform(lambda x: x.fillna(x.mean()))\nresult = sales_data\n```"
  }
]